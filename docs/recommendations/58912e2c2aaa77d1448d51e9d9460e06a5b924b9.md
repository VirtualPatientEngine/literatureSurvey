---
hide:
 - navigation
---
<!DOCTYPE html>
#
<html lang="en">
<head>
  <meta charset="utf-8">
</head>

<body>
  <p>
  <i class="footer">This page was last updated on 2024-05-19 10:25:12 UTC</i>
  </p>
  
  <div class="note info" onclick="startIntro()">
    <p>
      <button type="button" class="buttons">
        <div style="display: flex; align-items: center;">
        Click here for a quick intro of the page! <i class="material-icons">help</i>
        </div>
      </button>
    </p>
  </div>

  <p>
  <h3 data-intro='Recommendations for the article'>
    Recommendations for the article <i>VAMPnets for deep learning of molecular kinetics</i>
  </h3>
  <table id="table1" class="display wrap" style="width:100%">
  <thead>
    <tr>
        <th data-intro='Click to view the abstract (if available)'>Abstract</th>
        <th>Title</th>
        <th>Authors</th>
        <th>Publication Date</th>
        <th>Journal/Conference</th>
        <th>Citation count</th>
        <th data-intro='Highest h-index among the authors'>Highest h-index</th>
    </tr>
  </thead>
  <tbody>
    
        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f8a6341496701a0d7fdaa50e6a5aa157236a0ff8" target='_blank'>Author Correction: VAMPnets for deep learning of molecular kinetics</a></td>
          <td>
            Andreas Mardt, Luca Pasquali, Hao Wu, F. Noé
          </td>
          <td>2018-10-22</td>
          <td>Nature Communications</td>
          <td>24</td>
          <td>61</td>
        </tr>
    
        <tr id="Recent advances in computational power and algorithms have enabled molecular dynamics (MD) simulations to reach greater time scales. However, for observing conformational transitions associated with biomolecular processes, MD simulations still have limitations. Several enhanced sampling techniques seek to address this challenge, including the weighted ensemble (WE) method, which samples transitions between metastable states using many weighted trajectories to estimate kinetic rate constants. However, initial sampling of the potential energy surface has a significant impact on the performance of WE, i.e., convergence and efficiency. We therefore introduce deep-learned kinetic modeling approaches that extract statistically relevant information from short MD trajectories to provide a well-sampled initial state distribution for WE simulations. This hybrid approach overcomes any statistical bias to the system, as it runs short unbiased MD trajectories and identifies meaningful metastable states of the system. It is shown to provide a more refined free energy landscape closer to the steady state that could efficiently sample kinetic properties such as rate constants.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c4d9b7166a2ac580c195d72f64489b3f4e0b9c23" target='_blank'>DeepWEST: Deep Learning of Kinetic Models with the Weighted Ensemble Simulation Toolkit for Enhanced Sampling.</a></td>
          <td>
            Anupam Anand Ojha, Saumya Thakur, Surl-Hee Ahn, Rommie E. Amaro
          </td>
          <td>2023-01-31</td>
          <td>Journal of chemical theory and computation</td>
          <td>7</td>
          <td>53</td>
        </tr>
    
        <tr id="Finding a low dimensional representation of data from long-timescale trajectories of biomolecular processes, such as protein folding or ligand-receptor binding, is of fundamental importance, and kinetic models, such as Markov modeling, have proven useful in describing the kinetics of these systems. Recently, an unsupervised machine learning technique called VAMPNet was introduced to learn the low dimensional representation and the linear dynamical model in an end-to-end manner. VAMPNet is based on the variational approach for Markov processes and relies on neural networks to learn the coarse-grained dynamics. In this paper, we combine VAMPNet and graph neural networks to generate an end-to-end framework to efficiently learn high-level dynamics and metastable states from the long-timescale molecular dynamics trajectories. This method bears the advantages of graph representation learning and uses graph message passing operations to generate an embedding for each datapoint, which is used in the VAMPNet to generate a coarse-grained dynamical model. This type of molecular representation results in a higher resolution and a more interpretable Markov model than the standard VAMPNet, enabling a more detailed kinetic study of the biomolecular processes. Our GraphVAMPNet approach is also enhanced with an attention mechanism to find the important residues for classification into different metastable states.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e15c87cfb4d2b1f82076331f9c58085598440e46" target='_blank'>GraphVAMPNet, using graph neural networks and variational approach to markov processes for dynamical modeling of biomolecules</a></td>
          <td>
            Mahdi Ghorbani, Samarjeet Prasad, Jeffery B. Klauda, B. Brooks
          </td>
          <td>2022-01-12</td>
          <td>The Journal of chemical physics</td>
          <td>19</td>
          <td>64</td>
        </tr>
    
        <tr id="Molecular dynamics (MD) simulations have emerged to become the back-bone of today’s computational biophysics. Simulation tools such as, NAMD, AMBER and GROMACS have accumulated more than 100,000 users. Despite this remarkable success, now also bolstered by compatibility with graphics processor units (GPUs) and exascale computers, even the most scalable simulations cannot access biologically relevant timescales - the number of numerical integration steps necessary for solving differential equations in a million-to-billion-dimensional space is computationally in-tractable. Recent advancements in Deep Learning has made it such that patterns can be found in high dimensional data. In addition, Deep Learning have also been used for simulating physical dynamics. Here, we utilize LSTMs in order to predict future molecular dynamics from current and previous timesteps, and examine how this physics-guided learning can benefit researchers in computational biophysics. In particular, we test fully connected Feed-forward Neural Networks, Recurrent Neural Networks with LSTM / GRU memory cells with TensorFlow and PyTorch frame-works trained on data from NAMD simulations to predict conformational transitions on two different biological systems. We find that non-equilibrium MD is easier to train and performance improves under the assumption that each atom is independent of all other atoms in the system. Our study represents a case study for high-dimensional data that switches stochastically between fast and slow regimes. Applications of resolving these sets will allow real-world applications in the interpretation of data from Atomic Force Microscopy experiments.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/86de5fbe09c4381f548e1312d53f15d898c76c78" target='_blank'>Mind reading of the proteins: Deep-learning to forecast molecular dynamics</a></td>
          <td>
            C. Gupta, J. Cava, Daipayan Sarkar, Eric A. Wilson, J. Vant, Steven Murray, A. Singharoy, S. Karmaker
          </td>
          <td>2020-07-29</td>
          <td>bioRxiv</td>
          <td>4</td>
          <td>23</td>
        </tr>
    
        <tr id="The success of enhanced sampling molecular simulations that accelerate along collective variables (CVs) is predicated on the availability of variables coincident with the slow collective motions governing the long-time conformational dynamics of a system. It is challenging to intuit these slow CVs for all but the simplest molecular systems, and their data-driven discovery directly from molecular simulation trajectories has been a central focus of the molecular simulation community to both unveil the important physical mechanisms and drive enhanced sampling. In this work, we introduce state-free reversible VAMPnets (SRV) as a deep learning architecture that learns nonlinear CV approximants to the leading slow eigenfunctions of the spectral decomposition of the transfer operator that evolves equilibrium-scaled probability distributions through time. Orthogonality of the learned CVs is naturally imposed within network training without added regularization. The CVs are inherently explicit and differentiable functions of the input coordinates making them well-suited to use in enhanced sampling calculations. We demonstrate the utility of SRVs in capturing parsimonious nonlinear representations of complex system dynamics in applications to 1D and 2D toy systems where the true eigenfunctions are exactly calculable and to molecular dynamics simulations of alanine dipeptide and the WW domain protein.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2e7163e31e9b32cec11005678bae9e1dbeb6d573" target='_blank'>Nonlinear Discovery of Slow Molecular Modes using Hierarchical Dynamics Encoders</a></td>
          <td>
            , Hythem Sidky, Andrew L. Ferguson
          </td>
          <td>2019-02-09</td>
          <td>The Journal of chemical physics</td>
          <td>74</td>
          <td>35</td>
        </tr>
    
        <tr id="Small integration time steps limit molecular dynamics (MD) simulations to millisecond time scales. Markov state models (MSMs) and equation-free approaches learn low-dimensional kinetic models from MD simulation data by performing configurational or dynamical coarse-graining of the state space. The learned kinetic models enable the efficient generation of dynamical trajectories over vastly longer time scales than are accessible by MD, but the discretization of configurational space and/or absence of a means to reconstruct molecular configurations precludes the generation of continuous atomistic molecular trajectories. We propose latent space simulators (LSS) to learn kinetic models for continuous atomistic simulation trajectories by training three deep learning networks to (i) learn the slow collective variables of the molecular system, (ii) propagate the system dynamics within this slow latent space, and (iii) generatively reconstruct molecular configurations. We demonstrate the approach in an application to Trp-cage miniprotein to produce novel ultra-long synthetic folding trajectories that accurately reproduce atomistic molecular structure, thermodynamics, and kinetics at six orders of magnitude lower cost than MD. The dramatically lower cost of trajectory generation enables greatly improved sampling and greatly reduced statistical uncertainties in estimated thermodynamic averages and kinetic rates.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2d3000d245988a02d3c1060211e9d89c67147b49" target='_blank'>Molecular latent space simulators</a></td>
          <td>
            Hythem Sidky, Wei Chen, Andrew L. Ferguson
          </td>
          <td>2020-07-01</td>
          <td>Chemical Science</td>
          <td>30</td>
          <td>35</td>
        </tr>
    
        <tr id="Machine learning (ML) has emerged as a pervasive tool in science, engineering, and beyond. Its success has also led to several synergies with molecular dynamics (MD) simulations, which we use to identify and characterize the major metastable states of molecular systems. Typically, we aim to determine the relative stabilities of these states and how rapidly they interchange. This information allows mechanistic descriptions of molecular mechanisms, enables a quantitative comparison with experiments, and facilitates their rational design. ML impacts all aspects of MD simulations – from analyzing the data and accelerating sampling to deﬁning more eﬃcient or more accurate simulation models. This chapter focuses on three fundamental problems in MD simulations: accurately parameterizing coarse-grained force ﬁelds, sampling thermodynamically stable states, and analyzing the exchange kinetics between those states. In addition, we outline several state-of-the-art neural network architectures and show how they are combined with physics-motivated learning objectives to solve MD-speciﬁc problems. Finally, we highlight open questions and challenges in the ﬁeld and give some perspective on future developments.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/50c74a10fcddb0e41a5a00b965383fdc52534eec" target='_blank'>Machine Learning in Molecular Dynamics Simulations of Biomolecular Systems</a></td>
          <td>
            Christopher Kolloff, Simon Olsson
          </td>
          <td>2022-05-06</td>
          <td>ArXiv</td>
          <td>2</td>
          <td>4</td>
        </tr>
    
        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/13b52cd927d3daa5c95528b987734d97474e790c" target='_blank'>Markov field models: Scaling molecular kinetics approaches to large molecular machines.</a></td>
          <td>
            Tim Hempel, Simon Olsson, Frank No'e
          </td>
          <td>2022-06-23</td>
          <td>Current opinion in structural biology</td>
          <td>6</td>
          <td>9</td>
        </tr>
    
        <tr id="Rapid computational exploration of the free energy landscape of biological molecules remains an active area of research due to the difficulty of sampling rare state transitions in Molecular Dynamics (MD) simulations. In recent years, an increasing number of studies have exploited Machine Learning (ML) models to enhance and analyze MD simulations. Notably, unsupervised models that extract kinetic information from a set of parallel trajectories have been proposed, including the variational approach for Markov processes (VAMP), VAMPNets, and time-lagged variational autoencoders (TVAE). In this work, we propose a combination of adaptive sampling with active learning of kinetic models to accelerate the discovery of the conformational landscape of biomolecules. In particular, we introduce and compare several techniques that combine kinetic models with two adaptive sampling regimes (least counts and multi-agent reinforcement learning-based adaptive sampling) to enhance the exploration of conformational ensembles without introducing biasing forces. Moreover, inspired by the active learning approach of uncertainty-based sampling, we also present MaxEnt VAMPNet. This technique consists of restarting simulations from the microstates that maximize the Shannon entropy of a VAMPNet trained to perform soft discretization of metastable states. By running simulations on two test systems, the WLALL pentapeptide and the villin headpiece subdomain, we empirically demonstrate that MaxEnt VAMPNet results in faster exploration of conformational landscapes compared to the baseline and other proposed methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8271ca0056e9a3a09b33963054d04b7c14c9ed69" target='_blank'>Active Learning of the Conformational Ensemble of Proteins using Maximum Entropy VAMPNets</a></td>
          <td>
            D. Kleiman, D. Shukla
          </td>
          <td>2023-01-13</td>
          <td>bioRxiv</td>
          <td>10</td>
          <td>7</td>
        </tr>
    
        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/41c0783182ca3e23732b95ddfdb6654cd23a4b45" target='_blank'>Deep learning to decompose macromolecules into independent Markovian domains</a></td>
          <td>
            Andreas Mardt, Tim Hempel, C. Clementi, F. Noé
          </td>
          <td>2022-10-13</td>
          <td>Nature Communications</td>
          <td>13</td>
          <td>61</td>
        </tr>
    
  </tbody>
  <tfoot>
    <tr>
        <th>Abstract</th>
        <th>Title</th>
        <th>Authors</th>
        <th>Publication Date</th>
        <th>Journal/Conference</th>
        <th>Citation count</th>
        <th>Highest h-index</th>
    </tr>
  </tfoot>
  </table>
  </p>

</body>

<script>
var dataTableOptions = {
        initComplete: function () {
        this.api()
            .columns()
            .every(function () {
                let column = this;
 
                // Create select element
                let select = document.createElement('select');
                select.add(new Option(''));
                column.footer().replaceChildren(select);
 
                // Apply listener for user change in value
                select.addEventListener('change', function () {
                    column
                        .search(select.value, {exact: true})
                        .draw();
                });

                // keep the width of the select element same as the column
                select.style.width = '100%';
 
                // Add list of options
                column
                    .data()
                    .unique()
                    .sort()
                    .each(function (d, j) {
                        select.add(new Option(d));
                    });
            });
    },
    scrollX: false,
    scrollCollapse: true,
    paging: true,
    fixedColumns: true,
    columnDefs: [
        {"className": "dt-center", "targets": "_all"},
        // set width for both columns 0 and 1 as 25%
        { width: '5%', targets: 0 },
        { width: '25%', targets: 1 },
        { width: '20%', targets: 2 },
        { width: '10%', targets: 3 },
        { width: '20%', targets: 4 }

      ],
    pageLength: 10,
    layout: {
        topStart: {
            buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
        }
    }
  }
  new DataTable('#table1', dataTableOptions);
  
  var table = $('#table1').DataTable();
  $('#table1 tbody').on('click', 'td:first-child', function () {
    var tr = $(this).closest('tr');
    var row = table.row( tr );

    var rowId = tr.attr('id');
    // alert(rowId);

    if (row.child.isShown()) {
      // This row is already open - close it.
      row.child.hide();
      tr.removeClass('shown');
      tr.find('td:first-child').html('<i class="material-icons">visibility_off</i>');
    } else {
      // Open row.
      // row.child('foo').show();
      var content = '<div class="child-row-content"><strong>Abstract:</strong> ' + rowId + '</div>';
      row.child(content).show();
      tr.addClass('shown');
      tr.find('td:first-child').html('<i class="material-icons">visibility</i>');
    }
  });
</script>
<style>
  .child-row-content {
    text-align: justify;
    text-justify: inter-word;
    word-wrap: break-word; /* Ensure long words are broken */
    white-space: normal; /* Ensure text wraps to the next line */
    max-width: 100%; /* Ensure content does not exceed the table width */
    padding: 10px; /* Optional: add some padding for better readability */
    /* font size */
    font-size: small;
  }
</style>
</html>