<!DOCTYPE html>

<html lang="en">


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../Physics-based%20GNNs/">
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.12">
    
    
<title>Literature Survey (VPE)</title>

    
      <link rel="stylesheet" href="../assets/stylesheets/main.7e359304.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
  <!-- Add scripts that need to run before here -->
  <!-- Add jquery script -->
  <script src="https://code.jquery.com/jquery-3.7.1.js"></script>
  <!-- Add data table libraries -->
  <script src="https://cdn.datatables.net/2.0.1/js/dataTables.js"></script>
  <link rel="stylesheet" href="https://cdn.datatables.net/2.0.1/css/dataTables.dataTables.css">
  <!-- Load plotly.js into the DOM -->
	<script src='https://cdn.plot.ly/plotly-2.29.1.min.js'></script>
  <link rel="stylesheet" href="https://cdn.datatables.net/buttons/3.0.1/css/buttons.dataTables.css">
  <!-- fixedColumns -->
  <script src="https://cdn.datatables.net/fixedcolumns/5.0.0/js/dataTables.fixedColumns.js"></script>
  <script src="https://cdn.datatables.net/fixedcolumns/5.0.0/js/fixedColumns.dataTables.js"></script>
  <link rel="stylesheet" href="https://cdn.datatables.net/fixedcolumns/5.0.0/css/fixedColumns.dataTables.css">
  <!-- Already specified in mkdocs.yml -->
  <!-- <link rel="stylesheet" href="../docs/custom.css"> -->
  <script src="https://cdn.datatables.net/buttons/3.0.1/js/dataTables.buttons.js"></script>
  <script src="https://cdn.datatables.net/buttons/3.0.1/js/buttons.dataTables.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.1/jszip.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdfmake/0.2.7/pdfmake.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdfmake/0.2.7/vfs_fonts.js"></script>
  <script src="https://cdn.datatables.net/buttons/3.0.1/js/buttons.html5.min.js"></script>
  <script src="https://cdn.datatables.net/buttons/3.0.1/js/buttons.print.min.js"></script>
  <!-- Google fonts -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
  <!-- Intro.js -->
  <script src="https://cdn.jsdelivr.net/npm/intro.js@7.2.0/intro.min.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/intro.js@7.2.0/minified/introjs.min.css">


  <!-- 
      
     -->
  <!-- Add scripts that need to run afterwards here -->

    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../custom.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="black">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Literature Survey (VPE)" class="md-header__button md-logo" aria-label="Literature Survey (VPE)" data-md-component="logo">
      
  <img src="../assets/VPE.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Literature Survey (VPE)
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Latent space simulators (VAMP)
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="black"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="white" data-md-color-accent="black"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/VirtualPatientEngine/literatureSurvey" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    VPE/LiteratureSurvey
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href=".." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../Neural%20ODEs/" class="md-tabs__link">
        
  
    
  
  Neural ODEs

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../Physics-based%20GNNs/" class="md-tabs__link">
        
  
    
  
  Physics-based GNNs

      </a>
    </li>
  

      
        
  
  
    
  
  
    <li class="md-tabs__item md-tabs__item--active">
      <a href="./" class="md-tabs__link">
        
  
    
  
  Latent space simulators (VAMP)

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
                
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" hidden>
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Literature Survey (VPE)" class="md-nav__button md-logo" aria-label="Literature Survey (VPE)" data-md-component="logo">
      
  <img src="../assets/VPE.png" alt="logo">

    </a>
    Literature Survey (VPE)
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/VirtualPatientEngine/literatureSurvey" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    VPE/LiteratureSurvey
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Neural%20ODEs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Neural ODEs
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Physics-based%20GNNs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Physics-based GNNs
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Latent space simulators (VAMP)
  </span>
  

      </a>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
                
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>Latent space simulators (VAMP)</h1>

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
</head>

<body>
  <p>
  <i class="footer">This page was last updated on 2024-05-19 13:09:59 UTC</i>
  </p>

  <div class="note info" onclick="startIntro()">
    <p>
      <button type="button" class="buttons">
        <div style="display: flex; align-items: center;">
        Click here for a quick intro of the page! <i class="material-icons">help</i>
        </div>
      </button>
    </p>
  </div>

  <!--
  <div data-intro='Table of contents'>
    <p>
    <h3>Table of Contents</h3>
      <a href="#plot1">1. Citations over time on Latent space simulators (VAMP)</a><br>
      <a href="#manually_curated_articles">2. Manually curated articles on Latent space simulators (VAMP)</a><br>
      <a href="#recommended_articles">3. Recommended articles on Latent space simulators (VAMP)</a><br>
    <p>
  </div>

  <div data-intro='Plot displaying number of citations over time 
                  on the given topic based on recommended articles'>
    <p>
    <h3 id="plot1">1. Citations over time on Latent space simulators (VAMP)</h3>
      <div id='myDiv1'>
      </div>
    </p>
  </div>
  -->

  <div data-intro='Manually curated articles on the given topic'>
    <p>
    <h3 id="manually_curated_articles">Manually curated articles on <i>Latent space simulators (VAMP)</i></h3>
    <table id="table1" class="display" style="width:100%">
    <thead>
      <tr>
          <th data-intro='Click to view the abstract (if available)'>Abstract</th>
          <th>Title</th>
          <th>Authors</th>
          <th>Publication Date</th>
          <th>Journal/ Conference</th>
          <th>Citation count</th>
          <th data-intro='Highest h-index among the authors'>Highest h-index</th>
          <th data-intro='Recommended articles extracted by considering
                          only the given article'>
              View recommendations
              </th>
      </tr>
    </thead>
    <tbody>

        <tr id="Small integration time steps limit molecular dynamics (MD) simulations to millisecond time scales. Markov state models (MSMs) and equation-free approaches learn low-dimensional kinetic models from MD simulation data by performing configurational or dynamical coarse-graining of the state space. The learned kinetic models enable the efficient generation of dynamical trajectories over vastly longer time scales than are accessible by MD, but the discretization of configurational space and/or absence of a means to reconstruct molecular configurations precludes the generation of continuous atomistic molecular trajectories. We propose latent space simulators (LSS) to learn kinetic models for continuous atomistic simulation trajectories by training three deep learning networks to (i) learn the slow collective variables of the molecular system, (ii) propagate the system dynamics within this slow latent space, and (iii) generatively reconstruct molecular configurations. We demonstrate the approach in an application to Trp-cage miniprotein to produce novel ultra-long synthetic folding trajectories that accurately reproduce atomistic molecular structure, thermodynamics, and kinetics at six orders of magnitude lower cost than MD. The dramatically lower cost of trajectory generation enables greatly improved sampling and greatly reduced statistical uncertainties in estimated thermodynamic averages and kinetic rates.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2d3000d245988a02d3c1060211e9d89c67147b49" target='_blank'>
                Molecular latent space simulators
                </a>
              </td>
          <td>
            Hythem Sidky, Wei Chen, Andrew L. Ferguson
          </td>
          <td>2020-07-01</td>
          <td>Chemical Science</td>
          <td>30</td>
          <td>35</td>

            <td><a href='../recommendations/2d3000d245988a02d3c1060211e9d89c67147b49' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Numerical approximation methods for the Koopman operator have advanced considerably in the last few years. In particular, data-driven approaches such as dynamic mode decomposition (DMD)51 and its generalization, the extended-DMD (EDMD), are becoming increasingly popular in practical applications. The EDMD improves upon the classical DMD by the inclusion of a flexible choice of dictionary of observables which spans a finite dimensional subspace on which the Koopman operator can be approximated. This enhances the accuracy of the solution reconstruction and broadens the applicability of the Koopman formalism. Although the convergence of the EDMD has been established, applying the method in practice requires a careful choice of the observables to improve convergence with just a finite number of terms. This is especially difficult for high dimensional and highly nonlinear systems. In this paper, we employ ideas from machine learning to improve upon the EDMD method. We develop an iterative approximation algorithm which couples the EDMD with a trainable dictionary represented by an artificial neural network. Using the Duffing oscillator and the Kuramoto Sivashinsky partical differential equation as examples, we show that our algorithm can effectively and efficiently adapt the trainable dictionary to the problem at hand to achieve good reconstruction accuracy without the need to choose a fixed dictionary a priori. Furthermore, to obtain a given accuracy, we require fewer dictionary terms than EDMD with fixed dictionaries. This alleviates an important shortcoming of the EDMD algorithm and enhances the applicability of the Koopman framework to practical problems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/80744010d90c8ede052c7ac6ba8c38c9de959c6e" target='_blank'>
                Extended dynamic mode decomposition with dictionary learning: A data-driven adaptive spectral decomposition of the Koopman operator.
                </a>
              </td>
          <td>
            Qianxiao Li, Felix Dietrich, E. Bollt, I. Kevrekidis
          </td>
          <td>2017-07-02</td>
          <td>Chaos</td>
          <td>328</td>
          <td>76</td>

            <td><a href='../recommendations/80744010d90c8ede052c7ac6ba8c38c9de959c6e' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Inspired by the success of deep learning techniques in the physical and chemical sciences, we apply a modification of an autoencoder type deep neural network to the task of dimension reduction of molecular dynamics data. We can show that our time-lagged autoencoder reliably finds low-dimensional embeddings for high-dimensional feature spaces which capture the slow dynamics of the underlying stochastic processes-beyond the capabilities of linear dimension reduction techniques.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d8d8e2c04ca47bd628bd2a499e03ad7cd29633da" target='_blank'>
                Time-lagged autoencoders: Deep learning of slow collective variables for molecular kinetics
                </a>
              </td>
          <td>
            C. Wehmeyer, F. Noé
          </td>
          <td>2017-10-30</td>
          <td>The Journal of chemical physics, Journal of Chemical Physics</td>
          <td>327</td>
          <td>61</td>

            <td><a href='../recommendations/d8d8e2c04ca47bd628bd2a499e03ad7cd29633da' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/58912e2c2aaa77d1448d51e9d9460e06a5b924b9" target='_blank'>
                VAMPnets for deep learning of molecular kinetics
                </a>
              </td>
          <td>
            Andreas Mardt, Luca Pasquali, Hao Wu, F. Noé
          </td>
          <td>2017-10-16</td>
          <td>Nature Communications</td>
          <td>452</td>
          <td>61</td>

            <td><a href='../recommendations/58912e2c2aaa77d1448d51e9d9460e06a5b924b9' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="The success of enhanced sampling molecular simulations that accelerate along collective variables (CVs) is predicated on the availability of variables coincident with the slow collective motions governing the long-time conformational dynamics of a system. It is challenging to intuit these slow CVs for all but the simplest molecular systems, and their data-driven discovery directly from molecular simulation trajectories has been a central focus of the molecular simulation community to both unveil the important physical mechanisms and drive enhanced sampling. In this work, we introduce state-free reversible VAMPnets (SRV) as a deep learning architecture that learns nonlinear CV approximants to the leading slow eigenfunctions of the spectral decomposition of the transfer operator that evolves equilibrium-scaled probability distributions through time. Orthogonality of the learned CVs is naturally imposed within network training without added regularization. The CVs are inherently explicit and differentiable functions of the input coordinates making them well-suited to use in enhanced sampling calculations. We demonstrate the utility of SRVs in capturing parsimonious nonlinear representations of complex system dynamics in applications to 1D and 2D toy systems where the true eigenfunctions are exactly calculable and to molecular dynamics simulations of alanine dipeptide and the WW domain protein.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2e7163e31e9b32cec11005678bae9e1dbeb6d573" target='_blank'>
                Nonlinear Discovery of Slow Molecular Modes using Hierarchical Dynamics Encoders
                </a>
              </td>
          <td>
            , Hythem Sidky, Andrew L. Ferguson
          </td>
          <td>2019-02-09</td>
          <td>The Journal of chemical physics, Journal of Chemical Physics</td>
          <td>74</td>
          <td>35</td>

            <td><a href='../recommendations/2e7163e31e9b32cec11005678bae9e1dbeb6d573' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b921efbb226fe2618ec160563a2bcb5999c7c28f" target='_blank'>
                Variational Approach for Learning Markov Processes from Time Series Data
                </a>
              </td>
          <td>
            Hao Wu, Frank No'e
          </td>
          <td>2017-07-14</td>
          <td>Journal of Nonlinear Science</td>
          <td>203</td>
          <td>22</td>

            <td><a href='../recommendations/b921efbb226fe2618ec160563a2bcb5999c7c28f' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

    </tbody>
    <tfoot>
      <tr>
          <th>Abstract</th>
          <th>Title</th>
          <th>Authors</th>
          <th>Publication Date</th>
          <th>Journal/ Conference</th>
          <th>Citation count</th>
          <th>Highest h-index</th>
          <th>View recommendations</th>
      </tr>
    </tfoot>
    </table>
    </p>
  </div>

  <div data-intro='Recommended articles extracted by contrasting
                  articles that are relevant against not relevant for Latent space simulators (VAMP)'>
    <p>
    <h3 id="recommended_articles">Recommended articles on <i>Latent space simulators (VAMP)</i></h3>
    <table id="table2" class="display" style="width:100%">
    <thead>
      <tr>
          <th>Abstract</th>
          <th>Title</th>
          <th>Authors</th>
          <th>Publication Date</th>
          <th>Journal/Conference</th>
          <th>Citation count</th>
          <th>Highest h-index</th>
      </tr>
    </thead>
    <tbody>

        <tr id="Markov state models (MSMs) are valuable for studying dynamics of protein conformational changes via statistical analysis of molecular dynamics (MD) simulations. In MSMs, the complex configuration space is coarse-grained into conformational states, with the dynamics modeled by a series of Markovian transitions among these states at discrete lag times. Constructing the Markovian model at a specific lag time requires state defined without significant internal energy barriers, enabling internal dynamics relaxation within the lag time. This process coarse grains time and space, integrating out rapid motions within metastable states. This work introduces a continuous embedding approach for molecular conformations using the state predictive information bottleneck (SPIB), which unifies dimensionality reduction and state space partitioning via a continuous, machine learned basis set. Without explicit optimization of VAMP-based scores, SPIB demonstrates state-of-the-art performance in identifying slow dynamical processes and constructing predictive multi-resolution Markovian models. When applied to mini-proteins trajectories, SPIB showcases unique advantages compared to competing methods. It automatically adjusts the number of metastable states based on a specified minimal time resolution, eliminating the need for manual tuning. While maintaining efficacy in dynamical properties, SPIB excels in accurately distinguishing metastable states and capturing numerous well-populated macrostates. Furthermore, SPIB's ability to learn a low-dimensional continuous embedding of the underlying MSMs enhances the interpretation of dynamic pathways. Accordingly, we propose SPIB as an easy-to-implement methodology for end-to-end MSM construction.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/cb4d8f8b2b1169d210d289c6b2deac0ccbbc34fe" target='_blank'>
              An Information Bottleneck Approach for Markov Model Construction
              </a>
            </td>
          <td>
            Dedi Wang, Yunrui Qiu, E. Beyerle, Xuhui Huang, P. Tiwary
          </td>
          <td>2024-04-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>30</td>
        </tr>

        <tr id="Abstract A variety of enhanced sampling (ES) methods predict multidimensional free energy landscapes associated with biological and other molecular processes as a function of a few selected collective variables (CVs). The accuracy of these methods is crucially dependent on the ability of the chosen CVs to capture the relevant slow degrees of freedom of the system. For complex processes, finding such CVs is the real challenge. Machine learning (ML) CVs offer, in principle, a solution to handle this problem. However, these methods rely on the availability of high-quality datasets—ideally incorporating information about physical pathways and transition states—which are difficult to access, therefore greatly limiting their domain of application. Here, we demonstrate how these datasets can be generated by means of ES simulations in trajectory space via the metadynamics of paths algorithm. The approach is expected to provide a general and efficient way to generate efficient ML-based CVs for the fast prediction of free energy landscapes in ES simulations. We demonstrate our approach with two numerical examples, a 2D model potential and the isomerization of alanine dipeptide, using deep targeted discriminant analysis as our ML-based CV of choice.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5f33b1a4ac087b5dfa31d80dfd62728ed19d865d" target='_blank'>
              Effective data-driven collective variables for free energy calculations from metadynamics of paths
              </a>
            </td>
          <td>
            Lukas Müllender, Andrea Rizzi, Michele Parrinello, Paolo Carloni, Davide Mandelli
          </td>
          <td>2023-11-09</td>
          <td>PNAS Nexus</td>
          <td>1</td>
          <td>3</td>
        </tr>

        <tr id="Unraveling the relation between structural information and the dynamic properties of supercooled liquids is one of the grand challenges of physics. Dynamic heterogeneity, characterized by the propensity of particles, is often used as a proxy for the dynamic slowing down. In this work, we introduce an unsupervised machine learning approach based on a time-lagged autoencoder (TAE) to elucidate the effect of structural features on the long-time dynamic heterogeneity of supercooled liquids. The TAE uses an autoencoder to reconstruct features at time $t + \Delta t$ from input features at time $t$ for individual particles, and the resulting latent space variables are considered as order parameters. In the Kob-Andersen system, with a $\Delta t$ about a thousand times smaller than the relaxation time, the TAE order parameter exhibits a remarkable correlation with the long-time propensity. We find that radial features on all length-scales are required to capture the long-time dynamics, consistent with recent simulations. This shows that fluctuations of structural features contain sufficient information about the long-time dynamic heterogeneity.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e11ffa44708ce3e7e179e6d23e352c82d921c3f6" target='_blank'>
              Unsupervised machine learning for supercooled liquids
              </a>
            </td>
          <td>
            Yunrui Qiu, Inhyuk Jang, Xuhui Huang, Arun Yethiraj
          </td>
          <td>2024-04-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="An issue for molecular dynamics simulations is that events of interest often involve timescales that are much longer than the simulation time step, which is set by the fastest timescales of the model. Because of this timescale separation, direct simulation of many events is prohibitively computationally costly. This issue can be overcome by aggregating information from many relatively short simulations that sample segments of trajectories involving events of interest. This is the strategy of Markov state models (MSMs) and related approaches, but such methods suffer from approximation error because the variables defining the states generally do not capture the dynamics fully. By contrast, once converged, the weighted ensemble (WE) method aggregates information from trajectory segments so as to yield unbiased estimates of both thermodynamic and kinetic statistics. Unfortunately, errors decay no faster than unbiased simulation in WE. Here we introduce a theoretical framework for describing WE that shows that introduction of an element of stratification, as in nonequilibrium umbrella sampling (NEUS), accelerates convergence. Then, building on ideas from MSMs and related methods, we propose an improved stratification that allows approximation error to be reduced systematically. We show that the improved stratification can decrease simulation times required to achieve a desired precision by orders of magnitude.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/102a6a92a1338f7954afa9c18c73682f987eda36" target='_blank'>
              BAD-NEUS: Rapidly converging trajectory stratification
              </a>
            </td>
          <td>
            J. Strahan, Chatipat Lorpaiboon, J. Weare, Aaron R. Dinner
          </td>
          <td>2024-04-30</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>20</td>
        </tr>

        <tr id="Protein conformational changes play crucial roles in their biological functions. In recent years, the Markov State Model (MSM) constructed from extensive Molecular Dynamics (MD) simulations has emerged as a powerful tool for modeling complex protein conformational changes. In MSMs, dynamics are modeled as a sequence of Markovian transitions among metastable conformational states at discrete time intervals (called lag time). A major challenge for MSMs is that the lag time must be long enough to allow transitions among states to become memoryless (or Markovian). However, this lag time is constrained by the length of individual MD simulations available to track these transitions. To address this challenge, we have recently developed Generalized Master Equation (GME)-based approaches, encoding non-Markovian dynamics using a time-dependent memory kernel. In this Tutorial, we introduce the theory behind two recently developed GME-based non-Markovian dynamic models: the quasi-Markov State Model (qMSM) and the Integrative Generalized Master Equation (IGME). We subsequently outline the procedures for constructing these models and provide a step-by-step tutorial on applying qMSM and IGME to study two peptide systems: alanine dipeptide and villin headpiece. This Tutorial is available at https://github.com/xuhuihuang/GME_tutorials. The protocols detailed in this Tutorial aim to be accessible for non-experts interested in studying the biomolecular dynamics using these non-Markovian dynamic models.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6e6b7ff27cfd2baf49181ef5f4f782328b38f8f0" target='_blank'>
              Tutorial on how to build non-Markovian dynamic models from molecular dynamics simulations for studying protein conformational changes.
              </a>
            </td>
          <td>
            Yue Wu, Siqin Cao, Yunrui Qiu, Xuhui Huang
          </td>
          <td>2024-03-22</td>
          <td>The Journal of chemical physics</td>
          <td>0</td>
          <td>11</td>
        </tr>

        <tr id="The Koopman operator has entered and transformed many research areas over the last years. Although the underlying concept$\unicode{x2013}$representing highly nonlinear dynamical systems by infinite-dimensional linear operators$\unicode{x2013}$has been known for a long time, the availability of large data sets and efficient machine learning algorithms for estimating the Koopman operator from data make this framework extremely powerful and popular. Koopman operator theory allows us to gain insights into the characteristic global properties of a system without requiring detailed mathematical models. We will show how these methods can also be used to analyze complex networks and highlight relationships between Koopman operators and graph Laplacians.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/71e77a5371257de746caf49b4ba2c4de559e5197" target='_blank'>
              Dynamical systems and complex networks: A Koopman operator perspective
              </a>
            </td>
          <td>
            Stefan Klus, Natavsa Djurdjevac Conrad
          </td>
          <td>2024-05-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Proteins are inherently dynamic, and their conformational ensembles are functionally important in biology. Large-scale motions may govern protein structure–function relationship, and numerous transient but stable conformations of intrinsically disordered proteins (IDPs) can play a crucial role in biological function. Investigating conformational ensembles to understand regulations and disease-related aggregations of IDPs is challenging both experimentally and computationally. In this paper first an unsupervised deep learning-based model, termed Internal Coordinate Net (ICoN), is developed that learns the physical principles of conformational changes from molecular dynamics (MD) simulation data. Second, interpolating data points in the learned latent space are selected that rapidly identify novel synthetic conformations with sophisticated and large-scale sidechains and backbone arrangements. Third, with the highly dynamic amyloid-β1-42 (Aβ42) monomer, our deep learning model provided a comprehensive sampling of Aβ42’s conformational landscape. Analysis of these synthetic conformations revealed conformational clusters that can be used to rationalize experimental findings. Additionally, the method can identify novel conformations with important interactions in atomistic details that are not included in the training data. New synthetic conformations showed distinct sidechain rearrangements that are probed by our EPR and amino acid substitution studies. The proposed approach is highly transferable and can be used for any available data for training. The work also demonstrated the ability for deep learning to utilize learned natural atomistic motions in protein conformation sampling.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/717c3a0213e78c2703b40c54abc52ea18730fef1" target='_blank'>
              Sampling Conformational Ensembles of Highly Dynamic Proteins via Generative Deep Learning
              </a>
            </td>
          <td>
            T. Ruzmetov, Ta I Hung, Saisri Padmaja Jonnalagedda, Si-han Chen, Parisa Fasihianifard, Zhefeng Guo, B. Bhanu, Chia-en A. Chang
          </td>
          <td>2024-05-05</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>58</td>
        </tr>

        <tr id="Rare event sampling is a central problem in modern computational chemistry research. Among the existing methods, transition path sampling (TPS) can generate unbiased representations of reaction processes. However, its efficiency depends on the ability to generate reactive trial paths, which in turn depends on the quality of the shooting algorithm used. We propose a new algorithm based on the shooting success rate, i.e. reactivity, measured as a function of a reduced set of collective variables (CVs). These variables are extracted with a machine learning approach directly from TPS simulations, using a multi-task objective function. Iteratively, this workflow significantly improves shooting efficiency without any prior knowledge of the process. In addition, the optimized CVs can be used with biased enhanced sampling methodologies to accurately reconstruct the free energy profiles. We tested the method on three different systems: a two-dimensional toy model, conformational transitions of alanine dipeptide, and hydrolysis of acetyl chloride in bulk water. In the latter, we integrated our workflow with an active learning scheme to learn a reactive machine learning-based potential, which allowed us to study the mechanism and free energy profile with an ab initio-like accuracy.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8aceb5350468de437067e64d53c3e8d82e138711" target='_blank'>
              Combining transition path sampling with data-driven collective variables through a reactivity-biased shooting algorithm
              </a>
            </td>
          <td>
            Jintu Zhang, Odin Zhang, Luigi Bonati, Tingjun Hou
          </td>
          <td>2024-04-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Nonlinear differential equations are encountered as models of fluid flow, spiking neurons, and many other systems of interest in the real world. Common features of these systems are that their behaviors are difficult to describe exactly and invariably unmodeled dynamics present challenges in making precise predictions. In many cases the models exhibit extremely complicated behavior due to bifurcations and chaotic regimes. In this paper, we present a novel data-driven linear estimator that uses Koopman operator theory to extract finite-dimensional representations of complex nonlinear systems. The extracted model is used together with a deep reinforcement learning network that learns the optimal stepwise actions to predict future states of the original nonlinear system. Our estimator is also adaptive to a diffeomorphic transformation of the nonlinear system which enables transfer learning to compute state estimates of the transformed system without relearning from scratch.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/253489dec37ed05e844568d9dae4237b151b936f" target='_blank'>
              Koopman-based Deep Learning for Nonlinear System Estimation
              </a>
            </td>
          <td>
            Zexin Sun, Mingyu Chen, John Baillieul
          </td>
          <td>2024-05-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Understanding protein dynamics is crucial for elucidating their biological functions. While all-atom molecular dynamics (MD) simulations provide detailed information, coarse-grained (CG) MD simulations capture the essential collective motions of proteins at significantly lower computational cost. In this article, we present a unified framework for coarse-grained molecular dynamics simulation of proteins. Our approach utilizes a tree-structured representation of collective variables, enabling reconstruction of protein Cartesian coordinates with high fidelity. The force field is constructed using a deep neural network trained on trajectories generated from conventional all-atom MD simulations. We demonstrate the framework's effectiveness using the 168-amino protein target T1027 from CASP14. Statistical distributions of the collective variables and time series of root mean square deviation (RMSD) obtained from our coarse-grained simulations closely resemble those from all-atom MD simulations. This method is not only useful for studying the movements of complex proteins, but also has the potential to be adapted for simulating other biomolecules like DNA, RNA, and even electrolytes in batteries.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ae88f6b6903c377229e168f9ab759e37c5dbdd8a" target='_blank'>
              A unified framework for coarse grained molecular dynamics of proteins
              </a>
            </td>
          <td>
            Jinzhen Zhu, Jianpeng Ma
          </td>
          <td>2024-03-26</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The folding and unfolding of RNA stem-loops are critical biological processes; however, their computational studies are often hampered by the ruggedness of their folding landscape, necessitating long simulation times at the atomistic scale. Here, we adapted DeepDriveMD (DDMD), an advanced deep learning-driven sampling technique originally developed for protein folding, to address the challenges of RNA stem-loop folding. Although tempering- and order parameter-based techniques are commonly used for similar rare event problems, the computational costs and/or the need for a priori knowledge about the system often present a challenge in their effective use. DDMD overcomes these challenges by adaptively learning from an ensemble of running MD simulations using generic contact maps as the raw input. DeepDriveMD enables on-the-fly learning of a low-dimensional latent representation and guides the simulation toward the undersampled regions while optimizing the resources to explore the relevant parts of the phase space. We showed that DDMD estimates the free energy landscape of the RNA stem-loop reasonably well at room temperature. Our simulation framework runs at a constant temperature without external biasing potential, hence preserving the information of transition rates, with a computational cost much lower than that of the simulations performed with external biasing potentials. We also introduced a reweighting strategy for obtaining unbiased free energy surfaces and presented a qualitative analysis of the latent space. This analysis showed that the latent space captures the relevant slow degrees of freedom for the RNA folding problem of interest. Finally, throughout the manuscript, we outlined how different parameters are selected and optimized to adapt DDMD for this system. We believe this compendium of decision-making processes will help new users adapt this technique for the rare-event sampling problems of their interest.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/fdc1045cb29d704785f50dc3ff2162daaa9a9107" target='_blank'>
              A Deep Learning-Driven Sampling Technique to Explore the Phase Space of an RNA Stem-Loop
              </a>
            </td>
          <td>
            Ayush Gupta, Heng Ma, Arvind Ramanathan, Gül H. Zerze
          </td>
          <td>2024-04-07</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>19</td>
        </tr>

        <tr id="We present a reduction of Milestoning (ReM) algorithm to analyze the high-dimensional Milestoning kinetic network. The algorithm reduces the Milestoning network to low dimensions but preserves essential kinetic information, such as local residence time, exit time, and mean first passage time between any two states. This is achieved in three steps. First, nodes (milestones) in the high-dimensional Milestoning network are grouped into clusters based on the metastability identified by an auxiliary continuous-time Markov chain. Our clustering method is applicable not only to time-reversible networks but also to non-reversible networks generated from practical simulations with statistical fluctuations. Second, a reduced network is established via network transformation, containing only the core sets of clusters as nodes. Finally, transition pathways are analyzed in the reduced network based on the transition path theory. The algorithm is illustrated using a toy model and a solvated alanine dipeptide in two and four dihedral angles.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/016a6cd6ed42ef76aff66623d64bc9dbf67300a0" target='_blank'>
              Kinetic network in Milestoning: Clustering, reduction, and transition path analysis
              </a>
            </td>
          <td>
            Ru Wang, Xiaojun Ji, Hao Wang, Wenjian Liu
          </td>
          <td>2024-04-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Single-molecule experiments provide insight into the motion (conformational dynamics) of individual protein molecules. Usually, a well-defined but coarse-grained intramolecular coordinate is measured and subsequently analysed with the help of Hidden Markov Models (HMMs) to deduce the kinetics of protein conformational changes. Such approaches rely on the assumption that the microscopic dynamics of the protein evolve according to a Markov-jump process on some network. However, the manifestation and extent of memory in the dynamics of the observable strongly depends on the chosen underlying Markov model, which is generally not known and therefore can lead to misinterpretations. Here, we combine extensive single-molecule plasmon ruler experiments on the heat shock protein Hsp90, computer simulations, and theory to infer and quantify memory in a model-free fashion. Our analysis is based on the bare definition of non-Markovian behaviour and does not require any underlying model. In the case of Hsp90 probed by a plasmon ruler, the Markov assumption is found to be clearly and conclusively violated on timescales up to roughly 50 s, which corresponds roughly to $\sim$50% of the inferred correlation time of the signal. The extent of memory is striking and reaches biologically relevant timescales. This implies that memory effects penetrate even the slowest observed motions. We provide clear and reproducible guidelines on how to test for the presence and duration of memory in experimental single-molecule data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c9c2e461a57b7b5e51a547f739174760f2ad7c2e" target='_blank'>
              Model-free inference of memory in conformational dynamics of a multi-domain protein
              </a>
            </td>
          <td>
            L. Vollmar, Rick Bebon, J. Schimpf, Bastian Flietel, Sirin Celiksoy, Carsten Sonnichsen, Aljavz Godec, Thorsten Hugel
          </td>
          <td>2024-04-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="The committor function is a central object for quantifying the transitions between metastable states of dynamical systems. Recently, a number of computational methods based on deep neural networks have been developed for computing the high-dimensional committor function. The success of the methods relies on sampling adequate data for the transition, which still is a challenging task for complex systems at low temperatures. In this work, we propose a deep learning method with two novel adaptive sampling schemes (I and II). In the two schemes, the data are generated actively with a modified potential where the bias potential is constructed from the learned committor function. We theoretically demonstrate the advantages of the sampling schemes and show that the data in sampling scheme II are uniformly distributed along the transition tube. This makes a promising method for studying the transition of complex systems. The efficiency of the method is illustrated in high-dimensional systems including the alanine dipeptide and a solvated dimer system.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ac4d8b8fc34b31692c9f53b60e84fde14728854c" target='_blank'>
              Deep Learning Method for Computing Committor Functions with Adaptive Sampling
              </a>
            </td>
          <td>
            Bo Lin, Weiqing Ren
          </td>
          <td>2024-04-09</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Biomolecules often exhibit complex free energy landscapes in which long-lived metastable states are separated by large energy barriers. Overcoming these barriers to robustly sample transitions between the metastable states with classical molecular dynamics (MD) simulations presents a challenge. To circumvent this issue, collective variable (CV)-based enhanced sampling MD approaches are often employed. Traditional CV selection relies on intuition and prior knowledge of the system. This approach introduces bias, which can lead to incomplete mechanistic insights. Thus, automated CV detection is desired to gain a deeper understanding of the system/process. Analysis of MD data with various machine learning algorithms, such as Principal Component Analysis (PCA), Support Vector Machine (SVM), and Linear Discriminant Analysis (LDA)-based approaches have been implemented for automated CV detection. However, their performance has not been systematically evaluated on structurally and mechanistically complex biological systems. Here, we applied these methods to MD simulations of the MFSD2A (Major Facilitator Superfamily Domain 2A) lysolipid transporter in multiple functionally relevant metastable states with the goal of identifying optimal CVs that would structurally discriminate these states. Specific emphasis was on the automated detection and interpretive power of LDA-based CVs. We found that LDA methods, which included a novel gradient descent-based multiclass harmonic variant, termed GDHLDA, we developed here, outperform PCA in class separation, exhibiting remarkable consistency in extracting CVs critical for distinguishing metastable states. Furthermore, the identified CVs included features previously associated with conformational transitions in MFSD2A. Specifically, conformational shifts in transmembrane helix 7 and in residue Y294 on this helix emerged as critical features discriminating the metastable states in MFSD2A. This highlights the effectiveness of LDA-based approaches in automatically extracting from MD trajectories CVs of functional relevance that can be used to drive biased MD simulations to efficiently sample conformational transitions in the molecular system. STATEMENT OF SIGNIFICANCE To elucidate the biological mechanisms of pertinent biomolecules, it is crucial to understand their complex free energy landscapes. Such landscapes are often constructed from molecular dynamics (MD) simulations using collective variable (CV)-guided enhanced sampling methods. Identifying proper CVs for this task is critical but can be challenging with traditional intuition-based approaches. Here we propose an automated protocol for CV discovery which is based on linear discriminant analysis (LDA) for dimensionality reduction of MD data. By applying the protocol to MD simulations of the MFSD2A lysolipid transporter, a structurally and mechanistically complex biological system, we show that LDA-based methods efficiently detect system-specific CVs that accurately classify different metastable states of MFSD2A and are highly interpretable in a detailed structural context.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/cb020ab58e4021e9d2b0d4b1b34d93066c21e559" target='_blank'>
              Automated Collective Variable Discovery for MFSD2A transporter from molecular dynamics simulations
              </a>
            </td>
          <td>
            Myongin Oh, Margarida Rosa, Hengyi Xie, G. Khelashvili
          </td>
          <td>2024-04-25</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>38</td>
        </tr>

        <tr id="Understanding drug residence times in target proteins is key to improving drug efficacy and understanding target recognition in biochemistry. While drug residence time is just as important as binding affinity, atomiclevel understanding of drug residence times through molecular dynamics (MD) simulations has been difficult primarily due to the extremely long timescales. Recent advances in rare event sampling have allowed us to reach these timescales, yet predicting protein-ligand residence times remains a significant challenge. Here we present a semi-automated protocol to calculate the ligand residence times across 12 orders of magnitudes of timescales. In our proposed framework, we integrate a deep learning-based method, the state predictive information bottleneck (SPIB), to learn an approximate reaction coordinate (RC) and use it to guide the enhanced sampling method metadynamics. We demonstrate the performance of our algorithm by applying it to six different protein-ligand complexes with available benchmark residence times, including the dissociation of the widely studied anti-cancer drug Imatinib (Gleevec) from both wild-type Abl kinase and drug-resistant mutants. We show how our protocol can recover quantitatively accurate residence times, potentially opening avenues for deeper insights into drug development possibilities and ligand recognition mechanisms. TOC Graphic">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/15d9e0ffe0d154c41dd1902b028393745d33c781" target='_blank'>
              Calculating Protein-Ligand Residence Times Through State Predictive Information Bottleneck based Enhanced Sampling
              </a>
            </td>
          <td>
            Suemin Lee, Dedi Wang, Markus A. Seeliger, P. Tiwary
          </td>
          <td>2024-04-20</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>30</td>
        </tr>

        <tr id="The conformational landscape of proteins is crucial to understanding their functionality in complex biological processes. Traditional physics-based computational methods, such as molecular dynamics (MD) simulations, suffer from rare event sampling and long equilibration time problems, hindering their applications in general protein systems. Recently, deep generative modeling techniques, especially diffusion models, have been employed to generate novel protein conformations. However, existing score-based diffusion methods cannot properly incorporate important physical prior knowledge to guide the generation process, causing large deviations in the sampled protein conformations from the equilibrium distribution. In this paper, to overcome these limitations, we propose a force-guided SE(3) diffusion model, ConfDiff, for protein conformation generation. By incorporating a force-guided network with a mixture of data-based score models, ConfDiff can can generate protein conformations with rich diversity while preserving high fidelity. Experiments on a variety of protein conformation prediction tasks, including 12 fast-folding proteins and the Bovine Pancreatic Trypsin Inhibitor (BPTI), demonstrate that our method surpasses the state-of-the-art method.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2516bb58657965236cab56e71a98b9fa7ffc886d" target='_blank'>
              Protein Conformation Generation via Force-Guided SE(3) Diffusion Models
              </a>
            </td>
          <td>
            Yan Wang, Lihao Wang, Yuning Shen, Yiqun Wang, Huizhuo Yuan, Yue Wu, Quanquan Gu
          </td>
          <td>2024-03-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Establishing appropriate mathematical models for complex systems in natural phenomena not only helps deepen our understanding of nature but can also be used for state estimation and prediction. However, the extreme complexity of natural phenomena makes it extremely challenging to develop full-order models (FOMs) and apply them to studying many quantities of interest. In contrast, appropriate reduced-order models (ROMs) are favored due to their high computational efficiency and ability to describe the key dynamics and statistical characteristics of natural phenomena. Taking the viscous Burgers equation as an example, this paper constructs a Convolutional Autoencoder-Reservoir Computing-Normalizing Flow algorithm framework, where the Convolutional Autoencoder is used to construct latent space representations, and the Reservoir Computing-Normalizing Flow framework is used to characterize the evolution of latent state variables. In this way, a data-driven stochastic parameter reduced-order model is constructed to describe the complex system and its dynamic behavior.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f199be4cede75b9048f7e55d590a2a44646f487b" target='_blank'>
              Stochastic parameter reduced-order model based on hybrid machine learning approaches
              </a>
            </td>
          <td>
            Cheng Fang, Jinqiao Duan
          </td>
          <td>2024-03-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="The biochemical materials are described in terms of the opportune Hierarchical Markov-State Model and of the originating chain(s). The time evolution of the equations of motion of the Markov chain is controlled; to this aim, the transitions form the unrestrained simulations and those between the local Markov-State Models are compared. The formalisms of quantum-mechanical systems are applied in the opportune measure spaces. The ergodicity of the Markov chains is controlled. The numerical simulations, the properties to be requested on numerical approximations are studied. As a result, the ergodicity of the Mar">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/75dc1ca34bfaf53962b630a0d2a636c06af53526" target='_blank'>
              Time Evolution of Biochemical Materials: Markov chains and MarkovStates Models
              </a>
            </td>
          <td>
            Orchidea Maria Lecian
          </td>
          <td>2024-06-30</td>
          <td>Journal of Biomedical Sciences and Biotechnology Research</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Several related works have introduced Koopman-based Machine Learning architectures as a surrogate model for dynamical systems. These architectures aim to learn non-linear measurements (also known as observables) of the system's state that evolve by a linear operator and are, therefore, amenable to model-based linear control techniques. So far, mainly simple systems have been targeted, and Koopman architectures as reduced-order models for more complex dynamics have not been fully explored. Hence, we use a Koopman-inspired architecture called the Linear Recurrent Autoencoder Network (LRAN) for learning reduced-order dynamics in convection flows of a Rayleigh B\'enard Convection (RBC) system at different amounts of turbulence. The data is obtained from direct numerical simulations of the RBC system. A traditional fluid dynamics method, the Kernel Dynamic Mode Decomposition (KDMD), is used to compare the LRAN. For both methods, we performed hyperparameter sweeps to identify optimal settings. We used a Normalized Sum of Square Error measure for the quantitative evaluation of the models, and we also studied the model predictions qualitatively. We obtained more accurate predictions with the LRAN than with KDMD in the most turbulent setting. We conjecture that this is due to the LRAN's flexibility in learning complicated observables from data, thereby serving as a viable surrogate model for the main structure of fluid dynamics in turbulent convection settings. In contrast, KDMD was more effective in lower turbulence settings due to the repetitiveness of the convection flow. The feasibility of Koopman-based surrogate models for turbulent fluid flows opens possibilities for efficient model-based control techniques useful in a variety of industrial settings.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b14d40f8f539b3f8e07c3779360a96930d9f97db" target='_blank'>
              Koopman-Based Surrogate Modelling of Turbulent Rayleigh-B\'enard Convection
              </a>
            </td>
          <td>
            Thorben Markmann, Michiel Straat, Barbara Hammer
          </td>
          <td>2024-05-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="Understanding the transition events between metastable states in complex systems is an important subject in the fields of computational physics, chemistry and biology. The transition pathway plays an important role in characterizing the mechanism underlying the transition, for example, in the study of conformational changes of bio-molecules. In fact, computing the transition pathway is a challenging task for complex and high-dimensional systems. In this work, we formulate the path-finding task as a cost minimization problem over a particular path space. The cost function is adapted from the Freidlin-Wentzell action functional so that it is able to deal with rough potential landscapes. The path-finding problem is then solved using a actor-critic method based on the deep deterministic policy gradient algorithm (DDPG). The method incorporates the potential force of the system in the policy for generating episodes and combines physical properties of the system with the learning process for molecular systems. The exploitation and exploration nature of reinforcement learning enables the method to efficiently sample the transition events and compute the globally optimal transition pathway. We illustrate the effectiveness of the proposed method using three benchmark systems including an extended Mueller system and the Lennard-Jones system of seven particles.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a36560f7af41310b7cc14823d1a003cdc7a45da9" target='_blank'>
              Computing Transition Pathways for the Study of Rare Events Using Deep Reinforcement Learning
              </a>
            </td>
          <td>
            Bo Lin, Yangzheng Zhong, Weiqing Ren
          </td>
          <td>2024-04-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Markov processes serve as foundational models in many scientific disciplines, such as molecular dynamics, and their simulation forms a common basis for analysis. While simulations produce useful trajectories, obtaining macroscopic information directly from microstate data presents significant challenges. This paper addresses this gap by introducing the concept of membership functions being the macrostates themselves. We derive equations for the holding times of these macrostates and demonstrate their consistency with the classical definition. Furthermore, we discuss the application of the ISOKANN method for learning these quantities from simulation data. In addition, we present a novel method for extracting transition paths based on the ISOKANN results and demonstrate its efficacy by applying it to simulations of the mu-opioid receptor. With this approach we provide a new perspective on analyzing the macroscopic behaviour of Markov systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2ee817f48bf554c4c3d46ed71751bd57648b2609" target='_blank'>
              Capturing the Macroscopic Behaviour of Molecular Dynamics with Membership Functions
              </a>
            </td>
          <td>
            A. Sikorski, Robert Julian Rabben, Surahit Chewle, Marcus Weber
          </td>
          <td>2024-04-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Computational modeling of assembly is challenging for many systems because their timescales vastly exceed those accessible to simulations. This article describes the MultiMSM, which is a general framework that uses Markov state models (MSMs) to enable simulating self-assembly and self-organization on timescales that are orders of magnitude longer than those accessible to brute force dynamics simulations. In contrast to previous MSM approaches to simulating assembly, the framework describes simultaneous assembly of many clusters and the consequent depletion of free subunits or other small oligomers. The algorithm accounts for changes in transition rates as concentrations of monomers and intermediates evolve over the course of the reaction. Using two model systems, we show that the MultiMSM accurately predicts the concentrations of the full ensemble of intermediates on the long timescales required for reactions to reach equilibrium. Importantly, after constructing a MultiMSM for one system concentration, a wide range of other concentrations can be simulated without any further sampling. This capability allows for orders of magnitude additional speed up. In addition, the method enables highly efficient calculation of quantities such as free energy profiles, nucleation timescales, flux along the ensemble of assembly pathways, and entropy production rates. Identifying contributions of individual transitions to entropy production rates reveals sources of kinetic traps. The method is broadly applicable to systems with equilibrium or nonequilibrium dynamics, and is trivially parallelizable and thus highly scalable.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/194821b30ddd48db5957124832614a4afcafe12f" target='_blank'>
              Markov State Model Approach to Simulate Self-Assembly
              </a>
            </td>
          <td>
            A. Trubiano, Michael F. Hagan
          </td>
          <td>2024-05-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="The Chemical Master Equation (CME) provides a highly accurate, yet extremely resource-intensive representation of a stochastic chemical reaction network and its kinetics due to the exponential scaling of its possible states with the number of reacting species. In this work, we demonstrate how quantum algorithms and hardware can be employed to model stochastic chemical kinetics as described by the CME using the Schl\"ogl Model of a trimolecular reaction network as an illustrative example. To ground our study of the performance of our quantum algorithms, we first determine a range of suitable parameters for constructing the stochastic Schl\"ogl operator in the mono- and bistable regimes of the model using a classical computer and then discuss the appropriateness of our parameter choices for modeling approximate kinetics on a quantum computer. We then apply the Variational Quantum Deflation (VQD) algorithm to evaluate the smallest-magnitude eigenvalues, $\lambda_0$ and $\lambda_1$, which describe the transition rates of both the mono- and bi-stable systems, and the Quantum Phase Estimation (QPE) algorithm combined with the Variational Quantum Singular Value Decomposition (VQSVD) algorithm to estimate the zeromode (ground state) of the bistable case. Our quantum computed results from both noisy and noiseless quantum simulations agree within a few percent with the classically computed eigenvalues and zeromode. Altogether, our work outlines a practical path toward the quantum solution of exponentially complex stochastic chemical kinetics problems and other related stochastic differential equations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/11851277046b744bf80db0aef2312c99454bf00f" target='_blank'>
              Modeling Stochastic Chemical Kinetics on Quantum Computers
              </a>
            </td>
          <td>
            Tilas Kabengele, Yash Lokare, J. B. Marston, Brenda M. Rubenstein
          </td>
          <td>2024-04-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="A method for performing variable-width (thawed) Gaussian wavepacket (GWP) variational dynamics on machine-learned potentials is presented. Instead of fitting the potential energy surface (PES), the anharmonic correction to the global harmonic approximation (GHA) is fitted using kernel ridge regression -- this is a $\Delta$-machine learning approach. The training set consists of energy differences between ab initio electronic energies and values given by the GHA. The learned potential is subsequently used to propagate a single thawed GWP using the time-dependent variational principle to compute the autocorrelation function, which provides direct access to vibronic spectra via its Fourier transform. We applied the developed method to simulate the photoelectron spectrum of ammonia and found excellent agreement between theoretical and experimental spectra. We show that fitting the anharmonic corrections requires a smaller training set as compared to fitting total electronic energies. We also demonstrate that our approach allows to reduce the dimensionality of the nuclear space used to scan the PES when constructing the training set. Thus, only the degrees of freedom associated with large amplitude motions need to be treated with $\Delta$-machine learning, which paves a way for reliable simulations of vibronic spectra of large floppy molecules.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c7974709d04d9f0f3dbb132b6e0a90361f9dd0dd" target='_blank'>
              Thawed Gaussian wavepacket dynamics with $\Delta$-machine learned potentials
              </a>
            </td>
          <td>
            Rami Gherib, I. G. Ryabinkin, Scott N. Genin
          </td>
          <td>2024-04-30</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>24</td>
        </tr>

        <tr id="Simulating large molecular systems over long timescales requires force fields that are both accurate and efficient. In recent years, E(3) equivariant neural networks have lifted the tension between computational efficiency and accuracy of force fields, but they are still several orders of magnitude more expensive than classical molecular mechanics (MM) force fields. Here, we propose a novel machine learning architecture to predict MM parameters from the molecular graph, employing a graph attentional neural network and a transformer with symmetry-preserving positional encoding. The resulting force field, Grappa, outperforms established and other machine-learned MM force fields in terms of accuracy at the same computational efficiency and can be used in existing Molecular Dynamics (MD) engines like GROMACS and OpenMM. It predicts energies and forces of small molecules, peptides, RNA and - showcasing its extensibility to uncharted regions of chemical space - radicals at state-of-the-art MM accuracy. We demonstrate Grappa's transferability to macromolecules in MD simulations, during which large protein are kept stable and small proteins can fold. Our force field sets the stage for biomolecular simulations close to chemical accuracy, but with the same computational cost as established protein force fields.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3db6ec823a29d80d23cb195c8223fc01161fc469" target='_blank'>
              Grappa -- A Machine Learned Molecular Mechanics Force Field
              </a>
            </td>
          <td>
            Leif Seute, Eric Hartmann, Jan Stuhmer, Frauke Grater
          </td>
          <td>2024-03-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Turbulent flows are chaotic and multi-scale dynamical systems, which have large numbers of degrees of freedom. Turbulent flows, however, can be modelled with a smaller number of degrees of freedom when using the appropriate coordinate system, which is the goal of dimensionality reduction via nonlinear autoencoders. Autoencoders are expressive tools, but they are difficult to interpret. The goal of this paper is to propose a method to aid the interpretability of autoencoders. This is the decoder decomposition. First, we propose the decoder decomposition, which is a post-processing method to connect the latent variables to the coherent structures of flows. Second, we apply the decoder decomposition to analyse the latent space of synthetic data of a two-dimensional unsteady wake past a cylinder. We find that the dimension of latent space has a significant impact on the interpretability of autoencoders. We identify the physical and spurious latent variables. Third, we apply the decoder decomposition to the latent space of wind-tunnel experimental data of a three-dimensional turbulent wake past a bluff body. We show that the reconstruction error is a function of both the latent space dimension and the decoder size, which are correlated. Finally, we apply the decoder decomposition to rank and select latent variables based on the coherent structures that they represent. This is useful to filter unwanted or spurious latent variables, or to pinpoint specific coherent structures of interest. The ability to rank and select latent variables will help users design and interpret nonlinear autoencoders.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b0d533f9a79dba8eb27c8b9aeb89ecbe15955407" target='_blank'>
              Decoder Decomposition for the Analysis of the Latent Space of Nonlinear Autoencoders With Wind-Tunnel Experimental Data
              </a>
            </td>
          <td>
            Yaxin Mo, Tullio Traverso, L. Magri
          </td>
          <td>2024-04-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Molecular dynamics (MD) is a crucial technique for simulating biological systems, enabling the exploration of their dynamic nature and fostering an understanding of their functions and properties. To address exploration inefficiency, emerging enhanced sampling approaches like coarse-graining (CG) and generative models have been employed. In this work, we propose a \underline{Frame-to-Frame} generative model with guided \underline{Flow}-matching (F$3$low) for enhanced sampling, which (a) extends the domain of CG modeling to the SE(3) Riemannian manifold; (b) retreating CGMD simulations as autoregressively sampling guided by the former frame via flow-matching models; (c) targets the protein backbone, offering improved insights into secondary structure formation and intricate folding pathways. Compared to previous methods, F$3$low allows for broader exploration of conformational space. The ability to rapidly generate diverse conformations via force-free generative paradigm on SE(3) paves the way toward efficient enhanced sampling methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/20a6548e83fc464931ab8845c0f5e5d41ac6d640" target='_blank'>
              F$^3$low: Frame-to-Frame Coarse-grained Molecular Dynamics with SE(3) Guided Flow Matching
              </a>
            </td>
          <td>
            Shaoning Li, Yusong Wang, Mingyu Li, Jian Zhang, Bin Shao, Nanning Zheng, Jian Tang
          </td>
          <td>2024-05-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="Understanding the mechanisms underlying crystal formation is crucial. For most systems, crystallization typically goes through a nucleation process that involves dynamics that happen at short time and length scales. Due to this, molecular dynamics serves as a powerful tool to study this phenomenon. Existing approaches to study the mechanism often focus analysis on static snapshots of the global configuration, potentially overlooking subtle local fluctuations and history of the atoms involved in the formation of solid nuclei. To address this limitation, we propose a methodology that categorizes nucleation pathways into reactive pathways based on the time evolution of constituent atoms. Our approach effectively captures the diverse structural pathways explored by crystallizing Lennard-Jones-like particles and solidifying Ni$_3$Al, providing a more nuanced understanding of nucleating pathways. Moreover, our methodology enables the prediction of the resulting polymorph from each reactive trajectory. This deep learning-assisted comprehensive analysis offers an alternative view of crystal nucleation mechanisms and pathways.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/734e1f4d145aa409813ced436949cacec2844770" target='_blank'>
              LeaPP: Learning Pathways to Polymorphs through machine learning analysis of atomic trajectories
              </a>
            </td>
          <td>
            Steven W Hall, Porhouy Minh, Sapna Sarupria
          </td>
          <td>2024-05-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>19</td>
        </tr>

        <tr id="Dimensionality reduction often serves as the first step toward a minimalist understanding of physical systems as well as the accelerated simulations of them. In particular, neural network-based nonlinear dimensionality reduction methods, such as autoencoders, have shown promising outcomes in uncovering collective variables (CVs). However, the physical meaning of these CVs remains largely elusive. In this work, we constructed a framework that (1) determines the optimal number of CVs needed to capture the essential molecular motions using an ensemble of hierarchical autoencoders and (2) provides topology-based interpretations to the autoencoder-learned CVs with Morse-Smale complex and sublevelset persistent homology. This approach was exemplified using a series of n-alkanes and can be regarded as a general, explainable nonlinear dimensionality reduction method.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b589f55faeefb8ff1346474b39d4c4818b853722" target='_blank'>
              Interpretation of autoencoder-learned collective variables using Morse-Smale complex and sublevelset persistent homology: An application on molecular trajectories.
              </a>
            </td>
          <td>
            Shao-Chun Lee, Y. Z
          </td>
          <td>2024-04-09</td>
          <td>The Journal of chemical physics</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1446b534858fc3fc6d9406920450b5c3ca87ee13" target='_blank'>
              Predicting equilibrium distributions for molecular systems with deep learning
              </a>
            </td>
          <td>
            Shuxin Zheng, Jiyan He, Chang Liu, Yu Shi, Ziheng Lu, Weitao Feng, Fusong Ju, Jiaxi Wang, Jianwei Zhu, Yaosen Min, He Zhang, Shidi Tang, Hongxia Hao, Peiran Jin, Chi Chen, Frank Noé, Haiguang Liu, Tie-Yan Liu
          </td>
          <td>2024-05-08</td>
          <td>Nature Machine Intelligence</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="We propose a variational modelling method with differentiable temperature for canonical ensembles. Using a deep generative model, the free energy is estimated and minimized simultaneously in a continuous temperature range. At optimal, this generative model is a Boltzmann distribution with temperature dependence. The training process requires no dataset, and works with arbitrary explicit density generative models. We applied our method to study the phase transitions (PT) in the Ising and XY models, and showed that the direct-sampling simulation of our model is as accurate as the Markov Chain Monte Carlo (MCMC) simulation, but more efficient. Moreover, our method can give thermodynamic quantities as differentiable functions of temperature akin to an analytical solution. The free energy aligns closely with the exact one to the second-order derivative, so this inclusion of temperature dependence enables the otherwise biased variational model to capture the subtle thermal effects at the PTs. These findings shed light on the direct simulation of physical systems using deep generative models">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2467636b43371b223890a52934a03783d014d9a3" target='_blank'>
              Deep generative modelling of canonical ensemble with differentiable thermal properties
              </a>
            </td>
          <td>
            Shuo-Hui Li, Yao-Wen Zhang, Ding Pan
          </td>
          <td>2024-04-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Stochastic reaction networks are widely used in the modeling of stochastic systems across diverse domains such as biology, chemistry, physics, and ecology. However, the comprehension of the dynamic behaviors inherent in stochastic reaction networks is a formidable undertaking, primarily due to the exponential growth in the number of possible states or trajectories as the state space dimension increases. In this study, we introduce a knowledge distillation method based on reinforcement learning principles, aimed at compressing the dynamical knowledge encoded in stochastic reaction networks into a singular neural network construct. The trained neural network possesses the capability to accurately predict the state conditional joint probability distribution that corresponds to the given query contexts, when prompted with rate parameters, initial conditions, and time values. This obviates the need to track the dynamical process, enabling the direct estimation of normalized state and trajectory probabilities, without necessitating the integration over the complete state space. By applying our method to representative examples, we have observed a high degree of accuracy in both multimodal and high-dimensional systems. Additionally, the trained neural network can serve as a foundational model for developing efficient algorithms for parameter inference and trajectory ensemble generation. These results collectively underscore the efficacy of our approach as a universal means of distilling knowledge from stochastic reaction networks. Importantly, our methodology also spotlights the potential utility in harnessing a singular, pretrained, large-scale model to encapsulate the solution space underpinning a wide spectrum of stochastic dynamical systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9ceacaafe31a2cf6dd9a5da06470e4a7369110d8" target='_blank'>
              Distilling dynamical knowledge from stochastic reaction networks.
              </a>
            </td>
          <td>
            Chuanbo Liu, Jin Wang
          </td>
          <td>2024-03-26</td>
          <td>Proceedings of the National Academy of Sciences of the United States of America</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Extracting the relationship between high-dimensional recordings of neural activity and complex behav- ior is a ubiquitous problem in systems neuroscience. Toward this goal, encoding and decoding models attempt to infer the conditional distribution of neural activity given behavior and vice versa, while dimensionality reduc- tion techniques aim to extract interpretable low-dimensional representations. Variational autoencoders (VAEs) are flexible deep-learning models commonly used to infer low-dimensional embeddings of neural or behavioral data. However, it is challenging for VAEs to accurately model arbitrary conditional distributions, such as those encountered in neural encoding and decoding, and even more so simultaneously. Here, we present a VAE-based approach for accurately calculating such conditional distributions. We validate our approach on a task with known ground truth and demonstrate the applicability to high-dimensional behavioral time series by retrieving the condi- tional distributions over masked body parts of walking flies. Finally, we probabilistically decode motor trajectories from neural population activity in a monkey reach task and query the same VAE for the encoding distribution of neural activity given behavior. Our approach provides a unifying perspective on joint dimensionality reduction and learning conditional distributions of neural and behavioral data, which will allow for scaling common analyses in neuroscience to today’s high-dimensional multi-modal datasets.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/886c182b91d610f962caae71a25071b4ed3a8096" target='_blank'>
              Modeling conditional distributions of neural and behavioral data with masked variational autoencoders
              </a>
            </td>
          <td>
            Auguste Schulz, Julius Vetter, Richard Gao, Daniel Morales, Víctor Lobato-Ríos, Pavan Ramdya, Pedro J. Gonçalves, J. H. Macke
          </td>
          <td>2024-04-25</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>19</td>
        </tr>

        <tr id="The discovery of linear embedding is the key to the synthesis of linear control techniques for nonlinear systems. In recent years, while Koopman operator theory has become a prominent approach for learning these linear embeddings through data-driven methods, these algorithms often exhibit limitations in generalizability beyond the distribution captured by training data and are not robust to changes in the nominal system dynamics induced by intrinsic or environmental factors. To overcome these limitations, this study presents an adaptive Koopman architecture capable of responding to the changes in system dynamics online. The proposed framework initially employs an autoencoder-based neural network that utilizes input-output information from the nominal system to learn the corresponding Koopman embedding offline. Subsequently, we augment this nominal Koopman architecture with a feed-forward neural network that learns to modify the nominal dynamics in response to any deviation between the predicted and observed lifted states, leading to improved generalization and robustness to a wide range of uncertainties and disturbances compared to contemporary methods. Extensive tracking control simulations, which are undertaken by integrating the proposed scheme within a Model Predictive Control framework, are used to highlight its robustness against measurement noise, disturbances, and parametric variations in system dynamics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/302db61f58f8a2e62340fcfaacbceec2620e551a" target='_blank'>
              Adaptive Koopman Embedding for Robust Control of Complex Dynamical Systems
              </a>
            </td>
          <td>
            Rajpal Singh, Chandan Kumar Sah, J. Keshavan
          </td>
          <td>2024-05-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="We propose a self-supervised approach for learning physics-based subspaces for real-time simulation. Existing learning-based methods construct subspaces by approximating pre-defined simulation data in a purely geometric way. However, this approach tends to produce high-energy configurations, leads to entangled latent space dimensions, and generalizes poorly beyond the training set. To overcome these limitations, we propose a self-supervised approach that directly minimizes the system's mechanical energy during training. We show that our method leads to learned subspaces that reflect physical equilibrium constraints, resolve overfitting issues of previous methods, and offer interpretable latent space parameters.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8af663bff69f1f9808eaf47048759e64491d65cf" target='_blank'>
              Neural Modes: Self-supervised Learning of Nonlinear Modal Subspaces
              </a>
            </td>
          <td>
            Jiahong Wang, Yinwei Du, Stelian Coros, Bernhard Thomaszewski
          </td>
          <td>2024-04-26</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Molecular relaxation, finding the equilibrium state of a non-equilibrium structure, is an essential component of computational chemistry to understand reactivity. Classical force field methods often rely on insufficient local energy minimization, while neural network force field models require large labeled datasets encompassing both equilibrium and non-equilibrium structures. As a remedy, we propose MoreRed, molecular relaxation by reverse diffusion, a conceptually novel and purely statistical approach where non-equilibrium structures are treated as noisy instances of their corresponding equilibrium states. To enable the denoising of arbitrarily noisy inputs via a generative diffusion model, we further introduce a novel diffusion time step predictor. Notably, MoreRed learns a simpler pseudo potential energy surface instead of the complex physical potential energy surface. It is trained on a significantly smaller, and thus computationally cheaper, dataset consisting of solely unlabeled equilibrium structures, avoiding the computation of non-equilibrium structures altogether. We compare MoreRed to classical force fields, equivariant neural network force fields trained on a large dataset of equilibrium and non-equilibrium data, as well as a semi-empirical tight-binding model. To assess this quantitatively, we evaluate the root-mean-square deviation between the found equilibrium structures and the reference equilibrium structures as well as their DFT energies.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/402717ce4e4339fd5b1e97c2cd9d41c5273f01d7" target='_blank'>
              Molecular relaxation by reverse diffusion with time step prediction
              </a>
            </td>
          <td>
            Khaled Kahouli, Stefaan S. P. Hessmann, Klaus-Robert Muller, Shinichi Nakajima, Stefan Gugler, Niklas Wolf Andreas Gebauer
          </td>
          <td>2024-04-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Normalizing flows can transform a simple prior probability distribution into a more complex target distribution. Here, we evaluate the ability and efficiency of generative machine learning methods to sample the Boltzmann distribution of an atomistic model for glass-forming liquids. This is a notoriously difficult task, as it amounts to ergodically exploring the complex free energy landscape of a disordered and frustrated many-body system. We optimize a normalizing flow model to successfully transform high-temperature configurations of a dense liquid into low-temperature ones, near the glass transition. We perform a detailed comparative analysis with established enhanced sampling techniques developed in the physics literature to assess and rank the performance of normalizing flows against state-of-the-art algorithms. We demonstrate that machine learning methods are very promising, showing a large speedup over conventional molecular dynamics. Normalizing flows show performances comparable to parallel tempering and population annealing, while still falling far behind the swap Monte Carlo algorithm. Our study highlights the potential of generative machine learning models in scientific computing for complex systems, but also points to some of its current limitations and the need for further improvement.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8c0ef1d2cfb556d248a121e0fd07ed92b64d97ed" target='_blank'>
              Normalizing flows as an enhanced sampling method for atomistic supercooled liquids
              </a>
            </td>
          <td>
            Gerhard Jung, G. Biroli, Ludovic Berthier
          </td>
          <td>2024-04-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>57</td>
        </tr>

        <tr id="The efficiency of atomic simulations of materials and molecules can rapidly deteriorate when large free energy barriers exist between local minima. We propose smooth basin classification, a universal method to define reaction coordinates based on the internal feature representation of a graph neural network. We achieve high data efficiency by exploiting their built-in symmetry and adopting a transfer learning strategy. We benchmark our approach on challenging chemical and physical transformations, and show that it matches and even outperforms reaction coordinates defined based on human intuition.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bcbfd3311c4e222d8ca4331f8551b23b6df0edb2" target='_blank'>
              Free Energy Calculations using Smooth Basin Classification
              </a>
            </td>
          <td>
            S. Vandenhaute, Tom Braeckevelt, Pieter Dobbelaere, M. Bocus, V. Speybroeck
          </td>
          <td>2024-04-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>54</td>
        </tr>

        <tr id="Recent innovations from machine learning allow for data unfolding, without binning and including correlations across many dimensions. We describe a set of known, upgraded, and new methods for ML-based unfolding. The performance of these approaches are evaluated on the same two datasets. We find that all techniques are capable of accurately reproducing the particle-level spectra across complex observables. Given that these approaches are conceptually diverse, they offer an exciting toolkit for a new class of measurements that can probe the Standard Model with an unprecedented level of detail and may enable sensitivity to new phenomena.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b84b094597bdaa8ac3a29bd0c0574ba6585551ba" target='_blank'>
              The Landscape of Unfolding with Machine Learning
              </a>
            </td>
          <td>
            Nathan Huetsch, Javier Marino Villadamigo, Alexander Shmakov, S. Diefenbacher, Vinicius Mikuni, Theo Heimel, M. Fenton, Kevin Greif, Benjamin Nachman, D. Whiteson, A. Butter, Tilman Plehn
          </td>
          <td>2024-04-29</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>20</td>
        </tr>

        <tr id="Physics-based, atom-centered machine learning (ML) representations have been instrumental to the effective integration of ML within the atomistic simulation community. Many of these representations build off the idea of atoms as having spherical, or isotropic, interactions. In many communities, there is often a need to represent groups of atoms, either to increase the computational efficiency of simulation via coarse-graining or to understand molecular influences on system behavior. In such cases, atom-centered representations will have limited utility, as groups of atoms may not be well-approximated as spheres. In this work, we extend the popular Smooth Overlap of Atomic Positions (SOAP) ML representation for systems consisting of non-spherical anisotropic particles or clusters of atoms. We show the power of this anisotropic extension of SOAP, which we deem \AniSOAP, in accurately characterizing liquid crystal systems and predicting the energetics of Gay-Berne ellipsoids and coarse-grained benzene crystals. With our study of these prototypical anisotropic systems, we derive fundamental insights into how molecular shape influences mesoscale behavior and explain how to reincorporate important atom-atom interactions typically not captured by coarse-grained models. Moving forward, we propose \AniSOAP as a flexible, unified framework for coarse-graining in complex, multiscale simulation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/09d199ec29809c40a348ca95f45d37bbf109e58d" target='_blank'>
              Expanding Density-Correlation Machine Learning Representations for Anisotropic Coarse-Grained Particles
              </a>
            </td>
          <td>
            Arthur Y. Lin, Kevin K. Huguenin-Dumittan, Yong-Cheol Cho, Jigyasa Nigam, Rose K. Cersonsky
          </td>
          <td>2024-03-27</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Representation learning for the electronic structure problem is a major challenge of machine learning in computational condensed matter and materials physics. Within quantum mechanical first principles approaches, Kohn-Sham density functional theory (DFT) is the preeminent tool for understanding electronic structure, and the high-dimensional wavefunctions calculated in this approach serve as the building block for downstream calculations of correlated many-body excitations and related physical observables. Here, we use variational autoencoders (VAE) for the unsupervised learning of high-dimensional DFT wavefunctions and show that these wavefunctions lie in a low-dimensional manifold within the latent space. Our model autonomously determines the optimal representation of the electronic structure, avoiding limitations due to manual feature engineering and selection in prior work. To demonstrate the utility of the latent space representation of the DFT wavefunction, we use it for the supervised training of neural networks (NN) for downstream prediction of the quasiparticle bandstructures within the GW formalism, which includes many-electron correlations beyond DFT. The GW prediction achieves a low error of 0.11 eV for a combined test set of metals and semiconductors drawn from the Computational 2D Materials Database (C2DB), suggesting that latent space representation captures key physical information from the original data. Finally, we explore the interpretability of the VAE representation and show that the successful representation learning and downstream prediction by our model is derived from the smoothness of the VAE latent space, which also enables the generation of wavefunctions on arbitrary points in latent space. Our work provides a novel and general machine-learning framework for investigating electronic structure and many-body physics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9db6d6b2521a0d5948c53b20a8da887829b4ab0d" target='_blank'>
              Unsupervised Learning of Individual Kohn-Sham States: Interpretable Representations and Consequences for Downstream Predictions of Many-Body Effects
              </a>
            </td>
          <td>
            Bowen Hou, Jinyuan Wu, Diana Y Qiu
          </td>
          <td>2024-04-22</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Conformational heterogeneity of biological macromolecules is a challenge in single particle averaging (SPA). Current standard practice is to employ classification and filtering methods which may allow a discrete number of conformational states to be reconstructed. However, the conformation space accessible to these molecules is continuous and therefore explored incompletely by a small number of discrete classes. Recently developed heterogeneous reconstruction algorithms (HRAs) to analyse continuous heterogeneity rely on machine learning methods employing low-dimensional latent space representations. The non-linear nature of many of these methods pose challenges to their validation and interpretation, and to identifying functionally relevant conformational trajectories. We believe these methods would benefit from in-depth benchmarking using high quality synthetic data and concomitant ground truth information. Here we present a framework for the simulation and subsequent analysis with respect to ground-truth of cryo-EM micrographs containing conformationally heterogeneous particles whose conformational heterogeneity is sourced from molecular dynamics (MD) simulations. This synthetic data can then be processed as if it were experimental data allowing aspects of standard SPA workflows, as well as heterogeneous reconstruction methods, to be compared with known groundtruth using available utilities. We will demonstrate the simulation and analysis of several such datasets and present an initial investigation into HRAs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/53ef8860013b9ba40055efe37649d3dd7073094f" target='_blank'>
              Roodmus: A toolkit for benchmarking heterogeneous electron cryo-microscopy reconstructions
              </a>
            </td>
          <td>
            Maarten Joosten, Joel Greer, James Parkhurst, T. Burnley, A. Jakobi
          </td>
          <td>2024-04-30</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>18</td>
        </tr>

        <tr id="Finding low-dimensional interpretable models of complex physical fields such as turbulence remains an open question, 80 years after the pioneer work of Kolmogorov. Estimating high-dimensional probability distributions from data samples suffers from an optimization and an approximation curse of dimensionality. It may be avoided by following a hierarchic probability flow from coarse to fine scales. This inverse renormalization group is defined by conditional probabilities across scales, renormalized in a wavelet basis. For a $\varphi^4$ scalar potential, sampling these hierarchic models avoids the critical slowing down at the phase transition. An outstanding issue is to also approximate non-Gaussian fields having long-range interactions in space and across scales. We introduce low-dimensional models with robust multiscale approximations of high order polynomial energies. They are calculated with a second wavelet transform, which defines interactions over two hierarchies of scales. We estimate and sample these wavelet scattering models to generate 2D vorticity fields of turbulence, and images of dark matter densities.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d65e2612cc3968688394a7660934b8780d0f7e26" target='_blank'>
              Hierarchic Flows to Estimate and Sample High-dimensional Probabilities
              </a>
            </td>
          <td>
            Etienne Lempereur, Stéphane Mallat
          </td>
          <td>2024-05-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Balancing accuracy and efficiency is a common problem in molecular simulation. This tradeoff is evident in coarse-grained molecular dynamics simulation, which prioritizes efficiency, and all-atom molecular simulation, which prioritizes accuracy. Despite continuous efforts, creating a coarse-grained model that accurately captures both the system's structure and dynamics remains elusive. In this article, we present a data-driven approach for constructing coarse-grained models that aim to describe both the structure and dynamics of the system equally well. While the development of machine learning models is well-received in the scientific community, the significance of dataset creation for these models is often overlooked. However, data-driven approaches cannot progress without a robust dataset. To address this, we construct a database of synthetic coarse-grained potentials generated from unphysical all-atom models. A neural network is trained with the generated database to predict the coarse-grained potentials of real liquids. We evaluate their quality by calculating the combined loss of structural and dynamical accuracy upon coarse-graining. When we compare our machine learning-based coarse-grained potential with the one from iterative Boltzmann inversion, the machine learning prediction turns out better for all eight hydrocarbon liquids we studied. As all-atom surfaces turn more nonspherical, both ways of coarse-graining degrade. Still, the neural network outperforms iterative Boltzmann inversion in constructing good quality coarse-grained models for such cases. The synthetic database and the developed machine learning models are freely available to the community, and we believe that our approach will generate interest in efficiently deriving accurate coarse-grained models for liquids.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f150b0dd190b041bbf23edab970f507000eac410" target='_blank'>
              Synthetic Force-Field Database for Training Machine Learning Models to Predict Mobility-Preserving Coarse-Grained Molecular-Simulation Potentials.
              </a>
            </td>
          <td>
            Saientan Bag, Melissa K. Meinel, F. Müller-Plathe
          </td>
          <td>2024-04-09</td>
          <td>Journal of chemical theory and computation</td>
          <td>0</td>
          <td>59</td>
        </tr>

        <tr id="Intrinsically disordered proteins (IDPs) play pivotal roles in various biological functions and are closely linked to many human diseases including cancer. Structural investigations of IDPs typically involve a combination of molecular dynamics (MD) simulations and experimental data to correct for intrinsic biases in simulation methods. However, these simulations are hindered by their high computational cost and a scarcity of experimental data, severely limiting their applicability. Despite the recent advancements in structure prediction for structured proteins, understanding the conformational properties of IDPs remains challenging partly due to the poor conservation of disordered protein sequences and limited experimental characterization. Here, we introduced IDPFold, a method capable of predicting IDP conformation ensembles directly from their sequences using fine-tuned diffusion models. IDPFold bypasses the need for Multiple Sequence Alignments (MSA) or experimental data, achieving accurate predictions of ensemble properties across numerous IDPs. By sampling conformations at the backbone level, IDPFold provides more detailed structural features and more precise property estimation compared to the state-of-the-art methods, and will help to reveal the disorder-function paradigm of IDPs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/33589d0ef27a61dbaf271c2d89bb409ecbb470fc" target='_blank'>
              Precise Generation of Conformational Ensembles for Intrinsically Disordered Proteins Using Fine-tuned Diffusion Models
              </a>
            </td>
          <td>
            Junjie Zhu, Zhengxin Li, Bo Zhang, Zhuoqi Zheng, Bozitao Zhong, Jie Bai, Taifeng Wang, Ting Wei, Jianyi Yang, Hai-Feng Chen
          </td>
          <td>2024-05-07</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Quantum Monte Carlo (QMC) is a powerful method to calculate accurate energies and forces for molecular systems. In this work, we demonstrate how we can obtain accurate QMC forces for the fluxional ethanol molecule at room temperature by using either multi-determinant Jastrow-Slater wave functions in variational Monte Carlo or just a single determinant in diffusion Monte Carlo. The excellent performance of our protocols is assessed against high-level coupled cluster calculations on a diverse set of representative configurations of the system. Finally, we train machine-learning force fields on the QMC forces and compare them to models trained on coupled cluster reference data, showing that a force field based on the diffusion Monte Carlo forces with a single determinant can faithfully reproduce coupled cluster power spectra in molecular dynamics simulations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e910928f42db65bafb60e77ef48451cf71e74a0f" target='_blank'>
              Accurate quantum Monte Carlo forces for machine-learned force fields: Ethanol as a benchmark
              </a>
            </td>
          <td>
            Emiel Slootman, I. Poltavsky, Ravindra Shinde, Jacopo Cocomello, Saverio Moroni, Alexandre Tkatchenko, Claudia Filippi
          </td>
          <td>2024-04-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>13</td>
        </tr>

        <tr id="Identifying local structural motifs and packing patterns of molecular solids is a challenging task for both simulation and experiment. We demonstrate two novel approaches to characterize local environments in different polymorphs of molecular crystals using learning models that employ either flexibly learned or handcrafted molecular representations. In the first case, we follow our earlier work on graph learning in molecular crystals, deploying an atomistic graph convolutional network, combined with molecule-wise aggregation, to enable per-molecule environmental classification. For the second model, we develop a new set of descriptors based on symmetry functions combined with a point-vector representation of the molecules, encoding information about the positions as well as relative orientations of the molecule. We demonstrate very high classification accuracy for both approaches on urea and nicotinamide crystal polymorphs, and practical applications to the analysis of dynamical trajectory data for nanocrystals and solid-solid interfaces. Both architectures are applicable to a wide range of molecules and diverse topologies, providing an essential step in the exploration of complex condensed matter phenomena.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2276bec0e2d22faea0f4bfff38e5b8f13f591979" target='_blank'>
              Machine learning classification of local environments in molecular crystals
              </a>
            </td>
          <td>
            Daisuke Kuroshima, Michael Kilgour, M. Tuckerman, J. Rogal
          </td>
          <td>2024-03-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>70</td>
        </tr>

        <tr id="Nonsense correlations frequently develop between independent random variables that evolve with time. Therefore, it is not surprising that they appear between the components of vectors carrying out multidimensional random walks, such as those describing the trajectories of biomolecules in molecular dynamics simulations. The existence of these correlations does not imply in itself a problem. Still, it can present a problem when the trajectories are analyzed with an algorithm such as the Principal Component Analysis (PCA) because it seeks to maximize correlations without discriminating whether they have physical origin or not. In this Article, we employ random walks occurring on multidimensional harmonic potentials to evaluate the influence of fortuitous correlations in PCA. We demonstrate that, because of them, this algorithm affords misleading results when applied to a single trajectory. The errors do not only affect the directions of the first eigenvectors and their eigenvalues, but the very definition of the molecule’s “essential space” may be wrong. Additionally, the main principal component’s probability distributions present artificial structures which do not correspond with the shape of the potential energy surface. Finally, we show that the PCA of two realistic protein models, human serum albumin and lysozyme, behave similarly to the simple harmonic models. In all cases, the problems can be mitigated and eventually eliminated by doing PCA on concatenated trajectories formed from a large enough number of individual simulations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ccf5ef52381aa82f91efb91c8c43031ff16e58d6" target='_blank'>
              Fortuitous Correlations in Molecular Dynamics Simulations: Their Harmful Influence on the Probability Distributions of the Main Principal Components
              </a>
            </td>
          <td>
            Juliana Palma, Gustavo Pierdominici-Sottile
          </td>
          <td>2024-04-23</td>
          <td>ACS Omega</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id="Conformational dynamics play a crucial role in determining the behavior of the biomolecules. Polarizable force fields, such as AMOEBA, can accurately capture electrostatic interactions underlying the conformational space. However, applying a polarizable force field in molecular dynamics (MD) simulations can be computationally expensive, especially in studying long-time-scale dynamics. To overcome this challenge, we incorporated the AMOEBA potential with Milestoning, an enhanced sampling method in this work. This integration allows us to efficiently sample the rare and important conformational states of a biomolecule by using many short and independent molecular dynamics trajectories with the AMOEBA force field. We applied this method to investigate the conformational dynamics of alanine dipeptide, DNA, and RNA A-B form conversion. Well-converged thermodynamic and kinetic properties were obtained, including the free energy difference, mean first passage time, and critical transitions between states. Our results demonstrate the power of integrating polarizable force fields with enhanced sampling methods in quantifying the thermodynamic and kinetic properties of biomolecules at the atomic level.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e4deb51b002195eef777acae8e398de834c6e679" target='_blank'>
              Exploring Biomolecular Conformational Dynamics with Polarizable Force Field AMOEBA and Enhanced Sampling Method Milestoning.
              </a>
            </td>
          <td>
            , Chengwen Liu, Pengyu Ren
          </td>
          <td>2024-05-14</td>
          <td>Journal of chemical theory and computation</td>
          <td>0</td>
          <td>13</td>
        </tr>

        <tr id="Fluid dynamics problems are characterized by being multidimensional and nonlinear, causing the experiments and numerical simulations being complex, time-consuming and monetarily expensive. In this sense, there is a need to find new ways to obtain data in a more economical manner. Thus, in this work we study the application of time series forecasting to fluid dynamics problems, where the aim is to predict the flow dynamics using only past information. We focus our study on models based on deep learning that do not require a high amount of data for training, as this is the problem we are trying to address. Specifically in this work we have tested three autoregressive models where two of them are fully based on deep learning and the other one is a hybrid model that combines modal decomposition with deep learning. We ask these models to generate $200$ time-ahead predictions of two datasets coming from a numerical simulation and experimental measurements, where the latter is characterized by being turbulent. We show how the hybrid model generates more reliable predictions in the experimental case, as it is physics-informed in the sense that the modal decomposition extracts the physics in a way that allows us to predict it.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c7b99cbcae24e51709d38ebd55a9ffa77001107f" target='_blank'>
              Exploring the efficacy of a hybrid approach with modal decomposition over fully deep learning models for flow dynamics forecasting
              </a>
            </td>
          <td>
            Rodrigo Abad'ia-Heredia, A. Corrochano, Manuel López-Martín, S. L. Clainche
          </td>
          <td>2024-04-27</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="Molecular simulations have assumed a paramount role in the fields of chemistry, biology, and material sciences, being able to capture the intricate dynamic properties of systems. Within this realm, coarse-grained (CG) techniques have emerged as invaluable tools to sample large-scale systems and reach extended timescales by simplifying system representation. However, CG approaches come with a trade-off: they sacrifice atomistic details that might hold significant relevance in deciphering the investigated process. Therefore, a recommended approach is to identify key CG conformations and process them using backmapping methods, which retrieve atomistic coordinates. Currently, rule-based methods yield subpar geometries and rely on energy relaxation, resulting in less-than-optimal outcomes. Conversely, machine learning techniques offer higher accuracy but are either limited in transferability between systems or tied to specific CG mappings. In this work, we introduce HEroBM, a dynamic and scalable method that employs deep equivariant graph neural networks and a hierarchical approach to achieve high-resolution backmapping. HEroBM handles any type of CG mapping, offering a versatile and efficient protocol for reconstructing atomistic structures with high accuracy. Focused on local principles, HEroBM spans the entire chemical space and is transferable to systems of varying sizes. We illustrate the versatility of our framework through diverse biological systems, including a complex real-case scenario. Here, our end-to-end backmapping approach accurately generates the atomistic coordinates of a G protein-coupled receptor bound to an organic small molecule within a cholesterol/phospholipid bilayer.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/94800faf04d01d15a154fe1bf79ec38f7c0406d2" target='_blank'>
              HEroBM: a deep equivariant graph neural network for universal backmapping from coarse-grained to all-atom representations
              </a>
            </td>
          <td>
            Daniele Angioletti, S. Raniolo, V. Limongelli
          </td>
          <td>2024-04-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>35</td>
        </tr>

        <tr id="The fast and accurate conformation space modeling is an essential part of computational approaches for solving ligand and structure-based drug discovery problems. Recent state-of-the-art diffusion models for molecular conformation generation show promising distribution coverage and physical plausibility metrics but suffer from a slow sampling procedure. We propose a novel adversarial generative framework, COSMIC, that shows comparable generative performance but provides a time-efficient sampling and training procedure. Given a molecular graph and random noise, the generator produces a conformation in two stages. First, it constructs a conformation in a rotation and translation invariant representation—internal coordinates. In the second step, the model predicts the distances between neighboring atoms and performs a few fast optimization steps to refine the initial conformation. The proposed model considers conformation energy, achieving comparable space coverage, and diversity metrics results.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b96da84932140e6589bc174f13c6350d0eb169b8" target='_blank'>
              COSMIC: Molecular Conformation Space Modeling in Internal Coordinates with an Adversarial Framework
              </a>
            </td>
          <td>
            Maksim Kuznetsov, Fedor Ryabov, Roman Schutski, Shayakhmetov Rim, Yen-Chu Lin, Alex Aliper, Daniil Polykovskiy
          </td>
          <td>2024-04-26</td>
          <td>Journal of Chemical Information and Modeling</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="Molecular dynamics (MD) simulation is a popular method for elucidating the structures and functions of biomolecules. However, exploring the conformational space, especially for large systems with slow transitions, often requires enhanced sampling methods. Although conducting MD at high temperatures provides a straightforward approach, resulting conformational ensembles diverge significantly from those at low temperatures. To address this discrepancy, we propose a novel probability density-based reweighting (PDR) method. PDR exhibits robust performance across four distinct systems, including a miniprotein, a cyclic peptide, a protein loop, and a protein-peptide complex. It accurately restores the conformational distributions at high temperatures to those at low temperatures. Additionally, we apply PDR to reweight previously studied high-T MD simulations of 12 protein-peptide complexes, enabling a comprehensive investigation of the conformational space of protein-peptide complexes.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1432c3c0d5b1d591d42f90024a2b409ed157c958" target='_blank'>
              Probability Density Reweighting of High-Temperature Molecular Dynamics.
              </a>
            </td>
          <td>
            Jia-Nan Chen, Botao Dai, Yun-Dong Wu
          </td>
          <td>2024-05-17</td>
          <td>Journal of chemical theory and computation</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="The probabilistic characterization of non-Markovian responses to nonlinear dynamical systems under colored excitation is an important issue, arising in many applications. Extending the Fokker-Planck-Kolmogorov equation, governing the first-order response probability density function (pdf), to this case is a complicated task calling for special treatment. In this work, a new pdf-evolution equation is derived for the response of nonlinear dynamical systems under additive colored Gaussian noise. The derivation is based on the Stochastic Liouville equation (SLE), transformed, by means of an extended version of the Novikov-Furutsu theorem, to an exact yet non-closed equation, involving averages over the history of the functional derivatives of the non-Markovian response with respect to the excitation. The latter are calculated exactly by means of the state-transition matrix of variational, time-varying systems. Subsequently, an approximation scheme is implemented, relying on a decomposition of the state-transition matrix in its instantaneous mean value and its fluctuation around it. By a current-time approximation to the latter, we obtain our final equation, in which the effect of the instantaneous mean value of the response is maintained, rendering it nonlinear and non-local in time. Numerical results for the response pdf are provided for a bistable Duffing oscillator, under Gaussian excitation. The pdfs obtained from the solution of the novel equation and a simpler small correlation time (SCT) pdf-evolution equation are compared to Monde Carlo (MC) simulations. The novel equation outperforms the SCT equation as the excitation correlation time increases, keeping good agreement with the MC simulations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d0b6f6c03b839a52815976d672739470954a8602" target='_blank'>
              A systematic path to non-Markovian dynamics II: Probabilistic response of nonlinear multidimensional systems to Gaussian colored noise excitation
              </a>
            </td>
          <td>
            G. Athanassoulis, Nikolaos P. Nikoletatos-Kekatos, K. Mamis
          </td>
          <td>2024-05-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>22</td>
        </tr>

        <tr id="Condense phase molecular systems organize in wide range of distinct molecular configurations, including amorphous melt and glass as well as crystals often exhibiting polymorphism, that originate from their intricate intra- and intermolecular forces. While accurate coarse-grain (CG) models for these materials are critical to understand phenomena beyond the reach of all-atom simulations, current models cannot capture the diversity of molecular structures. We introduce a generally applicable approach to develop CG force fields for molecular crystals combining graph neural networks (GNN) and data from an all-atom simulations and apply it to the high-energy density material RDX. We address the challenge of expanding the training data with relevant configurations via an iterative procedure that performs CG molecular dynamics of processes of interest and reconstructs the atomistic configurations using a pre-trained neural network decoder. The multi-site CG model uses a GNN architecture constructed to satisfy translational invariance and rotational covariance for forces. The resulting model captures both crystalline and amorphous states for a wide range of temperatures and densities.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/58b0263a757fca3bbe5d09b926870095bbc672c0" target='_blank'>
              Graph neural network coarse-grain force field for the molecular crystal RDX
              </a>
            </td>
          <td>
            Brian H. Lee, J. Larentzos, John K. Brennan, Alejandro Strachan
          </td>
          <td>2024-03-22</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>15</td>
        </tr>

        <tr id="With a specific emphasis on control design objectives, achieving accurate system modeling with limited complexity is crucial in parametric system identification. The recently introduced deep structured state-space models (SSM), which feature linear dynamical blocks as key constituent components, offer high predictive performance. However, the learned representations often suffer from excessively large model orders, which render them unsuitable for control design purposes. The current paper addresses this challenge by means of system-theoretic model order reduction techniques that target the linear dynamical blocks of SSMs. We introduce two regularization terms which can be incorporated into the training loss for improved model order reduction. In particular, we consider modal $\ell_1$ and Hankel nuclear norm regularization to promote sparsity, allowing one to retain only the relevant states without sacrificing accuracy. The presented regularizers lead to advantages in terms of parsimonious representations and faster inference resulting from the reduced order models. The effectiveness of the proposed methodology is demonstrated using real-world ground vibration data from an aircraft.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b541371f45ddda342f254b0c397af73499762464" target='_blank'>
              Model order reduction of deep structured state-space models: A system-theoretic approach
              </a>
            </td>
          <td>
            Marco Forgione, Manas Mejari, Dario Piga
          </td>
          <td>2024-03-21</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>7</td>
        </tr>

        <tr id="The recently introduced class of architectures known as Neural Operators has emerged as highly versatile tools applicable to a wide range of tasks in the field of Scientific Machine Learning (SciML), including data representation and forecasting. In this study, we investigate the capabilities of Neural Implicit Flow (NIF), a recently developed mesh-agnostic neural operator, for representing the latent dynamics of canonical systems such as the Kuramoto-Sivashinsky (KS), forced Korteweg-de Vries (fKdV), and Sine-Gordon (SG) equations, as well as for extracting dynamically relevant information from them. Finally we assess the applicability of NIF as a dimensionality reduction algorithm and conduct a comparative analysis with another widely recognized family of neural operators, known as Deep Operator Networks (DeepONets).">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bd2ea0dbc681d0e289d33f89b612d08a007f2fc6" target='_blank'>
              Using Neural Implicit Flow To Represent Latent Dynamics Of Canonical Systems
              </a>
            </td>
          <td>
            Imran Nasim, Joao Lucas de Sousa Almeida
          </td>
          <td>2024-04-26</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="The paper by No\'e et al. [F. No\'e, S. Olsson, J. K\"ohler and H. Wu, Science, 365:6457 (2019)] introduced the concept of Boltzmann Generators (BGs), a deep generative model that can produce unbiased independent samples of many-body systems. They can generate equilibrium configurations from different metastable states, compute relative stabilities between different structures of proteins or other organic molecules, and discover new states. In this commentary, we motivate the necessity for a new generation of sampling methods beyond molecular dynamics, explain the methodology, and give our perspective on the future role of BGs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/38596c90a7da2fd6544d46a1136630ccbc26234b" target='_blank'>
              Boltzmann Generators and the New Frontier of Computational Sampling in Many-Body Systems
              </a>
            </td>
          <td>
            Alessandro Coretti, Sebastian Falkner, J. Weinreich, Christoph Dellago, O. V. Lilienfeld
          </td>
          <td>2024-04-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>23</td>
        </tr>

        <tr id="A new knowledge-based and machine learning hybrid modeling approach, called conditional Gaussian neural stochastic differential equation (CGNSDE), is developed to facilitate modeling complex dynamical systems and implementing analytic formulae of the associated data assimilation (DA). In contrast to the standard neural network predictive models, the CGNSDE is designed to effectively tackle both forward prediction tasks and inverse state estimation problems. The CGNSDE starts by exploiting a systematic causal inference via information theory to build a simple knowledge-based nonlinear model that nevertheless captures as much explainable physics as possible. Then, neural networks are supplemented to the knowledge-based model in a specific way, which not only characterizes the remaining features that are challenging to model with simple forms but also advances the use of analytic formulae to efficiently compute the nonlinear DA solution. These analytic formulae are used as an additional computationally affordable loss to train the neural networks that directly improve the DA accuracy. This DA loss function promotes the CGNSDE to capture the interactions between state variables and thus advances its modeling skills. With the DA loss, the CGNSDE is more capable of estimating extreme events and quantifying the associated uncertainty. Furthermore, crucial physical properties in many complex systems, such as the translate-invariant local dependence of state variables, can significantly simplify the neural network structures and facilitate the CGNSDE to be applied to high-dimensional systems. Numerical experiments based on chaotic systems with intermittency and strong non-Gaussian features indicate that the CGNSDE outperforms knowledge-based regression models, and the DA loss further enhances the modeling skills of the CGNSDE.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a639323a3ab8c39800f9e9f42ae3d95438cb1ec6" target='_blank'>
              CGNSDE: Conditional Gaussian Neural Stochastic Differential Equation for Modeling Complex Systems and Data Assimilation
              </a>
            </td>
          <td>
            Chuanqi Chen, Nan Chen, Jingbo Wu
          </td>
          <td>2024-04-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="
 The accurate prediction of thermodynamic properties is crucial in various fields such as drug discovery and materials design. This task relies on sampling from the underlying Boltzmann distribution, which is challenging using conventional approaches such as simulations. In this work, we introduce Surrogate Model-Assisted Molecular Dynamics (SMA-MD), a new procedure to sample the equilibrium ensemble of molecules. First, SMA-MD leverages Deep Generative Models to enhance the sampling of slow degrees of freedom. Subsequently, the generated ensemble undergoes statistical reweighting, followed by short simulations. Our empirical results show that SMA-MD generates more diverse and lower energy ensembles than conventional Molecular Dynamics simulations. Furthermore, we showcase the application of SMA-MD for the computation of thermodynamical properties by estimating implicit solvation free energies.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/712080b7b8d296e61827d6c738303ec6ed0d44c1" target='_blank'>
              Generation of conformational ensembles of small molecules via surrogate model-assisted molecular dynamics
              </a>
            </td>
          <td>
            Juan Viguera Diez, Sara Romeo Atance, Ola Engkvist, Simon Olsson
          </td>
          <td>2024-04-05</td>
          <td>Mach. Learn. Sci. Technol.</td>
          <td>1</td>
          <td>4</td>
        </tr>

        <tr id="Achieving precise preparation of quantum many-body states is crucial for the practical implementation of quantum computation and quantum simulation. However, the inherent challenges posed by unavoidable excitations at critical points during quench processes necessitate careful design of control fields. In this work, we introduce a promising and versatile dynamic control neural network tailored to optimize control fields. We address the problem of suppressing defect density and enhancing cat-state fidelity during the passage across the critical point in the quantum Ising model. Our method facilitates seamless transitions between different objective functions by adjusting the {optimization strategy}. In comparison to gradient-based power-law quench methods, our approach demonstrates significant advantages for both small system sizes and long-term evolutions. We provide a detailed analysis of the specific forms of control fields and summarize common features for experimental implementation. Furthermore, numerical simulations demonstrate the robustness of our proposal against random noise and spin number fluctuations. The optimized defect density and cat-state fidelity exhibit a transition at a critical ratio of the quench duration to the system size, coinciding with the quantum speed limit for quantum evolution.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/061c4f7890524ae07698b1b9d46f524e53340cf9" target='_blank'>
              Machine-learning-inspired quantum control in many-body dynamics
              </a>
            </td>
          <td>
            Meng-Yun Mao, Zheng Cheng, Liangsheng Li, Ning Wu, Wen-Long You
          </td>
          <td>2024-04-09</td>
          <td>Physical Review A</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Understanding how structural flexibility affects the properties of metal-organic frameworks (MOFs) is crucial for the design of better MOFs for targeted applications. Flexible MOFs can be studied with molecular dynamics simulations, whose accuracy depends on the force-field used to describe the interatomic interactions. Density functional theory (DFT) and quantum-chemistry methods are highly accurate, but the computational overheads limit their use in long time-dependent simulations for large systems. In contrast, classical force fields usually struggle with the description of coordination bonds. In this work we develop a DFT-accurate machine-learning spectral neighbor analysis potential, trained on DFT energies, forces and stress tensors, for two representative MOFs, namely ZIF-8 and MOF-5. Their structural and vibrational properties are then studied as a function of temperature and tightly compared with available experimental data. Most importantly, we demonstrate an active-learning algorithm, based on mapping the relevant internal coordinates, which drastically reduces the number of training data to be computed at the DFT level. Thus, the workflow presented here appears as an efficient strategy for the study of flexible MOFs with DFT accuracy, but at a fraction of the DFT computational cost.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0a92faa79f4fb2937668e2b10296a922fd1eb077" target='_blank'>
              Quantum-Accurate Machine Learning Potentials for Metal-Organic Frameworks using Temperature Driven Active Learning
              </a>
            </td>
          <td>
            Abhishek Sharma, Stefano Sanvito
          </td>
          <td>2024-05-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Binding thermodynamics and kinetics play critical roles in drug design. However, it has proven challenging to efficiently predict ligand binding thermodynamics and kinetics of small molecules and flexible peptides using conventional Molecular Dynamics (cMD), due to limited simulation timescales. Based on our previously developed Ligand Gaussian accelerated Molecular Dynamics (LiGaMD) method, we present a new approach, termed “LiGaMD3”, in which we introduce triple boosts into three individual energy terms that play important roles in small-molecule/peptide dissociation, rebinding and system conformational changes to improve the sampling efficiency of small-molecule/peptide interactions with target proteins. To validate the performance of LiGaMD3, MDM2 bound by a small molecule (Nutlin 3) and two highly flexible peptides (PMI and P53) were chosen as model systems. LiGaMD3 could efficiently capture repetitive small-molecule/peptide dissociation and binding events within 2 microsecond simulations. The predicted binding kinetic constant rates and free energies from LiGaMD3 agreed with available experimental values and previous simulation results. Therefore, LiGaMD3 provides a more general and efficient approach to capture dissociation and binding of both small-molecule ligand and flexible peptides, allowing for accurate prediction of their binding thermodynamics and kinetics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1537cea212e2f2ae36d10a542ad2c63187c0cd1c" target='_blank'>
              Ligand Gaussian accelerated Molecular Dynamics 3 (LiGaMD3): Improved Calculations of Binding Thermodynamics and Kinetics of Both Small Molecules and Flexible Peptides
              </a>
            </td>
          <td>
            Jinan Wang, Yinglong Miao
          </td>
          <td>2024-05-08</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="We consider a Graph Neural Network (GNN) non-Markovian modeling framework to identify coarse-grained dynamical systems on graphs. Our main idea is to systematically determine the GNN architecture by inspecting how the leading term of the Mori-Zwanzig memory term depends on the coarse-grained interaction coefficients that encode the graph topology. Based on this analysis, we found that the appropriate GNN architecture that will account for $K$-hop dynamical interactions has to employ a Message Passing (MP) mechanism with at least $2K$ steps. We also deduce that the memory length required for an accurate closure model decreases as a function of the interaction strength under the assumption that the interaction strength exhibits a power law that decays as a function of the hop distance. Supporting numerical demonstrations on two examples, a heterogeneous Kuramoto oscillator model and a power system, suggest that the proposed GNN architecture can predict the coarse-grained dynamics under fixed and time-varying graph topologies.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9c24fe27eaf7f498fa7256c6c06dd99bcf8df096" target='_blank'>
              Learning Coarse-Grained Dynamics on Graph
              </a>
            </td>
          <td>
            , John Harlim, , Yan Li
          </td>
          <td>2024-05-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The chemistry of an astrophysical environment is closely coupled to its dynamics, the latter often found to be complex. Hence, to properly model these environments a 3D context is necessary. However, solving chemical kinetics within a 3D hydro simulation is computationally infeasible for a even a modest parameter study. In order to develop a feasible 3D hydro-chemical simulation, the classical chemical approach needs to be replaced by a faster alternative. We present mace, a Machine learning Approach to Chemistry Emulation, as a proof-of-concept work on emulating chemistry in a dynamical environment. Using the context of AGB outflows, we have developed an architecture that combines the use of an autoencoder (to reduce the dimensionality of the chemical network) and a set of latent ordinary differential equations (that are solved to perform the temporal evolution of the reduced features). Training this architecture with an integrated scheme makes it possible to successfully reproduce a full chemical pathway in a dynamical environment. mace outperforms its classical analogue on average by a factor 26. Furthermore, its efficient implementation in PyTorch results in a sub-linear scaling with respect to the number of hydrodynamical simulation particles.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5a68a92bb31d2d2c457cfda8c158e7d23a370619" target='_blank'>
              MACE: A Machine learning Approach to Chemistry Emulation
              </a>
            </td>
          <td>
            S. Maes, F. D. Ceuster, M. Sande, L. Decin
          </td>
          <td>2024-05-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>13</td>
        </tr>

        <tr id="Conventional diffusion models typically relies on a fixed forward process, which implicitly defines complex marginal distributions over latent variables. This can often complicate the reverse process' task in learning generative trajectories, and results in costly inference for diffusion models. To address these limitations, we introduce Neural Flow Diffusion Models (NFDM), a novel framework that enhances diffusion models by supporting a broader range of forward processes beyond the fixed linear Gaussian. We also propose a novel parameterization technique for learning the forward process. Our framework provides an end-to-end, simulation-free optimization objective, effectively minimizing a variational upper bound on the negative log-likelihood. Experimental results demonstrate NFDM's strong performance, evidenced by state-of-the-art likelihood estimation. Furthermore, we investigate NFDM's capacity for learning generative dynamics with specific characteristics, such as deterministic straight lines trajectories. This exploration underscores NFDM's versatility and its potential for a wide range of applications.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d41a4ee3fa1fad1c444e8100aa8b82aaeea832e5" target='_blank'>
              Neural Flow Diffusion Models: Learnable Forward Process for Improved Diffusion Modelling
              </a>
            </td>
          <td>
            Grigory Bartosh, Dmitry Vetrov, C. A. Naesseth
          </td>
          <td>2024-04-19</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="The development of interatomic potentials that can effectively capture a wide range of atomic environments is a complex challenge due to several reasons. Materials can exist in numerous structural forms (e.g., crystalline, amorphous, defects, interfaces) and phases (solid, liquid, gas, plasma). Each form may require different treatment in potential modeling to reflect the real physical behavior correctly. Atoms interact through various forces such as electrostatic, van der Waals, ionic bonding, covalent bonding, and metallic bonding, which manifest differently depending on the chemical elements and their electronic structures. Furthermore, the effective interaction among atoms can change with external conditions like temperature, pressure, and chemical environment. Consequently, creating an interatomic potential that performs well across diverse conditions is difficult since optimizing the potential for one set of conditions can lead to a trade-off in the accuracy of predicted properties associated with other conditions. In this paper, we present a method to construct accurate, efficient and transferable interatomic potentials by adapting to the local atomic environment of each atom within a system. The collection of atomic environments of interest is partitioned into several clusters of atomic environments. Each cluster represents a distinctive local environment and is used to define a corresponding local potential. We introduce a many-body many-potential expansion to smoothly blend these local potentials to ensure global continuity of the potential energy surface. This is achieved by computing the probability functions that determine the likelihood of an atom belonging to each cluster. We apply the environment-adaptive machine learning potentials to predict observable properties for Ta element and InP compound, and compare them with density functional theory calculations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/12f572d73f868d18a6efee34618d4aaab0788be7" target='_blank'>
              Environment-adaptive machine learning potentials
              </a>
            </td>
          <td>
            Ngoc Cuong Nguyen, Dionysios G Sema
          </td>
          <td>2024-05-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c89a40750265888d7f9c1c557675e1656108cf7e" target='_blank'>
              Machine learning heralding a new development phase in molecular dynamics simulations
              </a>
            </td>
          <td>
            Eva Prasnikar, M. Ljubic, Andrej Perdih, J. Borišek
          </td>
          <td>2024-03-29</td>
          <td>Artif. Intell. Rev.</td>
          <td>1</td>
          <td>12</td>
        </tr>

        <tr id="Forecasting tasks using large datasets gathering thousands of heterogeneous time series is a crucial statistical problem in numerous sectors. The main challenge is to model a rich variety of time series, leverage any available external signals and provide sharp predictions with statistical guarantees. In this work, we propose a new forecasting model that combines discrete state space hidden Markov models with recent neural network architectures and training procedures inspired by vector quantized variational autoencoders. We introduce a variational discrete posterior distribution of the latent states given the observations and a two-stage training procedure to alternatively train the parameters of the latent states and of the emission distributions. By learning a collection of emission laws and temporarily activating them depending on the hidden process dynamics, the proposed method allows to explore large datasets and leverage available external signals. We assess the performance of the proposed method using several datasets and show that it outperforms other state-of-the-art solutions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/67b1ca32e081c1237b1c3f428bbd8adbf83d9c58" target='_blank'>
              Variational quantization for state space models
              </a>
            </td>
          <td>
            Étienne David, Jean Bellot, Sylvain Le Corff Lpsm, Su
          </td>
          <td>2024-04-17</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>1</td>
        </tr>

        <tr id="Identifying latent interactions within complex systems is key to unlocking deeper insights into their operational dynamics, including how their elements affect each other and contribute to the overall system behavior. For instance, in neuroscience, discovering neuron-to-neuron interactions is essential for understanding brain function; in ecology, recognizing the interactions among populations is key for understanding complex ecosystems. Such systems, often modeled as dynamical systems, typically exhibit noisy high-dimensional and non-stationary temporal behavior that renders their identification challenging. Existing dynamical system identification methods often yield operators that accurately capture short-term behavior but fail to predict long-term trends, suggesting an incomplete capture of the underlying process. Methods that consider extended forecasts (e.g., recurrent neural networks) lack explicit representations of element-wise interactions and require substantial training data, thereby failing to capture interpretable network operators. Here we introduce Lookahead-driven Inference of Networked Operators for Continuous Stability (LINOCS), a robust learning procedure for identifying hidden dynamical interactions in noisy time-series data. LINOCS integrates several multi-step predictions with adaptive weights during training to recover dynamical operators that can yield accurate long-term predictions. We demonstrate LINOCS' ability to recover the ground truth dynamical operators underlying synthetic time-series data for multiple dynamical systems models (including linear, piece-wise linear, time-changing linear systems' decomposition, and regularized linear time-varying systems) as well as its capability to produce meaningful operators with robust reconstructions through various real-world examples.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f005c8b19ca1d9171afc191fc78b81f136ddfb8c" target='_blank'>
              LINOCS: Lookahead Inference of Networked Operators for Continuous Stability
              </a>
            </td>
          <td>
            Noga Mudrik, Eva Yezerets, Yenho Chen, Christopher Rozell, Adam Charles
          </td>
          <td>2024-04-28</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Recurrent Neural Networks excel at predicting and generating complex high-dimensional temporal patterns. Due to their inherent nonlinear dynamics and memory, they can learn unbounded temporal dependencies from data. In a Machine Learning setting, the network's parameters are adapted during a training phase to match the requirements of a given task/problem increasing its computational capabilities. After the training, the network parameters are kept fixed to exploit the learned computations. The static parameters thereby render the network unadaptive to changing conditions, such as external or internal perturbation. In this manuscript, we demonstrate how keeping parts of the network adaptive even after the training enhances its functionality and robustness. Here, we utilize the conceptor framework and conceptualize an adaptive control loop analyzing the network's behavior continuously and adjusting its time-varying internal representation to follow a desired target. We demonstrate how the added adaptivity of the network supports the computational functionality in three distinct tasks: interpolation of temporal patterns, stabilization against partial network degradation, and robustness against input distortion. Our results highlight the potential of adaptive networks in machine learning beyond training, enabling them to not only learn complex patterns but also dynamically adjust to changing environments, ultimately broadening their applicability.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/81d77920a1f3057b33f9ab48db38a16dc2b0f292" target='_blank'>
              Adaptive control of recurrent neural networks using conceptors
              </a>
            </td>
          <td>
            Guillaume Pourcel, Mirko Goldmann, Ingo Fischer, Miguel C. Soriano
          </td>
          <td>2024-05-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="This paper presents an overview and comparative study of the state of the art in State-Order Reduction (SOR) and Scheduling Dimension Reduction (SDR) for Linear Parameter-Varying (LPV) State-Space (SS) models, comparing and benchmarking their capabilities, limitations and performance. The use case chosen for these studies is an interconnected network of nonlinear coupled mass spring damper systems with three different configurations, where some spring coefficients are described by arbitrary user-defined static nonlinear functions. For SOR, the following methods are compared: Linear Time-Invariant (LTI), LPV and LFR-based balanced reductions, moment matching and parameter-varying oblique projection. For SDR, the following methods are compared: Principal Component Analysis (PCA), trajectory PCA, Kernel PCA and LTI balanced truncation, autoencoders and deep neural network. The comparison reveals the most suitable reduction methods for the different benchmark configurations, from which we provide use case SOR and SDR guidelines that can be used to choose the best reduction method for a given LPV-SS model.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/db521cd814b2c0ea6c5e89c34e192c7077ffe7eb" target='_blank'>
              On the reduction of Linear Parameter-Varying State-Space models
              </a>
            </td>
          <td>
            E. J. Olucha, Bogoljub Terzin, Amritam Das, Roland T'oth
          </td>
          <td>2024-04-02</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>1</td>
        </tr>

        <tr id="Simulations of chemical reaction probabilities in gas surface dynamics require the calculation of ensemble averages over many tens of thousands of reaction events to predict dynamical observables that can be compared to experiments. At the same time, the energy landscapes need to be accurately mapped, as small errors in barriers can lead to large deviations in reaction probabilities. This brings a particularly interesting challenge for machine learning interatomic potentials, which are becoming well-established tools to accelerate molecular dynamics simulations. We compare state-of-the-art machine learning interatomic potentials with a particular focus on their inference performance on CPUs and suitability for high throughput simulation of reactive chemistry at surfaces. The considered models include polarizable atom interaction neural networks (PaiNN), recursively embedded atom neural networks (REANN), the MACE equivariant graph neural network, and atomic cluster expansion potentials (ACE). The models are applied to a dataset on reactive molecular hydrogen scattering on low-index surface facets of copper. All models are assessed for their accuracy, time-to-solution, and ability to simulate reactive sticking probabilities as a function of the rovibrational initial state and kinetic incidence energy of the molecule. REANN and MACE models provide the best balance between accuracy and time-to-solution and can be considered the current state-of-the-art in gas-surface dynamics. PaiNN models require many features for the best accuracy, which causes significant losses in computational efficiency. ACE models provide the fastest time-to-solution, however, models trained on the existing dataset were not able to achieve sufficiently accurate predictions in all cases.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/92f3fd5861c42f58a8ec3499b05a146656e7e131" target='_blank'>
              Benchmarking of machine learning interatomic potentials for reactive hydrogen dynamics at metal surfaces
              </a>
            </td>
          <td>
            Wojciech G Stark, Cas van der Oord, Ilyes Batatia, Yaolong Zhang, Bin Jiang, G'abor Cs'anyi, Reinhard J. Maurer
          </td>
          <td>2024-03-22</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>20</td>
        </tr>

        <tr id="Entropy is a central concept in physics, but can be challenging to calculate even for systems that are easily simulated. This is exacerbated out of equilibrium, where generally little is known about the distribution characterizing simulated configurations. However, modern machine learning algorithms can estimate the probability density characterizing an ensemble of images, given nothing more than sample images assumed to be drawn from this distribution. We show that by mapping system configurations to images, such approaches can be adapted to the efficient estimation of the density, and therefore the entropy, from simulated or experimental data. We then use this idea to obtain entropic limit cycles in a kinetic Ising model driven by an oscillating magnetic field. Despite being a global probe, we demonstrate that this allows us to identify and characterize stochastic dynamics at parameters near the dynamical phase transition.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/cc5c2639eefdb691a6b558afc70620258eb7d1be" target='_blank'>
              Nonequilibrium entropy from density estimation
              </a>
            </td>
          <td>
            Samuel D. Gelman, Guy Cohen
          </td>
          <td>2024-05-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Generative modeling via stochastic processes has led to remarkable empirical results as well as to recent advances in their theoretical understanding. In principle, both space and time of the processes can be discrete or continuous. In this work, we study time-continuous Markov jump processes on discrete state spaces and investigate their correspondence to state-continuous diffusion processes given by SDEs. In particular, we revisit the $\textit{Ehrenfest process}$, which converges to an Ornstein-Uhlenbeck process in the infinite state space limit. Likewise, we can show that the time-reversal of the Ehrenfest process converges to the time-reversed Ornstein-Uhlenbeck process. This observation bridges discrete and continuous state spaces and allows to carry over methods from one to the respective other setting. Additionally, we suggest an algorithm for training the time-reversal of Markov jump processes which relies on conditional expectations and can thus be directly related to denoising score matching. We demonstrate our methods in multiple convincing numerical experiments.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ab29dbecf177b75b1487492788362471c1342680" target='_blank'>
              Bridging discrete and continuous state spaces: Exploring the Ehrenfest process in time-continuous diffusion models
              </a>
            </td>
          <td>
            Ludwig Winkler, Lorenz Richter, Manfred Opper
          </td>
          <td>2024-05-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Quantum chemical simulations can be greatly accelerated by constructing machine learning potentials, which is often done using active learning (AL). The usefulness of the constructed potentials is often limited by the high effort required and their insufficient robustness in the simulations. Here we introduce the end-to-end AL for constructing robust data-efficient potentials with affordable investment of time and resources and minimum human interference. Our AL protocol is based on the physics-informed sampling of training points, automatic selection of initial data, and uncertainty quantification. The versatility of this protocol is shown in our implementation of quasi-classical molecular dynamics for simulating vibrational spectra, conformer search of a key biochemical molecule, and time-resolved mechanism of the Diels-Alder reaction. These investigations took us days instead of weeks of pure quantum chemical calculations on a high-performance computing cluster.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e017823a6497dd5abb78fabf8fccdb9d7ad5bddc" target='_blank'>
              Physics-informed active learning for accelerating quantum chemical simulations
              </a>
            </td>
          <td>
            Yi-Fan Hou, Lina Zhang, Quanhao Zhang, Fuchun Ge, Pavlo O. Dral
          </td>
          <td>2024-04-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>23</td>
        </tr>

        <tr id="Orbital-free density functional theory (OF-DFT) for real-space systems has historically depended on Lagrange optimization techniques, primarily due to the inability of previously proposed electron density ansatze to ensure the normalization constraint. This study illustrates how leveraging contemporary generative models, notably normalizing flows (NFs), can surmount this challenge. We pioneer a Lagrangian-free optimization framework by employing these machine learning models as ansatze for the electron density. This novel approach also integrates cutting-edge variational inference techniques and equivariant deep learning models, offering an innovative alternative to the OF-DFT problem. We demonstrate the versatility of our framework by simulating a one-dimensional diatomic system, LiH, and comprehensive simulations of H$_2$, LiH, and H$_2$O molecules. The inherent flexibility of NFs facilitates initialization with promolecular densities, markedly enhancing the efficiency of the optimization process.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/04c9ea163f48c6d9380cbefdbda2cf76800e126b" target='_blank'>
              Leveraging Normalizing Flows for Orbital-Free Density Functional Theory
              </a>
            </td>
          <td>
            Alexandre de Camargo, Ricky T. Q. Chen, R. A. Vargas-Hern'andez
          </td>
          <td>2024-04-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Optimization of chemical systems and processes have been enhanced and enabled by the guidance of algorithms and analytical approaches. While many methods will systematically investigate how underlying variables govern a given outcome, there is often a substantial number of experiments needed to accurately model these relations. As chemical systems increase in complexity, inexhaustive processes must propose experiments that efficiently optimize the underlying objective, while ideally avoiding convergence on unsatisfactory local minima. We have developed the Paddy software package around the Paddy Field Algorithm, a biologically inspired evolutionary optimization algorithm that propagates parameters without direct inference of the underlying objective function. Benchmarked against the Tree of Parzen Estimator, a Bayesian algorithm implemented in the Hyperopt software Library, Paddy displays efficient optimization with lower runtime, and avoidance of early convergence. Herein we report these findings for the cases of: global optimization of a two-dimensional bimodal distribution, interpolation of an irregular sinusoidal function, hyperparameter optimization of an artificial neural network tasked with classification of solvent for reaction components, and targeted molecule generation via optimization of input vectors for a decoder network. We anticipate that the facile nature of Paddy will serve to aid in automated experimentation, where minimization of investigative trials and or diversity of suitable solutions is of high priority.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7941285e006b2b76ea11a3888763e7a1a841d162" target='_blank'>
              Paddy: Evolutionary Optimization Algorithm for Chemical Systems and Spaces
              </a>
            </td>
          <td>
            Armen G. Beck, Jonathan A Fine, G. Chopra
          </td>
          <td>2024-03-22</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>18</td>
        </tr>

        <tr id="Machine learning (ML) offers promising new approaches to tackle complex problems and has been increasingly adopted in chemical and materials sciences. Broadly speaking, ML models employ generic mathematical functions and attempt to learn essential physics and chemistry from a large amount of data. Consequently, because of the lack of physical or chemical principles in the functional form, the reliability of the predictions is oftentimes not guaranteed, particularly for data far out of distribution. It is critical to quantify the uncertainty in model predictions and understand how the uncertainty propagates to downstream chemical and materials applications. Herein, we review and categorize existing uncertainty quantification (UQ) methods for atomistic ML under a united framework of probabilistic modeling with the aim of elucidating the similarities and differences between them. We also discuss performance metrics to evaluate the calibration, precision, accuracy, and efficiency of the UQ methods and techniques for model recalibration. In addition, we discuss uncertainty propagation (UP) in widely used simulation techniques in chemical and materials science, such as molecular dynamics and microkinetic modeling. We also provide remarks on the challenges and future opportunities of UQ and UP in atomistic ML.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/362f043306942684a825aa8b606069d8f4c468b3" target='_blank'>
              Uncertainty Quantification and Propagation in Atomistic Machine Learning
              </a>
            </td>
          <td>
            Jin Dai, Santosh Adhikari, Mingjian Wen
          </td>
          <td>2024-05-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The sparse identification of nonlinear dynamical systems (SINDy) is a data-driven technique employed for uncovering and representing the fundamental dynamics of intricate systems based on observational data. However, a primary obstacle in the discovery of models for nonlinear partial differential equations (PDEs) lies in addressing the challenges posed by the curse of dimensionality and large datasets. Consequently, the strategic selection of the most informative samples within a given dataset plays a crucial role in reducing computational costs and enhancing the effectiveness of SINDy-based algorithms. To this aim, we employ a greedy sampling approach to the snapshot matrix of a PDE to obtain its valuable samples, which are suitable to train a deep neural network (DNN) in a SINDy framework. SINDy based algorithms often consist of a data collection unit, constructing a dictionary of basis functions, computing the time derivative, and solving a sparse identification problem which ends to regularised least squares minimization. In this paper, we extend the results of a SINDy based deep learning model discovery (DeePyMoD) approach by integrating greedy sampling technique in its data collection unit and new sparsity promoting algorithms in the least squares minimization unit. In this regard we introduce the greedy sampling neural network in sparse identification of nonlinear partial differential equations (GN-SINDy) which blends a greedy sampling method, the DNN, and the SINDy algorithm. In the implementation phase, to show the effectiveness of GN-SINDy, we compare its results with DeePyMoD by using a Python package that is prepared for this purpose on numerous PDE discovery">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9f2e0f138fdb706edb87999a79e0c8ba055c75b7" target='_blank'>
              GN-SINDy: Greedy Sampling Neural Network in Sparse Identification of Nonlinear Partial Differential Equations
              </a>
            </td>
          <td>
            A. Forootani, Peter Benner
          </td>
          <td>2024-05-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="We present a flow-based method for simulating and calculating nucleation rates of first-order phase transitions in scalar field theory on a lattice. Motivated by recent advancements in machine learning tools, particularly normalizing flows for lattice field theory, we propose the ``partitioning flow-based Markov chain Monte Carlo (PFMCMC) sampling"method to address two challenges encountered in normalizing flow applications for lattice field theory: the ``mode-collapse"and ``rare-event sampling"problems. Using a (2+1)-dimensional real scalar model as an example, we demonstrate the effectiveness of our PFMCMC method in modeling highly hierarchical order parameter probability distributions and simulating critical bubble configurations. These simulations are then used to facilitate the calculation of nucleation rates. We anticipate the application of this method to (3+1)-dimensional theories for studying realistic cosmological phase transitions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a22f392a0ae4d4d4120a40c559896de97bfd276f" target='_blank'>
              Flow-based Nonperturbative Simulation of First-order Phase Transitions
              </a>
            </td>
          <td>
            Yang Bai, Ting-Kuo Chen
          </td>
          <td>2024-04-28</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Simulation of surface processes is a key part of computational chemistry that offers atomic-scale insights into mechanisms of heterogeneous catalysis, diffusion dynamics, and quantum tunneling phenomena. The most common theoretical approaches involve optimization of reaction pathways, including semiclassical tunneling pathways (called instantons). The computational effort can be demanding, especially for instanton optimizations with an ab initio electronic structure. Recently, machine learning has been applied to accelerate reaction-pathway optimization, showing great potential for a wide range of applications. However, previous methods still suffer from numerical and efficiency issues and were not designed for condensed-phase reactions. We propose an improved framework based on Gaussian process regression for general transformed coordinates, which has improved efficiency and numerical stability, and we propose a descriptor that combines internal and Cartesian coordinates suitable for modeling surface processes. We demonstrate with 11 instanton optimizations in three representative systems that the improved approach makes ab initio instanton optimization significantly cheaper, such that it becomes not much more expensive than a classical transition-state theory rate calculation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7bc68f0ff8269bbcab74c0615cd0b148c90b1e65" target='_blank'>
              Robust Gaussian Process Regression Method for Efficient Tunneling Pathway Optimization: Application to Surface Processes
              </a>
            </td>
          <td>
            Wei Fang, Yu-Cheng Zhu, Yi-Han Cheng, Yi-Ping Hao, Jeremy O. Richardson
          </td>
          <td>2024-05-06</td>
          <td>Journal of Chemical Theory and Computation</td>
          <td>0</td>
          <td>27</td>
        </tr>

        <tr id="Algorithms developed to solve many-body quantum problems, like tensor networks, can turn into powerful quantum-inspired tools to tackle problems in the classical domain. In this work, we focus on matrix product operators, a prominent numerical technique to study many-body quantum systems, especially in one dimension. It has been previously shown that such a tool can be used for classification, learning of deterministic sequence-to-sequence processes and of generic quantum processes. We further develop a matrix product operator algorithm to learn probabilistic sequence-to-sequence processes and apply this algorithm to probabilistic cellular automata. This new approach can accurately learn probabilistic cellular automata processes in different conditions, even when the process is a probabilistic mixture of different chaotic rules. In addition, we find that the ability to learn these dynamics is a function of the bit-wise difference between the rules and whether one is much more likely than the other.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8110beec24b4ccfaab141e29148faf176cdc0802" target='_blank'>
              Tensor-Networks-based Learning of Probabilistic Cellular Automata Dynamics
              </a>
            </td>
          <td>
            Heitor P. Casagrande, Bo Xing, William J. Munro, Chu Guo, Dario Poletti
          </td>
          <td>2024-04-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Atomic basis sets are widely employed within quantum mechanics based simulations of matter. We introduce a machine learning model that adapts the basis set to the local chemical environment of each atom, prior to the start of self consistent field (SCF) calculations. In particular, as a proof of principle and because of their historic popularity, we have studied the Gaussian type orbitals from the Pople basis set, i.e. the STO-3G, 3-21G, 6-31G and 6-31G*. We adapt the basis by scaling the variance of the radial Gaussian functions leading to contraction or expansion of the atomic orbitals.A data set of optimal scaling factors for C, H, O, N and F were obtained by variational minimization of the Hartree-Fock (HF) energy of the smallest 2500 organic molecules from the QM9 database. Kernel ridge regression based machine learning (ML) prediction errors of the change in scaling decay rapidly with training set size, typically reaching less than 1 % for training set size 2000. Overall, we find systematically lower variance, and consequently the larger training efficiencies, when going from hydrogen to carbon to nitrogen to oxygen. Using the scaled basis functions obtained from the ML model, we conducted HF calculations for the subsequent 30'000 molecules in QM9. In comparison to the corresponding default Pople basis set results we observed improved energetics in up to 99 % of all cases. With respect to the larger basis set 6-311G(2df,2pd), atomization energy errors are lowered on average by ~31, 107, 11, and 11 kcal/mol for STO-3G, 3-21G, 6-31G and 6-31G*, respectively -- with negligible computational overhead. We illustrate the high transferability of adaptive basis sets for larger out-of-domain molecules relevant to addiction, diabetes, pain, aging.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c174b2b2d974ac947107b322852fffcd9ab8415b" target='_blank'>
              Adaptive atomic basis sets
              </a>
            </td>
          <td>
            Danish Khan, Maximilian L. Ach, O. V. Lilienfeld
          </td>
          <td>2024-04-25</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>23</td>
        </tr>

        <tr id="Simulating spontaneous structural rearrangements in macromolecules with classical molecular dynamics is an outstanding challenge. Conventional supercomputers can access time intervals of up to tens of μs, while many key events occur on exponentially longer time scales. Path sampling techniques have the advantage of focusing the computational power on barrier-crossing trajectories, but generating uncorrelated transition paths that explore diverse conformational regions remains a problem. We employ a hybrid path-sampling paradigm that addresses this issue by generating trial transition paths using a quantum annealing (QA) machine. We first employ a classical computer to perform an uncharted exploration of the conformational space. The data set generated in this exploration is then postprocessed using a path integral-based method to yield a coarse-grained network representation of the reactive kinetics. By resorting to a quantum annealer, quantum superposition can be exploited to encode all of the transition pathways in the initial quantum state, thus potentially solving the path exploration problem. Furthermore, each QA cycle yields a completely uncorrelated trial trajectory. We previously validated this scheme on a prototypically simple transition, which could be extensively characterized on a desktop computer. Here, we scale up in complexity and perform an all-atom simulation of a protein conformational transition that occurs on the millisecond time scale, obtaining results that match those of the Anton special-purpose supercomputer. Despite limitations due to the available quantum annealers, our study highlights how realistic biomolecular simulations provide potentially impactful new ground for applying, testing, and advancing quantum technologies.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0915bc6adb2fee9a14716d117ddd5ec148869d2a" target='_blank'>
              Sampling a Rare Protein Transition Using Quantum Annealing.
              </a>
            </td>
          <td>
            Danial Ghamari, Roberto Covino, 
          </td>
          <td>2024-04-08</td>
          <td>Journal of chemical theory and computation</td>
          <td>0</td>
          <td>16</td>
        </tr>

        <tr id="Irregularly sampled time series with missing values are often observed in multiple real-world applications such as healthcare, climate and astronomy. They pose a significant challenge to standard deep learn- ing models that operate only on fully observed and regularly sampled time series. In order to capture the continuous dynamics of the irreg- ular time series, many models rely on solving an Ordinary Differential Equation (ODE) in the hidden state. These ODE-based models tend to perform slow and require large memory due to sequential operations and a complex ODE solver. As an alternative to complex ODE-based mod- els, we propose a family of models called Functional Latent Dynamics (FLD). Instead of solving the ODE, we use simple curves which exist at all time points to specify the continuous latent state in the model. The coefficients of these curves are learned only from the observed values in the time series ignoring the missing values. Through extensive experi- ments, we demonstrate that FLD achieves better performance compared to the best ODE-based model while reducing the runtime and memory overhead. Specifically, FLD requires an order of magnitude less time to infer the forecasts compared to the best performing forecasting model.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f2a5b8158db29854109275cb5c3fbcf47c080c1c" target='_blank'>
              Functional Latent Dynamics for Irregularly Sampled Time Series Forecasting
              </a>
            </td>
          <td>
            Christian Klotergens, Vijaya Krishna Yalavarthi, Maximilian Stubbemann, Lars Schmidt-Thieme
          </td>
          <td>2024-05-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="We discuss Hamiltonian and Liouvillian learning for analog quantum simulation from non-equilibrium quench dynamics in the limit of weakly dissipative many-body systems. We present various strategies to learn the operator content of the Hamiltonian and the Lindblad operators of the Liouvillian. We compare different ans\"atze based on an experimentally accessible"learning error"which we consider as a function of the number of runs of the experiment. Initially, the learning error decreasing with the inverse square root of the number of runs, as the error in the reconstructed parameters is dominated by shot noise. Eventually the learning error remains constant, allowing us to recognize missing ansatz terms. A central aspect of our approach is to (re-)parametrize ans\"atze by introducing and varying the dependencies between parameters. This allows us to identify the relevant parameters of the system, thereby reducing the complexity of the learning task. Importantly, this (re-)parametrization relies solely on classical post-processing, which is compelling given the finite amount of data available from experiments. A distinguishing feature of our approach is the possibility to learn the Hamiltonian, without the necessity of learning the complete Liouvillian, thus further reducing the complexity of the learning task. We illustrate our method with two, experimentally relevant, spin models.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/690545a3d51683d051059ba60a9d51c6979db019" target='_blank'>
              Hamiltonian and Liouvillian learning in weakly-dissipative quantum many-body systems
              </a>
            </td>
          <td>
            Tobias Olsacher, Tristan Kraft, C. Kokail, Barbara Kraus, Peter Zoller
          </td>
          <td>2024-05-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>15</td>
        </tr>

        <tr id="The machine learning force field has achieved significant strides in accurately reproducing the potential energy surface with quantum chemical accuracy. However, it still faces significant challenges, e.g., extrapolating to uncharted chemical spaces, interpreting long-range electrostatics, and mapping complex macroscopic properties. To address these issues, we advocate for a synergistic integration of physical principles and machine learning techniques within the framework of a physically informed neural network (PINN). This innovative approach involves the incorporation of physical constraints directly into the parameters of the neural network, coupled with the implementation of a global optimization strategy. We choose the AMOEBA+ force field as the physics-based model for embedding, and then train and test it using the diethylene glycol dimethyl ether (DEGDME) dataset as a case study. The results reveal a significant breakthrough in constructing a precise and noise-robust machine learning force field. Utilizing two training sets with hundreds of samples, our model exhibits remarkable generalization and DFT accuracy in describing molecular interactions and enables a precise prediction of the macroscopic properties such as diffusion coefficient with minimal cost. This work provides a crucial insight into establishing a fundamental framework of PINN.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/352dc4317d22dab64117865f5f72c3e30dcbcfe9" target='_blank'>
              Synergistic integration of physical embedding and machine learning enabling precise and reliable force field
              </a>
            </td>
          <td>
            Lifeng Xu, Jian Jiang
          </td>
          <td>2024-04-20</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Water-mediated proton transfer reactions are central for catalytic processes in a wide range of biochemical systems, ranging from biological energy conversion to chemical transformations in the metabolism. Yet, the accurate computational treatment of such complex bio-chemical reactions is highly challenging and requires the application of multiscale methods, in particular hybrid quantum/classical (QM/MM) approaches combined with free energy simulations. Here we combine the unique exploration power of new advanced sampling methods with density functional theory (DFT)-based QM/MM free energy methods for multiscale simulations of long-range protonation dynamics in biological systems. In this regard, we show that combining multiple walkers/well-tempered metadynamics with an extended-system adaptive biasing force method (MWE), provides a powerful approach for exploration of water-mediated proton transfer reactions in complex biochemical systems. We compare and combine the MWE method also with QM/MM-umbrella sampling and explore the sampling of the free energy landscape with both geometric (linear combination of proton transfer distances) and physical (center of excess charge) reaction coordinates, and show how these affect the convergence of the potential of mean force (PMF) and the activation free energy. We find that the QM/MM-MWE method can efficiently explore both direct and water-mediated proton transfer pathways together with forward and reverse hole transfer mechanisms in the highly complex proton channel of respiratory Complex I, while the QM/MM-US approach shows a systematic convergence of selected long-range proton transfer pathways. In this regard, we show that the PMF along multiple proton transfer pathways is recovered by combining the strengths of both approaches in a QM/MM-MWE/focused US (FUS) scheme, and revealing new mechanistic insight into the proton transfer principles of Complex I. Our findings provide a promising basis for the quantitative multi-scale simulations of long-range proton transfer reactions in biological systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2ba20ae804196c34c24b84c65bbfe8a7fa0ac559" target='_blank'>
              QM/MM Free Energy Calculations of Long-Range Biological Protonation Dynamics by Adaptive and Focused Sampling
              </a>
            </td>
          <td>
            Maximilian C Pöverlein, Andreas Hulm, Johannes C. B. Dietschreit, J. Kussmann, C. Ochsenfeld, Ville R. I. Kaila
          </td>
          <td>2024-04-26</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>55</td>
        </tr>

        <tr id="Formulating dynamical models for physical phenomena is essential for understanding the interplay between the different mechanisms and predicting the evolution of physical states. However, a dynamical model alone is often insufficient to address these fundamental tasks, as it suffers from model errors and uncertainties. One common remedy is to rely on data assimilation, where the state estimate is updated with observations of the true system. Ensemble filters sequentially assimilate observations by updating a set of samples over time. They operate in two steps: a forecast step that propagates each sample through the dynamical model and an analysis step that updates the samples with incoming observations. For accurate and robust predictions of dynamical systems, discrete solutions must preserve their critical invariants. While modern numerical solvers satisfy these invariants, existing invariant-preserving analysis steps are limited to Gaussian settings and are often not compatible with classical regularization techniques of ensemble filters, e.g., inflation and covariance tapering. The present work focuses on preserving linear invariants, such as mass, stoichiometric balance of chemical species, and electrical charges. Using tools from measure transport theory (Spantini et al., 2022, SIAM Review), we introduce a generic class of nonlinear ensemble filters that automatically preserve desired linear invariants in non-Gaussian filtering problems. By specializing this framework to the Gaussian setting, we recover a constrained formulation of the Kalman filter. Then, we show how to combine existing regularization techniques for the ensemble Kalman filter (Evensen, 1994, J. Geophys. Res.) with the preservation of the linear invariants. Finally, we assess the benefits of preserving linear invariants for the ensemble Kalman filter and nonlinear ensemble filters.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d141c58886abcc457131832eb29eed4ce25f26e6" target='_blank'>
              Preserving linear invariants in ensemble filtering methods
              </a>
            </td>
          <td>
            M. Provost, Jan Glaubitz, Youssef Marzouk
          </td>
          <td>2024-04-22</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="Over the last decade, an increasing body of evidence has emerged, supporting the existence of a metastable liquid-liquid critical point in supercooled water, whereby two distinct liquid phases of different densities coexist. Analysing long molecular dynamics simulations performed using deep neural-network force fields trained to accurate quantum mechanical data, we demonstrate that the low-density liquid phase displays a strong propensity toward spontaneous polarization, as witnessed by large and long-lived collective dipole fluctuations. Our findings suggest that the dynamical stability of the low-density phase, and hence the transition from high-density to low-density liquid, is triggered by a collective process involving an accumulation of rotational angular jumps, which could ignite large dipole fluctuations. This dynamical transition involves subtle changes in the electronic polarizability of water molecules which affects their rotational mobility within the two phases. These findings hold the potential for catalyzing new activity in the search for dielectric-based probes of the putative second critical point.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/06d44225e3222908379d1fa18ff847f72cffce26" target='_blank'>
              Evidence of ferroelectric features in low-density supercooled water from ab initio deep neural-network simulations
              </a>
            </td>
          <td>
            Cesare Malosso, Natalia Manko, M. G. Izzo, Stefano Baroni, Ali A Hassanali
          </td>
          <td>2024-04-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>29</td>
        </tr>

        <tr id="Kohn-Sham Density Functional Theory (KS-DFT) provides the exact ground state energy and electron density of a molecule, contingent on the as-yet-unknown universal exchange-correlation (XC) functional. Recent research has demonstrated that neural networks can efficiently learn to represent approximations to that functional, offering accurate generalizations to molecules not present during the training process. With the latest advancements in quantum-enhanced machine learning (ML), evidence is growing that Quantum Neural Network (QNN) models may offer advantages in ML applications. In this work, we explore the use of QNNs for representing XC functionals, enhancing and comparing them to classical ML techniques. We present QNNs based on differentiable quantum circuits (DQCs) as quantum (hybrid) models for XC in KS-DFT, implemented across various architectures. We assess their performance on 1D and 3D systems. To that end, we expand existing differentiable KS-DFT frameworks and propose strategies for efficient training of such functionals, highlighting the importance of fractional orbital occupation for accurate results. Our best QNN-based XC functional yields energy profiles of the H$_2$ and planar H$_4$ molecules that deviate by no more than 1 mHa from the reference DMRG and FCI/6-31G results, respectively. Moreover, they reach chemical precision on a system, H$_2$H$_2$, not present in the training dataset, using only a few variational parameters. This work lays the foundation for the integration of quantum models in KS-DFT, thereby opening new avenues for expressing XC functionals in a differentiable way and facilitating computations of various properties.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0ac7fa3927f8a87baa18aa364d920844daa93771" target='_blank'>
              Quantum-Enhanced Neural Exchange-Correlation Functionals
              </a>
            </td>
          <td>
            I. O. Sokolov, Gert-Jan Both, A. Bochevarov, Pavel A. Dub, Daniel S. Levine, Christopher T. Brown, Shaheen Acheche, P. Barkoutsos, V. Elfving
          </td>
          <td>2024-04-22</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>23</td>
        </tr>

        <tr id="In molecular simulations, neural network force fields aim at achieving \emph{ab initio} accuracy with reduced computational cost. This work introduces enhancements to the Deep Potential network architecture, integrating a message-passing framework and a new lightweight implementation with various improvements. Our model achieves accuracy on par with leading machine learning force fields and offers significant speed advantages, making it well-suited for large-scale, accuracy-sensitive systems. We also introduce a new iterative model for Wannier center prediction, allowing us to keep track of electron positions in simulations of general insulating systems. We apply our model to study the solvated electron in bulk water, an ostensibly simple system that is actually quite challenging to represent with neural networks. Our trained model is not only accurate, but can also transfer to larger systems. Our simulation confirms the cavity model, where the electron's localized state is observed to be stable. Through an extensive run, we accurately determine various structural and dynamical properties of the solvated electron.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4ff8c41aeea65f626c2a695b8104ee7a328f9d05" target='_blank'>
              Enhanced Deep Potential Model for Fast and Accurate Molecular Dynamics; Application to the Hydrated Electron
              </a>
            </td>
          <td>
            Ruiqi Gao, Yifan Li, Roberto Car
          </td>
          <td>2024-04-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="We study the long-time dynamics in non-Markovian single-population stochastic models, where one or more reactions are modelled as a stochastic process with a fat-tailed non-exponential distribution of waiting times, mimicking long-term memory. We focus on three prototypical examples: genetic switching, population establishment and population extinction, all with non-exponential production rates. The system is studied in two regimes. In the first, the distribution of waiting times has a finite mean. Here, the system approaches a (quasi)stationary steady state at long times, and we develop a general WKB approach for these non-Markovian systems. We derive explicit results for the mean population size and mean escape time from the metastable state of the stochastic dynamics. In this realm, we reveal that for sufficiently strong memory, a memory-induced (meta)stable state can emerge in the system. In the second regime, the waiting time distribution is assumed to have an infinite mean. Here, for bistable systems we find two distinct scaling regimes, separated by an exponentially long time which may strongly depend on the initial conditions of the system.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8c1d9ecef8998a36d3f2ed5c15541b0ccea926e1" target='_blank'>
              Escape from a metastable state in non-Markovian population dynamics
              </a>
            </td>
          <td>
            Ohad Vilk, Michael Assaf
          </td>
          <td>2024-04-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Parallel cascade selection molecular dynamics (PaCS-MD) is an enhanced conformational sampling method conducted as a “repetition of time leaps in parallel worlds”, comprising cycles of multiple molecular dynamics (MD) simulations performed in parallel and selection of the initial structures of MDs for the next cycle. We developed PaCS-Toolkit, an optimized software utility enabling the use of different MD software and trajectory analysis tools to facilitate the execution of the PaCS-MD simulation and analyze the obtained trajectories, including the preparation for the subsequent construction of the Markov state model. PaCS-Toolkit is coded with Python, is compatible with various computing environments, and allows for easy customization by editing the configuration file and specifying the MD software and analysis tools to be used. We present the software design of PaCS-Toolkit and demonstrate applications of PaCS-MD variations: original targeted PaCS-MD to peptide folding; rmsdPaCS-MD to protein domain motion; and dissociation PaCS-MD to ligand dissociation from adenosine A2A receptor.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/dc7da9a2859f282e60f8b5671bad5b49b53ad433" target='_blank'>
              PaCS-Toolkit: Optimized Software Utilities for Parallel Cascade Selection Molecular Dynamics (PaCS-MD) Simulations and Subsequent Analyses
              </a>
            </td>
          <td>
            Shinji Ikizawa, Tatsuki Hori, T. N. Wijaya, Hiroshi Kono, Zhen Bai, Tatsuhiro Kimizono, Wenbo Lu, D. Tran, Akio Kitao
          </td>
          <td>2024-04-05</td>
          <td>The Journal of Physical Chemistry. B</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="Recent advances in fast sampling methods for diffusion models have demonstrated significant potential to accelerate generation on image modalities. We apply these methods to 3-dimensional molecular conformations by building on the recently introduced GeoLDM equivariant latent diffusion model (Xu et al., 2023). We evaluate trade-offs between speed gains and quality loss, as measured by molecular conformation structural stability. We introduce Equivariant Latent Progressive Distillation, a fast sampling algorithm that preserves geometric equivariance and accelerates generation from latent diffusion models. Our experiments demonstrate up to 7.5x gains in sampling speed with limited degradation in molecular stability. These results suggest this accelerated sampling method has strong potential for high-throughput in silico molecular conformations screening in computational biochemistry, drug discovery, and life sciences applications.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2e02bf6c25cde6b660dc479cc524ada87db85f8f" target='_blank'>
              Accelerating the Generation of Molecular Conformations with Progressive Distillation of Equivariant Latent Diffusion Models
              </a>
            </td>
          <td>
            Romain Lacombe, Neal Vaidya
          </td>
          <td>2024-04-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="We develop a framework for on-the-fly machine learned force field molecular dynamics simulations based on the multipole featurization scheme that overcomes the bottleneck with the number of chemical elements. Considering bulk systems with up to 6 elements, we demonstrate that the number of density functional theory calls remains approximately independent of the number of chemical elements, in contrast to the increase in the smooth overlap of atomic positions scheme.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a05a4bd79c898dfeb0c6f3cc6b220d080d2c3a42" target='_blank'>
              Overcoming the chemical complexity bottleneck in on-the-fly machine learned molecular dynamics simulations
              </a>
            </td>
          <td>
            Lucas R. Timmerman, Shashikant Kumar, Phanish Suryanarayana, A. Medford
          </td>
          <td>2024-04-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>39</td>
        </tr>

        <tr id="Separating relevant and irrelevant information is key to any modeling process or scientific inquiry. Theoretical physics offers a powerful tool for achieving this in the form of the renormalization group (RG). Here we demonstrate a practical approach to performing Wilsonian RG in the context of Gaussian Process (GP) Regression. We systematically integrate out the unlearnable modes of the GP kernel, thereby obtaining an RG flow of the Gaussian Process in which the data plays the role of the energy scale. In simple cases, this results in a universal flow of the ridge parameter, which becomes input-dependent in the richer scenario in which non-Gaussianities are included. In addition to being analytically tractable, this approach goes beyond structural analogies between RG and neural networks by providing a natural connection between RG flow and learnable vs. unlearnable modes. Studying such flows may improve our understanding of feature learning in deep neural networks, and identify potential universality classes in these models.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2ffb0c50aedbc2b6f786ab5dbdc2e8f25674ee4d" target='_blank'>
              Wilsonian Renormalization of Neural Network Gaussian Processes
              </a>
            </td>
          <td>
            Jessica N. Howard, Ro Jefferson, Anindita Maiti, Z. Ringel
          </td>
          <td>2024-05-09</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>16</td>
        </tr>

        <tr id="The process of training an artificial neural network involves iteratively adapting its parameters so as to minimize the error of the network's prediction, when confronted with a learning task. This iterative change can be naturally interpreted as a trajectory in network space -- a time series of networks -- and thus the training algorithm (e.g. gradient descent optimization of a suitable loss function) can be interpreted as a dynamical system in graph space. In order to illustrate this interpretation, here we study the dynamical properties of this process by analyzing through this lens the network trajectories of a shallow neural network, and its evolution through learning a simple classification task. We systematically consider different ranges of the learning rate and explore both the dynamical and orbital stability of the resulting network trajectories, finding hints of regular and chaotic behavior depending on the learning rate regime. Our findings are put in contrast to common wisdom on convergence properties of neural networks and dynamical systems theory. This work also contributes to the cross-fertilization of ideas between dynamical systems theory, network theory and machine learning">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/72e81727419ca3da67887cc9cd6a76a2a0394b00" target='_blank'>
              Dynamical stability and chaos in artificial neural network trajectories along training
              </a>
            </td>
          <td>
            Kaloyan Danovski, Miguel C. Soriano, Lucas Lacasa
          </td>
          <td>2024-04-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Understanding how neural systems efficiently process information through distributed representations is a fundamental challenge at the interface of neuroscience and machine learning. Recent approaches analyze the statistical and geometrical attributes of neural representations as population-level mechanistic descriptors of task implementation. In particular, manifold capacity has emerged as a promising framework linking population geometry to the separability of neural manifolds. However, this metric has been limited to linear readouts. Here, we propose a theoretical framework that overcomes this limitation by leveraging contextual input information. We derive an exact formula for the context-dependent capacity that depends on manifold geometry and context correlations, and validate it on synthetic and real data. Our framework's increased expressivity captures representation untanglement in deep networks at early stages of the layer hierarchy, previously inaccessible to analysis. As context-dependent nonlinearity is ubiquitous in neural systems, our data-driven and theoretically grounded approach promises to elucidate context-dependent computation across scales, datasets, and models.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/eeb127e6d37330d3773dc9829d77a67179be68f0" target='_blank'>
              Nonlinear classification of neural manifolds with contextual information
              </a>
            </td>
          <td>
            Francesca Mignacco, Chi-Ning Chou, SueYeon Chung
          </td>
          <td>2024-05-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Neural network interatomic potentials (NNPs) have recently proven to be powerful tools to accurately model complex molecular systems while bypassing the high numerical cost of ab-initio molecular dynamics simulations. In recent years, numerous advances in model architectures as well as the development of hybrid models combining machine-learning (ML) with more traditional, physically-motivated, force-field interactions have considerably increased the design space of ML potentials. In this paper, we present FeNNol, a new library for building, training and running force-field-enhanced neural network potentials. It provides a flexible and modular system for building hybrid models, allowing to easily combine state-of-the-art embeddings with ML-parameterized physical interaction terms without the need for explicit programming. Furthermore, FeNNol leverages the automatic differentiation and just-in-time compilation features of the Jax Python library to enable fast evaluation of NNPs, shrinking the performance gap between ML potentials and standard force-fields. This is demonstrated with the popular ANI-2x model reaching simulation speeds nearly on par with the AMOEBA polarizable force-field on commodity GPUs (GPU=Graphics processing unit). We hope that FeNNol will facilitate the development and application of new hybrid NNP architectures for a wide range of molecular simulation problems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/22bc3f3862180fc0e77cd3db1bef53946f3ad19d" target='_blank'>
              FeNNol: an Efficient and Flexible Library for Building Force-field-enhanced Neural Network Potentials
              </a>
            </td>
          <td>
            Thomas Pl'e, Olivier Adjoua, Louis Lagardère, Jean‐Philip Piquemal
          </td>
          <td>2024-05-02</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>50</td>
        </tr>

        <tr id="Advances in simulations, combined with technological developments in high-performance computing, have made it possible to produce a physically accurate dynamic representation of complex biological systems involving millions to billions of atoms over increasingly long simulation times. The analysis of these computed simulations is crucial, involving the interpretation of structural and dynamic data to gain insights into the underlying biological processes. However, this analysis becomes increasingly challenging due to the complexity of the generated systems with a large number of individual runs, ranging from hundreds to thousands of trajectories. This massive increase in raw simulation data creates additional processing and visualization challenges. Effective visualization techniques play a vital role in facilitating the analysis and interpretation of molecular dynamics simulations. In this paper, we focus mainly on the techniques and tools that can be used for visualization of molecular dynamics simulations, among which we highlight the few approaches used specifically for this purpose, discussing their advantages and limitations, and addressing the future challenges of molecular dynamics visualization.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/236bb3bb6b0c6a747714984fd4d9483edf764e5c" target='_blank'>
              From complex data to clear insights: visualizing molecular dynamics trajectories
              </a>
            </td>
          <td>
            Hayet Belghit, Mariano Spivak, Manuel Dauchez, Marc Baaden, J. Jonquet-Prevoteau
          </td>
          <td>2024-04-11</td>
          <td>Frontiers in Bioinformatics</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Deep-Learning-based Variational Monte Carlo (DL-VMC) has recently emerged as a highly accurate approach for finding approximate solutions to the many-electron Schr\"odinger equation. Despite its favorable scaling with the number of electrons, $\mathcal{O}(n_\text{el}^{4})$, the practical value of DL-VMC is limited by the high cost of optimizing the neural network weights for every system studied. To mitigate this problem, recent research has proposed optimizing a single neural network across multiple systems, reducing the cost per system. Here we extend this approach to solids, where similar but distinct calculations using different geometries, boundary conditions, and supercell sizes are often required. We show how to optimize a single ansatz across all of these variations, reducing the required number of optimization steps by an order of magnitude. Furthermore, we exploit the transfer capabilities of a pre-trained network. We successfully transfer a network, pre-trained on 2x2x2 supercells of LiH, to 3x3x3 supercells. This reduces the number of optimization steps required to simulate the large system by a factor of 50 compared to previous work.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c7d2f126078d4ab5492f4fd1d14bde65f5c3bdb7" target='_blank'>
              Transferable Neural Wavefunctions for Solids
              </a>
            </td>
          <td>
            Leon Gerard, Michael Scherbela, H. Sutterud, Matthew Foulkes, Philipp Grohs
          </td>
          <td>2024-05-13</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Diffusion models, a powerful and universal generative AI technology, have achieved tremendous success in computer vision, audio, reinforcement learning, and computational biology. In these applications, diffusion models provide flexible high-dimensional data modeling, and act as a sampler for generating new samples under active guidance towards task-desired properties. Despite the significant empirical success, theory of diffusion models is very limited, potentially slowing down principled methodological innovations for further harnessing and improving diffusion models. In this paper, we review emerging applications of diffusion models, understanding their sample generation under various controls. Next, we overview the existing theories of diffusion models, covering their statistical properties and sampling capabilities. We adopt a progressive routine, beginning with unconditional diffusion models and connecting to conditional counterparts. Further, we review a new avenue in high-dimensional structured optimization through conditional diffusion models, where searching for solutions is reformulated as a conditional sampling problem and solved by diffusion models. Lastly, we discuss future directions about diffusion models. The purpose of this paper is to provide a well-rounded theoretical exposure for stimulating forward-looking theories and methods of diffusion models.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/50a8e13366d19625e1ce60a3fe51c79f6b5a6a34" target='_blank'>
              An Overview of Diffusion Models: Applications, Guided Generation, Statistical Rates and Optimization
              </a>
            </td>
          <td>
            Minshuo Chen, Song Mei, Jianqing Fan, Mengdi Wang
          </td>
          <td>2024-04-11</td>
          <td>ArXiv</td>
          <td>2</td>
          <td>3</td>
        </tr>

        <tr id="In this paper we consider adaptive deep neural network approximation for stochastic dynamical systems. Based on the Liouville equation associated with the stochastic dynamical systems, a new temporal KRnet (tKRnet) is proposed to approximate the probability density functions (PDFs) of the state variables. The tKRnet gives an explicit density model for the solution of the Liouville equation, which alleviates the curse of dimensionality issue that limits the application of traditional grid based numerical methods. To efficiently train the tKRnet, an adaptive procedure is developed to generate collocation points for the corresponding residual loss function, where samples are generated iteratively using the approximate density function at each iteration. A temporal decomposition technique is also employed to improve the long-time integration. Theoretical analysis of our proposed method is provided, and numerical examples are presented to demonstrate its performance.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/827723bda19209701daa5c4d36f6625034285087" target='_blank'>
              Adaptive deep density approximation for stochastic dynamical systems
              </a>
            </td>
          <td>
            Junjie He, Qifeng Liao, Xiaoliang Wan
          </td>
          <td>2024-05-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Learning complex trajectories from demonstrations in robotic tasks has been effectively addressed through the utilization of Dynamical Systems (DS). State-of-the-art DS learning methods ensure stability of the generated trajectories; however, they have three shortcomings: a) the DS is assumed to have a single attractor, which limits the diversity of tasks it can achieve, b) state derivative information is assumed to be available in the learning process and c) the state of the DS is assumed to be measurable at inference time. We propose a class of provably stable latent DS with possibly multiple attractors, that inherit the training methods of Neural Ordinary Differential Equations, thus, dropping the dependency on state derivative information. A diffeomorphic mapping for the output and a loss that captures time-invariant trajectory similarity are proposed. We validate the efficacy of our approach through experiments conducted on a public dataset of handwritten shapes and within a simulated object manipulation task.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/cc227c83d593a317b47926de7d4a6905d2fc78a4" target='_blank'>
              Learning Deep Dynamical Systems using Stable Neural ODEs
              </a>
            </td>
          <td>
            Andreas Sochopoulos, M. Gienger, S. Vijayakumar
          </td>
          <td>2024-04-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>46</td>
        </tr>

        <tr id="Machine learning interatomic potentials (MLIPs) enable more efficient molecular dynamics (MD) simulations with ab initio accuracy, which have been used in various domains of physical science. However, distribution shift between training and test data causes deterioration of the test performance of MLIPs, and even leads to collapse of MD simulations. In this work, we propose an online Test-time Adaptation Interatomic Potential (TAIP) framework to improve the generalization on test data. Specifically, we design a dual-level self-supervised learning approach that leverages global structure and atomic local environment information to align the model with the test data. Extensive experiments demonstrate TAIP's capability to bridge the domain gap between training and test dataset without additional data. TAIP enhances the test performance on various benchmarks, from small molecule datasets to complex periodic molecular systems with various types of elements. Remarkably, it also enables stable MD simulations where the corresponding baseline models collapse.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/75000aee86c173f66cb62bd429264301bd2c280b" target='_blank'>
              Online Test-time Adaptation for Interatomic Potentials
              </a>
            </td>
          <td>
            Taoyong Cui, Chenyu Tang, Dongzhan Zhou, Yuqiang Li, Xingao Gong, Wanli Ouyang, Mao Su, Shufei Zhang
          </td>
          <td>2024-05-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Effective learning in neuronal networks requires the adaptation of individual synapses given their relative contribution to solving a task. However, physical neuronal systems -- whether biological or artificial -- are constrained by spatio-temporal locality. How such networks can perform efficient credit assignment, remains, to a large extent, an open question. In Machine Learning, the answer is almost universally given by the error backpropagation algorithm, through both space (BP) and time (BPTT). However, BP(TT) is well-known to rely on biologically implausible assumptions, in particular with respect to spatiotemporal (non-)locality, while forward-propagation models such as real-time recurrent learning (RTRL) suffer from prohibitive memory constraints. We introduce Generalized Latent Equilibrium (GLE), a computational framework for fully local spatio-temporal credit assignment in physical, dynamical networks of neurons. We start by defining an energy based on neuron-local mismatches, from which we derive both neuronal dynamics via stationarity and parameter dynamics via gradient descent. The resulting dynamics can be interpreted as a real-time, biologically plausible approximation of BPTT in deep cortical networks with continuous-time neuronal dynamics and continuously active, local synaptic plasticity. In particular, GLE exploits the ability of biological neurons to phase-shift their output rate with respect to their membrane potential, which is essential in both directions of information propagation. For the forward computation, it enables the mapping of time-continuous inputs to neuronal space, performing an effective spatiotemporal convolution. For the backward computation, it permits the temporal inversion of feedback signals, which consequently approximate the adjoint states necessary for useful parameter updates.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c792c4fd76204bea7c35e45625c8cacdb7e0afc3" target='_blank'>
              Backpropagation through space, time, and the brain
              </a>
            </td>
          <td>
            B. Ellenberger, Paul Haider, Jakob Jordan, Kevin Max, Ismael Jaras, Laura Kriener, Federico Benitez, Mihai A. Petrovici
          </td>
          <td>2024-03-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>19</td>
        </tr>

        <tr id="Abstract The dynamics and variability of protein conformations are directly linked to their functions. Many comparative studies of X-ray protein structures have been conducted to elucidate the relevant conformational changes, dynamics and heterogeneity. The rapid increase in the number of experimentally determined structures has made comparison an effective tool for investigating protein structures. For example, it is now possible to compare structural ensembles formed by enzyme species, variants or the type of ligands bound to them. In this study, the author developed a multilevel model for estimating two covariance matrices that represent inter- and intra-ensemble variability in the Cartesian coordinate space. Principal component analysis using the two estimated covariance matrices identified the inter-/intra-enzyme variabilities, which seemed to be important for the enzyme functions, with the illustrative examples of cytochrome P450 family 2 enzymes and class A \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{upgreek} \usepackage{mathrsfs} \setlength{\oddsidemargin}{-69pt} \begin{document} $\beta$\end{document}-lactamases. In P450, in which each enzyme has its own active site of a distinct size, an active-site motion shared universally between the enzymes was captured as the first principal mode of the intra-enzyme covariance matrix. In this case, the method was useful for understanding the conformational variability after adjusting for the differences between enzyme sizes. The developed method is advantageous in small ensemble-size problems and hence promising for use in comparative studies on experimentally determined structures where ensemble sizes are smaller than those generated, for example, by molecular dynamics simulations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7ef1d9376ec82cc04d939687075b3ecf2478b1b3" target='_blank'>
              Multilevel superposition for deciphering the conformational variability of protein ensembles
              </a>
            </td>
          <td>
            Takashi Amisaki
          </td>
          <td>2024-03-27</td>
          <td>Briefings in Bioinformatics</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="An accurate description of information is relevant for a range of problems in atomistic modeling, such as sampling methods, detecting rare events, analyzing datasets, or performing uncertainty quantification (UQ) in machine learning (ML)-driven simulations. Although individual methods have been proposed for each of these tasks, they lack a common theoretical background integrating their solutions. Here, we introduce an information theoretical framework that unifies predictions of phase transformations, kinetic events, dataset optimality, and model-free UQ from atomistic simulations, thus bridging materials modeling, ML, and statistical mechanics. We first demonstrate that, for a proposed representation, the information entropy of a distribution of atom-centered environments is a surrogate value for thermodynamic entropy. Using molecular dynamics (MD) simulations, we show that information entropy differences from trajectories can be used to build phase diagrams, identify rare events, and recover classical theories of nucleation. Building on these results, we use this general concept of entropy to quantify information in datasets for ML interatomic potentials (IPs), informing compression, explaining trends in testing errors, and evaluating the efficiency of active learning strategies. Finally, we propose a model-free UQ method for MLIPs using information entropy, showing it reliably detects extrapolation regimes, scales to millions of atoms, and goes beyond model errors. This method is made available as the package QUESTS: Quick Uncertainty and Entropy via STructural Similarity, providing a new unifying theory for data-driven atomistic modeling and combining efforts in ML, first-principles thermodynamics, and simulations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8e99b6feff6791ccfee904ee2f02b239d0ced776" target='_blank'>
              Information theory unifies atomistic machine learning, uncertainty quantification, and materials thermodynamics
              </a>
            </td>
          <td>
            Daniel Schwalbe-Koda, Sebastien Hamel, Babak Sadigh, Fei Zhou, Vincenzo Lordi
          </td>
          <td>2024-04-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Water molecules are integral to the structural stability of proteins and vital for facilitating molecular interactions. However, accurately predicting their precise position around protein structures remains a significant challenge, making it a vibrant research area. In this paper, we introduce HydraProt (deep Hydration of Proteins), a novel methodology for predicting precise positions of water molecule oxygen atoms around protein structures, leveraging two interconnected deep learning architectures: a 3D U-net and a Multi-Layer Perceptron (MLP). Our approach starts by introducing a coarse voxel-based representation of the protein, which allows for rapid sampling of candidate water positions via the 3D U-net. These water positions are then assessed by embedding the water–protein relationship in the Euclidean space by means of an MLP. Finally, a postprocessing step is applied to further refine the MLP predictions. HydraProt surpasses existing state-of-the-art approaches in terms of precision and recall and has been validated on large data sets of protein structures. Notably, our method offers rapid inference runtime and should constitute the method of choice for protein structure studies and drug discovery applications. Our pretrained models, data, and the source code required to reproduce these results are accessible at https://github.com/azamanos/HydraProt.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/cfaa674fb6a1de059d769a9b1d888eb5e214d61d" target='_blank'>
              HydraProt: A New Deep Learning Tool for Fast and Accurate Prediction of Water Molecule Positions for Protein Structures
              </a>
            </td>
          <td>
            Andreas Zamanos, G. Ioannakis, I. Emiris
          </td>
          <td>2024-03-29</td>
          <td>Journal of Chemical Information and Modeling</td>
          <td>0</td>
          <td>35</td>
        </tr>

        <tr id="In this study, we present a systematic computational investigation to analyze the long debated crystal stability of two well known aspirin polymorphs, labeled as Form I and Form II. Specifically, we developed a strategy to collect training configurations covering diverse interatomic interactions between representative functional groups in the aspirin crystals. Utilizing a state-of-the-art neural network interatomic potential (NNIP) model, we developed an accurate machine learning potential to simulate aspirin crystal dynamics under finite temperature conditions with $\sim$0.46 kJ/mol/molecule accuracy. Employing the trained NNIP model, we performed thermodynamic integration to assess the free energy difference between aspirin Forms I and II, accounting for the anharmonic effects in a large supercell consisting of 512 molecules. For the first time, our results convincingly demonstrated that Form I is more stable than Form II at 300 K, ranging from 0.74 to 1.83 kJ/mol/molecule, aligning with the experimental observations. Unlike the majority of previous simulations based on (quasi)harmonic approximations in a small super cell, which often found the degenerate energies between aspirin I and II, our findings underscore the importance of anharmonic effects in determining polymorphic stability ranking. Furthermore, we proposed the use of rotational degrees of freedom of methyl and ester/phenyl groups in the aspirin crystal, as characteristic motions to highlight rotational entropic contribution that favors the stability of Form I. Beyond the aspirin polymorphism, we anticipate that such entropy-driven stabilization can be broadly applicable to many other organic systems and thus our approach, suggesting our approach holds a great promise for stability studies in small molecule drug design.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a05c8d06a4a53c3cd39345a1cdc0e9a0b49b8eca" target='_blank'>
              Study of Entropy-Driven Polymorphic Stability for Aspirin Using Accurate Neural Network Interatomic Potential
              </a>
            </td>
          <td>
            Shinnosuke Hattori, Qiang Zhu
          </td>
          <td>2024-04-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="A problem in nonlinear and complex dynamical systems with broad applications is forecasting the occurrence of a critical transition based solely on data without knowledge about the system equations. When such a transition leads to system collapse, as often is the case, all the available data are from the pre-critical regime where the system still functions normally, making the prediction problem challenging. In recent years, a machine-learning based approach tailored to solving this difficult prediction problem, adaptable reservoir computing, has been articulated. This Perspective introduces the basics of this machine-learning scheme and describes representative results. The general setting is that the system dynamics live on a normal attractor with oscillatory dynamics at the present time and, as a bifurcation parameter changes into the future, a critical transition can occur after which the system switches to a completely different attractor, signifying system collapse. To predict a critical transition, it is essential that the reservoir computer not only learns the dynamical "climate" of the system of interest at some specific parameter value but, more importantly, discovers how the system dynamics changes with the bifurcation parameter. It is demonstrated that this capability can be endowed into the machine through a training process with time series from a small number of distinct, pre-critical parameter values, thereby enabling accurate and reliable prediction of the catastrophic critical transition. Three applications are presented: predicting crisis, forecasting amplitude death, and creating digital twins of nonlinear dynamical systems. Limitations and future perspectives are discussed.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f1749f284391bc6f9be0f2b8f564c797144a8e75" target='_blank'>
              Adaptable reservoir computing: A paradigm for model-free data-driven prediction of critical transitions in nonlinear dynamical systems.
              </a>
            </td>
          <td>
            Shirin Panahi, Ying-Cheng Lai
          </td>
          <td>2024-05-01</td>
          <td>Chaos</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Discovering a suitable neural network architecture for modeling complex dynamical systems poses a formidable challenge, often involving extensive trial and error and navigation through a high-dimensional hyper-parameter space. In this paper, we discuss a systematic approach to constructing neural architectures for modeling a subclass of dynamical systems, namely, Linear Time-Invariant (LTI) systems. We use a variant of continuous-time neural networks in which the output of each neuron evolves continuously as a solution of a first-order or second-order Ordinary Differential Equation (ODE). Instead of deriving the network architecture and parameters from data, we propose a gradient-free algorithm to compute sparse architecture and network parameters directly from the given LTI system, leveraging its properties. We bring forth a novel neural architecture paradigm featuring horizontal hidden layers and provide insights into why employing conventional neural architectures with vertical hidden layers may not be favorable. We also provide an upper bound on the numerical errors of our neural networks. Finally, we demonstrate the high accuracy of our constructed networks on three numerical examples.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/db63cb90ec895b72fae7529101e17e991276dd72" target='_blank'>
              Systematic construction of continuous-time neural networks for linear dynamical systems
              </a>
            </td>
          <td>
            Chinmay Datar, Adwait Datar, Felix Dietrich, W. Schilders
          </td>
          <td>2024-03-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>16</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/cb9afd81edb127e2c386053f9d2ddd6c0fab657e" target='_blank'>
              Prediction of order parameters based on protein NMR structure ensemble and machine learning.
              </a>
            </td>
          <td>
            Qianqian Wang, Zhiwei Miao, Xiongjie Xiao, Xu Zhang, Daiwen Yang, Bin Jiang, Maili Liu
          </td>
          <td>2024-03-26</td>
          <td>Journal of biomolecular NMR</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="The sparse identification of nonlinear dynamics (SINDy) has been established as an effective technique to produce interpretable models of dynamical systems from time-resolved state data via sparse regression. However, to model parameterized systems, SINDy requires data from transient trajectories for various parameter values over the range of interest, which are typically difficult to acquire experimentally. In this work, we extend SINDy to be able to leverage data on fixed points and/or limit cycles to reduce the number of transient trajectories needed for successful system identification. To achieve this, we incorporate the data on these attractors at various parameter values as constraints in the optimization problem. First, we show that enforcing these as hard constraints leads to an ill-conditioned regression problem due to the large number of constraints. Instead, we implement soft constraints by modifying the cost function to be minimized. This leads to the formulation of a multi-objective sparse regression problem where we simultaneously seek to minimize the error of the fit to the transients trajectories and to the data on attractors, while penalizing the number of terms in the model. Our extension, demonstrated on several numerical examples, is more robust to noisy measurements and requires substantially less training data than the original SINDy method to correctly identify a parameterized dynamical system.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0c03c126b4d641a81099470f03a7d5215a2a6820" target='_blank'>
              Multi-objective SINDy for parameterized model discovery from single transient trajectory data
              </a>
            </td>
          <td>
            Javier A. Lemus, Benjamin Herrmann
          </td>
          <td>2024-05-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Classical molecular dynamics (MD) simulations represent a very popular and powerful tool for materials modeling and design. The predictive power of MD hinges on the ability of the interatomic potential to capture the underlying physics and chemistry. There have been decades of seminal work on developing interatomic potentials, albeit with a focus predominantly on capturing the properties of bulk materials. Such physics-based models, while extensively deployed for predicting the dynamics and properties of nanoscale systems over the past two decades, tend to perform poorly in predicting nanoscale potential energy surfaces (PESs) when compared to high-fidelity first-principles calculations. These limitations stem from the lack of flexibility in such models, which rely on a predefined functional form. Machine learning (ML) models and approaches have emerged as a viable alternative to capture the diverse size-dependent cluster geometries, nanoscale dynamics, and the complex nanoscale PESs, without sacrificing the bulk properties. Here, we introduce an ML workflow that combines transfer and active learning strategies to develop high-dimensional neural networks (NNs) for capturing the cluster and bulk properties for several different transition metals with applications in catalysis, microelectronics, and energy storage, to name a few. Our NN first learns the bulk PES from the high-quality physics-based models in literature and subsequently augments this learning via retraining with a higher-fidelity first-principles training data set to concurrently capture both the nanoscale and bulk PES. Our workflow departs from status-quo in its ability to learn from a sparsely sampled data set that nonetheless covers a diverse range of cluster configurations from near-equilibrium to highly nonequilibrium as well as learning strategies that iteratively improve the fingerprinting depending on model fidelity. All the developed models are rigorously tested against an extensive first-principles data set of energies and forces of cluster configurations as well as several properties of bulk configurations for 10 different transition metals. Our approach is material agnostic and provides a methodology to transfer and build upon the learnings from decades of seminal work in molecular simulations on to a new generation of ML-trained potentials to accelerate materials discovery and design.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d76b4d6e760d1b287b310104f11d2c8aea330394" target='_blank'>
              Active and Transfer Learning of High-Dimensional Neural Network Potentials for Transition Metals.
              </a>
            </td>
          <td>
            Bilvin Varughese, Sukriti Manna, T. Loeffler, Rohit Batra, M. Cherukara, SubramanianK.R.S. Sankaranarayanan
          </td>
          <td>2024-04-09</td>
          <td>ACS applied materials & interfaces</td>
          <td>0</td>
          <td>25</td>
        </tr>

        <tr id="We demonstrate a novel approach to reservoir computer measurements through the use of a simple quantum system and random matrices to motivate how atomic-scale devices might be used for real-world computing applications. In our approach, random matrices are used to construct reservoir measurements, introducing a simple, scalable means for producing state descriptions. In our studies, systems as simple as a five-atom Heisenberg spin chain are used to perform several tasks, including time series prediction and data interpolation. The performance of the measurement technique as well as their current limitations are discussed in detail alongside an exploration of the diversity of measurements yielded by the random matrices. Additionally, we explore the role of the parameters of the spin chain, adjusting coupling strength and the measurement dimension, yielding insights into how these learning machines might be automatically tuned for different problems. This research highlights the use of random matrices as measurements of simple quantum systems for natural learning devices and outlines a path forward for improving their performance and experimental realisation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5b6eb88745a91b0b4e19fb08450afd92c95bc868" target='_blank'>
              Generating Reservoir State Descriptions with Random Matrices
              </a>
            </td>
          <td>
            S. Tovey, Christian Holm, Michael Spannowsky
          </td>
          <td>2024-04-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="
 Deep neural networks give us a powerful method to model the training dataset’s relationship between input and output. We can regard that as a complex adaptive system consisting of many artificial neurons that work as an adaptive memory as a whole. The network’s behavior is training dynamics with a feedback loop from the evaluation of the loss function. We already know the training response can be constant or shows power law-like aging in some ideal situations. However, we still have gaps between those findings and other complex phenomena, like network fragility. To fill the gap, we introduce a very simple network and analyze it. We show the training response consists of some different factors based on training stages, activation functions, or training methods. In addition, we show feature space reduction as an effect of stochastic training dynamics, which can result in network fragility. Finally, we discuss some complex phenomena of deep networks.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/fe0a5a682bae32fc9da39ee442ef4b9d570ca111" target='_blank'>
              A simple theory for training response of deep neural networks
              </a>
            </td>
          <td>
            Kenichi Nakazato
          </td>
          <td>2024-05-07</td>
          <td>Physica Scripta</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Locally interacting dynamical systems, such as epidemic spread, rumor propagation through crowd, and forest fire, exhibit complex global dynamics originated from local, relatively simple, and often stochastic interactions between dynamic elements. Their temporal evolution is often driven by transitions between a finite number of discrete states. Despite significant advancements in predictive modeling through deep learning, such interactions among many elements have rarely explored as a specific domain for predictive modeling. We present Attentive Recurrent Neural Cellular Automata (AR-NCA), to effectively discover unknown local state transition rules by associating the temporal information between neighboring cells in a permutation-invariant manner. AR-NCA exhibits the superior generalizability across various system configurations (i.e., spatial distribution of states), data efficiency and robustness in extremely data-limited scenarios even in the presence of stochastic interactions, and scalability through spatial dimension-independent prediction.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1388550b7dbb3f7941311d9f11f9bec99880c0bf" target='_blank'>
              Learning Locally Interacting Discrete Dynamical Systems: Towards Data-Efficient and Scalable Prediction
              </a>
            </td>
          <td>
            Beomseok Kang, H. Kumar, Minah Lee, Biswadeep Chakraborty, Saibal Mukhopadhyay
          </td>
          <td>2024-04-09</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>6</td>
        </tr>

        <tr id="The numerical treatment of fluid-particle systems is a very challenging problem because of the complex coupling phenomena occurring between the two phases. Although accurate mathematical modelling is available to address this kind of application, the computational cost of the numerical simulations is very expensive. The use of the most modern high-performance computing infrastructures could help to mitigate such an issue but not completely fix it. In this work, we develop a non-intrusive data-driven reduced order model (ROM) for Computational Fluid Dynamics (CFD) - Discrete Element Method (DEM) simulations. The ROM is built using the proper orthogonal decomposition (POD) for the computation of the reduced basis space and the Long Short-Term Memory (LSTM) network for the computation of the reduced coefficients. We are interested in dealing both with system identification and prediction. The most relevant novelties rely on (i) a filtering procedure of the full-order snapshots to reduce the dimensionality of the reduced problem and (ii) a preliminary treatment of the particle phase. The accuracy of our ROM approach is assessed against the classic Goldschmidt fluidized bed benchmark problem. Finally, we also provide some insights about the efficiency of our ROM approach.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d6fc3c93bcb25262f8059ef4dc83436e309191c7" target='_blank'>
              A LSTM-enhanced surrogate model to simulate the dynamics of particle-laden fluid systems
              </a>
            </td>
          <td>
            Arash Hajisharifi, Rahul Halder, M. Girfoglio, A. Beccari, Domenico Bonanni, G. Rozza
          </td>
          <td>2024-03-21</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>48</td>
        </tr>

        <tr id="Simulating chemically reactive phenomena such as proton transport on nanosecond to microsecond and beyond time scales is a challenging task. Ab initio methods are unable to currently access these time scales routinely, and traditional molecular dynamics methods feature fixed bonding arrangements that cannot account for changes in the system's bonding topology. The Multiscale Reactive Molecular Dynamics (MS-RMD) method, as implemented in the Rapid Approach for Proton Transport and Other Reactions (RAPTOR) software package for the LAMMPS molecular dynamics code, offers a method to routinely sample longer time scale reactive simulation data with statistical precision. RAPTOR may also be interfaced with enhanced sampling methods to drive simulations toward the analysis of reactive rare events, and a number of collective variables (CVs) have been developed to facilitate this. Key advances to this methodology, including GPU acceleration efforts and novel CVs to model water wire formation are reviewed, along with recent applications of the method which demonstrate its versatility and robustness.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/350bcad44c97a2e3607afc23005a305f2904f6e1" target='_blank'>
              Molecular Dynamics Simulation of Complex Reactivity with the Rapid Approach for Proton Transport and Other Reactions (RAPTOR) Software Package.
              </a>
            </td>
          <td>
            Scott Kaiser, Z. Yue, Yuxing Peng, Trung Dac Nguyen, Sijia Chen, Da Teng, G. A. Voth
          </td>
          <td>2024-05-14</td>
          <td>The journal of physical chemistry. B</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="Predicting how a material's microscopic structure and dynamics determine its transport properties remains a fundamental challenge. To alleviate this task's often prohibitive computational expense, we propose a Mori-based generalized quantum master equation (GQME) to predict the frequency-resolved conductivity of small-polaron forming systems described by the dispersive Holstein model. Unlike previous GQME-based approaches to transport that scale with the system size and only give access to the DC conductivity, our method requires only one calculation and yields both the DC and AC mobilities. We further show to easily augment our GQME with numerically accessible derivatives of the current to increase computational efficiency, collectively offering computational cost reductions of up to $90\%$, depending on the transport regime. Finally, we leverage our exact simulations to demonstrate the limited applicability of the celebrated and widely invoked Drude-Smith model in small-polaron forming systems. We instead introduce a cumulant-based analysis of experimentally accessible frequency data to infer the microscopic Hamiltonian parameters. This approach promises to provide valuable insights into material properties and facilitate guided design by linking macroscopic terahertz measurements to the microscopic details of small polaron-forming systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a497c9d1fec93287434aa3548abd7c8d870d4ddd" target='_blank'>
              Mori generalized master equations offer an efficient route to predict and interpret transport
              </a>
            </td>
          <td>
            Srijan Bhattacharyya, Thomas Sayer, Andrés Montoya-Castillo
          </td>
          <td>2024-05-02</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>11</td>
        </tr>

        <tr id="In this study, we propose a multi branched network approach to predict the dynamics of a physics attractor characterized by intricate and chaotic behavior. We introduce a unique neural network architecture comprised of Radial Basis Function (RBF) layers combined with an attention mechanism designed to effectively capture nonlinear inter-dependencies inherent in the attractor's temporal evolution. Our results demonstrate successful prediction of the attractor's trajectory across 100 predictions made using a real-world dataset of 36,700 time-series observations encompassing approximately 28 minutes of activity. To further illustrate the performance of our proposed technique, we provide comprehensive visualizations depicting the attractor's original and predicted behaviors alongside quantitative measures comparing observed versus estimated outcomes. Overall, this work showcases the potential of advanced machine learning algorithms in elucidating hidden structures in complex physical systems while offering practical applications in various domains requiring accurate short-term forecasting capabilities.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/263a32e783722b09eefe90e0bbdf88a61c93c0c4" target='_blank'>
              A Multi-Branched Radial Basis Network Approach to Predicting Complex Chaotic Behaviours
              </a>
            </td>
          <td>
            Aarush Sinha
          </td>
          <td>2024-03-31</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="We construct a fast, transferable, general purpose, machine-learning interatomic potential suitable for large-scale simulations of $N_2$. The potential is trained only on high quality quantum chemical molecule-molecule interactions, no condensed phase information is used. The potential reproduces the experimental phase diagram including the melt curve and the molecular solid phases of nitrogen up to 10 GPa. This demonstrates that many-molecule interactions are unnecessary to explain the condensed phases of $N_2$. With increased pressure, transitions are observed from cubic ($\alpha-N_2$), which optimises quadrupole-quadrupole interactions, through tetragonal ($\gamma-N_2$) which allows more efficient packing, through to monoclinic ($\lambda-N_2$) which packs still more efficiently. On heating, we obtain the hcp 3D rotor phase ($\beta-N_2$) and, at pressure, the cubic $\delta-N_2$ phase which contains both 3D and 2D rotors, tetragonal $\delta^\star-N_2$ phase with 2D rotors and the rhombohedral $\epsilon-N_2$. Molecular dynamics demonstrates where these phases are indeed rotors, rather than frustrated order. The model does not support the existence of the wide range of bondlengths reported for the complex $\iota-N_2$ phase. The thermodynamic transitions involve both shifts of molecular centres and rotations of molecules. We simulate these phase transitions between finding that the onset of rotation is rapid whereas motion of molecular centres is inhibited and the cause of the observed sluggishness of transitions. Routine density functional theory calculations give a similar picture to the potential.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/930cbb34d428f22c891b9b6679f9224a8a957e45" target='_blank'>
              Understanding solid nitrogen through machine learning simulation
              </a>
            </td>
          <td>
            Marcin Kirsz, Ciprian G. Pruteanu, Peter I C Cooke, Graeme J Ackland
          </td>
          <td>2024-05-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="In this paper, we consider the problem of reference tracking in uncertain nonlinear systems. A neural State-Space Model (NSSM) is used to approximate the nonlinear system, where a deep encoder network learns the nonlinearity from data, and a state-space component captures the temporal relationship. This transforms the nonlinear system into a linear system in a latent space, enabling the application of model predictive control (MPC) to determine effective control actions. Our objective is to design the optimal controller using limited data from the \textit{target system} (the system of interest). To this end, we employ an implicit model-agnostic meta-learning (iMAML) framework that leverages information from \textit{source systems} (systems that share similarities with the target system) to expedite training in the target system and enhance its control performance. The framework consists of two phases: the (offine) meta-training phase learns a aggregated NSSM using data from source systems, and the (online) meta-inference phase quickly adapts this aggregated model to the target system using only a few data points and few online training iterations, based on local loss function gradients. The iMAML algorithm exploits the implicit function theorem to exactly compute the gradient during training, without relying on the entire optimization path. By focusing solely on the optimal solution, rather than the path, we can meta-train with less storage complexity and fewer approximations than other contemporary meta-learning algorithms. We demonstrate through numerical examples that our proposed method can yield accurate predictive models by adaptation, resulting in a downstream MPC that outperforms several baselines.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2140b914c25c6c89e81a3b8e30f2c87f5d4bcd5d" target='_blank'>
              MPC of Uncertain Nonlinear Systems with Meta-Learning for Fast Adaptation of Neural Predictive Models
              </a>
            </td>
          <td>
            Jiaqi Yan, Ankush Chakrabarty, Alisa Rupenyan, John Lygeros
          </td>
          <td>2024-04-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Increasing effort is put into the development of methods for learning mechanistic models from data. This task entails not only the accurate estimation of parameters, but also a suitable model structure. Recent work on the discovery of dynamical systems formulates this problem as a linear equation system. Here, we explore several simulation-based optimization approaches, which allow much greater freedom in the objective formulation and weaker conditions on the available data. We show that even for relatively small stochastic population models, simultaneous estimation of parameters and structure poses major challenges for optimization procedures. Particularly, we investigate the application of the local stochastic gradient descent method, commonly used for training machine learning models. We demonstrate accurate estimation of models but find that enforcing the inference of parsimonious, interpretable models drastically increases the difficulty. We give an outlook on how this challenge can be overcome.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/69f3306c5d346d91ce086b55f87d085d98c721dd" target='_blank'>
              Towards Learning Stochastic Population Models by Gradient Descent
              </a>
            </td>
          <td>
            J. N. Kreikemeyer, Philipp Andelfinger, A. Uhrmacher
          </td>
          <td>2024-04-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>31</td>
        </tr>

        <tr id="Machine learning force fields (MLFFs) have emerged as a promising approach to bridge the accuracy of quantum mechanical methods and the efficiency of classical force fields. However, the abundance of MLFF models and the challenge of accurately predicting atomic forces pose significant obstacles in their practical application. In this paper, we propose a novel ensemble learning framework, EL-MLFFs, which leverages the stacking method to integrate predictions from diverse MLFFs and enhance force prediction accuracy. By constructing a graph representation of molecular structures and employing a graph neural network (GNN) as the meta-model, EL-MLFFs effectively captures atomic interactions and refines force predictions. We evaluate our approach on two distinct datasets: methane molecules and methanol adsorbed on a Cu(100) surface. The results demonstrate that EL-MLFFs significantly improves force prediction accuracy compared to individual MLFFs, with the ensemble of all eight models yielding the best performance. Moreover, our ablation study highlights the crucial roles of the residual network and graph attention layers in the model's architecture. The EL-MLFFs framework offers a promising solution to the challenges of model selection and force prediction accuracy in MLFFs, paving the way for more reliable and efficient molecular simulations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b63fbe1f531c1e9ae09f46e22eed6defb05e3fd2" target='_blank'>
              EL-MLFFs: Ensemble Learning of Machine Leaning Force Fields
              </a>
            </td>
          <td>
            Bangchen Yin, Yue Yin, Yuda W. Tang, Hai Xiao
          </td>
          <td>2024-03-26</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="When a liquid is rapidly cooled below its melting point without inducing crystallization, its dynamics slow down significantly without noticeable structural changes. Elucidating the origin of this slowdown has been a long-standing challenge. Here, we report a theoretical investigation into the mechanism of the dynamic slowdown in supercooled water, a ubiquitous yet extraordinary substance characterized by various anomalous properties arising from local density fluctuations. Using molecular dynamics simulations, we found that the jump dynamics, which are elementary structural change processes, deviate from Poisson statistics with decreasing temperature. This deviation is attributed to slow variables competing with the jump motions, i.e., dynamic disorder. The present analysis of the dynamic disorder showed that the primary slow variable is the displacement of the fourth nearest oxygen atom of a jumping molecule, which occurs in an environment created by the fluctuations of molecules outside the first hydration shell. As the temperature decreases, the jump dynamics become slow and intermittent. These intermittent dynamics are attributed to the prolonged trapping of jumping molecules within extended and stable low-density domains. As the temperature continues to decrease, the number of slow variables increases due to the increased cooperative motions. Consequently, the jump dynamics proceed in a higher-dimensional space consisting of multiple slow variables, becoming slower and more intermittent. It is then conceivable that with further decreasing temperature, the slowing and intermittency of the jump dynamics intensify, eventually culminating in a glass transition.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/53e6df1a1e20b4936d4ae9d2bf8c1c4cf379283c" target='_blank'>
              Unraveling the dynamic slowdown in supercooled water: The role of dynamic disorder in jump motions
              </a>
            </td>
          <td>
            Shinji Saito
          </td>
          <td>2024-05-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Data-driven modelling and scientific machine learning have been responsible for significant advances in determining suitable models to describe data. Within dynamical systems, neural ordinary differential equations (ODEs), where the system equations are set to be governed by a neural network, have become a popular tool for this challenge in recent years. However, less emphasis has been placed on systems that are only partially-observed. In this work, we employ a hybrid neural ODE structure, where the system equations are governed by a combination of a neural network and domain-specific knowledge, together with symbolic regression (SR), to learn governing equations of partially-observed dynamical systems. We test this approach on two case studies: A 3-dimensional model of the Lotka-Volterra system and a 5-dimensional model of the Lorenz system. We demonstrate that the method is capable of successfully learning the true underlying governing equations of unobserved states within these systems, with robustness to measurement noise.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8e5f91324b2ca816ed10e0d9a1d6565fb12a4a1f" target='_blank'>
              Learning Governing Equations of Unobserved States in Dynamical Systems
              </a>
            </td>
          <td>
            Gevik Grigorian, Sandip V. George, S. Arridge
          </td>
          <td>2024-04-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="The intrinsic Helmholtz free-energy functional, the centerpiece of classical density functional theory (cDFT), is at best only known approximately for 3D systems. Here we introduce a method for learning a quasi-exact neural-network approximation of this functional by exclusively training on a dataset of radial distribution functions, circumventing the need to sample costly heterogeneous density profiles in a wide variety of external potentials. For a supercritical 3D Lennard-Jones system, we demonstrate that the learned neural free-energy functional accurately predicts planar inhomogeneous density profiles under various complex external potentials obtained from simulations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/423e63279e218c6c7f54a58a0884839891371b23" target='_blank'>
              Learning Neural Free-Energy Functionals with Pair-Correlation Matching
              </a>
            </td>
          <td>
            Jacobus Dijkman, Marjolein Dijkstra, Renévan Roij, Max Welling, Jan-Willem van de Meent, Bernd Ensing
          </td>
          <td>2024-03-22</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="The development of inductive biases has been shown to be a very effective way to increase the accuracy and robustness of neural networks, particularly when they are used to predict physical phenomena. These biases significantly increase the certainty of predictions, decrease the error made and allow considerably smaller datasets to be used. There are a multitude of methods in the literature to develop these biases. One of the most effective ways, when dealing with physical phenomena, is to introduce physical principles of recognised validity into the network architecture. The problem becomes more complex without knowledge of the physical principles governing the phenomena under study. A very interesting possibility then is to turn to the principles of thermodynamics, which are universally valid, regardless of the level of abstraction of the description sought for the phenomenon under study. To ensure compliance with the principles of thermodynamics, there are formulations that have a long tradition in many branches of science. In the field of rheology, for example, two main types of formalisms are used to ensure compliance with these principles: one-generator and two-generator formalisms. In this paper we study the advantages and disadvantages of each, using classical problems with known solutions and synthetic data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ae16a6d3554ec55f805d228b8b398294925333bc" target='_blank'>
              A comparison of Single- and Double-generator formalisms for Thermodynamics-Informed Neural Networks
              </a>
            </td>
          <td>
            Pau Urdeitx, Ic´ıar Alfaro, David Gonz'alez, Francisco Chinesta, Elias Cueto
          </td>
          <td>2024-04-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="Deep Ensemble (DE) approach is a straightforward technique used to enhance the performance of deep neural networks by training them from different initial points, converging towards various local optima. However, a limitation of this methodology lies in its high computational overhead for inference, arising from the necessity to store numerous learned parameters and execute individual forward passes for each parameter during the inference stage. We propose a novel approach called Diffusion Bridge Network (DBN) to address this challenge. Based on the theory of the Schr\"odinger bridge, this method directly learns to simulate an Stochastic Differential Equation (SDE) that connects the output distribution of a single ensemble member to the output distribution of the ensembled model, allowing us to obtain ensemble prediction without having to invoke forward pass through all the ensemble models. By substituting the heavy ensembles with this lightweight neural network constructing DBN, we achieved inference with reduced computational cost while maintaining accuracy and uncertainty scores on benchmark datasets such as CIFAR-10, CIFAR-100, and TinyImageNet. Our implementation is available at https://github.com/kim-hyunsu/dbn.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3fda3f4a647b61db1a2b4a1f3b59db770ec6fc30" target='_blank'>
              Fast Ensembling with Diffusion Schr\"odinger Bridge
              </a>
            </td>
          <td>
            Hyunsu Kim, Jongmin Yoon, Juho Lee
          </td>
          <td>2024-04-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="This study broadens the scope of theoretical frameworks in deep learning by delving into the dynamics of neural networks with inputs that demonstrate the structural characteristics to Gaussian Mixture (GM). We analyzed how the dynamics of neural networks under GM-structured inputs diverge from the predictions of conventional theories based on simple Gaussian structures. A revelation of our work is the observed convergence of neural network dynamics towards conventional theory even with standardized GM inputs, highlighting an unexpected universality. We found that standardization, especially in conjunction with certain nonlinear functions, plays a critical role in this phenomena. Consequently, despite the complex and varied nature of GM distributions, we demonstrate that neural networks exhibit asymptotic behaviors in line with predictions under simple Gaussian frameworks.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/69817ef3eea7ed3389406520f417d2ca2735e656" target='_blank'>
              From Empirical Observations to Universality: Dynamics of Deep Learning with Inputs Built on Gaussian mixture
              </a>
            </td>
          <td>
            Jaeyong Bae, Hawoong Jeong
          </td>
          <td>2024-05-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="In one calculation, adjoint sensitivity analysis provides the gradient of a quantity of interest with respect to all system's parameters. Conventionally, adjoint solvers need to be implemented by differentiating computational models, which can be a cumbersome task and is code-specific. To propose an adjoint solver that is not code-specific, we develop a data-driven strategy. We demonstrate its application on the computation of gradients of long-time averages of chaotic flows. First, we deploy a parameter-aware echo state network (ESN) to accurately forecast and simulate the dynamics of a dynamical system for a range of system's parameters. Second, we derive the adjoint of the parameter-aware ESN. Finally, we combine the parameter-aware ESN with its adjoint version to compute the sensitivities to the system parameters. We showcase the method on a prototypical chaotic system. Because adjoint sensitivities in chaotic regimes diverge for long integration times, we analyse the application of ensemble adjoint method to the ESN. We find that the adjoint sensitivities obtained from the ESN match closely with the original system. This work opens possibilities for sensitivity analysis without code-specific adjoint solvers.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/553a6afc439089894b231b44d32efab776f1e7b8" target='_blank'>
              Adjoint Sensitivities of Chaotic Flows without Adjoint Solvers: A Data-Driven Approach
              </a>
            </td>
          <td>
            D. E. Ozan, Luca Magri
          </td>
          <td>2024-04-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Numerous applications in biology, statistics, science, and engineering require generating samples from high-dimensional probability distributions. In recent years, the Hamiltonian Monte Carlo (HMC) method has emerged as a state-of-the-art Markov chain Monte Carlo technique, exploiting the shape of such high-dimensional target distributions to efficiently generate samples. Despite its impressive empirical success and increasing popularity, its wide-scale adoption remains limited due to the high computational cost of gradient calculation. Moreover, applying this method is impossible when the gradient of the posterior cannot be computed (for example, with black-box simulators). To overcome these challenges, we propose a novel two-stage Hamiltonian Monte Carlo algorithm with a surrogate model. In this multi-fidelity algorithm, the acceptance probability is computed in the first stage via a standard HMC proposal using an inexpensive differentiable surrogate model, and if the proposal is accepted, the posterior is evaluated in the second stage using the high-fidelity (HF) numerical solver. Splitting the standard HMC algorithm into these two stages allows for approximating the gradient of the posterior efficiently, while producing accurate posterior samples by using HF numerical solvers in the second stage. We demonstrate the effectiveness of this algorithm for a range of problems, including linear and nonlinear Bayesian inverse problems with in-silico data and experimental data. The proposed algorithm is shown to seamlessly integrate with various low-fidelity and HF models, priors, and datasets. Remarkably, our proposed method outperforms the traditional HMC algorithm in both computational and statistical efficiency by several orders of magnitude, all while retaining or improving the accuracy in computed posterior statistics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/23b79a6a98cc568851b1afeef58bbe852efbd73a" target='_blank'>
              Multi-fidelity Hamiltonian Monte Carlo
              </a>
            </td>
          <td>
            Dhruv V. Patel, Jonghyun Lee, Matthew Farthing, P. Kitanidis, Eric F. Darve
          </td>
          <td>2024-05-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>67</td>
        </tr>

        <tr id="Fractional Brownian trajectories (fBm) feature both randomness and strong scale-free correlations, challenging generative models to reproduce the intrinsic memory characterizing the underlying process. Here we test a diffusion probabilistic model on a specific dataset of corrupted images corresponding to incomplete Euclidean distance matrices of fBm at various memory exponents $H$. Our dataset implies uniqueness of the data imputation in the regime of low missing ratio, where the remaining partial graph is rigid, providing the ground truth for the inpainting. We find that the conditional diffusion generation stably reproduces the statistics of missing fBm-distributed distances for different values of $H$ exponent. Furthermore, while diffusion models have been recently shown to remember samples from the training database, we show that diffusion-based inpainting behaves qualitatively different from the database search with the increasing database size. Finally, we apply our fBm-trained diffusion model with $H=1/3$ for completion of chromosome distance matrices obtained in single-cell microscopy experiments, showing its superiority over the standard bioinformatics algorithms. Our source code is available on GitHub at https://github.com/alobashev/diffusion_fbm.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e9165cf12c8b1ce3e74ef719f332d7f5000bb777" target='_blank'>
              Diffusion-based inpainting of incomplete Euclidean distance matrices of trajectories generated by a fractional Brownian motion
              </a>
            </td>
          <td>
            Alexander Lobashev, Kirill Polovnikov
          </td>
          <td>2024-04-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Molecular-level nucleation has not been clearly understood due to the complexity of multi-body potentials and the stochastic, rare nature of the process. This work utilizes molecular dynamics (MD) simulations, incorporating a first-principles-based deep neural network (DNN) potential model, to investigate homogeneous water vapor condensation. The nucleation rates and critical nucleus sizes predicted by the DNN model are compared against commonly used semi-empirical models, namely extended simple point charge (SPC/E), TIP4P, and OPC, in addition to classical nucleation theory (CNT). The nucleation rates from the DNN model are comparable with those from the OPC model yet surpass the rates from the SPC/E and TIP4P models, a discrepancy that could mainly arise from the overestimated bulk free energy by SPC/E and TIP4P. The surface free energy predicted by CNT is lower than that in MD simulations, while its bulk free energy is higher than that in MD simulations, irrespective of the potential model used. Further analysis of cluster properties with the DNN model unveils pronounced variations of O-H bond length and H-O-H bond angle, along with averaged bond lengths and angles that are enlarged during embryonic cluster formation. Properties such as cluster surface free energy and liquid-to-vapor density transition profiles exhibit significant deviations from CNT assumptions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e7516a9a63642d058671aa54ee626b21fd91f7fc" target='_blank'>
              Homogeneous water vapor condensation with a deep neural network potential model.
              </a>
            </td>
          <td>
            Shenghui Zhong, Zheyu Shi, Bin Zhang, Zhengcheng Wen, Longfei Chen
          </td>
          <td>2024-03-22</td>
          <td>The Journal of chemical physics</td>
          <td>1</td>
          <td>2</td>
        </tr>

        <tr id="Despite the widespread applications of machine learning force field (MLFF) on solids and small molecules, there is a notable gap in applying MLFF to complex liquid electrolytes. In this work, we introduce BAMBOO (ByteDance AI Molecular Simulation Booster), a novel framework for molecular dynamics (MD) simulations, with a demonstration of its capabilities in the context of liquid electrolytes for lithium batteries. We design a physics-inspired graph equivariant transformer architecture as the backbone of BAMBOO to learn from quantum mechanical simulations. Additionally, we pioneer an ensemble knowledge distillation approach and apply it on MLFFs to improve the stability of MD simulations. Finally, we propose the density alignment algorithm to align BAMBOO with experimental measurements. BAMBOO demonstrates state-of-the-art accuracy in predicting key electrolyte properties such as density, viscosity, and ionic conductivity across various solvents and salt combinations. Our current model, trained on more than 15 chemical species, achieves the average density error of 0.01 g/cm$^3$ on various compositions compared with experimental data. Moreover, our model demonstrates transferability to molecules not included in the quantum mechanical dataset. We envision this work as paving the way to a"universal MLFF"capable of simulating properties of common organic liquids.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a99beaf865ac1f72b4d1e79aae2b8b4e59dae461" target='_blank'>
              BAMBOO: a predictive and transferable machine learning force field framework for liquid electrolyte development
              </a>
            </td>
          <td>
            Sheng Gong, Yumin Zhang, Zhen-Hai Mu, Zhichen Pu, Hongyi Wang, Zhiao Yu, Mengyi Chen, Tianze Zheng, Zhi Wang, Lifei Chen, Xiaojie Wu, Shaochen Shi, Weihao Gao, Wen Yan, Liang Xiang
          </td>
          <td>2024-04-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="In this work, we report a simple, efficient, and scalable machine-learning (ML) approach for mapping non-self-consistent Kohn-Sham Hamiltonians constructed with one kind of density functional to the nearly self-consistent Hamiltonians constructed with another kind of density functional. This approach is designed as a fast surrogate Hamiltonian calculator for use in long nonadiabatic dynamics simulations of large atomistic systems. In this approach, the input and output features are Hamiltonian matrices computed from different levels of theory. We demonstrate that the developed ML-based Hamiltonian mapping method (1) speeds up the calculations by several orders of magnitude, (2) is conceptually simpler than alternative ML approaches, (3) is applicable to different systems and sizes and can be used for mapping Hamiltonians constructed with arbitrary density functionals, (4) requires a modest training data, learns fast, and generates molecular orbitals and their energies with the accuracy nearly matching that of conventional calculations, and (5) when applied to nonadiabatic dynamics simulation of excitation energy relaxation in large systems yields the corresponding time scales within the margin of error of the conventional calculations. Using this approach, we explore the excitation energy relaxation in C60 fullerene and Si75H64 quantum dot structures and derive qualitative and quantitative insights into dynamics in these systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0e3a435f8c1d5c8c579922566ca3eff11257b11d" target='_blank'>
              Machine-Learned Kohn-Sham Hamiltonian Mapping for Nonadiabatic Molecular Dynamics.
              </a>
            </td>
          <td>
            Mohammad Shakiba, Alexey V Akimov
          </td>
          <td>2024-04-06</td>
          <td>Journal of chemical theory and computation</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Descriptors are physically-inspired schemes for representing atomistic systems that play a central role in the construction of models of potential energy surfaces. Although physical intuition can be flexibly encoded into descriptor schemes, they are generally ultimately guided only by the spatial or topological arrangement of atoms in the system. Here, we propose a novel approach for the optimization of descriptors based on encoding information about geodesic distances along potential energy manifolds into the hyperparameters of commonly used descriptor schemes. To accomplish this, we combine two ideas: (1) a differential-geometric approach for the fast estimation of approximate geodesic distances; and (2) an information-theoretic evaluation metric - information imbalance - for measuring the shared information between two distance measures. Using the MD22 datasets of ethanol, malonaldehyde, and aspirin, we first show that Euclidean (in Cartesian coordinates) and geodesic distances are inequivalent distance measures, indicating the need for updated ground-truth distance measures that go beyond the Euclidean distance. We then utilize a Bayesian optimization framework to show that descriptors (in this case, atom-centered symmetry functions) can be optimized to maximally express a certain type of distance information, such as Euclidean or geodesic information. We also show that modifying the Bayesian optimization algorithm to minimize a combined Euclidean+geodesic objective function can yield descriptors that not only express both Euclidean and geodesic distance information simultaneously, but in fact resolve substantial disagreements between descriptors optimized to encode only one type of distance measure. We discuss the relevance of our approach to the design of more physically rich and informative descriptors that can encode useful, alternative information about molecular systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/73d25c786db3592e31746100bc4b6efd6e2a94b7" target='_blank'>
              Atomistic Descriptor Optimization Using Complementary Euclidean and Geodesic Distance Information
              </a>
            </td>
          <td>
            Gopal R. Iyer, Brenda M. Rubenstein
          </td>
          <td>2024-03-26</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="We investigate the learning dynamics of fully-connected neural networks through the lens of gradient signal-to-noise ratio (SNR), examining the behavior of first-order optimizers like Adam in non-convex objectives. By interpreting the drift/diffusion phases in the information bottleneck theory, focusing on gradient homogeneity, we identify a third phase termed ``total diffusion", characterized by equilibrium in the learning rates and homogeneous gradients. This phase is marked by an abrupt SNR increase, uniform residuals across the sample space and the most rapid training convergence. We propose a residual-based re-weighting scheme to accelerate this diffusion in quadratic loss functions, enhancing generalization. We also explore the information compression phenomenon, pinpointing a significant saturation-induced compression of activations at the total diffusion phase, with deeper layers experiencing negligible information loss. Supported by experimental data on physics-informed neural networks (PINNs), which underscore the importance of gradient homogeneity due to their PDE-based sample inter-dependence, our findings suggest that recognizing phase transitions could refine ML optimization strategies for improved generalization.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5c1016776c68cf297468b91e56233d7cc8a141c2" target='_blank'>
              Learning in PINNs: Phase transition, total diffusion, and generalization
              </a>
            </td>
          <td>
            Sokratis J. Anagnostopoulos, Juan Diego Toscano, Nikolaos Stergiopulos, G. Karniadakis
          </td>
          <td>2024-03-27</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>125</td>
        </tr>

        <tr id="Machine learning (ML) provides a great opportunity for the construction of models with improved accuracy in classical molecular dynamics (MD). However, the accuracy of a ML trained model is limited by the quality and quantity of the training data. Generating large sets of accurate ab initio training data can require significant computational resources. Furthermore, inconsistent or incompatible data with different accuracies obtained using different methods may lead to biased or unreliable ML models that do not accurately represent the underlying physics. Recently, transfer learning showed its potential for avoiding these problems as well as for improving the accuracy, efficiency, and generalization of ML models using multifidelity data. In this work, ab initio trained ML-based MD (aML-MD) models are developed through transfer learning using DFT and multireference data from multiple sources with varying accuracy within the Deep Potential MD framework. The accuracy of the force field is demonstrated by calculating rate constants for the H + HO2 → H2 + 3O2 reaction using quasi-classical trajectories. We show that the aML-MD model with transfer learning can accurately predict the rate constants while reducing the computational cost by more than five times compared to the use of more expensive quantum chemistry training data sets. Hence, the aML-MD model with transfer learning shows great potential in using multifidelity data to reduce the computational cost involved in generating the training set for these potentials.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6595ee27356347b45170f9d57843a1941dc6fbb5" target='_blank'>
              Quasi-Classical Trajectory Calculation of Rate Constants Using an Ab Initio Trained Machine Learning Model (aML-MD) with Multifidelity Data.
              </a>
            </td>
          <td>
            Zhiyu Shi, A. Lele, A. Jasper, S. Klippenstein, Yiguang Ju
          </td>
          <td>2024-04-20</td>
          <td>The journal of physical chemistry. A</td>
          <td>0</td>
          <td>75</td>
        </tr>

        <tr id="Partial differential equations (PDEs) are instrumental for modeling dynamical systems in science and engineering. The advent of neural networks has initiated a significant shift in tackling these complexities though challenges in accuracy persist, especially for initial value problems. In this paper, we introduce the $\textit{Time-Evolving Natural Gradient (TENG)}$, generalizing time-dependent variational principles and optimization-based time integration, leveraging natural gradient optimization to obtain high accuracy in neural-network-based PDE solutions. Our comprehensive development includes algorithms like TENG-Euler and its high-order variants, such as TENG-Heun, tailored for enhanced precision and efficiency. TENG's effectiveness is further validated through its performance, surpassing current leading methods and achieving machine precision in step-by-step optimizations across a spectrum of PDEs, including the heat equation, Allen-Cahn equation, and Burgers' equation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ecc56a1b67361349c21c1fd5c588dc93f8ce39fc" target='_blank'>
              TENG: Time-Evolving Natural Gradient for Solving PDEs with Deep Neural Net
              </a>
            </td>
          <td>
            Zhuo Chen, Jacob McCarran, Esteban Vizcaino, Marin Soljacic, Di Luo
          </td>
          <td>2024-04-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Gaussian processes (GPs) are commonly used for prediction and inference for spatial data analyses. However, since estimation and prediction tasks have cubic time and quadratic memory complexity in number of locations, GPs are difficult to scale to large spatial datasets. The Vecchia approximation induces sparsity in the dependence structure and is one of several methods proposed to scale GP inference. Our work adds to the substantial research in this area by developing a stochastic gradient Markov chain Monte Carlo (SGMCMC) framework for efficient computation in GPs. At each step, the algorithm subsamples a minibatch of locations and subsequently updates process parameters through a Vecchia-approximated GP likelihood. Since the Vecchia-approximated GP has a time complexity that is linear in the number of locations, this results in scalable estimation in GPs. Through simulation studies, we demonstrate that SGMCMC is competitive with state-of-the-art scalable GP algorithms in terms of computational time and parameter estimation. An application of our method is also provided using the Argo dataset of ocean temperature measurements.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2c2998d8ea44e0f6dcdf1c07ec83ada98bc45ed6" target='_blank'>
              Stochastic Gradient MCMC for Massive Geostatistical Data
              </a>
            </td>
          <td>
            M. Abba, Brian J. Reich, Reetam Majumder, Brandon Feng
          </td>
          <td>2024-05-07</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Data-driven, machine learning (ML) models of atomistic interactions are often based on flexible and non-physical functions that can relate nuanced aspects of atomic arrangements into predictions of energies and forces. As a result, these potentials are as good as the training data (usually results of so-called ab initio simulations) and we need to make sure that we have enough information for a model to become sufficiently accurate, reliable and transferable. The main challenge stems from the fact that descriptors of chemical environments are often sparse high-dimensional objects without a well-defined continuous metric. Therefore, it is rather unlikely that any ad hoc method of choosing training examples will be indiscriminate, and it will be easy to fall into the trap of confirmation bias, where the same narrow and biased sampling is used to generate train- and test- sets. We will demonstrate that classical concepts of statistical planning of experiments and optimal design can help to mitigate such problems at a relatively low computational cost. The key feature of the method we will investigate is that they allow us to assess the informativeness of data (how much we can improve the model by adding/swapping a training example) and verify if the training is feasible with the current set before obtaining any reference energies and forces -- a so-called off-line approach. In other words, we are focusing on an approach that is easy to implement and doesn't require sophisticated frameworks that involve automated access to high-performance computational (HPC).">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c6ab83f0ca1c9d593f2f0fb9a608ec87561d55e7" target='_blank'>
              Optimal design of experiments in the context of machine-learning inter-atomic potentials: improving the efficiency and transferability of kernel based methods
              </a>
            </td>
          <td>
            Bartosz Barzdajn, Christopher P. Race
          </td>
          <td>2024-05-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Identifying partial differential equations (PDEs) from data is crucial for understanding the governing mechanisms of natural phenomena, yet it remains a challenging task. We present an extension to the ARGOS framework, ARGOS-RAL, which leverages sparse regression with the recurrent adaptive lasso to identify PDEs from limited prior knowledge automatically. Our method automates calculating partial derivatives, constructing a candidate library, and estimating a sparse model. We rigorously evaluate the performance of ARGOS-RAL in identifying canonical PDEs under various noise levels and sample sizes, demonstrating its robustness in handling noisy and non-uniformly distributed data. We also test the algorithm's performance on datasets consisting solely of random noise to simulate scenarios with severely compromised data quality. Our results show that ARGOS-RAL effectively and reliably identifies the underlying PDEs from data, outperforming the sequential threshold ridge regression method in most cases. We highlight the potential of combining statistical methods, machine learning, and dynamical systems theory to automatically discover governing equations from collected data, streamlining the scientific modeling process.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8e6ba94461e38ca92209eaa1e802d6a39c777186" target='_blank'>
              Automating the Discovery of Partial Differential Equations in Dynamical Systems
              </a>
            </td>
          <td>
            Weizhen Li, Rui Carvalho
          </td>
          <td>2024-04-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="This paper explores the efficacy of diffusion-based generative models as neural operators for partial differential equations (PDEs). Neural operators are neural networks that learn a mapping from the parameter space to the solution space of PDEs from data, and they can also solve the inverse problem of estimating the parameter from the solution. Diffusion models excel in many domains, but their potential as neural operators has not been thoroughly explored. In this work, we show that diffusion-based generative models exhibit many properties favourable for neural operators, and they can effectively generate the solution of a PDE conditionally on the parameter or recover the unobserved parts of the system. We propose to train a single model adaptable to multiple tasks, by alternating between the tasks during training. In our experiments with multiple realistic dynamical systems, diffusion models outperform other neural operators. Furthermore, we demonstrate how the probabilistic diffusion model can elegantly deal with systems which are only partially identifiable, by producing samples corresponding to the different possible solutions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/93f7dd73bdb8cf078d6f19120987ab3c21100bc5" target='_blank'>
              Diffusion models as probabilistic neural operators for recovering unobserved states of dynamical systems
              </a>
            </td>
          <td>
            Katsiaryna Haitsiukevich, O. Poyraz, Pekka Marttinen, Alexander Ilin
          </td>
          <td>2024-05-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Quantum dynamics simulations are becoming a powerful tool for understanding photo-excited molecules. Their poor scaling, however, means that it is hard to study molecules with more than a few atoms accurately, and a major challenge at the moment is the inclusion of the molecular environment. Here, we present a proof of principle for a way to break the two bottlenecks preventing large but accurate simulations. First, the problem of providing the potential energy surfaces for a general system is addressed by parameterizing a standard force field to reproduce the potential surfaces of the molecule's excited-states, including the all-important vibronic coupling. While not shown here, this would trivially enable the use of an explicit solvent. Second, to help the scaling of the nuclear dynamics propagation, a hierarchy of approximations is introduced to the variational multi-configurational Gaussian method that retains the variational quantum wavepacket description of the key quantum degrees of freedom and uses classical trajectories for the remaining in a quantum mechanics/molecular mechanics like approach. The method is referred to as force field quantum dynamics (FF-QD), and a two-state ππ*/nπ* model of uracil, excited to its lowest bright ππ* state, is used as a test case.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/81cf5abc27816841b075485ed67149949b8d029c" target='_blank'>
              Non-adiabatic direct quantum dynamics using force fields: Toward solvation.
              </a>
            </td>
          <td>
            L. L. E. Cigrang, J. Green, S. Gómez, J. Cerezo, R. Improta, G. Prampolini, F. Santoro, G. Worth
          </td>
          <td>2024-05-07</td>
          <td>The Journal of chemical physics</td>
          <td>0</td>
          <td>49</td>
        </tr>

        <tr id="Despite their widespread use as therapeutics, clinical development of small molecule drugs remains challenging. Among the many parameters that undergo optimization during the drug development process, increasing passive cell permeability (i.e., log(P)) can have some of the largest impact on potency. Cyclic peptides (CPs) have emerged as a viable alternative to small molecules, as they retain many of the advantages of small molecules (oral availability, target specificity) while being highly effective at traversing the plasma membrane. However, the relationship between the dominant conformations that typify CPs in an aqueous versus a membrane environment and cell permeability remain poorly characterized. In this study, we have used Gaussian accelerated molecular dynamics (GaMD) simulations to characterize the effect of solvent on the free energy landscape of lariat peptides, a subset of CPs that have recently shown potential for drug development (Kelly et al., JACS 2021). Differences in the free energy of lariat peptides as a function of solvent can be used to predict permeability of these molecules, and our results show that permeability is most greatly influenced by N-methylation and exposure to solvent. Our approach lays the groundwork for using GaMD as a way to virtually screen large libraries of CPs and drive forward development of CP-based therapeutics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b7697c8c061e4ecd3d1b24f1c7dccd85e467c0b9" target='_blank'>
              Gaussian accelerated molecular dynamics simulations facilitate prediction of the permeability of cyclic peptides
              </a>
            </td>
          <td>
            Nicolas Frazee, Kyle R. Billlings, Blake Mertz
          </td>
          <td>2024-04-23</td>
          <td>PLOS ONE</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="A common obstruction to efficient sampling from high-dimensional distributions is the multimodality of the target distribution because Markov chains may get trapped far from stationarity. Still, one hopes that this is only a barrier to the mixing of Markov chains from worst-case initializations and can be overcome by choosing high-entropy initializations, e.g., a product or weakly correlated distribution. Ideally, from such initializations, the dynamics would escape from the saddle points separating modes quickly and spread its mass between the dominant modes. In this paper, we study convergence from high-entropy initializations for the random-cluster and Potts models on the complete graph -- two extensively studied high-dimensional landscapes that pose many complexities like discontinuous phase transitions and asymmetric metastable modes. We study the Chayes--Machta and Swendsen--Wang dynamics for the mean-field random-cluster model and the Glauber dynamics for the Potts model. We sharply characterize the set of product measure initializations from which these Markov chains mix rapidly, even though their mixing times from worst-case initializations are exponentially slow. Our proofs require careful approximations of projections of high-dimensional Markov chains (which are not themselves Markovian) by tractable 1-dimensional random processes, followed by analysis of the latter's escape from saddle points separating stable modes.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e5183d3786fbfbcec90ea93383c3057ff50a2821" target='_blank'>
              Mean-field Potts and random-cluster dynamics from high-entropy initializations
              </a>
            </td>
          <td>
            Antonio Blanca, Reza Gheissari, Xusheng Zhang
          </td>
          <td>2024-04-19</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="Molecular dynamics (MD) simulations are ideally suited to describe conformational ensembles of biomolecules such as proteins and nucleic acids. Microsecond-long simulations are now routine, facilitated by the emergence of graphical processing units. Processing such ensembles on the basis of statistical mechanics can bring insights about different biologically relevant states, their representative structures, states, and even dynamics between states. Clustering, which groups objects based on structural similarity, is typically used to process ensembles, leading to different states, their populations, and the identification of representative structures. For some purposes, such as in protein structure prediction, we are interested in identifying the representative structure that is more similar to the native state of the protein. The traditional pipeline combines hierarchical clustering for clustering and selecting the cluster centroid as representative of the cluster. However, even when the first cluster represents the native basin, the centroid can be several angstroms away in RMSD from the native state – and many other structures inside this cluster could be better choices of representative structures, reducing the need for protein structure refinement. In this study, we developed a module—Protein Retrieval via Integrative Molecular Ensemble (PRIME), that consists of tools to determine the most prevalent states in an ensemble using extended continuous similarity. PRIME is integrated with our Molecular Dynamics Analysis with N -ary Clustering Ensembles (MDANCE) package and can be used as a post-processing tool for arbitrary clustering algorithms, compatible with several MD suites. PRIME was validated with ensembles of different protein and protein complex systems for their ability to reliably identify the most native-like state, which we compare to their experimental structure, and to the traditional approach. Systems were chosen to represent different degrees of difficulty such as folding processes and binding which require large conformational changes. PRIME predictions produced structures that when aligned to the experimental structure were better superposed (lower RMSD). A further benefit of PRIME is its linear scaling – rather than the traditional O(N 2) traditionally associated to comparisons of elements in a set.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f36d580be97fb1e9dd10eefffec93c7c3dd7a956" target='_blank'>
              Protein Retrieval via Integrative Molecular Ensembles (PRIME) through extended similarity indices
              </a>
            </td>
          <td>
            Lexin Chen, Arup Mondal, Alberto Perez, R. Miranda‐Quintana
          </td>
          <td>2024-03-21</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>21</td>
        </tr>

        <tr id="As a favorable tool for explainable artificial intelligence (XAI), Shapley value has been widely used to interpret deep learning based predictive models. However, accurate and efficient estimation of Shapley value is difficult since the computation load grows exponentially with the increase of input features. Most existing accelerated estimation methods have to compromise on estimation accuracy with efficiency. In this article, we present EmSHAP(Energy-based model for Shapley value estimation) to estimate the expectation of Shapley contribution function under arbitrary subset of features given the rest. The energy-based model estimates the conditional density in the Shapley contribution function, which involves an energy network for approximating the unnormalized conditional density and a GRU (Gated Recurrent Unit) network for approximating the partition function. The GRU network maps the input features onto a hidden space to eliminate the impact of input orderings. In order to theoretically evaluate the performance of different Shapley value estimation methods, Theorems 1, 2 and 3 analyzed the error bounds of EmSHAP as well as two state-of-the-art methods, namely KernelSHAP and VAEAC. It is proved that EmSHAP has tighter error bound than KernelSHAP and VAEAC. Finally, case studies on two application examples show the enhanced estimation accuracy of EmSHAP.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a6a87cc70b40f53416401e74b0350bd643b33572" target='_blank'>
              Energy-based Model for Accurate Shapley Value Estimation in Interpretable Deep Learning Predictive Modeling
              </a>
            </td>
          <td>
            Cheng Lu, Jiusun Zeng, Yu Xia, Jinhui Cai, Shihua Luo
          </td>
          <td>2024-04-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="Macromolecular complexes are often composed of diverse subunits. The self-assembly of these subunits is inherently nonequilibrium and must avoid kinetic traps to achieve high yield over feasible timescales. We show how the kinetics of self-assembly benefits from diversity in subunits because it generates an expansive parameter space that naturally improves the "expressivity" of self-assembly, much like a deeper neural network. By using automatic differentiation algorithms commonly used in deep learning, we searched the parameter spaces of mass-action kinetic models to identify classes of kinetic protocols that mimic biological solutions for productive self-assembly. Our results reveal how high-yield complexes that easily become kinetically trapped in incomplete intermediates can instead be steered by internal design of rate-constants or external and active control of subunits to efficiently assemble. Internal design of a hierarchy of subunit binding rates generates self-assembly that can robustly avoid kinetic traps for all concentrations and energetics, but it places strict constraints on selection of relative rates. External control via subunit titration is more versatile, avoiding kinetic traps for any system without requiring molecular engineering of binding rates, albeit less efficiently and robustly. We derive theoretical expressions for the timescales of kinetic traps, and we demonstrate our optimization method applies not just for design but inference, extracting intersubunit binding rates from observations of yield-vs.-time for a heterotetramer. Overall, we identify optimal kinetic protocols for self-assembly as a powerful mechanism to achieve efficient and high-yield assembly in synthetic systems whether robustness or ease of "designability" is preferred.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/66c707fb1d6771caadfda0dcd5eb427ea766cf13" target='_blank'>
              Discovering optimal kinetic pathways for self-assembly using automatic differentiation.
              </a>
            </td>
          <td>
            Adip Jhaveri, Spencer R. Loggia, Yian Qian, Margaret E Johnson
          </td>
          <td>2024-05-01</td>
          <td>Proceedings of the National Academy of Sciences of the United States of America</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Many complicated dynamical events may be broken down into simpler pieces and efficiently described by a system that shifts among a variety of conditionally dynamical modes. Building on switching linear dynamical systems, we develop a new model that extends the switching linear dynamical systems for better discovering these dynamical modes. In the proposed model, the linear dynamics of latent variables can be described by a higher-order vector autoregressive process, which makes it feasible to evaluate the higher-order dependency relationships in the dynamics. In addition, the transition of switching states is determined by a stick-breaking logistic regression, overcoming the limitation of a restricted geometric state duration and recovering the symmetric dependency between the switching states and the latent variables from asymmetric relationships. Furthermore, logistic regression evidence potentials can appear as conditionally Gaussian potentials by utilizing the Pólya-gamma augmentation strategy. Filtering and smoothing algorithms and Bayesian inference for parameter learning in the proposed model are presented. The utility and versatility of the proposed model are demonstrated on synthetic data and public functional magnetic resonance imaging data. Our model improves the current methods for learning the switching linear dynamical modes, which will facilitate the identification and assessment of the dynamics of complex systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f180f44aa0cab4e14882a44aef54b3e4ae757688" target='_blank'>
              Bayesian Inference of Recurrent Switching Linear Dynamical Systems with Higher-Order Dependence
              </a>
            </td>
          <td>
            Houxiang Wang, Jiaqing Chen
          </td>
          <td>2024-04-13</td>
          <td>Symmetry</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Two-Temperature molecular dynamics (2T-MD) is a common approach for describing how electrons contribute to the evolution of a damage cascade by addressing their role in the redistribution of energy in the system. However, inaccuracies in 2TMD's treatment of the high-energy particles have limited its utilisation. Here, we propose a reformulation of the traditional 2T-MD scheme to overcome this limitation by addressing the spurious double-interaction of high-energy atoms with electrons. We conduct a series of radiation damage cascades for 30, 50, and 100 keV primary knock-on atoms (PKA) in increasingly large cubic W cells. In the simulations, we employ our modified 2T-MD scheme along with other treatments of electron-phonon coupling to explore their impact on the cascade evolution and the number of remnant defects. The results suggest that with the proposed modification, 2T-MD simulations account for the temperature time evolution during the ballistic phase and remove arbitrary choices, thus providing a better description of the underlying physics of the damage process.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6e5184d18ca24a1be4a31ca6cea0e4915eec6f74" target='_blank'>
              A modified two temperature molecular dynamics (2T-MD) model for cascades.
              </a>
            </td>
          <td>
            Andres Rojano, Ryan Hunt, J. Crocombette, Samuel T Murphy
          </td>
          <td>2024-05-09</td>
          <td>Journal of physics. Condensed matter : an Institute of Physics journal</td>
          <td>0</td>
          <td>34</td>
        </tr>

        <tr id="Correlated systems represent a class of materials that are difficult to describe through traditional electronic structure methods. The computational demand to simulate the structural dynamics of such systems, with correlation effects considered, is substantial. Here, we investigate the structural dynamics of $f$- and $d$-electron correlated systems by integrating quantum embedding techniques with interatomic potentials derived from graph neural networks. For Cerium, a prototypical correlated $f$-electron system, we use Density Functional Theory with the Gutzwiller approximation to generate training data due to efficiency with which correlations effects are included for large multi-orbital systems. For Nickel Oxide, a prototypical correlated $d$-electron system, advancements in computational capabilities now permit the use of full Dynamical Mean Field Theory to obtain energies and forces. We train neural networks on this data to create a model of the potential energy surface, enabling rapid and effective exploration of structural dynamics. Utilizing these potentials, we delineate transition pathways between the $\alpha$, $\alpha'$, and $\alpha''$ phases of Cerium and predict the melting curve of Nickel Oxide. Our results demonstrate the potential of machine learning potentials to accelerate the study of strongly correlated systems, offering a scalable approach to explore and understand the complex physics governing these materials.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e35d69311259ea0ea3d365c723f9f96e744cf2b2" target='_blank'>
              Phase transitions of correlated systems from graph neural networks with quantum embedding techniques
              </a>
            </td>
          <td>
            Rishi Rao, Li Zhu
          </td>
          <td>2024-04-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Machine learning interatomic potentials (MLIPs) have become a workhorse of modern atomistic simulations, and recently published universal MLIPs, pre-trained on large datasets, have demonstrated remarkable accuracy and generalizability. However, the computational cost of MLIPs limits their applicability to chemically disordered systems requiring large simulation cells or to sample-intensive statistical methods. Here, we report the use of continuous and differentiable alchemical degrees of freedom in atomistic materials simulations, exploiting the fact that graph neural network MLIPs represent discrete elements as real-valued tensors. The proposed method introduces alchemical atoms with corresponding weights into the input graph, alongside modifications to the message-passing and readout mechanisms of MLIPs, and allows smooth interpolation between the compositional states of materials. The end-to-end differentiability of MLIPs enables efficient calculation of the gradient of energy with respect to the compositional weights. Leveraging these gradients, we propose methodologies for optimizing the composition of solid solutions towards target macroscopic properties and conducting alchemical free energy simulations to quantify the free energy of vacancy formation and composition changes. The approach offers an avenue for extending the capabilities of universal MLIPs in the modeling of compositional disorder and characterizing the phase stabilities of complex materials systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/311b2f006eaf9e656637d955e70bc7198b4793f8" target='_blank'>
              Interpolation and differentiation of alchemical degrees of freedom in machine learning interatomic potentials
              </a>
            </td>
          <td>
            Juno Nam, Rafael G'omez-Bombarelli
          </td>
          <td>2024-04-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Willems' fundamental lemma enables a trajectory-based characterization of linear systems through data-based Hankel matrices. However, in the presence of measurement noise, we ask: Is this noisy Hankel-based model expressive enough to re-identify itself? In other words, we study the output prediction accuracy from recursively applying the same persistently exciting input sequence to the model. We find an asymptotic connection to this self-consistency question in terms of the amount of data. More importantly, we also connect this question to the depth (number of rows) of the Hankel model, showing the simple act of reconfiguring a finite dataset significantly improves accuracy. We apply these insights to find a parsimonious depth for LQR problems over the trajectory space.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a5a8c3dd68d42cacef8f099fb744c61a43353a85" target='_blank'>
              Deep Hankel matrices with random elements
              </a>
            </td>
          <td>
            Nathan P. Lawrence, Philip D. Loewen, Shuyuan Wang, M. Forbes, R. B. Gopaluni
          </td>
          <td>2024-04-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>24</td>
        </tr>

        <tr id="A technical note aiming to offer deeper intuition for the LayerNorm function common in deep neural networks. LayerNorm is defined relative to a distinguished 'neural' basis, but it does more than just normalize the corresponding vector elements. Rather, it implements a composition -- of linear projection, nonlinear scaling, and then affine transformation -- on input activation vectors. We develop both a new mathematical expression and geometric intuition, to make the net effect more transparent. We emphasize that, when LayerNorm acts on an N-dimensional vector space, all outcomes of LayerNorm lie within the intersection of an (N-1)-dimensional hyperplane and the interior of an N-dimensional hyperellipsoid. This intersection is the interior of an (N-1)-dimensional hyperellipsoid, and typical inputs are mapped near its surface. We find the direction and length of the principal axes of this (N-1)-dimensional hyperellipsoid via the eigen-decomposition of a simply constructed matrix.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9b5d98880d73c9895cb3e33f18e26a11e64d0be2" target='_blank'>
              Geometry and Dynamics of LayerNorm
              </a>
            </td>
          <td>
            P. Riechers
          </td>
          <td>2024-05-07</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>11</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3ba863a2355eeb560dcea879c96cbc75572354ce" target='_blank'>
              Dimensionality reduction beyond neural subspaces with slice tensor component analysis.
              </a>
            </td>
          <td>
            Arthur Pellegrino, H. Stein, N. A. Cayco-Gajic
          </td>
          <td>2024-05-06</td>
          <td>Nature neuroscience</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id="Motivation Successfully predicting the development of biological systems can lead to advances in various research fields, such as cellular biology and epidemiology. While machine learning has proven its capabilities in generalizing the underlying non-linear dynamics of such systems, unlocking its predictive power is often restrained by the limited availability of large, curated datasets. To supplement real-world data, informing machine learning by transfer learning with data simulated from ordinary differential equations has emerged as a promising solution. However, the success of this approach highly depends on the designed characteristics of the synthetic data. Results We optimize dataset characteristics such as size, diversity, and noise of ordinary differential equation-based synthetic time series datasets in three relevant and representative biological systems. To achieve this, we here, for the first time, present a framework to systematically evaluate the influence of such design choices on transfer learning performance in one place. We achieve a performance improvement of up to 92% in mean absolute error for our optimized simulation-based transfer learning compared to non-informed deep learning. We find a strong interdependency between dataset size and diversity effects. The optimal transfer learning setting heavily relies on real-world data characteristics as well as its coherence with the synthetic data’s dynamics, emphasizing the relevance of such a framework. Availability and Implementation The code is available at https://github.com/DILiS-lab/opt-synthdata-4tl.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ae1c7d62233a0ff735ce7ae98aa19a9ca10c7ff1" target='_blank'>
              Optimizing ODE-derived Synthetic Data for Transfer Learning in Dynamical Biological Systems
              </a>
            </td>
          <td>
            Julian Zabbarov, Simon Witzke, Maximilian Kleissl, Pascal Iversen, Bernhard Y. Renard, Katharina Baum
          </td>
          <td>2024-03-29</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Autonomous driving presents a complex challenge, which is usually addressed with artificial intelligence models that are end-to-end or modular in nature. Within the landscape of modular approaches, a bio-inspired neural circuit policy model has emerged as an innovative control module, offering a compact and inherently interpretable system to infer a steering wheel command from abstract visual features. Here, we take a leap forward by integrating a variational autoencoder with the neural circuit policy controller, forming a solution that directly generates steering commands from input camera images. By substituting the traditional convolutional neural network approach to feature extraction with a variational autoencoder, we enhance the system's interpretability, enabling a more transparent and understandable decision-making process. In addition to the architectural shift toward a variational autoencoder, this study introduces the automatic latent perturbation tool, a novel contribution designed to probe and elucidate the latent features within the variational autoencoder. The automatic latent perturbation tool automates the interpretability process, offering granular insights into how specific latent variables influence the overall model's behavior. Through a series of numerical experiments, we demonstrate the interpretative power of the variational autoencoder-neural circuit policy model and the utility of the automatic latent perturbation tool in making the inner workings of autonomous driving systems more transparent.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2265db15d8eb56c3cbc7981ff8ed2fb5a154fe06" target='_blank'>
              Exploring Latent Pathways: Enhancing the Interpretability of Autonomous Driving with a Variational Autoencoder
              </a>
            </td>
          <td>
            Anass Bairouk, Mirjana Maras, Simon Herlin, Alexander Amini, Marc Blanchon, Ramin M. Hasani, Patrick Chareyre, Daniela Rus
          </td>
          <td>2024-04-02</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>23</td>
        </tr>

        <tr id="Intragenic translational heterogeneity describes the variation in translation at the level of transcripts for an individual gene. A factor that contributes to this source of variation is the mRNA structure. Both the composition of the thermodynamic ensemble, i.e., the stationary distribution of mRNA structures, and the switching dynamics between those play a role. The effect of the switching dynamics on intragenic translational heterogeneity remains poorly understood. We present a stochastic translation model that accounts for mRNA structure switching and is derived from a Markov model via approximate stochastic filtering. We assess the approximation on various timescales and provide a method to quantify how mRNA structure dynamics contributes to translational heterogeneity. With our approach, we allow quantitative information on mRNA switching from biophysical experiments or coarse-grain molecular dynamics simulations of mRNA structures to be included in gene regulatory chemical reaction network models without an increase in the number of species. Thereby, our model bridges a gap between mRNA structure kinetics and gene expression models, which we hope will further improve our understanding of gene regulatory networks and facilitate genetic circuit design.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a78de3fd00c6e921f2a8954038b6d97cd058ee30" target='_blank'>
              Effects of mRNA conformational switching on translational noise in gene circuits.
              </a>
            </td>
          <td>
            Mark Sinzger-D’Angelo, Maleen Hanst, Felix Reinhardt, Heinz Koeppl
          </td>
          <td>2024-04-04</td>
          <td>The Journal of chemical physics</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="The conventional wisdom of manifold learning is based on nonlinear dimensionality reduction techniques such as IsoMAP and locally linear embedding (LLE). We challenge this paradigm by exploiting the blessing of dimensionality. Our intuition is simple: it is easier to untangle a low-dimensional manifold in a higher-dimensional space due to its vastness, as guaranteed by Whitney embedding theorem. A new insight brought by this work is to introduce class labels as the context variables in the lifted higher-dimensional space (so supervised learning becomes unsupervised learning). We rigorously show that manifold untangling leads to linearly separable classifiers in the lifted space. To correct the inevitable overfitting, we consider the dual process of manifold untangling -- tangling or aliasing -- which is important for generalization. Using context as the bonding element, we construct a pair of manifold untangling and tangling operators, known as tangling-untangling cycle (TUC). Untangling operator maps context-independent representations (CIR) in low-dimensional space to context-dependent representations (CDR) in high-dimensional space by inducing context as hidden variables. The tangling operator maps CDR back to CIR by a simple integral transformation for invariance and generalization. We also present the hierarchical extensions of TUC based on the Cartesian product and the fractal geometry. Despite the conceptual simplicity, TUC admits a biologically plausible and energy-efficient implementation based on the time-locking behavior of polychronization neural groups (PNG) and sleep-wake cycle (SWC). The TUC-based theory applies to the computational modeling of various cognitive functions by hippocampal-neocortical systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/dc7225640501d773f8ba2ea925dd1a235335174c" target='_blank'>
              Tangling-Untangling Cycle for Efficient Learning
              </a>
            </td>
          <td>
            Xin Li
          </td>
          <td>2024-04-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="
 For Ising models with complex energy landscapes, whether the ground state can be found by neural networks depends heavily on the Hamming distance between the training datasets and the ground state. Despite the fact that various recently proposed generative models have shown good performance in solving Ising models, there is no adequate discussion on how to quantify their generalization capabilities. Here we design a Hamming distance regularizer in the framework of a class of generative models, variational autoregressive networks (VAN), to quantify the generalization capabilities of various network architectures combined with VAN. The regularizer can control the size of the overlaps between the ground state and the training datasets generated by networks, which, together with the success rates of finding the ground state, form a quantitative metric to quantify their generalization capabilities. We conduct numerical experiments on several prototypical network architectures combined with VAN, including feed-forward neural networks, recurrent neural networks, and graph neural networks, to quantify their generalization capabilities when solving Ising models. Moreover, considering the fact that the quantification of the generalization capabilities of networks on small-scale problems can be used to predict their relative performance on large-scale problems, our method is of great significance for assisting in the Neural Architecture Search field of searching for the optimal network architectures when solving large-scale Ising models.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e8b9e06ac83da223e4b3015fccc872930ade5074" target='_blank'>
              A method for quantifying the generalization capabilities of generative models for solving Ising models
              </a>
            </td>
          <td>
            Qunlong Ma, Zhi Ma, Ming Gao
          </td>
          <td>2024-03-22</td>
          <td>Mach. Learn. Sci. Technol.</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Neural Ordinary Differential Equations typically struggle to generalize to new dynamical behaviors created by parameter changes in the underlying system, even when the dynamics are close to previously seen behaviors. The issue gets worse when the changing parameters are unobserved, i.e., their value or influence is not directly measurable when collecting data. We introduce Neural Context Flow (NCF), a framework that encodes said unobserved parameters in a latent context vector as input to a vector field. NCFs leverage differentiability of the vector field with respect to the parameters, along with first-order Taylor expansion to allow any context vector to influence trajectories from other parameters. We validate our method and compare it to established Multi-Task and Meta-Learning alternatives, showing competitive performance in mean squared error for in-domain and out-of-distribution evaluation on the Lotka-Volterra, Glycolytic Oscillator, and Gray-Scott problems. This study holds practical implications for foundational models in science and related areas that benefit from conditional neural ODEs. Our code is openly available at https://github.com/ddrous/ncflow.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2c738e0450649ed6c04ff7e82d993987c381e35a" target='_blank'>
              Neural Context Flows for Learning Generalizable Dynamical Systems
              </a>
            </td>
          <td>
            Roussel Desmond Nzoyem, David A.W. Barton, Tom Deakin
          </td>
          <td>2024-05-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="We demonstrate the application of a recurrent neural network (RNN) to perform multistep and multivariate time-series performance predictions for stirred and static mixers as exemplars of complex multiphase systems. We employ two network architectures in this study, fitted with either long short-term memory and gated recurrent unit cells, which are trained on high-fidelity, three-dimensional, computational fluid dynamics simulations of the mixer performance, in the presence and absence of surfactants, in terms of drop size distributions and interfacial areas as a function of system parameters; these include physicochemical properties, mixer geometry, and operating conditions. Our results demonstrate that while it is possible to train RNNs with a single fully connected layer more efficiently than with an encoder–decoder structure, the latter is shown to be more capable of learning long-term dynamics underlying dispersion metrics. Details of the methodology are presented, which include data preprocessing, RNN model exploration, and methods for model performance visualization; an ensemble-based procedure is also introduced to provide a measure of the model uncertainty. The workflow is designed to be generic and can be deployed to make predictions in other industrial applications with similar time-series data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f097de3e6d9869ed978fbb5d99261ced7a9d1250" target='_blank'>
              Liquid–Liquid Dispersion Performance Prediction and Uncertainty Quantification Using Recurrent Neural Networks
              </a>
            </td>
          <td>
            Fuyue Liang, J. Valdés, Sibo Cheng, L. Kahouadji, Seungwon Shin, J. Chergui, D. Juric, Rossella Arcucci, O. K. Matar
          </td>
          <td>2024-04-22</td>
          <td>Industrial & Engineering Chemistry Research</td>
          <td>0</td>
          <td>22</td>
        </tr>

        <tr id="Recurrent neural networks (RNNs) hold immense potential for computations due to their Turing completeness and sequential processing capabilities, yet existing methods for their training encounter efficiency challenges. Backpropagation through time (BPTT), the prevailing method, extends the backpropagation (BP) algorithm by unrolling the RNN over time. However, this approach suffers from significant drawbacks, including the need to interleave forward and backward phases and store exact gradient information. Furthermore, BPTT has been shown to struggle with propagating gradient information for long sequences, leading to vanishing gradients. An alternative strategy to using gradient-based methods like BPTT involves stochastically approximating gradients through perturbation-based methods. This learning approach is exceptionally simple, necessitating only forward passes in the network and a global reinforcement signal as feedback. Despite its simplicity, the random nature of its updates typically leads to inefficient optimization, limiting its effectiveness in training neural networks. In this study, we present a new approach to perturbation-based learning in RNNs whose performance is competitive with BPTT, while maintaining the inherent advantages over gradient-based learning. To this end, we extend the recently introduced activity-based node perturbation (ANP) method to operate in the time domain, leading to more efficient learning and generalization. Subsequently, we conduct a range of experiments to validate our approach. Our results show similar performance, convergence time and scalability when compared to BPTT, strongly outperforming standard node perturbation and weight perturbation methods. These findings suggest that perturbation-based learning methods offer a versatile alternative to gradient-based methods for training RNNs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e337cf8a107322f291c0405aafc66e9c3338a978" target='_blank'>
              Perturbation-based Learning for Recurrent Neural Networks
              </a>
            </td>
          <td>
            Jesus Garcia Fernandez, Sander Keemink, M. Gerven
          </td>
          <td>2024-05-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>37</td>
        </tr>

        <tr id="Intracellular protein patterns regulate many vital cellular functions, such as the processing of spatiotemporal information or the control of shape deformations. To do so, pattern-forming systems can be sensitive to the cell geometry by means of coupling the protein dynamics on the cell membrane to dynamics in the cytosol. Recent studies demonstrated that modeling the cytosolic dynamics in terms of an averaged protein pool disregards possibly crucial aspects of the pattern formation, most importantly concentration gradients normal to the membrane. At the same time, the coupling of two domains (surface and volume) with different dimensions renders many standard tools for the numerical analysis of self-organizing systems inefficient. Here, we present a generic framework for projecting the cytosolic dynamics onto the lower-dimensional surface that respects the influence of cytosolic concentration gradients in static and evolving geometries. This method uses a priori physical information about the system to approximate the cytosolic dynamics by a small number of dominant characteristic concentration profiles (basis), akin to basis transformations of finite element methods. As a proof of concept, we apply our framework to a toy model for volume-dependent interrupted coarsening, evaluate the accuracy of the results for various basis choices, and discuss the optimal basis choice for biologically relevant systems. Our analysis presents an efficient yet accurate method for analysing pattern formation with surface-volume coupling in evolving geometries.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b91b3f501b4a2415b600b2d4111da38e4f987e79" target='_blank'>
              Dimensionality reduction in bulk-boundary reaction-diffusion systems
              </a>
            </td>
          <td>
            Tom Burkart, Benedikt J. Muller, Erwin Frey
          </td>
          <td>2024-05-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="We propose a novel discrete Poisson equation approach to estimate the statistical error of a broad class of numerical integrators for the underdamped Langevin dynamics. The statistical error refers to the mean square error of the estimator to the exact ensemble average with a finite number of iterations. With the proposed error analysis framework, we show that when the potential function $U(x)$ is strongly convex in $\mathbb R^d$ and the numerical integrator has strong order $p$, the statistical error is $O(h^{2p}+\frac1{Nh})$, where $h$ is the time step and $N$ is the number of iterations. Besides, this approach can be adopted to analyze integrators with stochastic gradients, and quantitative estimates can be derived as well. Our approach only requires the geometric ergodicity of the continuous-time underdamped Langevin dynamics, and relaxes the constraint on the time step.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3db5e743d8ace2d3799ad0aa392c1473c740afb1" target='_blank'>
              Statistical Error of Numerical Integrators for Underdamped Langevin Dynamics with Deterministic And Stochastic Gradients
              </a>
            </td>
          <td>
            , Zhennan Zhou
          </td>
          <td>2024-05-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/95cd06e0367aeed562804ddb1d04f7a33e88e53c" target='_blank'>
              Reconstructing the evolution history of networked complex systems
              </a>
            </td>
          <td>
            Junya Wang, Yi-Jiao Zhang, Cong Xu, Jiaze Li, Jiachen Sun, Jiarong Xie, Ling Feng, Tianshou Zhou, Yanqing Hu
          </td>
          <td>2024-03-22</td>
          <td>Nature Communications</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="This review aims to highlight the role that computational chemistry has played in advancing the supramolecular chemistry field. We demonstrated recent uses of computational methodologies to elucidate noncovalent interactions in various processes occurring in supramolecular systems. We also emphasized the contributions of these techniques to studying reactions within confined space, showing how computational methodologies help clarify the effects of reactivity and conformational locking. Furthermore, we underscore the utilization of Molecular Dynamics (MD) in elucidating dynamical processes, understanding temperature and pressure effects, and exploring conformational space within supramolecular chemistry. Finally, we highlight the impact that the age of machine learning has on computational chemistry, showing how these universal approximators can enhance existing methods, predict properties, and efficiently explore the chemical space encompassed by these complex systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/fd1c5b7f8cb8d1adcdbe8582456a714af1fc6c8c" target='_blank'>
              Supramolecular Chemistry: Exploring the Use of Electronic Structure, Molecular Dynamics, and Machine Learning Approaches
              </a>
            </td>
          <td>
            M. C. Colaço, Vinícius A Glitz, Amanda K. Jacobs, Vinicius Capriles Port, G. Caramori
          </td>
          <td>2024-05-03</td>
          <td>European Journal of Organic Chemistry</td>
          <td>0</td>
          <td>22</td>
        </tr>

        <tr id="Polyacrylonitrile (PAN) is an important commercial polymer, bearing atactic stereochemistry resulting from nonselective radical polymerization. As such, an accurate, fundamental understanding of governing interactions among PAN molecular units are indispensable to advance the design principles of final products at reduced processability costs. While ab initio molecular dynamics (AIMD) simulations can provide the necessary accuracy for treating key interactions in polar polymers such as dipole-dipole interactions and hydrogen bonding, and analyzing their influence on molecular orientation, their implementation is limited to small molecules only. Herein, we show that the neural network interatomic potentials (NNIP) that are trained on the small-scale AIMD data (acquired for oligomers) can be efficiently employed to examine the structures/properties at large scales (polymers). NNIP provides critical insight into intra- and interchain hydrogen bonding and dipolar correlations, and accurately predicts the amorphous bulk PAN structure validated by modeling the experimental X-ray structure factor. Furthermore, the NNIP-predicted PAN properties such as density and elastic modulus are in good agreement with their experimental values. Overall, the trend in the elastic modulus is found to correlate strongly with the PAN structural orientations encoded in Hermans orientation factor. This study enables the ability to predict the structure-property relations for PAN and analogs with sustainable ab initio accuracy across scales.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4f22984e90d2d7cdbc90ed9101e120784f552760" target='_blank'>
              Deep Learning Interatomic Potential Connects Molecular Structural Ordering to Macroscale Properties of Polyacrylonitrile (PAN) Polymer
              </a>
            </td>
          <td>
            Rajni Chahal, Michael D. Toomey, Logan T Kearney, Ada Sedova, Joshua T Damron, Amit K. Naskar, Santanu Roy
          </td>
          <td>2024-04-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="Bistable autonomous systems can be found inmany areas of science. When the intrinsic noise intensity is large, these systems exhibits stochastic transitions from onemetastable steady state to another. In electronic bistable memories, these transitions are failures, usually simulated in a Monte-Carlo fashion at a high CPU-time price. Existing closed-form formulas, relying on near-stable-steady-state approximations of the nonlinear system dynamics to estimate the mean transition time, have turned out inaccurate. Our contribution is twofold. From a unidimensional stochastic model of overdamped autonomous systems, we propose an extended Eyring-Kramers analytical formula accounting for both nonlinear drift and state-dependent white noise variance, rigorously derived from It\^o stochastic calculus. We also adapt it to practical system engineering situations where the intrinsic noise sources are hidden and can only be inferred from the fluctuations of observables measured in steady states. First numerical trials on an industrial electronic case study suggest that our approximate prediction formula achieve remarkable accuracy, outperforming previous non-Monte-Carlo approaches.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/225568d587ca00a55e72291cfa248b1a5edae4b1" target='_blank'>
              Predicting State Transitions in Autonomous Nonlinear Bistable Systems With Hidden Stochasticity
              </a>
            </td>
          <td>
            Léopold Van Brandt, Jean-Charles Delvenne
          </td>
          <td>2024-05-13</td>
          <td>IEEE Control Systems Letters</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="Ligand binding free energy simulations (LB-FES) that involve sampling of protein functional conformations have been longstanding challenges in research on molecular recognition. Particularly, modeling of the conformational transition pathway and design of the heuristic biasing mechanism are severe bottlenecks for the existing enhanced configurational sampling (ECS) methods. Inspired by the key role of hydration in regulating conformational dynamics of macromolecules, this report proposes a novel ECS approach that facilitates binding-associated structural dynamics by accelerated hydration transitions in combination with the λ-exchange of free energy perturbation (FEP). Two challenging protein-ligand binding processes involving large configurational transitions of the receptor are studied, with hydration transitions at binding sites accelerated by Hamiltonian-simulated annealing of the hydration layer. Without the need for pathway analysis or ad hoc barrier flattening potential, LB-FES were performed with FEP/λ-exchange molecular dynamics simulation at a minor overhead for annealing of the hydration layer. The LB-FES studies showed that the accelerated rehydration significantly enhances the collective conformational transitions of the receptor, and convergence of binding affinity calculations is obtained at a sweet-spot simulation time scale. Alchemical LB-FES with the proposed ECS strategy is free from the effort of trial and error for the setup and realizes efficient on-the-fly sampling for the collective functional response of the receptor and bound water and therefore presents a practical approach to high-throughput screening in drug discovery.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8c1709e5615db6d6e3f6802085c47a1773f9de24" target='_blank'>
              Studying the Collective Functional Response of a Receptor in Alchemical Ligand Binding Free Energy Simulations with Accelerated Solvation Layer Dynamics.
              </a>
            </td>
          <td>
            Wei Jiang
          </td>
          <td>2024-04-03</td>
          <td>Journal of chemical theory and computation</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="We propose the idea of using Kuramoto models (including their higher-dimensional generalizations) for machine learning over non-Euclidean data sets. These models are systems of matrix ODE's describing collective motions (swarming dynamics) of abstract particles (generalized oscillators) on spheres, homogeneous spaces and Lie groups. Such models have been extensively studied from the beginning of XXI century both in statistical physics and control theory. They provide a suitable framework for encoding maps between various manifolds and are capable of learning over spherical and hyperbolic geometries. In addition, they can learn coupled actions of transformation groups (such as special orthogonal, unitary and Lorentz groups). Furthermore, we overview families of probability distributions that provide appropriate statistical models for probabilistic modeling and inference in Geometric Deep Learning. We argue in favor of using statistical models which arise in different Kuramoto models in the continuum limit of particles. The most convenient families of probability distributions are those which are invariant with respect to actions of certain symmetry groups.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6140d9bf7e31537e13dcf3cf1b9d37e9b71d1eec" target='_blank'>
              Kuramoto Oscillators and Swarms on Manifolds for Geometry Informed Machine Learning
              </a>
            </td>
          <td>
            Vladimir Jacimovic
          </td>
          <td>2024-05-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Gradient boosting is a sequential ensemble method that fits a new base learner to the gradient of the remaining loss at each step. We propose a novel family of gradient boosting, Wasserstein gradient boosting, which fits a new base learner to an exactly or approximately available Wasserstein gradient of a loss functional on the space of probability distributions. Wasserstein gradient boosting returns a set of particles that approximates a target probability distribution assigned at each input. In probabilistic prediction, a parametric probability distribution is often specified on the space of output variables, and a point estimate of the output-distribution parameter is produced for each input by a model. Our main application of Wasserstein gradient boosting is a novel distributional estimate of the output-distribution parameter, which approximates the posterior distribution over the output-distribution parameter determined pointwise at each data point. We empirically demonstrate the superior performance of the probabilistic prediction by Wasserstein gradient boosting in comparison with various existing methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5cb518a493da32226d96110d42770c537d7fad6e" target='_blank'>
              Wasserstein Gradient Boosting: A General Framework with Applications to Posterior Regression
              </a>
            </td>
          <td>
            Takuo Matsubara
          </td>
          <td>2024-05-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Many biological functions are mediated by large complexes formed by multiple proteins and other cellular macromolecules. Recent progress in experimental structure determination, as well as in integrative modeling and protein structure prediction using deep learning approaches, has resulted in a rapid increase in the number of solved multiprotein assemblies. However, the assembly process of large complexes from their components is much less well-studied. We introduce a rapid computational structure-based (SB) model, GoCa, that allows to follow the assembly process of large multiprotein complexes based on a known native structure. Beyond existing SB Go̅-type models, it distinguishes between intra- and intersubunit interactions, allowing us to include coupled folding and binding. It accounts automatically for the permutation of identical subunits in a complex and allows the definition of multiple minima (native) structures in the case of proteins that undergo global transitions during assembly. The model is successfully tested on several multiprotein complexes. The source code of the GoCa program including a tutorial is publicly available on Github: https://github.com/ZachariasLab/GoCa. We also provide a web source that allows users to quickly generate the necessary input files for a GoCa simulation: https://goca.t38webservices.nat.tum.de.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2cebaaad028f848acd9c29cc1ccd3588581ad764" target='_blank'>
              Structure-Based Protein Assembly Simulations Including Various Binding Sites and Conformations
              </a>
            </td>
          <td>
            Luis J Walter, Patrick K. Quoika, Martin Zacharias
          </td>
          <td>2024-04-11</td>
          <td>Journal of Chemical Information and Modeling</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id="The Cluster Expansion (CE) Method encounters significant computational challenges in multicomponent systems due to the computational expense of generating training data through density functional theory (DFT) calculations. This work aims to refine the cluster and structure selection processes to mitigate these challenges. We introduce a novel method that significantly reduces the computational load associated with the calculation of fitting parameters. This method employs a Graph Neural Network (GNN) model, leveraging the M3GNet network, which is trained using a select subset of DFT calculations at each ionic step. The trained surrogate model excels in predicting the volume and energy of the final structure for a relaxation run. By employing this model, we sample thousands of structures and fit a CE model to the energies of these GNN-relaxed structures. This approach, utilizing a large training dataset, effectively reduces the risk of overfitting, yielding a CE model with a root-mean-square error (RMSE) below 10 meV/atom. We validate our method's effectiveness in two test cases: the (Cr,Hf,Mo,Ta,Ti,Zr)B$_2$ diboride system and the Refractory High-Entropy Alloy (HEA) AlHfNbTaTiZr system. Our findings demonstrate the significant advantages of integrating a GNN model, specifically the M3GNet network, with CE methods for the efficient predictive analysis of chemical ordering in High Entropy Materials. The accelerating capabilities of the hybrid ML-CE approach to investigate the evolution of Short Range Ordering (SRO) in a large number of stoichiometric systems. Finally, we show how it is possible to correlate the strength of chemical ordering to easily accessible alloy parameters.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f5219351bd8ccad549f8d6b4f54e61240ed06b24" target='_blank'>
              Deciphering Chemical Ordering in High Entropy Materials: A Machine Learning-Accelerated High-throughput Cluster Expansion Approach
              </a>
            </td>
          <td>
            Guillermo Vazquez, Daniel Sauceda, Raymundo Arr'oyave
          </td>
          <td>2024-03-27</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Ecology has been surprisingly slow to address the uncertainty and bias that results from using short-term time series to draw long-term inference. To improve our understanding of assumptions around the temporal structure of vital rates (e.g., survival, reproduction), we need tools that are feasible and capture longer-term, state-structured population dynamics. Here, we use inverse modelling of a set of integral projection models (IPMs) to show how demographic rates can be accurately reconstructed from state-structure fluctuations in a population time-series. We use a particle-filtering optimisation algorithm to fit vital rates from time-series of varying length, parameter combinations, priors, and life histories. We show how key life history traits such as generation time have little effect on the ability of our approach to accurately identify vital rates using state structure over time. Further, contrary to our expectations, the duration of our time-series data has relatively modest impact on the estimation of vital rates compared to the critical role of prior knowledge on vital rates. ur framework to estimate IPM vital rates highlights the potential of inverse models to extend time-series for demographic models, but also demonstrates that long-term time-series are not a perfect surrogate for detailed demographic inference. We discuss the need for more work exploring the conditions when inverse modelling is an adequate tool based on species traits.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0503619aae60fa2d6fc142d4d4797e4142a3bdb2" target='_blank'>
              Life Histories and Study Duration matter less than Prior Knowledge of Vital Rates to Inverse Integral Projection Models
              </a>
            </td>
          <td>
            Connor D. Bernard, Michael B. Bonsall, R. Salguero‐Gómez
          </td>
          <td>2024-04-10</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>36</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d63afa9ac9d835d94e1d88390467934811db53a5" target='_blank'>
              Task-oriented machine learning surrogates for tipping points of agent-based models
              </a>
            </td>
          <td>
            Gianluca Fabiani, N. Evangelou, Tianqi Cui, J. M. Bello-Rivas, Cristina P. Martin-Linares, Constantinos Siettos, I. Kevrekidis
          </td>
          <td>2024-05-15</td>
          <td>Nature Communications</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="We present an open-source MLatom@XACS software ecosystem for on-the-fly surface hopping nonadiabatic dynamics based on the Landau-Zener-Belyaev-Lebedev (LZBL) algorithm. The dynamics can be performed via Python API with a wide range of quantum mechanical (QM) and machine learning (ML) methods, including ab initio QM (CASSCF and ADC(2)), semi-empirical QM methods (e.g., AM1, PM3, OMx, and ODMx), and many types of machine learning potentials (e.g., KREG, ANI, and MACE). Combinations of QM and ML methods can also be used. While the user can build their own combinations, we provide AIQM1, which is based on {\Delta}-learning and can be used out of the box. We showcase how AIQM1 reproduces the isomerization quantum yield of trans-azobenzene at a low cost. We provide example scripts that, in a dozen lines, enable the user to obtain the final population plots by simply providing the initial geometry of a molecule. Thus, those scripts perform geometry optimization, normal mode calculations, initial condition sampling, parallel trajectories propagation, population analysis, and final result plotting. Given the capabilities of MLatom to be used for training different ML models, this ecosystem can be seamlessly integrated into the protocols building ML models for nonadiabatic dynamics. In the future, a deeper and more efficient integration of MLatom with Newton-X will enable vast range of functionalities for surface hopping dynamics, such as fewest-switches surface hopping, to facilitate similar workflows via the Python API.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/144cdb1694814fd9aa81ff6da82f03647595c8f6" target='_blank'>
              MLatom software ecosystem for surface hopping dynamics in Python with quantum mechanical and machine learning methods
              </a>
            </td>
          <td>
            Lina Zhang, Sebastian V. Pios, M. Martyka, Fuchun Ge, Yi-Fan Hou, Yuxinxin Chen, Lipeng Chen, Joanna Jankowska, M. Barbatti, Pavlo O. Dral
          </td>
          <td>2024-04-09</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>47</td>
        </tr>

        <tr id="This article presents an in-depth analysis and evaluation of artificial neural networks (ANNs) when applied to replicate trajectories in molecular dynamics (MD) simulations or other particle methods. This study focuses on several architectures—feedforward neural networks (FNNs), convolutional neural networks (CNNs), recurrent neural networks (RNNs), time convolutions (TCs), self-attention (SA), graph neural networks (GNNs), neural ordinary differential equation (ODENets), and an example of physics-informed machine learning (PIML) model—assessing their effectiveness and limitations in understanding and replicating the underlying physics of particle systems. Through this analysis, this paper introduces a comprehensive set of criteria designed to evaluate the capability of ANNs in this context. These criteria include the minimization of losses, the permutability of particle indices, the ability to predict trajectories recursively, the conservation of particles, the model’s handling of boundary conditions, and its scalability. Each network type is systematically examined to determine its strengths and weaknesses in adhering to these criteria. While, predictably, none of the networks fully meets all criteria, this study extends beyond the simple conclusion that only by integrating physics-based models into ANNs is it possible to fully replicate complex particle trajectories. Instead, it probes and delineates the extent to which various neural networks can “understand” and interpret aspects of the underlying physics, with each criterion targeting a distinct aspect of this understanding.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3d2cd2e98b8c0ad116f74af97b8583a17b803b5f" target='_blank'>
              Designing a set of criteria for evaluating artificial neural networks trained with physics-based data to replicate molecular dynamics and other particle method trajectories
              </a>
            </td>
          <td>
            Alessio Alexiadis
          </td>
          <td>2024-04-10</td>
          <td>Frontiers in Nanotechnology</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Replica exchange stochastic gradient Langevin dynamics (reSGLD) is an effective sampler for non-convex learning in large-scale datasets. However, the simulation may encounter stagnation issues when the high-temperature chain delves too deeply into the distribution tails. To tackle this issue, we propose reflected reSGLD (r2SGLD): an algorithm tailored for constrained non-convex exploration by utilizing reflection steps within a bounded domain. Theoretically, we observe that reducing the diameter of the domain enhances mixing rates, exhibiting a \emph{quadratic} behavior. Empirically, we test its performance through extensive experiments, including identifying dynamical systems with physical constraints, simulations of constrained multi-modal distributions, and image classification tasks. The theoretical and empirical findings highlight the crucial role of constrained exploration in improving the simulation efficiency.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b9dcbea8a77266cae6843675d2d6458ddb2259e5" target='_blank'>
              Constrained Exploration via Reflected Replica Exchange Stochastic Gradient Langevin Dynamics
              </a>
            </td>
          <td>
            Haoyang Zheng, Hengrong Du, Qi Feng, Wei Deng, Guang Lin
          </td>
          <td>2024-05-13</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="The Structure and TOpology Replica Molecular Mechanics (STORMM) code is a next-generation molecular simulation engine and associated libraries optimized for performance on fast, multicore central processor units (CPUs) and graphics processing units (GPUs) with independent memory and tens of thousands of threads. STORMM is built to run thousands of independent molecular mechanical calculations on a single GPU with novel implementations that optimize numerical precision, mathematical operations, throughput, and resource management. The libraries are built around accessible classes with detailed documentation, supporting fine-grained parallelism and algorithm development as well as macroscopic manipulations of groups of systems on and off of the GPU. A primary intention of the STORMM libraries is to provide developers of atomic simulation methods with access to a high-performance molecular mechanics engine with extensive facilities to prototype and develop bespoke tools aimed toward drug discovery applications. In its present state, STORMM delivers molecular dynamics simulations of small molecules and small proteins in implicit solvent with tens to hundreds of times the throughput of conventional codes. The engineering paradigm also transforms two of the most memory bandwidth-intensive aspects of condensed-phase dynamics, particle-mesh mapping and valence interactions, into compute-bound problems for several times the scalability of existing programs. Numerical methods for getting the most out of each bit of information present in stored coordinates and lookup tables are also presented, delivering improved accuracy over methods implemented in other molecular dynamics engines. The open-source code is released under the MIT license.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9bb44ffc16812efc47c603b8135aae83b9b92f70" target='_blank'>
              STORMM: Structure and TOpology Replica Molecular Mechanics for chemical simulations
              </a>
            </td>
          <td>
            David S. Cerutti, Rafal P. Wiewiora, Simon Boothroyd, Woody Sherman
          </td>
          <td>2024-03-28</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id="We present a neural-network-based high-throughput molecular conformer-generation algorithm. A chemical graph-convolutional network is trained to predict low-energy conformers in internal coordinate representation (bond lengths, bond, and torsion angles), starting from two-dimensional (2D) chemical topology. Generative neural network (NN) architecture performs denoising from torsion space, producing conformer ensembles with populations that are well correlated with torsion energy profiles. Short force-field-based energy minimization is applied to refine final conformers. All computation-intensive stages of the algorithm are GPU-optimized. The procedure (termed GINGER) is benchmarked on a commonly used test set of bioactive three-dimensional (3D) conformers from the PDB. We demonstrate highly competitive results in conformer recovery and throughput rates suitable for giga-scale compound library processing. A web server that allows interactive conformer ensemble generation by GINGER and their viewing is made freely available at https://www.molsoft.com/gingerdemo.html.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/136b29e725e610657a9f961a3782f7a77409c259" target='_blank'>
              Efficient Generation of Conformer Ensembles Using Internal Coordinates and a Generative Directional Graph Convolution Neural Network.
              </a>
            </td>
          <td>
            E. Raush, R. Abagyan, M. Totrov
          </td>
          <td>2024-04-26</td>
          <td>Journal of chemical theory and computation</td>
          <td>0</td>
          <td>46</td>
        </tr>

        <tr id="Spectrum-structure correlation is playing an increasingly crucial role in spectral analysis and has undergone significant development in recent decades. With the advancement of spectrometers, the high-throughput detection triggers the explosive growth of spectral data, and the research extension from small molecules to biomolecules accompanies massive chemical space. Facing the evolving landscape of spectrum-structure correlation, conventional chemometrics becomes ill-equipped, and deep learning assisted chemometrics rapidly emerges as a flourishing approach with superior ability of extracting latent features and making precise predictions. In this review, the molecular and spectral representations and fundamental knowledge of deep learning are first introduced. We then summarize the development of how deep learning assist to establish the correlation between spectrum and molecular structure in the recent 5 years, by empowering spectral prediction (i.e., forward structure-spectrum correlation) and further enabling library matching and de novo molecular generation (i.e., inverse spectrum-structure correlation). Finally, we highlight the most important open issues persisted with corresponding potential solutions. With the fast development of deep learning, it is expected to see ultimate solution of establishing spectrum-structure correlation soon, which would trigger substantial development of various disciplines.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9fdd05d270f40056b0eea65d0b96bd1a8fff8e75" target='_blank'>
              Deep Learning-Assisted Spectrum-Structure Correlation: State-of-the-Art and Perspectives.
              </a>
            </td>
          <td>
            Xinyu Lu, Hao-Ping Wu, Hao Ma, Hui Li, Jia Li, Yan-Ti Liu, Zheng-Yan Pan, Yi Xie, Lei Wang, Bin Ren, Guo-kun Liu
          </td>
          <td>2024-04-25</td>
          <td>Analytical chemistry</td>
          <td>0</td>
          <td>14</td>
        </tr>

        <tr id="Identifying optimal reaction coordinates for complex conformational changes and protein folding remains an outstanding challenge. This study combines collective variable (CV) discovery based on chemical intuition and machine learning with enhanced sampling to converge the folding free energy landscape of lasso peptides, a unique class of natural products with knot-like tertiary structures. This knotted scaffold imparts remarkable stability, making lasso peptides resistant to proteolytic degradation, thermal denaturation, and extreme pH conditions. Although their direct synthesis would enable therapeutic design, it has not yet been possible due to the improbable occurrence of spontaneous lasso folding. Thus, simulations characterizing the folding propensity are needed to identify strategies for increasing access to the lasso architecture by stabilizing the pre-lasso ensemble before isopeptide bond formation. Herein, harmonic linear discriminant analysis (HLDA) is combined with metadynamics-enhanced sampling to discover CVs capable of distinguishing the pre-lasso fold and converging the folding propensity. Intuitive CVs are compared to iterative rounds of HLDA to identify CVs that not only accomplish these goals for one lasso peptide but also seem to be transferable to others, establishing a protocol for the identification of folding reaction coordinates for lasso peptides.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7edd092c257f03c84c515e356f5108514e7a2830" target='_blank'>
              One Descriptor to Fold Them All: Harnessing Intuition and Machine Learning to Identify Transferable Lasso Peptide Reaction Coordinates.
              </a>
            </td>
          <td>
            Gabriel C. A. da Hora, Myongin Oh, John D. M. Nguyen, Jessica M J Swanson
          </td>
          <td>2024-04-03</td>
          <td>The journal of physical chemistry. B</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Even at low temperatures, metal nanoparticles (NPs) possess atomic dynamics that are key for their properties but challenging to elucidate. Recent experimental advances allow obtaining atomic-resolution snapshots of the NPs in realistic regimes, but data acquisition limitations hinder the experimental reconstruction of the atomic dynamics present within them. Molecular simulations have the advantage that these allow directly tracking the motion of atoms over time. However, these typically start from ideal/perfect NP structures and, suffering from sampling limits, provide results that are often dependent on the initial/putative structure and remain purely indicative. Here, by combining state-of-the-art experimental and computational approaches, how it is possible to tackle the limitations of both approaches and resolve the atomistic dynamics present in metal NPs in realistic conditions is demonstrated. Annular dark-field scanning transmission electron microscopy enables the acquisition of ten high-resolution images of an Au NP at intervals of 0.6 s. These are used to reconstruct atomistic 3D models of the real NP used to run ten independent molecular dynamics simulations. Machine learning analyses of the simulation trajectories allow resolving the real-time atomic dynamics present within the NP. This provides a robust combined experimental/computational approach to characterize the structural dynamics of metal NPs in realistic conditions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/dfa2f5b30f588d1970bed4e4f904745133c7c756" target='_blank'>
              Sampling Real-Time Atomic Dynamics in Metal Nanoparticles by Combining Experiments, Simulations, and Machine Learning.
              </a>
            </td>
          <td>
            M. Cioni, Massimo Delle Piane, D. Polino, Daniele Rapetti, M. Crippa, E. A. Irmak, Sandra Van Aert, S. Bals, Giovanni M Pavan
          </td>
          <td>2024-04-24</td>
          <td>Advanced science</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="A deep neural network (DNN) has been developed to generate the distributions of nuclear charge density, utilizing the training data from the relativistic density functional theory and incorporating available experimental charge radii of 1014 nuclei into the loss function. The DNN achieved a root-mean-square (rms) deviation of 0.0193 fm for charge radii on its validation set. Furthermore, the DNN can improve the description in both the tail and central regions of the charge density, enhancing agreement with experimental findings. The model's predictive capability has been further validated by its agreement with recent experimental data on charge radii. Finally, this refined model is employed to predict the charge density distributions in a wider range of nuclide chart, and the parameterized charge densities, charge radii, and higher-order moments of charge density distributions are given, providing a robust reference for future experimental investigations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/031a2fae151ebbf5b3dbcf66018cedeed367d562" target='_blank'>
              Global prediction of nuclear charge density distributions using deep neural network
              </a>
            </td>
          <td>
            Tian-Shuai Shang, H. Xie, Jian Li, Haozhao Liang
          </td>
          <td>2024-04-15</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>2</td>
        </tr>

        <tr id="The macroscopic behaviors of materials are determined by interactions that occur at multiple lengths and time scales. Depending on the application, describing, predicting, and understanding these behaviors require models that rely on insights from electronic and atomic scales. In such cases, classical simplified approximations at those scales are insufficient, and quantum-based modeling is required. In this paper, we study how quantum effects can modify the mechanical properties of systems relevant to materials engineering. We base our study on a high-fidelity modeling framework that combines two computationally efficient models rooted in quantum first principles: Density Functional Tight Binding (DFTB) and many-body dispersion (MBD). The MBD model is applied to accurately describe non-covalent van der Waals interactions. Through various benchmark applications, we demonstrate the capabilities of this framework and the limitations of simplified modeling. We provide an open-source repository containing all codes, datasets, and examples presented in this work. This repository serves as a practical toolkit that we hope will support the development of future research in effective large-scale and multiscale modeling with quantum-mechanical fidelity.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/208f45f5ead7398b0a11d066742bca5eb6eb072f" target='_blank'>
              Quantum-informed simulations for mechanics of materials: DFTB+MBD framework
              </a>
            </td>
          <td>
            Zhaoxiang Shen, Ra'ul I. Sosa, St'ephane P.A. Bordas, Alexandre Tkatchenko, Jakub Lengiewicz
          </td>
          <td>2024-04-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Parallel tempering molecular dynamics simulation, also known as temperature replica exchange simulation, is a popular enhanced sampling method used to study biomolecular systems. This method makes it possible to calculate the free energy differences between states of the system for a series of temperatures. We developed a method to easily calculate the errors (standard errors or confidence intervals) of these predictions using a modified version of our recently introduced JumpCount method. The number of transitions between states (e.g., protein folding events) is counted for each temperature. This number of transitions, together with the temperature, fully determines the value of the standard error or the confidence interval of the free energy difference. We also address the issue of convergence in the situation where all replicas start from one state by developing an estimator of the equilibrium constant from simulations that are not fully equilibrated. The prerequisite of the method is the Markovianity of the process studied.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b93824aea004c2366ffae35a7e55f7d7763a2efc" target='_blank'>
              Uncertainties of predictions from temperature replica exchange simulations.
              </a>
            </td>
          <td>
            Pavel Kříž, Jan Beránek, V. Spiwok
          </td>
          <td>2024-05-10</td>
          <td>The Journal of chemical physics</td>
          <td>0</td>
          <td>24</td>
        </tr>

        <tr id="To achieve chemical accuracy in free energy calculations, it is necessary to accurately describe the system's potential energy surface and efficiently sample configurations from its Boltzmann distribution. While neural network potentials (NNPs) have shown significantly higher accuracy than classical molecular mechanics (MM) force fields, they have a limited range of applicability and are considerably slower than MM potentials, often by orders of magnitude. To address this challenge, Rufa et al. [Rufa et al. bioRxiv 2020, 10.1101/2020.07.29.227959.] suggested a two-stage approach that uses a fast and established MM alchemical energy protocol, followed by reweighting the results using NNPs, known as endstate correction or indirect free energy calculation. This study systematically investigates the accuracy and robustness of reweighting from an MM reference to a neural network target potential (ANI-2x) for an established data set in vacuum, using single-step free-energy perturbation (FEP) and nonequilibrium (NEQ) switching simulation. We assess the influence of longer switching lengths and the impact of slow degrees of freedom on outliers in the work distribution and compare the results to those of multistate equilibrium free energy simulations. Our results demonstrate that free energy calculations between NNPs and MM potentials should be preferably performed using NEQ switching simulations to obtain accurate free energy estimates. NEQ switching simulations between the MM potentials and NNPs are efficient, robust, and trivial to implement.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/149f0e354cd11d6865d048988faac37680c26d61" target='_blank'>
              Reweighting from Molecular Mechanics Force Fields to the ANI-2x Neural Network Potential.
              </a>
            </td>
          <td>
            S. Tkaczyk, Johannes Karwounopoulos, Andreas Schöller, H. L. Woodcock, Thierry Langer, S. Boresch, M. Wieder
          </td>
          <td>2024-03-25</td>
          <td>Journal of chemical theory and computation</td>
          <td>1</td>
          <td>32</td>
        </tr>

        <tr id="The use of machine learning algorithms to investigate phase transitions in physical systems is a valuable way to better understand the characteristics of these systems. Neural networks have been used to extract information of phases and phase transitions directly from many-body configurations. However, one limitation of neural networks is that they require the definition of the model architecture and parameters previous to their application, and such determination is itself a difficult problem. In this paper, we investigate for the first time the relationship between the accuracy of neural networks for information of phases and the network configuration (that comprises the architecture and hyperparameters). We formulate the phase analysis as a regression task, address the question of generating data that reflects the different states of the physical system, and evaluate the performance of neural architecture search for this task. After obtaining the optimized architectures, we further implement smart data processing and analytics by means of neuron coverage metrics, assessing the capability of these metrics to estimate phase transitions. Our results identify the neuron coverage metric as promising for detecting phase transitions in physical systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b8819fbe666a86bbd1778a2812240835c4b28b78" target='_blank'>
              Identifying phase transitions in physical systems with neural networks: a neural architecture search perspective
              </a>
            </td>
          <td>
            R. C. Terin, Z. G. Arenas, Roberto Santana
          </td>
          <td>2024-04-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Solid-state electrolytes mark a significant leap forward in the field of electrochemical energy storage, offering improved safety and efficiency compared to conventional liquid electrolytes. Among these, antiperovskite electrolytes, particularly those based on Li and Na, have emerged as promising candidates due to their superior ionic conductivity and straightforward synthesis processes. This study focuses on the amorphous phase of antiperovskite Na$_3$OCl, assessing its structural properties through a combination of first-principles molecular dynamics (FPMD) and machine learning interatomic potential (MLIP) simulations. Our comprehensive analysis spans models ranging from 135 to 3645 atoms, allowing for a detailed examination of X-ray and neutron structure factors, total and partial pair correlation functions, coordination numbers, and structural unit distributions. We demonstrate the minimal, albeit partially present, size effects on these structural features and validate the accuracy of the MLIP model in reproducing the intricate details of the amorphous Na$_3$OCl structure described at the FPMD level.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/15cace58d7bceac0ad577874f894a1c49af25d90" target='_blank'>
              Structural properties of amorphous Na$_3$OCl electrolyte by first-principles and machine learning molecular dynamics
              </a>
            </td>
          <td>
            Tan Pham, Young-Han Shin, Mohammed Guerboub, Steve Dave, Wansi Wendj, Mauro Boero, C. Massobrio, G. Ori, A. Bouzid, C. Tugène
          </td>
          <td>2024-04-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>32</td>
        </tr>

        <tr id="Designing polymers with high intrinsic thermal conductivity (TC) is critically important for the thermal management of organic electronics and photonics. However, this is a challenging task owing to the diversity of the chemical space and the barriers to advanced synthetic experiments/characterization techniques for polymers. In this Tutorial, the fundamentals and implementation of combining classical molecular dynamics simulation and machine learning (ML) for the development of polymers with high TC are comprehensively introduced. We begin by describing the core components of a universal ML framework, involving polymer data sets, property calculators, feature engineering, and informatics algorithms. Then, the process of constructing interpretable regression algorithms for TC prediction is introduced, aiming to extract the underlying relationships between microstructures and TCs for polymers. We also explore the design of sequence-ordered polymers with high TC using lightweight and mainstream active learning algorithms. Lastly, we conclude by addressing the current limitations and suggesting potential avenues for future research on this topic.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0708a50ec706d90922ba3332d41b7cefc72b4459" target='_blank'>
              Tutorial: AI-assisted exploration and active design of polymers with high intrinsic thermal conductivity
              </a>
            </td>
          <td>
            Xiang Huang, Shenghong Ju
          </td>
          <td>2024-03-23</td>
          <td>Journal of Applied Physics</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Widespread deployment of societal-scale machine learning systems necessitates a thorough understanding of the resulting long-term effects these systems have on their environment, including loss of trustworthiness, bias amplification, and violation of AI safety requirements. We introduce a repeated learning process to jointly describe several phenomena attributed to unintended hidden feedback loops, such as error amplification, induced concept drift, echo chambers and others. The process comprises the entire cycle of obtaining the data, training the predictive model, and delivering predictions to end-users within a single mathematical model. A distinctive feature of such repeated learning setting is that the state of the environment becomes causally dependent on the learner itself over time, thus violating the usual assumptions about the data distribution. We present a novel dynamical systems model of the repeated learning process and prove the limiting set of probability distributions for positive and negative feedback loop modes of the system operation. We conduct a series of computational experiments using an exemplary supervised learning problem on two synthetic data sets. The results of the experiments correspond to the theoretical predictions derived from the dynamical model. Our results demonstrate the feasibility of the proposed approach for studying the repeated learning processes in machine learning systems and open a range of opportunities for further research in the area.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bbdf526001c151c67507de963a0c683064b1f630" target='_blank'>
              A Mathematical Model of the Hidden Feedback Loop Effect in Machine Learning Systems
              </a>
            </td>
          <td>
            Andrey Veprikov, Alexander Afanasiev, Anton Khritankov
          </td>
          <td>2024-05-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Stochastic reaction-diffusion models are employed to represent many complex physical, biological, societal, and ecological systems. The macroscopic reaction rates describing the large-scale kinetics in such systems are effective, scale-dependent parameters that need to be either measured experimentally or computed using a microscopic model. In a Monte Carlo simulation of stochastic reaction-diffusion systems, microscopic probabilities for specific events to happen serve as the input control parameters. Finding the functional dependence of emergent macroscopic rates on the microscopic probabilities is a difficult problem, and there is no systematic analytical way to achieve this goal. Therefore, we introduce a straightforward numerical method of using Monte Carlo simulations to evaluate the macroscopic reaction rates by directly obtaining the count statistics of how many events occur per simulation time step. Our technique is first tested on well-understood fundamental examples, namely restricted birth processes, diffusion-limited two-particle coagulation, and two-species pair annihilation kinetics. Next we utilize the thus gained experience to investigate how the microscopic algorithmic probabilities become coarse-grained into effective macroscopic rates in more complex model systems such as the Lotka--Volterra model for predator-prey competition and coexistence, as well as the rock-paper-scissors or cyclic Lotka--Volterra model as well as its May--Leonard variant that capture population dynamics with cyclic dominance motifs. Thereby we achieve a deeper understanding of coarse-graining in spatially extended stochastic reaction systems and the nontrivial relationships between the associated microscopic and macroscopic model parameters. The proposed technique should generally provide a useful means to better fit Monte Carlo simulation results to experimental or observational data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0cea07da7c5d93142d9d4556a95260861e8653ef" target='_blank'>
              Computing macroscopic reaction rates in reaction-diffusion systems using Monte Carlo simulations
              </a>
            </td>
          <td>
            M. Swailem, U. Tauber
          </td>
          <td>2024-04-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>21</td>
        </tr>

        <tr id="A machine-learned interatomic potential for Ge-rich Ge$_x$Te alloys has been developed aiming at uncovering the kinetics of phase separation and crystallization in these materials. The results are of interest for the operation of embedded phase change memories which exploits Ge-enrichment of GeSbTe alloys to raise the crystallization temperature. The potential is generated by fitting a large database of energies and forces computed within Density Functional Theory with the neural network scheme implemented in the DeePMD-kit package. The potential is highly accurate and suitable to describe the structural and dynamical properties of the liquid, amorphous and crystalline phases of the wide range of compositions from pure Ge and stoichiometric GeTe to the Ge-rich Ge$_2$Te alloy. Large scale molecular dynamics simulations revealed a crystallization mechanism which depends on temperature. At 600 K, segregation of most of Ge in excess occurs on the ns time scale followed by crystallization of nearly stoichiometric GeTe regions. At 500 K, nucleation of crystalline GeTe occurs before phase separation, followed by a slow crystal growth due to the concurrent expulsion of Ge in excess.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a64ef038eca4073ae762ab8e889a426dbaec37ce" target='_blank'>
              Unveiling the crystallization kinetics in Ge-rich Ge$_x$Te alloys by large scale simulations with a machine-learned interatomic potential
              </a>
            </td>
          <td>
            Dario Baratella, O. A. E. Kheir, Marco Bernasconi
          </td>
          <td>2024-04-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Molecular dynamics (MD) simulations have transformed our understanding of the nanoscale, driving breakthroughs in materials science, computational chemistry, and several other fields, including biophysics and drug design. Even on exascale supercomputers, however, runtimes are excessive for systems and timescales of scientific interest. Here, we demonstrate strong scaling of MD simulations on the Cerebras Wafer-Scale Engine. By dedicating a processor core for each simulated atom, we demonstrate a 179-fold improvement in timesteps per second versus the Frontier GPU-based Exascale platform, along with a large improvement in timesteps per unit energy. Reducing every year of runtime to two days unlocks currently inaccessible timescales of slow microstructure transformation processes that are critical for understanding material behavior and function. Our dataflow algorithm runs Embedded Atom Method (EAM) simulations at rates over 270,000 timesteps per second for problems with up to 800k atoms. This demonstrated performance is unprecedented for general-purpose processing cores.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/81e28f559db0fb721d293df59961c7322e5ae221" target='_blank'>
              Breaking the Molecular Dynamics Timescale Barrier Using a Wafer-Scale System
              </a>
            </td>
          <td>
            Kylee Santos, Stan Moore, Tomas Oppelstrup, Amirali Sharifian, I. Sharapov, Aidan Thompson, D. Kalchev, Danny Perez, Robert Schreiber, Scott Pakin, Edgar A Leon, J. Laros, Michael James, S. Rajamanickam
          </td>
          <td>2024-05-13</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>25</td>
        </tr>

        <tr id="Ab initio molecular dynamics (AIMD) simulations have become an important tool used in the construction of equations of state (EOS) tables for warm dense matter. Due to computational costs, only a limited number of system state conditions can be simulated, and the remaining EOS surface must be interpolated for use in radiation-hydrodynamic simulations of experiments. In this work, we develop a thermodynamically consistent EOS model that utilizes a physics-informed machine learning approach to implicitly learn the underlying Helmholtz free-energy from AIMD generated energies and pressures. The model, referred to as PIML-EOS, was trained and tested on warm dense polystyrene producing a fit within a 1% relative error for both energy and pressure and is shown to satisfy both the Maxwell and Gibbs–Duhem relations. In addition, we provide a path toward obtaining thermodynamic quantities, such as the total entropy and chemical potential (containing both ionic and electronic contributions), which are not available from current AIMD simulations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e5903ff595ab92c73a50349b1587f2fdc6f76bdd" target='_blank'>
              The development of thermodynamically consistent and physics-informed equation-of-state model through machine learning
              </a>
            </td>
          <td>
            J. Hinz, Dayou Yu, Deep Shankar Pandey, Hitesh Sapkota, Qi Yu, D. Mihaylov, V. V. Karasiev, S. Hu
          </td>
          <td>2024-05-07</td>
          <td>APL Machine Learning</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="A linear regression-based machine learned interatomic potential (MLIP) was developed for the silicon-carbon system. The MLIP was predominantly trained on structures discovered through a genetic algorithm, encompassing the entire silicon-carbon composition space, and uses as its foundation the Ultra-Fast Force Fields (UF3) formulation. To improve MLIP performance, the learning algorithm was modified to include higher spline interpolation resolution in regions with large potential energy surface curvature. The developed MLIP demonstrates exceptional predictive performance, accurately estimating energies and forces for structures across the silicon-carbon composition and configuration space. The MLIP predicts mechanical properties of SiC with high precision and captures fundamental volume-pressure and volume-temperature relationships. Uniquely, this silicon-carbon MLIP is adept at modeling complex high-temperature phenomena, including the peritectic decomposition of SiC and carbon dimer formation during SiC surface reconstruction, which cannot be captured with prior classical interatomic potentials for this material.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d9d0964d0fd4605569956cdfd63ed127b8ebab2f" target='_blank'>
              A Genetic Algorithm Trained Machine-Learned Interatomic Potential for the Silicon-Carbon System
              </a>
            </td>
          <td>
            Michael MacIsaac, Salil Ashish Bavdekar, D. Spearot, G. Subhash
          </td>
          <td>2024-03-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>51</td>
        </tr>

        <tr id="All-atom simulations are a powerful approach to study the structure and dynamics of biological membranes. However, sampling the atomic configurations of inhomogeneous membranes can be challenging due to the slow lateral diffusion of the various constituents. To address this issue, a hybrid nonequilibrium molecular dynamics Monte Carlo (neMD/MC) simulation method is proposed in which randomly chosen lipid molecules are swapped to generate configurations that are subsequently accepted or rejected according to a Metropolis criterion based on the alchemical work for the attempted swap calculated via a short trajectory. A dual-topology framework constraining the common atoms of the exchanging molecules yields a good acceptance probability using switching trajectories as short as 10 ps. The performance of the hybrid neMD/MC algorithm and its ability to sample the distribution of lipids near a transmembrane helix carrying a net charge are illustrated for a binary mixture of charged and zwitterionic lipids.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e3a18df5ce4330a70e39617627c14848644c28e0" target='_blank'>
              Configurational Sampling of All-Atom Solvated Membranes Using Hybrid Nonequilibrium Molecular Dynamics Monte Carlo Simulations.
              </a>
            </td>
          <td>
            Florence Szczepaniak, F. Dehez, Benoı T Roux
          </td>
          <td>2024-04-01</td>
          <td>The journal of physical chemistry letters</td>
          <td>0</td>
          <td>30</td>
        </tr>

        <tr id="Recent work has found that sparse autoencoders (SAEs) are an effective technique for unsupervised discovery of interpretable features in language models' (LMs) activations, by finding sparse, linear reconstructions of LM activations. We introduce the Gated Sparse Autoencoder (Gated SAE), which achieves a Pareto improvement over training with prevailing methods. In SAEs, the L1 penalty used to encourage sparsity introduces many undesirable biases, such as shrinkage -- systematic underestimation of feature activations. The key insight of Gated SAEs is to separate the functionality of (a) determining which directions to use and (b) estimating the magnitudes of those directions: this enables us to apply the L1 penalty only to the former, limiting the scope of undesirable side effects. Through training SAEs on LMs of up to 7B parameters we find that, in typical hyper-parameter ranges, Gated SAEs solve shrinkage, are similarly interpretable, and require half as many firing features to achieve comparable reconstruction fidelity.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bbf218fd97d3c18801eb6eb09345bb38e7bcc871" target='_blank'>
              Improving Dictionary Learning with Gated Sparse Autoencoders
              </a>
            </td>
          <td>
            Senthooran Rajamanoharan, Arthur Conmy, Lewis Smith, Tom Lieberum, Vikrant Varma, J'anos Kram'ar, Rohin Shah, Neel Nanda
          </td>
          <td>2024-04-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="Machine learning interatomic potentials (MLIPs) have introduced a new paradigm for atomic simulations. Recent advancements have seen the emergence of universal MLIPs (uMLIPs) that are pre-trained on diverse materials datasets, providing opportunities for both ready-to-use universal force fields and robust foundations for downstream machine learning refinements. However, their performance in extrapolating to out-of-distribution complex atomic environments remains unclear. In this study, we highlight a consistent potential energy surface (PES) softening effect in three uMLIPs: M3GNet, CHGNet, and MACE-MP-0, which is characterized by energy and force under-prediction in a series of atomic-modeling benchmarks including surfaces, defects, solid-solution energetics, phonon vibration modes, ion migration barriers, and general high-energy states. We find that the PES softening behavior originates from a systematic underprediction error of the PES curvature, which derives from the biased sampling of near-equilibrium atomic arrangements in uMLIP pre-training datasets. We demonstrate that the PES softening issue can be effectively rectified by fine-tuning with a single additional data point. Our findings suggest that a considerable fraction of uMLIP errors are highly systematic, and can therefore be efficiently corrected. This result rationalizes the data-efficient fine-tuning performance boost commonly observed with foundational MLIPs. We argue for the importance of a comprehensive materials dataset with improved PES sampling for next-generation foundational MLIPs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/448cca88fdf0f1984d79d8e2207d2ca949bc8ad0" target='_blank'>
              Overcoming systematic softening in universal machine learning interatomic potentials by fine-tuning
              </a>
            </td>
          <td>
            Bowen Deng, Yunyeong Choi, Peichen Zhong, Janosh Riebesell, Shashwat Anand, Zhuohan Li, KyuJung Jun, Kristin A. Persson, G. Ceder
          </td>
          <td>2024-05-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>146</td>
        </tr>

        <tr id="Host-guest interactions are important to the design of pharmaceuticals and, more broadly, to soft materials as they can enable targeted, strong, and specific interactions between molecules. The binding process between the host and guest may be classified as a "rare event" when viewing the system at atomic scales, such as those explored in molecular dynamics simulations. To obtain equilibrium binding conformations and dissociation constants from these simulations, it is essential to resolve these rare events. Advanced sampling methods such as the adaptive biasing force (ABF) promote the occurrence of less probable configurations in a system, therefore facilitating the sampling of essential collective variables that characterize the host-guest interactions. Here, we present the application of ABF to a rod-cavitand coarse-grained model of host-guest systems to acquire the potential of mean force. We show that the employment of ABF enables the computation of the configurational and thermodynamic properties of bound and unbound states, including the free energy landscape. Moreover, we identify important dynamic bottlenecks that limit sampling and discuss how these may be addressed in more general systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/656a51ddb4aac8ba68559d9d543be60e90c7bfec" target='_blank'>
              Calculating Binding Free Energies in Model Host-Guest Systems with Unrestrained Advanced Sampling.
              </a>
            </td>
          <td>
            Andrew V Marquardt, Mohsenzadeh Farshad, J. Whitmer
          </td>
          <td>2024-04-18</td>
          <td>Journal of chemical theory and computation</td>
          <td>0</td>
          <td>20</td>
        </tr>

        <tr id="MiMiC is a framework for performing multiscale simulations, where individual subsystems are handled at different resolutions and/or levels of theory by loosely coupled external programs. To make it highly efficient and flexible, we adopt an interoperable approach based on a multiple-program multiple-data paradigm, serving as an intermediary responsible for fast data exchange and interactions between the subsystems. The main goal of MiMiC is to avoid interfering with the underlying parallelization of the external programs, including the operability on hybrid architectures (e.g., CPU/GPU), and keep their setup and execution as close as possible to the original. At the moment, MiMiC offers an efficient implementation of electrostatic embedding QM/MM that has demonstrated unprecedented parallel scaling in simulations of large biomolecules using CPMD and GROMACS as QM and MM engines, respectively. However, as it is designed for high flexibility with general multiscale models in mind, it can be straightforwardly extended beyond QM/MM. In this article, we illustrate the software design and the features of the framework, which make it a compelling choice for multiscale simulations in the upcoming era of exascale high-performance computing.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/dfdd7a808d4660bb6aa9a1b76052e8ef3ba4a458" target='_blank'>
              MiMiC: A High-Performance Framework for Multiscale Molecular Dynamics Simulations
              </a>
            </td>
          <td>
            Andrej Antal'ik, Andrea Levy, Sonata Kvedaravivciut.e, Sophia K. Johnson, David Carrasco‐Busturia, Bharath Raghavan, Franccois Mouvet, Angela Acocella, Sambit Das, V. Gavini, Davide Mandelli, E. Ippoliti, Simone Meloni, Paolo Carloni, Ursula Rothlisberger, J'ogvan Magnus Haugaard Olsen
          </td>
          <td>2024-03-27</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>24</td>
        </tr>

        <tr id="Coarse-grained (CG) models informed from molecular dynamics simulations provide a way to represent the structure of an underlying all-atom (AA) model by deriving an effective interaction potential. However, this leads to a speed-up in dynamics due to the lost friction, which is especially pronounced in CG implicit solvent models. Applying a thermostat based on the Langevin equation (LE) provides a way to represent the long-time dynamics of CG particles by reintroducing friction to the system. To improve the representability CG models of heterogeneous molecular mixtures and their transferability over the mixture compositions, we parameterize an LE thermostat in which the friction coefficient depends on the local particle density (LD). The thermostat friction was iteratively optimized with a Markovian variant of the recently introduced Iterative Optimization of Memory Kernels (IOMK) method. We simulated tert-butanol/water mixtures over a range of compositions, which show a distinct clustering behavior. Our model with LD-dependent friction reproduces the AA diffusion coefficients well over the full range of mixtures and is, therefore, transferable with respect to dynamics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4fcbd436e3e9e44a2c9b748636fce2a4f330b5a6" target='_blank'>
              Transferable local density-dependent friction in tert-butanol/water mixtures.
              </a>
            </td>
          <td>
            Moritz Mathes, V. Klippenstein, N. V. D. van der Vegt
          </td>
          <td>2024-05-10</td>
          <td>The Journal of chemical physics</td>
          <td>0</td>
          <td>39</td>
        </tr>

        <tr id="A tremendous range of design tasks in materials, physics, and biology can be formulated as finding the optimum of an objective function depending on many parameters without knowing its closed-form expression or the derivative. Traditional derivative-free optimization techniques often rely on strong assumptions about objective functions, thereby failing at optimizing non-convex systems beyond 100 dimensions. Here, we present a tree search method for derivative-free optimization that enables accelerated optimal design of high-dimensional complex systems. Specifically, we introduce stochastic tree expansion, dynamic upper confidence bound, and short-range backpropagation mechanism to evade local optimum, iteratively approximating the global optimum using machine learning models. This development effectively confronts the dimensionally challenging problems, achieving convergence to global optima across various benchmark functions up to 2,000 dimensions, surpassing the existing methods by 10- to 20-fold. Our method demonstrates wide applicability to a wide range of real-world complex systems spanning materials, physics, and biology, considerably outperforming state-of-the-art algorithms. This enables efficient autonomous knowledge discovery and facilitates self-driving virtual laboratories. Although we focus on problems within the realm of natural science, the advancements in optimization techniques achieved herein are applicable to a broader spectrum of challenges across all quantitative disciplines.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/383c030cc1d9a568808e59e7f90cf8e0ef70b283" target='_blank'>
              Derivative-free tree optimization for complex systems
              </a>
            </td>
          <td>
            Ye Wei, Bo Peng, Ruiwen Xie, Yangtao Chen, Yu Qin, Peng Wen, Stefan Bauer, Po-Yen Tung
          </td>
          <td>2024-04-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Recent advancements in machine learning have showcased its potential to significantly accelerate the discovery of new materials. Central to this progress is the development of rapidly computable property predictors, enabling the identification of novel materials with desired properties from vast material spaces. However, the limited availability of data resources poses a significant challenge in data-driven materials research, particularly hindering the exploration of innovative materials beyond the boundaries of existing data. While machine learning predictors are inherently interpolative, establishing a general methodology to create an extrapolative predictor remains a fundamental challenge, limiting the search for innovative materials beyond existing data boundaries. In this study, we leverage an attention-based architecture of neural networks and meta-learning algorithms to acquire extrapolative generalization capability. The meta-learners, experienced repeatedly with arbitrarily generated extrapolative tasks, can acquire outstanding generalization capability in unexplored material spaces. Through the tasks of predicting the physical properties of polymeric materials and hybrid organic--inorganic perovskites, we highlight the potential of such extrapolatively trained models, particularly with their ability to rapidly adapt to unseen material domains in transfer learning scenarios.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a70c637c4c4c8baf9bc0c7c221f61fb72a807ffd" target='_blank'>
              Advancing Extrapolative Predictions of Material Properties through Learning to Learn
              </a>
            </td>
          <td>
            Kohei Noda, Araki Wakiuchi, Yoshihiro Hayashi, Ryo Yoshida
          </td>
          <td>2024-03-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Fully atomistic multiscale polarizable quantum mechanics (QM)/molecular mechanics (MM) approaches, combined with techniques to sample the solute-solvent phase space, constitute the most accurate method to compute spectral signals in aqueous solution. Conventional sampling strategies, such as classical molecular dynamics (MD), may encounter drawbacks when the conformational space is particularly complex, and transition barriers between conformers are high. This can lead to inaccurate sampling, which can potentially impact the accuracy of spectral calculations. For this reason, in this work, we compare classical MD with enhanced sampling techniques, i.e., replica exchange MD and metadynamics. In particular, we show how the different sampling techniques affect computed UV, electronic circular dichroism, nuclear magnetic resonance shielding, and optical rotatory dispersion of N-acetylproline-amide in aqueous solution. Such a system is a model peptide characterized by complex conformational variability. Calculated values suggest that spectral properties are influenced by solute conformers, relative population, and solvent effects; therefore, particular care needs to be paid for when choosing the sampling technique.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d96ae94dadbc97a47422c5b8559e945cfd0aad70" target='_blank'>
              Computational Spectroscopy of Aqueous Solutions: The Underlying Role of Conformational Sampling.
              </a>
            </td>
          <td>
            Chiara Sepali, Sara Gómez, E. Grifoni, Tommaso Giovannini, Chiara Cappelli
          </td>
          <td>2024-05-11</td>
          <td>The journal of physical chemistry. B</td>
          <td>0</td>
          <td>37</td>
        </tr>

        <tr id="We develop a thermodynamic theory for machine learning (ML) systems. Similar to physical thermodynamic systems which are characterized by energy and entropy, ML systems possess these characteristics as well. This comparison inspire us to integrate the concept of temperature into ML systems grounded in the fundamental principles of thermodynamics, and establish a basic thermodynamic framework for machine learning systems with non-Boltzmann distributions. We introduce the concept of states within a ML system, identify two typical types of state, and interpret model training and refresh as a process of state phase transition. We consider that the initial potential energy of a ML system is described by the model's loss functions, and the energy adheres to the principle of minimum potential energy. For a variety of energy forms and parameter initialization methods, we derive the temperature of systems during the phase transition both analytically and asymptotically, highlighting temperature as a vital indicator of system data distribution and ML training complexity. Moreover, we perceive deep neural networks as complex heat engines with both global temperature and local temperatures in each layer. The concept of work efficiency is introduced within neural networks, which mainly depends on the neural activation functions. We then classify neural networks based on their work efficiency, and describe neural networks as two types of heat engines.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b562793a90ace11e972615234c347a06107e2828" target='_blank'>
              On the Temperature of Machine Learning Systems
              </a>
            </td>
          <td>
            Dong Zhang
          </td>
          <td>2024-04-19</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Foundation models, such as large language models, have demonstrated success in addressing various language and image processing tasks. In this work, we introduce a multi-modal foundation model for scientific problems, named PROSE-PDE. Our model, designed for bi-modality to bi-modality learning, is a multi-operator learning approach which can predict future states of spatiotemporal systems while concurrently learning the underlying governing equations of the physical system. Specifically, we focus on multi-operator learning by training distinct one-dimensional time-dependent nonlinear constant coefficient partial differential equations, with potential applications to many physical applications including physics, geology, and biology. More importantly, we provide three extrapolation studies to demonstrate that PROSE-PDE can generalize physical features through the robust training of multiple operators and that the proposed model can extrapolate to predict PDE solutions whose models or data were unseen during the training. Furthermore, we show through systematic numerical experiments that the utilization of the symbolic modality in our model effectively resolves the well-posedness problems with training multiple operators and thus enhances our model's predictive capabilities.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/819bc0d5e0ea2efadac1364064e40b76cf3a3a11" target='_blank'>
              Towards a Foundation Model for Partial Differential Equations: Multi-Operator Learning and Extrapolation
              </a>
            </td>
          <td>
            Jingmin Sun, Yuxuan Liu, Zecheng Zhang, Hayden Schaeffer
          </td>
          <td>2024-04-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>15</td>
        </tr>

        <tr id="Although Reinforcement Learning (RL) algorithms acquire sequential behavioral patterns through interactions with the environment, their effectiveness in noisy and high-dimensional scenarios typically relies on specific structural priors. In this paper, we propose a novel and general Structural Information principles-based framework for effective Decision-Making, namely SIDM, approached from an information-theoretic perspective. This paper presents a specific unsupervised partitioning method that forms vertex communities in the state and action spaces based on their feature similarities. An aggregation function, which utilizes structural entropy as the vertex weight, is devised within each community to obtain its embedding, thereby facilitating hierarchical state and action abstractions. By extracting abstract elements from historical trajectories, a directed, weighted, homogeneous transition graph is constructed. The minimization of this graph's high-dimensional entropy leads to the generation of an optimal encoding tree. An innovative two-layer skill-based learning mechanism is introduced to compute the common path entropy of each state transition as its identified probability, thereby obviating the requirement for expert knowledge. Moreover, SIDM can be flexibly incorporated into various single-agent and multi-agent RL algorithms, enhancing their performance. Finally, extensive evaluations on challenging benchmarks demonstrate that, compared with SOTA baselines, our framework significantly and consistently improves the policy's quality, stability, and efficiency up to 32.70%, 88.26%, and 64.86%, respectively.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9a8656054c6801e2b9b4a2b8da80b56a7f690789" target='_blank'>
              Effective Reinforcement Learning Based on Structural Information Principles
              </a>
            </td>
          <td>
            Xianghua Zeng, Hao Peng, Dingli Su, Angsheng Li
          </td>
          <td>2024-04-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Most QM-cluster models of enzymes are constructed based on X-ray crystal structures, which limits comparison to in vivo structure and mechanism. The active site of chorismate mutase from Bacillus subtilis and the enzymatic transformation of chorismate to prephenate is used as a case study to guide construction of QM-cluster models built first from the X-ray crystal structure, then from molecular dynamics (MD) simulation snapshots. The Residue Interaction Network ResidUe Selector (RINRUS) software toolkit, developed by our group to simplify and automate the construction of QM-cluster models, is expanded to handle MD to QM-cluster model workflows. Several options, some employing novel topological clustering from residue interaction network (RIN) information, are evaluated for generating conformational clustering from MD simulation. RINRUS then generates a statistical thermodynamic framework for QM-cluster modeling of the chorismate mutase mechanism via refining 250 MD frames with density functional theory (DFT). The 250 QM-cluster models sampled provide a mean ΔG‡ of 10.3 ± 2.6 kcal mol-1 compared to the experimental value of 15.4 kcal mol-1 at 25 °C. While the difference between theory and experiment is consequential, the level of theory used is modest and therefore "chemical" accuracy is unexpected. More important are the comparisons made between QM-cluster models designed from the X-ray crystal structure versus those from MD frames. The large variations in kinetic and thermodynamic properties arise from geometric changes in the ensemble of QM-cluster models, rather from the composition of the QM-cluster models or from the active site-solvent interface. The findings open the way for further quantitative and reproducible calibration in the field of computational enzymology using the model construction framework afforded with the RINRUS software toolkit.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2e608f1464e6524268098775b692ea638cede097" target='_blank'>
              The influence of model building schemes and molecular dynamics sampling on QM-cluster models: the chorismate mutase case study.
              </a>
            </td>
          <td>
            Donatus A Agbaglo, Thomas J. Summers, Qianyi Cheng, Nathan J. DeYonker
          </td>
          <td>2024-04-15</td>
          <td>Physical chemistry chemical physics : PCCP</td>
          <td>0</td>
          <td>26</td>
        </tr>

        <tr id="In recent years, there has been a growing interest in integrating linear state-space models (SSM) in deep neural network architectures of foundation models. This is exemplified by the recent success of Mamba, showing better performance than the state-of-the-art Transformer architectures in language tasks. Foundation models, like e.g. GPT-4, aim to encode sequential data into a latent space in order to learn a compressed representation of the data. The same goal has been pursued by control theorists using SSMs to efficiently model dynamical systems. Therefore, SSMs can be naturally connected to deep sequence modeling, offering the opportunity to create synergies between the corresponding research areas. This paper is intended as a gentle introduction to SSM-based architectures for control theorists and summarizes the latest research developments. It provides a systematic review of the most successful SSM proposals and highlights their main features from a control theoretic perspective. Additionally, we present a comparative analysis of these models, evaluating their performance on a standardized benchmark designed for assessing a model's efficiency at learning long sequences.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2a53d07a399c47151a7b440dacfb3673b9c4e753" target='_blank'>
              State Space Models as Foundation Models: A Control Theoretic Overview
              </a>
            </td>
          <td>
            Carmen Amo Alonso, Jerome Sieber, M. Zeilinger
          </td>
          <td>2024-03-25</td>
          <td>ArXiv</td>
          <td>3</td>
          <td>35</td>
        </tr>

        <tr id="Discovering an informative, or agent-centric, state representation that encodes only the relevant information while discarding the irrelevant is a key challenge towards scaling reinforcement learning algorithms and efficiently applying them to downstream tasks. Prior works studied this problem in high-dimensional Markovian environments, when the current observation may be a complex object but is sufficient to decode the informative state. In this work, we consider the problem of discovering the agent-centric state in the more challenging high-dimensional non-Markovian setting, when the state can be decoded from a sequence of past observations. We establish that generalized inverse models can be adapted for learning agent-centric state representation for this task. Our results include asymptotic theory in the deterministic dynamics setting as well as counter-examples for alternative intuitive algorithms. We complement these findings with a thorough empirical study on the agent-centric state discovery abilities of the different alternatives we put forward. Particularly notable is our analysis of past actions, where we show that these can be a double-edged sword: making the algorithms more successful when used correctly and causing dramatic failure when used incorrectly.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/908b81ad418773cbe5c5e601459d43fdb11dfc73" target='_blank'>
              Generalizing Multi-Step Inverse Models for Representation Learning to Finite-Memory POMDPs
              </a>
            </td>
          <td>
            Lili Wu, Ben Evans, Riashat Islam, Raihan Seraj, Yonathan Efroni, Alex Lamb
          </td>
          <td>2024-04-22</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/31fe6fb31658147df5b7f75350879b4eab8c006d" target='_blank'>
              Predicting quantum emitter fluctuations with time-series forecasting models
              </a>
            </td>
          <td>
            F. Ramezani, Matthew C Strasbourg, S. Parvez, Ravindra Saxena, D. Jariwala, Nicholas J. Borys, Bradley M. Whitaker
          </td>
          <td>2024-03-22</td>
          <td>Scientific Reports</td>
          <td>0</td>
          <td>48</td>
        </tr>

        <tr id="Cannabinoid receptor 1 (CB1) is a G protein-coupled receptor (GPCR) that regulates critical physiological processes including pain, appetite, and cognition. Understanding the confor- mational dynamics of CB1 associated with transitions between inactive and active signaling states is imperative for developing targeted modulators. Using microsecond-level all-atom molecular dynamics (MD) simulations, we identified marked differences in the conformational ensembles of inactive and active CB1 in apo. The inactive state exhibited substantially in- creased structural heterogeneity and plasticity compared to the more rigidified active state in the absence of stabilizing ligands. Transmembrane helices TM3 and TM7 were identified as distinguishing factors modulating the state-dependent dynamics. TM7 displayed amplified fluctuations selectively in the inactive state simulations attributed to disruption of conserved electrostatic contacts anchoring it to surrounding helices in the active state. Additionally, we identified significant reorganizations in key salt bridge and hydrogen bond networks con- tributing to the CB1 activation/inactivation. For instance, D213-Y224 hydrogen bond and D184-K192 salt bridge showed marked rearrangements between the states. Collectively, these findings reveal the specialized role of TM7 in directing state-dependent CB1 dynamics through electrostatic switch mechanisms. By elucidating the intrinsic enhanced flexibility of inactive CB1, this study provides valuable insights into the conformational landscape enabling functional transitions. Our perspective advances understanding of CB1 activation mechanisms and offers opportunities for structure-based drug discovery targeting the state- specific conformational dynamics of this receptor. Graphic for manuscript For Table of Contents Only">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/711af14545029aa62f734abec0fad1275f5d7f03" target='_blank'>
              Differential Behavior of Conformational Dynamics in Active and Inactive States of Cannabinoid Receptor 1
              </a>
            </td>
          <td>
            Ugochi H Isu, Adithya Polasa, Mahmoud Moradi
          </td>
          <td>2024-02-01</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Manifold learning techniques play a pivotal role in machine learning by revealing lower-dimensional embeddings within high-dimensional data, thus enhancing both the efficiency and interpretability of data analysis by transforming the data into a lower-dimensional representation. However, a notable challenge with current manifold learning methods is their lack of explicit functional mappings, crucial for explainability in many real-world applications. Genetic programming, known for its interpretable functional tree-based models, has emerged as a promising approach to address this challenge. Previous research leveraged multi-objective GP to balance manifold quality against embedding dimensionality, producing functional mappings across a range of embedding sizes. Yet, these mapping trees often became complex, hindering explainability. In response, in this paper, we introduce Genetic Programming for Explainable Manifold Learning (GP-EMaL), a novel approach that directly penalises tree complexity. Our new method is able to maintain high manifold quality while significantly enhancing explainability and also allows customisation of complexity measures, such as symmetry balancing, scaling, and node complexity, catering to diverse application needs. Our experimental analysis demonstrates that GP-EMaL is able to match the performance of the existing approach in most cases, while using simpler, smaller, and more interpretable tree structures. This advancement marks a significant step towards achieving interpretable manifold learning.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/69d95d5bd28ed13d92b120ea2f2dbb4f53b5ef9d" target='_blank'>
              Genetic Programming for Explainable Manifold Learning
              </a>
            </td>
          <td>
            Ben Cravens, Andrew Lensen, Paula Maddigan, Bing Xue
          </td>
          <td>2024-03-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="While advances in single-particle cryoEM have enabled the structural determination of macromolecular complexes at atomic resolution, particle orientation bias (the so-called “preferred” orientation problem) remains a complication for most specimens. Existing solutions have relied on biochemical and physical strategies applied to the specimen and are often complex and challenging. Here, we develop spIsoNet, an end-to-end self-supervised deep-learning-based software to address the preferred orientation problem. Using preferred-orientation views to recover molecular information in under-sampled views, spIsoNet improves both angular isotropy and particle alignment accuracy during 3D reconstruction. We demonstrate spIsoNet’s capability of generating near-isotropic reconstructions from representative biological systems with limited views, including ribosomes, β-galactosidases, and a previously intractable hemagglutinin trimer dataset. spIsoNet can also be generalized to improve map isotropy and particle alignment of preferentially oriented molecules in subtomogram averaging. Therefore, without additional specimen-preparation procedures, spIsoNet provides a general computational solution to the preferred orientation problem.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/470b351e87e579d42201a876acfebaf14d36746f" target='_blank'>
              Overcoming the preferred orientation problem in cryoEM with self-supervised deep-learning
              </a>
            </td>
          <td>
            Yun-Tao Liu, Hongcheng Fan, Jason J. Hu, Z. H. Zhou
          </td>
          <td>2024-04-14</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="We present a detailed assessment of deep neural network potentials developed within the Deep Potential Molecular Dynamics (DeePMD) framework and trained on the MB-pol data-driven many-body potential energy function. Specific focus is directed at the ability of DeePMD-based potentials to correctly reproduce the accuracy of MB-pol across various water systems. Analyses of bulk and interfacial properties as well as many-body interactions characteristic of water elucidate inherent limitations in the transferability and predictive accuracy of DeePMD-based potentials. These limitations can be traced back to an incomplete implementation of the "nearsightedness of electronic matter" principle, which may be common throughout machine learning potentials that do not include a proper representation of self-consistently determined long-range electric fields. These findings provide further support for the "short-blanket dilemma" faced by DeePMD-based potentials, highlighting the challenges in achieving a balance between computational efficiency and a rigorous, physics-based representation of the properties of water. Finally, we believe that our study contributes to the ongoing discourse on the development and application of machine learning models in simulating water systems, offering insights that could guide future improvements in the field.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/408903176a93857a6220394613e113c05192f7f5" target='_blank'>
              Many-body interactions and deep neural network potentials for water.
              </a>
            </td>
          <td>
            Yaoguang Zhai, Richa Rashmi, Etienne Palos, F. Paesani
          </td>
          <td>2024-04-08</td>
          <td>The Journal of chemical physics</td>
          <td>0</td>
          <td>51</td>
        </tr>

        <tr id="Reaction-diffusion processes are the foundational model for a diverse range of complex systems, ranging from biochemical reactions to social agent-based phenomena. The underlying dynamics of these systems occur at the individual particle/agent level, and in realistic applications, they often display interaction with their environment through energy or material exchange with a reservoir. This requires intricate mathematical considerations, especially in the case of material exchange since the varying number of particles/agents results in ``on-the-fly'' modification of the system dimension. In this work, we first overview the probabilistic description of reaction-diffusion processes at the particle level, which readily handles varying numbers of particles. We then extend this model to consistently incorporate interactions with macroscopic material reservoirs. Based on the resulting expressions, we bridge the probabilistic description with macroscopic concentration-based descriptions for linear and nonlinear reaction-diffusion systems, as well as for an archetypal open reaction-diffusion system. This establishes a methodological workflow to bridge particle-based probabilistic descriptions with macroscopic concentration-based descriptions of reaction-diffusion in open settings, laying the foundations for a multiscale theoretical framework upon which to construct theory and simulation schemes that are consistent across scales.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ce3dd2e0bf5250e986e0ee413c1804d96b0decfd" target='_blank'>
              Open reaction-diffusion systems: bridging probabilistic theory across scales
              </a>
            </td>
          <td>
            M. D. Razo
          </td>
          <td>2024-04-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="We consider using deep neural networks to solve time-dependent partial differential equations (PDEs), where multi-scale processing is crucial for modeling complex, time-evolving dynamics. While the U-Net architecture with skip connections is commonly used by prior studies to enable multi-scale processing, our analysis shows that the need for features to evolve across layers results in temporally misaligned features in skip connections, which limits the model's performance. To address this limitation, we propose SineNet, consisting of multiple sequentially connected U-shaped network blocks, referred to as waves. In SineNet, high-resolution features are evolved progressively through multiple stages, thereby reducing the amount of misalignment within each stage. We furthermore analyze the role of skip connections in enabling both parallel and sequential processing of multi-scale information. Our method is rigorously tested on multiple PDE datasets, including the Navier-Stokes equations and shallow water equations, showcasing the advantages of our proposed approach over conventional U-Nets with a comparable parameter budget. We further demonstrate that increasing the number of waves in SineNet while maintaining the same number of parameters leads to a monotonically improved performance. The results highlight the effectiveness of SineNet and the potential of our approach in advancing the state-of-the-art in neural PDE solver design. Our code is available as part of AIRS (https://github.com/divelab/AIRS).">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/fc950089c44fe403b89b1c7866ac826557e08284" target='_blank'>
              SineNet: Learning Temporal Dynamics in Time-Dependent Partial Differential Equations
              </a>
            </td>
          <td>
            Xuan Zhang, Jacob Helwig, Yu-Ching Lin, Yaochen Xie, Cong Fu, Stephan Wojtowytsch, Shuiwang Ji
          </td>
          <td>2024-03-28</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>13</td>
        </tr>

        <tr id="Molecular docking is a pivotal process in drug discovery. While traditional techniques rely on extensive sampling and simulation governed by physical principles, these methods are often slow and costly. The advent of deep learning-based approaches has shown significant promise, offering increases in both accuracy and efficiency. Building upon the foundational work of FABind, a model designed with a focus on speed and accuracy, we present FABind+, an enhanced iteration that largely boosts the performance of its predecessor. We identify pocket prediction as a critical bottleneck in molecular docking and propose a novel methodology that significantly refines pocket prediction, thereby streamlining the docking process. Furthermore, we introduce modifications to the docking module to enhance its pose generation capabilities. In an effort to bridge the gap with conventional sampling/generative methods, we incorporate a simple yet effective sampling technique coupled with a confidence model, requiring only minor adjustments to the regression framework of FABind. Experimental results and analysis reveal that FABind+ remarkably outperforms the original FABind, achieves competitive state-of-the-art performance, and delivers insightful modeling strategies. This demonstrates FABind+ represents a substantial step forward in molecular docking and drug discovery. Our code is in https://github.com/QizhiPei/FABind.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6594ec85ba41682c2ae0b2c205a92ec372f0ec4b" target='_blank'>
              FABind+: Enhancing Molecular Docking through Improved Pocket Prediction and Pose Generation
              </a>
            </td>
          <td>
            Kaiyuan Gao, Qizhi Pei, Jinhua Zhu, Tao Qin, Kun He, Tie-Yan Liu, Lijun Wu
          </td>
          <td>2024-03-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>15</td>
        </tr>

        <tr id="Of all the vector fields surrounding the minima of recurrent learning setups, the gradient field with its exploding and vanishing updates appears a poor choice for optimization, offering little beyond efficient computability. We seek to improve this suboptimal practice in the context of physics simulations, where backpropagating feedback through many unrolled time steps is considered crucial to acquiring temporally coherent behavior. The alternative vector field we propose follows from two principles: physics simulators, unlike neural networks, have a balanced gradient flow, and certain modifications to the backpropagation pass leave the positions of the original minima unchanged. As any modification of backpropagation decouples forward and backward pass, the rotation-free character of the gradient field is lost. Therefore, we discuss the negative implications of using such a rotational vector field for optimization and how to counteract them. Our final procedure is easily implementable via a sequence of gradient stopping and component-wise comparison operations, which do not negatively affect scalability. Our experiments on three control problems show that especially as we increase the complexity of each task, the unbalanced updates from the gradient can no longer provide the precise control signals necessary while our method still solves the tasks. Our code can be found at https://github.com/tum-pbs/StableBPTT.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/548ed7572cbe5de1e13cfba73e4cb22db79e14a2" target='_blank'>
              Stabilizing Backpropagation Through Time to Learn Complex Physics
              </a>
            </td>
          <td>
            Patrick Schnell, Nils Thuerey
          </td>
          <td>2024-05-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="We study discrete time crystals (DTCs) in periodically driven quantum systems, in the presence of non-Markovian dissipation. In contrast to DTCs observed in earlier works in the presence of Markovian dynamics, using the open Dicke model in presence of Jaynes-Cummings-like dissipation, we show that non-Markovian regime can be highly beneficial for stabilizing DTCs over a wide range of parameter values. This may be attributed to periodically varying dissipation rates even at long times in the case of non-Markovian dynamics. Further the Markovian and non-Markovian regimes show sharp distinctions for intermediate strengths of the dissipator coefficient, with a time-independent steady-state in the Markovian regime being replaced by varied dynamical phases, including DTC order, in the non-Markovian regime. We also verify the robustness of the DTC phase in the non-Markovian regime by introducing errors both in the Hamiltonian as well as in the dissipation. Our study shows the possibility of using DTC as a probe for non-Markovian dynamics in periodically modulated open quantum systems, at long times.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9deed2e6fa312ae94bd318199c774d91f4d2b1f2" target='_blank'>
              Discrete time crystals in the presence of non-Markovian dynamics
              </a>
            </td>
          <td>
            Bandita Das, Noufal Jaseem, Victor Mukherjee
          </td>
          <td>2024-04-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/df403bacd189e2b5777a867988eb2d0ba7e97d01" target='_blank'>
              On the statistical foundation of a recent single molecule FRET benchmark
              </a>
            </td>
          <td>
            A. Saurabh, L. W. Xu, Steve Pressé
          </td>
          <td>2024-04-30</td>
          <td>Nature Communications</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Two computational approaches for computing the rates of internal conversions in molecular systems where a large set of nuclear degrees of freedom plays a role are discussed and compared. One approach is based on the numerical solution of the time-dependent Schrödinger equation and allows us to include almost the whole set of vibrational coordinates, thanks to the employment of effective procedures for selecting those elements of the Hilbert space which play a significant role in dynamics. The other approach, based on the time-dependent perturbation theory and limited to the use of the harmonic approximation, allows us to include the whole Hilbert space spanned by the vibrational states of the system. The two approaches are applied to the photophysics of azulene, whose anti-Kasha behavior caused by anomalous internal conversion rates is well assessed. The calculated rates for the decays of the first two excited singlet states are in very good agreement with experimental data, indicating the reliability of both methodologies.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/88b054829676282cdcc98fa8090110ade33ea51d" target='_blank'>
              The rates of non-adiabatic processes in large molecular systems: Toward an effective full-dimensional quantum mechanical approach.
              </a>
            </td>
          <td>
            Alessandro Landi, Andrea Landi, Anna Leo, Andrea Peluso
          </td>
          <td>2024-05-03</td>
          <td>The Journal of chemical physics</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="In this study, we combined AlphaFold-based approaches for atomistic modeling of multiple protein states and microsecond molecular simulations to accurately characterize conformational ensembles and binding mechanisms of convergent evolution for the SARS-CoV-2 Spike Omicron variants BA.1, BA.2, BA.2.75, BA.3, BA.4/BA.5 and BQ.1.1. We employed and validated several different adaptations of the AlphaFold methodology for modeling of conformational ensembles including the introduced randomized full sequence scanning for manipulation of sequence variations to systematically explore conformational dynamics of Omicron Spike protein complexes with the ACE2 receptor. Microsecond atomistic molecular dynamic simulations provide a detailed characterization of the conformational landscapes and thermodynamic stability of the Omicron variant complexes. By integrating the predictions of conformational ensembles from different AlphaFold adaptations and applying statistical confidence metrics we can expand characterization of the conformational ensembles and identify functional protein conformations that determine the equilibrium dynamics for the Omicron Spike complexes with the ACE2. Conformational ensembles of the Omicron RBD-ACE2 complexes obtained using AlphaFold-based approaches for modeling protein states and molecular dynamics simulations are employed for accurate comparative prediction of the binding energetics revealing an excellent agreement with the experimental data. In particular, the results demonstrated that AlphaFold-generated extended conformational ensembles can produce accurate binding energies for the Omicron RBD-ACE2 complexes. The results of this study suggested complementarities and potential synergies between AlphaFold predictions of protein conformational ensembles and molecular dynamics simulations showing that integrating information from both methods can potentially yield a more adequate characterization of the conformational landscapes for the Omicron RBD-ACE2 complexes. This study provides insights in the interplay between conformational dynamics and binding, showing that evolution of Omicron variants through acquisition of convergent mutational sites may leverage conformational adaptability and dynamic couplings between key binding energy hotspots to optimize ACE2 binding affinity and enable immune evasion.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3ebdef3925f23996ba78b713b27a3232a00f08a3" target='_blank'>
              Predicting Functional Conformational Ensembles and Binding Mechanisms of Convergent Evolution for SARS-CoV-2 Spike Omicron Variants Using AlphaFold2 Sequence Scanning Adaptations and Molecular Dynamics Simulations
              </a>
            </td>
          <td>
            Nishank Raisinghani, Mohammed Alshahrani, Grace Gupta, Sian Xiao, Peng-Chu Tao, Gennady M. Verkhivker
          </td>
          <td>2024-04-03</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Brain networks display a hierarchical organization, a complexity that poses a challenge for existing deep learning models, often structured as flat classifiers, leading to difficulties in interpretability and the 'black box' issue. To bridge this gap, we propose a novel architecture: a symbolic autoencoder informed by weak supervision and an Emergent Language (EL) framework. This model moves beyond traditional flat classifiers by producing hierarchical clusters and corresponding imagery, subsequently represented through symbolic sentences to improve the clinical interpretability of hierarchically organized data such as intrinsic brain networks, which can be characterized using resting-state fMRI images. Our innovation includes a generalized hierarchical loss function designed to ensure that both sentences and images accurately reflect the hierarchical structure of functional brain networks. This enables us to model functional brain networks from a broader perspective down to more granular details. Furthermore, we introduce a quantitative method to assess the hierarchical consistency of these symbolic representations. Our qualitative analyses show that our model successfully generates hierarchically organized, clinically interpretable images, a finding supported by our quantitative evaluations. We find that our best performing loss function leads to a hierarchical consistency of over 97% when identifying images corresponding to brain networks. This approach not only advances the interpretability of deep learning models in neuroimaging analysis but also represents a significant step towards modeling the intricate hierarchical nature of brain networks.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1411a977b0d62e36376e750741cd0d972a64af9a" target='_blank'>
              Emergent Language Symbolic Autoencoder (ELSA) with Weak Supervision to Model Hierarchical Brain Networks
              </a>
            </td>
          <td>
            Ammar Ahmed Pallikonda Latheef, Alberto Santamaría-Pang, Craig Jones, Haris I. Sair
          </td>
          <td>2024-04-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/aab58c9e76ae10342be60b3d3e983ce80e372f29" target='_blank'>
              Coupled cluster finite temperature simulations of periodic materials via machine learning
              </a>
            </td>
          <td>
            Basile Herzog, A. Gallo, Felix Hummel, Michael Badawi, T. Bučko, S. Lebègue, Andreas Grüneis, Dario Rocca
          </td>
          <td>2024-04-04</td>
          <td>npj Computational Materials</td>
          <td>1</td>
          <td>41</td>
        </tr>

        <tr id="INTRODUCTION
For rational drug design, it is crucial to understand the receptor-drug binding processes and mechanisms. A new era for the use of computer simulations in predicting drug-receptor interactions at an atomic level has begun with remarkable advances in supercomputing and methodological breakthroughs.


AREAS COVERED
End-point free energy calculation methods such as Molecular Mechanics/Poisson Boltzmann Surface Area (MM/PBSA) or Molecular-Mechanics/Generalized Born Surface Area (MM/GBSA), free energy perturbation (FEP), and thermodynamic integration (TI) are commonly used for binding free energy calculations in drug discovery. In addition, kinetic dissociation and association rate constants (koff and kon) play critical roles in the function of drugs. Nowadays, Molecular Dynamics (MD) and enhanced sampling simulations are increasingly being used in drug discovery. Here, the authors provide a review of the computational techniques used in drug binding free energy and kinetics calculations.


EXPERT OPINION
The applications of computational methods in drug discovery and design are expanding, thanks to improved predictions of the binding free energy and kinetic rates of drug molecules. Recent microsecond-timescale enhanced sampling simulations have made it possible to accurately capture repetitive ligand binding and dissociation, facilitating more efficient and accurate calculations of ligand binding free energy and kinetics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/99593f2b2e262c3df388ca0f2cce6625fad2043b" target='_blank'>
              Understanding the impact of binding free energy and kinetics calculations in modern drug discovery.
              </a>
            </td>
          <td>
            Victor A Adediwura, Kushal Koirala, H. Do, Jinan Wang, Yinglong Miao
          </td>
          <td>2024-05-09</td>
          <td>Expert opinion on drug discovery</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Artificial neural networks (ANN) have proven to be effective in dealing with the identification nonlinear models for highly complex systems. To still make use of the prior information available from baseline models derived from, e.g., first-principles (FP), methods have been developed that integrate the prior knowledge into the identification algorithm for the ANN in a variety of methods. These methods have shown better estimation speeds and/or accuracy on unseen data. Among these methods are model augmentation structures. A variety of these structures have been considered in literature, there is however no unifying theory to these. In this paper, we propose a flexible linear-fractional-representation (LFR) based model augmentation structure. This model structure is able to represent many common model augmentation structures, thus unifying them under the proposed model structure. Furthermore, we introduce an identification algorithm capable of estimating the proposed model augmentation structure. The performance and generalization capabilities of the identification algorithm and the augmentation structure is demonstrated on a hardening mass-spring-damper simulation example.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d1ebbe27817bb8c9a15a4eabef540a9423f10260" target='_blank'>
              Learning-based model augmentation with LFRs
              </a>
            </td>
          <td>
            Jan H. Hoekstra, C. Verhoek, Roland T'oth, M. Schoukens
          </td>
          <td>2024-04-02</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="This work proposes a physics-informed deep learning (PIDL)-based constitutive model for investigating the viscoelastic-viscoplastic behavior of short fiber-reinforced nanoparticle-filled epoxies under various ambient conditions. The deep-learning model is trained to enforce thermodynamic principles, leading to a thermodynamically consistent constitutive model. To accomplish this, a long short-term memory network is combined with a feed-forward neural network to predict internal variables required for characterizing the internal dissipation of the nanocomposite materials. In addition, another feed-forward neural network is used to indicate the free-energy function, which enables defining the thermodynamic state of the entire system. The PIDL model is initially developed for the three-dimensional case by generating synthetic data from a classical constitutive model. The model is then trained by extracting the data directly from cyclic loading-unloading experimental tests. Numerical examples show that the PIDL model can accurately predict the mechanical behavior of epoxy-based nanocomposites for different volume fractions of fibers and nanoparticles under various hygrothermal conditions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/396a9508e128d0bc335456c3f0cd1cd4856e5d75" target='_blank'>
              A thermodynamically consistent physics-informed deep learning material model for short fiber/polymer nanocomposites
              </a>
            </td>
          <td>
            Betim Bahtiri, B. Arash, Sven Scheffler, Maximilian Jux, R. Rolfes
          </td>
          <td>2024-03-27</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>26</td>
        </tr>

        <tr id="This paper explores the interplay between statistics and generative artificial intelligence. Generative statistics, an integral part of the latter, aims to construct models that can {\it generate} efficiently and meaningfully new data across the whole of the (usually high dimensional) sample space, e.g. a new photo. Within it, the gradient-based approach is a current favourite that exploits effectively, for the above purpose, the information contained in the observed sample, e.g. an old photo. However, often there are missing data in the observed sample, e.g. missing bits in the old photo. To handle this situation, we have proposed a gradient-based algorithm for generative modelling. More importantly, our paper underpins rigorously this powerful approach by introducing a new F-entropy that is related to Fisher's divergence. (The F-entropy is also of independent interest.) The underpinning has enabled the gradient-based approach to expand its scope. For example, it can now provide a tool for generative model selection. Possible future projects include discrete data and Bayesian variational inference.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9db22fdfebd639b62f50b499cc37ffc52bc5e429" target='_blank'>
              On foundation of generative statistics with F-entropy: a gradient-based approach
              </a>
            </td>
          <td>
            B. Cheng, Howell Tong
          </td>
          <td>2024-05-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>11</td>
        </tr>

        <tr id="In the realm of medicinal chemistry, the primary objective is to swiftly optimize a multitude of chemical properties of a set of compounds to yield a clinical candidate poised for clinical trials. In recent years, two computational techniques, machine learning (ML) and physics-based methods, have evolved substantially and are now frequently incorporated into the medicinal chemist’s toolbox to enhance the efficiency of both hit optimization and candidate design. Both computational methods come with their own set of limitations, and they are often used independently of each other. ML’s capability to screen extensive compound libraries expediently is tempered by its reliance on quality data, which can be scarce especially during early-stage optimization. Contrarily, physics-based approaches like free energy perturbation (FEP) are frequently constrained by low throughput and high cost by comparison; however, physics-based methods are capable of making highly accurate binding affinity predictions. In this study, we harnessed the strength of FEP to overcome data paucity in ML by generating virtual activity data sets which then inform the training of algorithms. Here, we show that ML algorithms trained with an FEP-augmented data set could achieve comparable predictive accuracy to data sets trained on experimental data from biological assays. Throughout the paper, we emphasize key mechanistic considerations that must be taken into account when aiming to augment data sets and lay the groundwork for successful implementation. Ultimately, the study advocates for the synergy of physics-based methods and ML to expedite the lead optimization process. We believe that the physics-based augmentation of ML will significantly benefit drug discovery, as these techniques continue to evolve.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c68098f1f72af3b2975f4a681ad88eea00c73c0e" target='_blank'>
              FEP Augmentation as a Means to Solve Data Paucity Problems for Machine Learning in Chemical Biology
              </a>
            </td>
          <td>
            Pieter B Burger, Xiaohu Hu, Ilya Balabin, Morné Muller, Megan Stanley, Fourie Joubert, Thomas M Kaiser
          </td>
          <td>2024-04-23</td>
          <td>Journal of Chemical Information and Modeling</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="We present VoxBind, a new score-based generative model for 3D molecules conditioned on protein structures. Our approach represents molecules as 3D atomic density grids and leverages a 3D voxel-denoising network for learning and generation. We extend the neural empirical Bayes formalism (Saremi&Hyvarinen, 2019) to the conditional setting and generate structure-conditioned molecules with a two-step procedure: (i) sample noisy molecules from the Gaussian-smoothed conditional distribution with underdamped Langevin MCMC using the learned score function and (ii) estimate clean molecules from the noisy samples with single-step denoising. Compared to the current state of the art, our model is simpler to train, significantly faster to sample from, and achieves better results on extensive in silico benchmarks -- the generated molecules are more diverse, exhibit fewer steric clashes, and bind with higher affinity to protein pockets.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8b24792a732f53505b4f3538fc7f5c705b881deb" target='_blank'>
              Structure-based drug design by denoising voxel grids
              </a>
            </td>
          <td>
            Pedro O. Pinheiro, Arian R. Jamasb, Omar Mahmood, Vishnu Sresht, Saeed Saremi
          </td>
          <td>2024-05-07</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="Reservoir computing is a recurrent neural network that has been applied across various domains in machine learning. The implementation of reservoir computing, however, often demands heavy computations for activating the reservoir. Configuring physical reservoir networks and harnessing the nonlinearity from the underlying devices for activation is an emergent solution to address the computational challenge. Herein, we analyze the feasibility of employing the nonlinearity from solution-processed molybdenum disulfide (MoS2) devices for reservoir activation. The devices, fabricated using liquid-phase exfoliated MoS2, exhibit a high-order nonlinearity achieved by Stark modulation of the MoS2 material. We demonstrate that this nonlinearity can be fitted and employed as the activation function to facilitate reservoir computing implementation. Notably, owing to the high-order nonlinearity, the network exhibits long-term synchronization and robust generalization abilities for approximating complex dynamical systems. Given the remarkable reservoir activation capability, coupled with the scalability of the device fabrication, our findings open the possibility for the physical realization of lightweight, efficient reservoir computing for, for instance, signal classification, motion tracking, and pattern recognition of complex time series as well as secure cryptography. As an example, we show the network can be appointed to generate chaotic random numbers for secure data encryption.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/efce4f5df3fa14875ad8d0515a837cfd7b4364dd" target='_blank'>
              Analysis on reservoir activation with the nonlinearity harnessed from solution-processed MoS2 devices
              </a>
            </td>
          <td>
            Songwei Liu, Yang Liu, Yingyi Wen, Jingfang Pei, Pengyu Liu, Lekai Song, Xiaoyue Fan, Wen-Jun Yang, Danmei Pan, Teng Ma, Yue Lin, Gang Wang, Guohua Hu
          </td>
          <td>2024-03-26</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Allostery is a fundamental mechanism driving biomolecular processes that holds significant therapeutic concern. Our study rigorously investigates how two distinct machine-learning algorithms uniquely classify two already close-to-active DFG-in states of TAK1, differing just by the presence or absence of its allosteric activator TAB1, from an ensemble mixture of conformations (obtained from 2.4 μs molecular dynamics (MD) simulations). The novelty, however, lies in understanding the deeper algorithmic potentials to systematically derive a diverse set of differential residue connectivity features that reconstruct the essential mechanistic architecture for TAK1-TAB1 allostery in such a close-to-active biochemical scenario. While the recursive, random forest-based workflow displays the potential of conducting discretized, hierarchical derivation of allosteric features, a multilayer perceptron-based approach gains considerable efficacy in revealing fluid connected patterns of features when hybridized with mutual information scoring. Interestingly, both pipelines benchmark similar directions of functional conformational changes for TAK1's activation. The findings significantly advance the depth of mechanistic understanding by highlighting crucial activation signatures along a directed C-lobe → activation loop → ATP pocket channel of information flow, including (1) the αF-αE biterminal alignments and (2) the "catalytic" drift of the activation loop toward kinase active site. Besides, some novel allosteric hotspots (K253, Y206, N189, etc.) are further recognized as TAB1 sensors, transducers, and responders, including a benchmark E70 mutation site, precisely mapping the important structural segments for sequential allosteric execution. Hence, our work demonstrates how to navigate through greater structural depths and dimensions of dynamic allosteric machineries just by leveraging standard ML methods in suitable streamlined workflows adaptive to the specific system and objectives.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9e656737754f86ab9ba75a485691b12e7213422c" target='_blank'>
              Adaptive Workflows of Machine Learning Illuminate the Sequential Operation Mechanism of the TAK1's Allosteric Network.
              </a>
            </td>
          <td>
            Nibedita Ray Chaudhuri, Shubhra Ghosh Dastidar
          </td>
          <td>2024-05-14</td>
          <td>Biochemistry</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id="In this paper, we advance the understanding of neural network training dynamics by examining the intricate interplay of various factors introduced by weight parameters in the initialization process. Motivated by the foundational work of Luo et al. (J. Mach. Learn. Res., Vol. 22, Iss. 1, No. 71, pp 3327-3373), we explore the gradient descent dynamics of neural networks through the lens of macroscopic limits, where we analyze its behavior as width $m$ tends to infinity. Our study presents a unified approach with refined techniques designed for multi-layer fully connected neural networks, which can be readily extended to other neural network architectures. Our investigation reveals that gradient descent can rapidly drive deep neural networks to zero training loss, irrespective of the specific initialization schemes employed by weight parameters, provided that the initial scale of the output function $\kappa$ surpasses a certain threshold. This regime, characterized as the theta-lazy area, accentuates the predominant influence of the initial scale $\kappa$ over other factors on the training behavior of neural networks. Furthermore, our approach draws inspiration from the Neural Tangent Kernel (NTK) paradigm, and we expand its applicability. While NTK typically assumes that $\lim_{m\to\infty}\frac{\log \kappa}{\log m}=\frac{1}{2}$, and imposes each weight parameters to scale by the factor $\frac{1}{\sqrt{m}}$, in our theta-lazy regime, we discard the factor and relax the conditions to $\lim_{m\to\infty}\frac{\log \kappa}{\log m}>0$. Similar to NTK, the behavior of overparameterized neural networks within the theta-lazy regime trained by gradient descent can be effectively described by a specific kernel. Through rigorous analysis, our investigation illuminates the pivotal role of $\kappa$ in governing the training dynamics of neural networks.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/511c92211f3ac9eefa495e6b5ecfb0b5288bce8d" target='_blank'>
              Demystifying Lazy Training of Neural Networks from a Macroscopic Viewpoint
              </a>
            </td>
          <td>
            Yuqing Li, Tao Luo, Qixuan Zhou
          </td>
          <td>2024-04-07</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="The progress in machine learning during the last decade has had a considerable impact on many areas of science and technology, including quantum technology. This work explores the application of reinforcement learning (RL) methods to the quantum control problem of state transfer in a single qubit. The goal is to create an RL agent that learns an optimal policy and thus discovers optimal pulses to control the qubit. The most crucial step is to mathematically formulate the problem of interest as a Markov decision process (MDP). This enables the use of RL algorithms to solve the quantum control problem. Deep learning and the use of deep neural networks provide the freedom to employ continuous action and state spaces, offering the expressivity and generalization of the process. This flexibility helps to formulate the quantum state transfer problem as an MDP in several different ways. All the developed methodologies are applied to the fundamental problem of population inversion in a qubit. In most cases, the derived optimal pulses achieve fidelity equal to or higher than 0.9999, as required by quantum computing applications. The present methods can be easily extended to quantum systems with more energy levels and may be used for the efficient control of collections of qubits and to counteract the effect of noise, which are important topics for quantum sensing applications.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/13af08f7229b2dba5160b36075cccf2a0c40d2d7" target='_blank'>
              Control of Qubit Dynamics Using Reinforcement Learning
              </a>
            </td>
          <td>
            Dimitris Koutromanos, D. Stefanatos, E. Paspalakis
          </td>
          <td>2024-05-11</td>
          <td>Information</td>
          <td>0</td>
          <td>40</td>
        </tr>

        <tr id="In this article, we consider two dynamical systems: the McMillan sextupole and octupole integrable mappings, originally proposed by Edwin McMillan. Both represent the simplest symmetric McMillan maps, characterized by a single intrinsic parameter. While these systems find numerous applications across various domains of mathematics and physics, some of their dynamical properties remain unexplored. We aim to bridge this gap by providing a comprehensive description of all stable trajectories, including the parametrization of invariant curves, Poincar\'e rotation numbers, and canonical action-angle variables. In the second part, we establish connections between these maps and general chaotic maps in standard form. Our investigation reveals that the McMillan sextupole and octupole serve as first-order approximations of the dynamics around the fixed point, akin to the linear map and quadratic invariant (known as the Courant-Snyder invariant in accelerator physics), which represents zeroth-order approximations (referred to as linearization). Furthermore, we propose a novel formalism for nonlinear Twiss parameters, which accounts for the dependence of rotation number on amplitude. This stands in contrast to conventional betatron phase advance used in accelerator physics, which remains independent of amplitude. Notably, in the context of accelerator physics, this new formalism demonstrates its capability in predicting dynamical aperture around low-order resonances for flat beams, a critical aspect in beam injection/extraction scenarios.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6a8d139a939d3e8f40522265c89f6fb72d4cb1c3" target='_blank'>
              Dynamics of McMillan mappings I. McMillan multipoles
              </a>
            </td>
          <td>
            T. Zolkin, Sergei Nagaitsev, Ivan Morozov
          </td>
          <td>2024-05-09</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Machine learning (ML) methods have reached high accuracy levels for the prediction of in vacuo molecular properties. However, the simulation of large systems solely through ML methods (such as those based on neural network potentials) is still a challenge. In this context, one of the most promising frameworks for integrating ML schemes in the simulation of complex molecular systems are the so-called ML/MM methods. These multiscale approaches combine ML methods with classical force fields (MM), in the same spirit as the successful hybrid quantum mechanics-molecular mechanics methods (QM/MM). The key issue for such ML/MM methods is an adequate description of the coupling between the region of the system described by ML and the region described at the MM level. In the context of QM/MM schemes, the main ingredient of the interaction is electrostatic, and the state of the art is the so-called electrostatic-embedding. In this study, we analyze the quality of simpler mechanical embedding-based approaches, specifically focusing on their application within a ML/MM framework utilizing atomic partial charges derived in vacuo. Taking as reference electrostatic embedding calculations performed at a QM(DFT)/MM level, we explore different atomic charges schemes, as well as a polarization correction computed using atomic polarizabilites. Our benchmark data set comprises a set of about 80k small organic structures from the ANI-1x and ANI-2x databases, solvated in water. The results suggest that the minimal basis iterative stockholder (MBIS) atomic charges yield the best agreement with the reference coupling energy. Remarkable enhancements are achieved by including a simple polarization correction.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/53fcbd5cf105d82a7f476f4811455e46ced24b25" target='_blank'>
              Assessment of Embedding Schemes in a Hybrid Machine Learning/Classical Potentials (ML/MM) Approach.
              </a>
            </td>
          <td>
            Juan S Grassano, Ignacio Pickering, A. Roitberg, M. C. González Lebrero, Dario A. Estrin, J. Semelak
          </td>
          <td>2024-05-06</td>
          <td>Journal of chemical information and modeling</td>
          <td>0</td>
          <td>57</td>
        </tr>

        <tr id="Molecular representation learning has emerged as a game-changer at the intersection of AI and chemistry, with great potential in applications such as drug design and materials discovery. A substantial obstacle in successfully applying molecular representation learning is the difficulty of effectively and completely characterizing and learning molecular geometry, which has not been well addressed to date. To overcome this challenge, we propose a novel framework that features a novel geometric graph, termed HAGO-Graph, and a specifically designed geometric graph learning model, HAGO-Net. In the framework, the foundation is HAGO-Graph, which enables a complete characterization of molecular geometry in a hierarchical manner. Specifically, we leverage the concept of n-body in physics to characterize geometric patterns at multiple spatial scales. We then specifically design a message passing scheme, HAGO-MPS, and implement the scheme as a geometric graph neural network, HAGO-Net, to effectively learn the representation of HAGO-Graph by horizontal and vertical aggregation. We further prove DHAGO-Net, the derivative function of HAGO-Net, is an equivariant model. The proposed models are validated by extensive comparisons on four challenging benchmarks. Notably, the models exhibited state-of-the-art performance in molecular chirality identification and property prediction, achieving state-of-the-art performance on five properties of QM9 dataset. The models also achieved competitive results on molecular dynamics prediction task.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/290d0b33a7d52a8c5c3e73fc6e626f3b08ecb3ad" target='_blank'>
              HAGO-Net: Hierarchical Geometric Massage Passing for Molecular Representation Learning
              </a>
            </td>
          <td>
            Hongbin Pei, Taile Chen, Chen A, Huiqi Deng, Jing Tao, Pinghui Wang, Xiaohong Guan
          </td>
          <td>2024-03-24</td>
          <td>DBLP</td>
          <td>1</td>
          <td>3</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/68de982fad2e9f78cb4a92f3643ed6c568dd7beb" target='_blank'>
              Learning minimal automata with recurrent neural networks
              </a>
            </td>
          <td>
            B. Aichernig, Sandra König, Cristinel Mateis, Andrea Pferscher, Martin Tappler
          </td>
          <td>2024-03-21</td>
          <td>Software and Systems Modeling</td>
          <td>0</td>
          <td>25</td>
        </tr>

        <tr id="The evolution of AI and high-throughput technologies has boosted a rapid increase in the number of new materials, challenging our computational ability to comprehensively analyze their properties. Relaxed crystal structures often serve as the foundational basis for further property calculations. However, determining equilibrium structures traditionally involves computationally expensive iterative calculations. Here, we develop DeepRelax, an efficient deep generative model designed for rapid structural relaxation without any iterative process. DeepRelax learns the equilibrium structural distribution, enabling it to predict relaxed structures directly from their unrelaxed counterparts. The ability to perform structural relaxation in just a few hundred milliseconds per structure, combined with the scalability of parallel processing, makes DeepRelax particularly useful for large-scale virtual screening. To demonstrate the universality of DeepRelax, we benchmark it against three different databases of X-Mn-O oxides, Materials Project, and Computational 2D Materials Database with various types of materials. In these tests, DeepRelax exhibits both high accuracy and efficiency in structural relaxation, as further validated by DFT calculations. Finally, we integrate DeepRelax with an implementation of uncertainty quantification, enhancing its reliability and trustworthiness in material discovery. This work provides an efficient and trustworthy method to significantly accelerate large-scale computations, offering substantial advancements in the field of computational materials science.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0079d3c1eaff2cbe6496e57bb145b7504eff28b1" target='_blank'>
              Scaling Crystal Structure Relaxation with a Universal Trustworthy Deep Generative Model
              </a>
            </td>
          <td>
            Ziduo Yang, Yiming Zhao, Xiaoqing Liu, Xiuying Zhang, Yifan Li, Qiujie Lyu, Calvin Yu-Chian Chen, Lei Shen
          </td>
          <td>2024-04-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id="We propose a novel nonlinear bidirectionally coupled heterogeneous chain network whose dynamics evolve in discrete time. The backbone of the model is a pair of popular map-based neuron models, the Chialvo and the Rulkov maps. This model is assumed to proximate the intricate dynamical properties of neurons in the widely complex nervous system. The model is first realized via various nonlinear analysis techniques: fixed point analysis, phase portraits, Jacobian matrix, and bifurcation diagrams. We observe the coexistence of chaotic and period-4 attractors. Various codimension-1 and -2 patterns for example saddle-node, period-doubling, Neimark-Sacker, double Neimark-Sacker, flip- and fold-Neimark Sacker, and 1:1 and 1:2 resonance are also explored. Furthermore, the study employs two synchronization measures to quantify how the oscillators in the network behave in tandem with each other over a long number of iterations. Finally, a time series analysis of the model is performed to investigate its complexity in terms of sample entropy.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f5375ce11f3e9ca8219dcac0c58408d4b1b551d6" target='_blank'>
              Dynamical properties of a small heterogeneous chain network of neurons in discrete time
              </a>
            </td>
          <td>
            Indranil Ghosh, Anjana S. Nair, H. O. Fatoyinbo, S. S. Muni
          </td>
          <td>2024-05-09</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="This work combines auto encoders with cellular automata (CA) to present a novel hybrid strategy for anomaly identification. For feature learning, auto encoders are used to identify spatial patterns in the input data. Simultaneously, temporal and geographical dependencies are captured by CA, which improves the model's capacity to identify complicated anomalies. Training on spatially altered data, the auto encoder-CA hybrid model makes use of CA's temporal evolution to reveal dynamic patterns. Reconstruction errors between the input data and its decoded representation are computed to identify anomalies. A comprehensive framework for anomaly identification is provided by the synergy between spatial-temporal analysis of CA and auto encoder-based feature learning. Performance is optimized by fine-tuning the model's parameters, which include the auto encoder architecture and CA setup. The hybrid model's dynamic adaptation ensures robustness over time by accommodating changing data distributions. Evaluation measures show how well the suggested method captures abnormalities that appear in both temporal and geographical dimensions. A promising method for identifying abnormalities in complicated datasets with detailed spatial and temporal patterns is presented by this novel combination of auto encoders and cellular automata. The proposed method is evaluated with various parameters like reconstruction error, precision , recall, F1 score and Area Under the Receiver Operating Characteristic (ROC-AUC). The average accuracy is reported as 97.36% which is promising when compared with baseline methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a866bdc50d86ec8740fdb734e46e60a57da22706" target='_blank'>
              Auto encoders with Cellular Automata for Anomaly Detection
              </a>
            </td>
          <td>
            Pokkuluri Kiran Sree,Prasun Chakrabarti,Martin Margala, SSSN Usha Devi N
          </td>
          <td>2024-03-28</td>
          <td>Journal of Electrical Systems</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Coarse-grained modeling has become an important tool to supplement experimental measurements, allowing access to spatio-temporal scales beyond all-atom based approaches. The GōMartini model combines structure- and physics-based coarse-grained approaches, balancing computational efficiency and accurate representation of protein dynamics with the capabilities of studying proteins in different biological environments. This paper introduces an enhanced GōMartini model, which combines a virtual-site implementation of Gō models with Martini 3. The implementation has been extensively tested by the community since the release of the new version of Martini. This work demonstrates the capabilities of the model in diverse case studies, ranging from protein-membrane binding to protein-ligand interactions and AFM force profile calculations. The model is also versatile, as it can address recent inaccuracies reported in the Martini protein model. Lastly, the paper discusses the advantages, limitations, and future perspectives of the Martini 3 protein model and its combination with Gō models.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d1cf0b507c756cfdbca2198985ea08f532ad9417" target='_blank'>
              GōMartini 3: From large conformational changes in proteins to environmental bias corrections
              </a>
            </td>
          <td>
            Paulo C. T. Souza, Luís Borges-Araújo, Christopher Brasnett, Rodrigo A. Moreira, F. Grünewald, Peter Park, Liguo Wang, Hafez Razmazma, Ana C. Borges-Araújo, L. F. Cofas-Vargas, Luca Monticelli, Raúl Mera-Adasme, Manuel N. Melo, Sangwook Wu, S. Marrink, Adolfo B Poma, S. Thallmair
          </td>
          <td>2024-04-16</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>97</td>
        </tr>

        <tr id="Understanding the dynamics of the turbulent velocity gradient tensor (VGT) is essential to gain insights into the Navier-Stokes equations and improve small-scale turbulence modeling. However, characterizing the VGT dynamics conditional on all its relevant invariants in a continuous fashion is extremely difficult. In this paper, we represent the VGT Lagrangian dynamics using a network where each node represents a unique flow state. This approach enables us to discern how the VGT transitions from one state to another in a simplified fashion. Our analysis reveals intriguing features of the resulting network, such as the clustering of the commonly visited nodes where the eigenvalues of the VGT are real, in the proximity of the Vieillefosse tail. We then relate our complex network approach to the well-established VGT discretization based on the sign of its principal invariants, $Q$ and $R$, and its discriminant, $\Delta$. To this end, we separate the shortest paths on the network (geodesics) based on the $Q$-$R$ region to which their starting and arrival nodes belong. The distribution of the length of intra-region geodesics, with starting and arrival nodes belonging to the same $Q$-$R$ region, exhibits a distinct bimodality in two regions of the $Q$-$R$ plane, those in which the deviatoric part of the pressure Hessian introduces complexity to the VGT dynamics. Such bimodality is associated with infrequently visited nodes having to follow a long, low probability path to drastically change the state of the VGT compared to other flow states that can acquire the necessary characteristics without changing their sign for $Q$ or $R$. We complement the geodesics approach by examining random walks on the network, showing how the VGT non-normality and the associated production terms distinguish the shortest commuting paths between different $Q$-$R$ regions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/83be3f04aca29356871a2e334a055eb509f493c3" target='_blank'>
              Complex network approach to the turbulent velocity gradient dynamics: High- and low-probability Lagrangian paths
              </a>
            </td>
          <td>
            Christopher J. Keylock, Maurizio Carbone
          </td>
          <td>2024-04-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Physics-informed machine learning emerges as a transformative approach, bridging the gap between the high fidelity of mechanistic models and the adaptive, data-driven insights afforded by artificial intelligence and machine learning. In the realm of chemical reaction network modeling, this synergy is particularly valuable. It offers a solution to the pro-hibitive computational costs associated with detailed mechanistic models, while also capitalizing on the predictive power and flexibility of machine learning algorithms. This study exemplifies this innovative fusion by applying it to the critical biomedical challenge of Aβ fibril aggregation, shedding light on the mechanisms underlying Alzheimer’s disease. A corner-stone of this research is the introduction of an automatic reaction order model reduction framework, tailored to optimize the scale of reduced order kinetic models. This framework is not merely a technical enhancement; it represents a paradigm shift in how models are constructed and refined. By automatically determining the most appropriate level of detail for modeling reaction networks, our proposed approach significantly enhances the efficiency and accuracy of simulations. This is particularly crucial for systems like Aβ aggregation, where the precise characterization of nucleation and growth kinetics can provide insights into potential therapeutic targets. The potential generalizability of this automatic model reduction technique to other network models is a key highlight of this study. The methodology developed here has far-reaching implications, offering a scalable and adaptable tool for a wide range of applications beyond biomedical research. The ability to dynamically adjust model complexity in response to the specific demands of the system under study is a powerful asset. This flexibility ensures that the models remain both computationally feasible and scientifically relevant, capable of accommodating new data and evolving understandings of complex phenomena.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c94bd71338acf8a4f759c45587c85b0b03c79f0e" target='_blank'>
              Physics-informed machine learning for automatic model reduction in chemical reaction networks
              </a>
            </td>
          <td>
            J. Pateras, Colin Zhang, Shriya Majumdar, Ayush Pal, Preetam Ghosh
          </td>
          <td>2024-03-23</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Investigating reconstructive phase transitions in large-sized systems requires a highly efficient computational framework with computational cost proportional to the system size. Traditionally, widely used frameworks such as density functional theory (DFT) have been prohibitively expensive for extensive simulations on large systems that require long-time scales. To address this challenge, this study employed well-trained machine learning potential to simulate phase transitions in a large-size system. This work integrates the metadynamics simulation approach with machine learning potential, specifically deep potential, to enhance computational efficiency and accelerate the study of phase transition and consequent development of grains and dislocation defects in a system. The new method is demonstrated using the phase transitions of bulk silicon under high pressure. This approach has revealed the transition path and formation of polycrystalline silicon systems under specific stress conditions, demonstrating the effectiveness of deep potential-driven metadynamics simulations in gaining insights into complex material behaviors in large-sized systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/182e0e700457a67c0ed1191b6833eaba4ec2a3fb" target='_blank'>
              Phase Transition in Silicon from Machine Learning Informed Metadynamics.
              </a>
            </td>
          <td>
            Mangladeep Bhullar, Zihao Bai, Akinwumi Akinpelu, Yansun Yao
          </td>
          <td>2024-04-22</td>
          <td>Chemphyschem : a European journal of chemical physics and physical chemistry</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Networked dynamical systems are widely used as formal models of real-world cascading phenomena, such as the spread of diseases and information. Prior research has addressed the problem of learning the behavior of an unknown dynamical system when the underlying network has a single layer. In this work, we study the learnability of dynamical systems over multilayer networks, which are more realistic and challenging. First, we present an efficient PAC learning algorithm with provable guarantees to show that the learner only requires a small number of training examples to infer an unknown system. We further provide a tight analysis of the Natarajan dimension which measures the model complexity. Asymptotically, our bound on the Nararajan dimension is tight for almost all multilayer graphs. The techniques and insights from our work provide the theoretical foundations for future investigations of learning problems for multilayer dynamical systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4d4c0063e47ca85cf9c10b3ade6904eaa76704c7" target='_blank'>
              Efficient PAC Learnability of Dynamical Systems Over Multilayer Networks
              </a>
            </td>
          <td>
            Zirou Qiu, Abhijin Adiga, M. Marathe, S. S. Ravi, D. Rosenkrantz, R. Stearns, Anil Vullikanti
          </td>
          <td>2024-05-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>55</td>
        </tr>

        <tr id="Trajectory similarity search plays an essential role in autonomous driving, as it enables vehicles to analyze the information and characteristics of different trajectories to make informed decisions and navigate safely in dynamic environments. Existing work on the trajectory similarity search task primarily utilizes sequence-processing algorithms or Recurrent Neural Networks (RNNs), which suffer from the inevitable issues of complicated architecture and heavy training costs. Considering the intricate connections between trajectories, using Graph Neural Networks (GNNs) for data modeling is feasible. However, most methods directly use existing mathematical graph structures as the input instead of constructing specific graphs from certain vehicle trajectory data. This ignores such data's unique and dynamic characteristics. To bridge such a research gap, we propose VeTraSS -- an end-to-end pipeline for Vehicle Trajectory Similarity Search. Specifically, VeTraSS models the original trajectory data into multi-scale graphs, and generates comprehensive embeddings through a novel multi-layer attention-based GNN. The learned embeddings can be used for searching similar vehicle trajectories. Extensive experiments on the Porto and Geolife datasets demonstrate the effectiveness of VeTraSS, where our model outperforms existing work and reaches the state-of-the-art. This demonstrates the potential of VeTraSS for trajectory analysis and safe navigation in self-driving vehicles in the real world.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8c2ccaf6d6494346b87bb9837887072cc4e9472c" target='_blank'>
              VeTraSS: Vehicle Trajectory Similarity Search Through Graph Modeling and Representation Learning
              </a>
            </td>
          <td>
            Ming Cheng, Bowen Zhang, Ziyu Wang, Ziyi Zhou, Weiqi Feng, Yi Lyu, Xingjian Diao
          </td>
          <td>2024-04-11</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>3</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/dabd071ab522df047a3703298ac2d13e4bb72edc" target='_blank'>
              Global ranking of the sensitivity of interaction potential contributions within classical molecular dynamics force fields
              </a>
            </td>
          <td>
            W. Edeling, M. Vassaux, Yiming Yang, S. Wan, Serge Guillas, Peter V. Coveney
          </td>
          <td>2024-05-03</td>
          <td>npj Computational Materials</td>
          <td>0</td>
          <td>22</td>
        </tr>

        <tr id="Automated molecular simulations are used extensively for predicting material properties. Typically, these simulations exhibit two regimes: a dynamic equilibration part, followed by a steady state. For extracting observable properties, the simulations must first reach a steady state so that thermodynamic averages can be taken. However, as equilibration depends on simulation conditions, predicting the optimal number of simulation steps a priori is impossible. Here, we demonstrate the application of the Marginal Standard Error Rule (MSER) for automatically identifying the optimal truncation point in Grand Canonical Monte Carlo (GCMC) simulations. This novel automatic procedure determines the point in which steady state is reached, ensuring that figures-of-merits are extracted in an objective, accurate, and reproducible fashion. In the case of GCMC simulations of gas adsorption in metal-organic frameworks, we find that this methodology reduces the computational cost by up to 90%. As MSER statistics are independent of the simulation method that creates the data, this library is, in principle, applicable to any time series analysis in which equilibration truncation is required. The open-source Python implementation of our method, pyMSER, is publicly available for reuse and validation at https://github.com/IBM/pymser.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9ba1588312bda727da8237e695f280590589c954" target='_blank'>
              pyMSER -- An open-source library for automatic equilibration detection in molecular simulations
              </a>
            </td>
          <td>
            Felipe Lopes Oliveira, Binquan Luan, Pierre Moth'e Esteves, Mathias Steiner, Rodrigo Neumann Barros Ferreira
          </td>
          <td>2024-03-28</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>34</td>
        </tr>

        <tr id="Effective agent coordination is crucial in cooperative Multi-Agent Reinforcement Learning (MARL). While agent cooperation can be represented by graph structures, prevailing graph learning methods in MARL are limited. They rely solely on one-step observations, neglecting crucial historical experiences, leading to deficient graphs that foster redundant or detrimental information exchanges. Additionally, high computational demands for action-pair calculations in dense graphs impede scalability. To address these challenges, we propose inferring a Latent Temporal Sparse Coordination Graph (LTS-CG) for MARL. The LTS-CG leverages agents' historical observations to calculate an agent-pair probability matrix, where a sparse graph is sampled from and used for knowledge exchange between agents, thereby simultaneously capturing agent dependencies and relation uncertainty. The computational complexity of this procedure is only related to the number of agents. This graph learning process is further augmented by two innovative characteristics: Predict-Future, which enables agents to foresee upcoming observations, and Infer-Present, ensuring a thorough grasp of the environmental context from limited data. These features allow LTS-CG to construct temporal graphs from historical and real-time information, promoting knowledge exchange during policy learning and effective collaboration. Graph learning and agent training occur simultaneously in an end-to-end manner. Our demonstrated results on the StarCraft II benchmark underscore LTS-CG's superior performance.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bb7c548ebe4e622c9f828336a914164f6279551a" target='_blank'>
              Inferring Latent Temporal Sparse Coordination Graph for Multi-Agent Reinforcement Learning
              </a>
            </td>
          <td>
            Wei Duan, Jie Lu, Junyu Xuan
          </td>
          <td>2024-03-28</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>16</td>
        </tr>

        <tr id="
 Zirconium hydride (ZrH2) is an ideal neutron moderator material. However, radiation effects significantly alter its properties, subsequently impacting its behavior and the lifespan of the reactor. The threshold energy of displacement is an important quantity of the number of radiation defects produced, which helps us to predict the evolution of radiation defects in ZrH2. Molecular dynamics (MD) and ab initio molecular dynamics (AIMD) are two main methods for calculating the threshold energy of displacement. MD simulations with empirical potentials often fail to accurately depict the transitional states that lattice atoms must surpass to reach an interstitial state. Additionally, the AIMD method does not afford large-scale calculation, posing a computational challenge beyond the scope of density functional theory simulations. Machine learning potentials are renowned for their high accuracy and efficiency, making them an increasingly preferred choice for molecular dynamics simulations. In this work, we developed an accurate potential energy model for the ZrH2 system by using the deep-potential (DP) method. The DP model has a high degree of agreement with first-principles calculations for the typic defect energies and mechanical properties of the ZrH2 system, including the basic bulk properties, formation energy of point defects, as well as diffusion behavior of hydrogen and zirconium. By integrating the DP model with Ziegler-Biersack-Littmark (ZBL) potential, we have predicted the threshold energies of displacement of zirconium and hydrogen in ε-ZrH2.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9dc87017a307838d11cef852b80f595718458ad1" target='_blank'>
              The properties of radiation defects and threshold energies of displacement in zirconium hydride obtained by a new deep-learning potential
              </a>
            </td>
          <td>
            Xi Wang, Meng Tang, Mingxuan Jiang, Yangchun Chen, Zhixiao Liu, Huiqiu Deng
          </td>
          <td>2024-03-21</td>
          <td>Chinese Physics B</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="

The application of deep generative models for molecular discovery has
witnessed a significant surge in recent years. Currently, the field of molecular generation and molecular
optimization is predominantly governed by autoregressive models regardless of how molecular
data is represented. However, an emerging paradigm in the generation domain is diffusion models,
which treat data non-autoregressively and have achieved significant breakthroughs in areas such
as image generation.



The potential and capability of diffusion models in molecular generation and optimization
tasks remain largely unexplored. In order to investigate the potential applicability of diffusion models
in the domain of molecular exploration, we proposed DiffSeqMol, a molecular sequence generation
model, underpinned by diffusion process.



DiffSeqMol distinguishes itself from traditional autoregressive methods by
its capacity to draw samples from random noise and direct generating the entire molecule. Through
experiment evaluations, we demonstrated that DiffSeqMol can achieve, even surpass, the performance
of established state-of-the-art models on unconditional generation tasks and molecular optimization
tasks.



Taken together, our results show that DiffSeqMol can be considered a promising molecular
generation method. It opens new pathways to traverse the expansive chemical space and to
discover novel molecules.
">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/891b3c88d685308528c25d6d0992c81b9e2cdb51" target='_blank'>
              DiffSeqMol: A Non-Autoregressive Diffusion-Based Approach for Molecular Sequence Generation and Optimization
              </a>
            </td>
          <td>
            Zixu Wang, Yangyang Chen, Xiulan Guo, Yayang Li, Pengyong Li, Chunyan Li, Xiucai Ye, Tetsuya Sakurai
          </td>
          <td>2024-04-01</td>
          <td>Current Bioinformatics</td>
          <td>0</td>
          <td>16</td>
        </tr>

        <tr id="Generative models for structure-based drug design (SBDD) have shown promising results in recent years. Existing works mainly focus on how to generate molecules with higher binding affinity, ignoring the feasibility prerequisites for generated 3D poses and resulting in false positives. We conduct thorough studies on key factors of ill-conformational problems when applying autoregressive methods and diffusion to SBDD, including mode collapse and hybrid continuous-discrete space. In this paper, we introduce MolCRAFT, the first SBDD model that operates in the continuous parameter space, together with a novel noise reduced sampling strategy. Empirical results show that our model consistently achieves superior performance in binding affinity with more stable 3D structure, demonstrating our ability to accurately model interatomic interactions. To our best knowledge, MolCRAFT is the first to achieve reference-level Vina Scores (-6.59 kcal/mol) with comparable molecular size, outperforming other strong baselines by a wide margin (-0.84 kcal/mol). Code is available at https://github.com/AlgoMole/MolCRAFT.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/81f1f7518ff1db7992d66fac0663efabdb7ab430" target='_blank'>
              MolCRAFT: Structure-Based Drug Design in Continuous Parameter Space
              </a>
            </td>
          <td>
            Yanru Qu, Keyue Qiu, Yuxuan Song, Jingjing Gong, Jiawei Han, Mingyue Zheng, Hao Zhou, Wei-Ying Ma
          </td>
          <td>2024-04-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Continuous time recurrent neural networks (CTRNNs) are systems of coupled ordinary differential equations (ODEs) inspired by the structure of neural networks in the brain. CTRNNs are known to be universal dynamical approximators: given a large enough system, the parameters of a CTRNN can be tuned to produce output that is arbitrarily close to that of any other dynamical system. However, in practice, both designing systems of CTRNN to have a certain output, and the reverse-understanding the dynamics of a given system of CTRNN-can be nontrivial. In this article, we describe a method for embedding any specified Turing machine in its entirety into a CTRNN. As such, we describe in detail a continuous time dynamical system that performs arbitrary discrete-state computations. We suggest that in acting as both a continuous time dynamical system and as a computer, the study of such systems can help refine and advance the debate concerning the Computational Hypothesis that cognition is a form of computation and the Dynamical Hypothesis that cognitive systems are dynamical systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a4c18d67633c17f70ffc53a4f2853ff51348378c" target='_blank'>
              A Continuous Time Dynamical Turing Machine.
              </a>
            </td>
          <td>
            C. Postlethwaite, Peter Ashwin, Matthew Egbert
          </td>
          <td>2024-05-16</td>
          <td>IEEE transactions on neural networks and learning systems</td>
          <td>0</td>
          <td>18</td>
        </tr>

        <tr id="This paper introduces a novel theoretical simplification of the Diffusion Schr\"odinger Bridge (DSB) that facilitates its unification with Score-based Generative Models (SGMs), addressing the limitations of DSB in complex data generation and enabling faster convergence and enhanced performance. By employing SGMs as an initial solution for DSB, our approach capitalizes on the strengths of both frameworks, ensuring a more efficient training process and improving the performance of SGM. We also propose a reparameterization technique that, despite theoretical approximations, practically improves the network's fitting capabilities. Our extensive experimental evaluations confirm the effectiveness of the simplified DSB, demonstrating its significant improvements. We believe the contributions of this work pave the way for advanced generative modeling. The code is available at https://github.com/checkcrab/SDSB.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/84541396e137fa8cc45799646cf2b6834b16803c" target='_blank'>
              Simplified Diffusion Schrödinger Bridge
              </a>
            </td>
          <td>
            Zhicong Tang, Tiankai Hang, Shuyang Gu, Dong Chen, Baining Guo
          </td>
          <td>2024-03-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="In complex and unknown processes, global models are initially generated over the entire experimental space, but they often fail to provide accurate predictions in local areas. Recognizing this limitation, this study addresses the need for models that effectively represent both global and local experimental spaces. It introduces a novel machine learning (ML) approach: Polynomial Chaos Expanded Gaussian Process (PCEGP), leveraging polynomial chaos expansion (PCE) to calculate input-dependent hyperparameters of the Gaussian process (GP). This approach provides a mathematically interpretable method that incorporates non-stationary covariance functions and heteroscedastic noise estimation to generate locally adapted models. The model performance is compared to different algorithms in benchmark tests for regression tasks. The results demonstrate low prediction errors of the PCEGP in these benchmark applications, highlighting model performance that is often competitive with or superior to previous methods. A key advantage of the presented model is the transparency and traceability in the calculation of hyperparameters and model predictions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/79fcfc9d7d191364d7c1f0e349ea576035887a86" target='_blank'>
              Polynomial Chaos Expanded Gaussian Process
              </a>
            </td>
          <td>
            Dominik Polke, Tim Kosters, Elmar Ahle, Dirk Soffker
          </td>
          <td>2024-05-02</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Neural networks in fluid mechanics offer an efficient approach for exploring complex flows, including multiphase and free surface flows. The recurrent neural network, particularly the Long Short-Term Memory (LSTM) model, proves attractive for learning mappings from transient inputs to dynamic outputs. This study applies LSTM to predict transient and static outputs for fluid flows under surface tension effects. Specifically, we explore two distinct droplet dynamic scenarios: droplets with diverse initial shapes impacting with solid surfaces, as well as the coalescence of two droplets following collision. Using only dimensionless numbers and geometric time series data from numerical simulations, LSTM predicts the energy budget. The marker-and-cell front-tracking methodology combined with a marker-and-cell finite-difference strategy is adopted for simulating the droplet dynamics. Using a recurrent neural network (RNN) architecture fed with time series data derived from geometrical parameters, as for example droplet diameter variation, our study shows the accuracy of our approach in predicting energy budgets, as for instance the kinetic, dissipation, and surface energy trends, across a range of Reynolds and Weber numbers in droplet dynamic problems. Finally, a two-phase sequential neural network using only geometric data, which is readily available in experimental settings, is employed to predict the energies and then use them to estimate static parameters, such as the Reynolds and Weber numbers. While our methodology has been primarily validated with simulation data, its adaptability to experimental datasets is a promising avenue for future exploration. We hope that our strategy can be useful for diverse applications, spanning from inkjet printing to combustion engines, where the prediction of energy budgets or dissipation energies is crucial.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a3e51c446c3a8a6b0a0b8275259b4269b089e2ed" target='_blank'>
              Predicting Energy Budgets in Droplet Dynamics: A Recurrent Neural Network Approach
              </a>
            </td>
          <td>
            Diego A. de Aguiar, Hugo L. França, C. Oishi
          </td>
          <td>2024-03-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>15</td>
        </tr>

        <tr id="Biological sequences do not come at random. Instead, they appear with particular frequencies that reflect properties of the associated system or phenomenon. Knowing how biological sequences are distributed in sequence space is thus a natural first step toward understanding the underlying mechanisms. Here we propose a new method for inferring the probability distribution from which a sample of biological sequences were drawn for the case where the sequences are composed of elements that admit a natural ordering. Our method is based on Bayesian field theory, a physics-based machine learning approach, and can be regarded as a nonparametric extension of the traditional maximum entropy estimate. As an example, we use it to analyze the aneuploidy data pertaining to gliomas from The Cancer Genome Atlas project. In addition, we demonstrate two follow-up analyses that can be performed with the resulting probability distribution. One of them is to investigate the associations among the sequence sites. This provides us a way to infer the governing biological grammar. The other is to study the global geometry of the probability landscape, which allows us to look at the problem from an evolutionary point of view. It can be seen that this methodology enables us to learn from a sample of sequences about how a biological system or phenomenon in the real world works.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7e118a5dd74efba53e070f95ac6d091754f7bf58" target='_blank'>
              Density estimation for ordinal biological sequences and its applications.
              </a>
            </td>
          <td>
            Wei-Chia Chen, Juannan Zhou, David M. McCandlish
          </td>
          <td>2024-04-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>16</td>
        </tr>

        <tr id="Recent advances in stochastic optimization have yielded the interactive particle Langevin algorithm (IPLA), which leverages the notion of interacting particle systems (IPS) to efficiently sample from approximate posterior densities. This becomes particularly crucial within the framework of Expectation-Maximization (EM), where the E-step is computationally challenging or even intractable. Although prior research has focused on scenarios involving convex cases with gradients of log densities that grow at most linearly, our work extends this framework to include polynomial growth. Taming techniques are employed to produce an explicit discretization scheme that yields a new class of stable, under such non-linearities, algorithms which are called tamed interactive particle Langevin algorithms (tIPLA). We obtain non-asymptotic convergence error estimates in Wasserstein-2 distance for the new class under an optimal rate.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/de9330f9d603bede4488d1033057ba3fb7e4edb1" target='_blank'>
              Taming the Interacting Particle Langevin Algorithm -- the superlinear case
              </a>
            </td>
          <td>
            Tim Johnston, Nikolaos Makras, S. Sabanis
          </td>
          <td>2024-03-28</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>19</td>
        </tr>

        <tr id="A dynamic Monte Carlo (MC) method recently proposed by us [Nagai et al., J. Chem. Phys. 156, 154506 (2022)] to describe single-particle diffusion of a molecule in a heterogeneous space with position-dependent diffusion coefficient and free energy is generalized here to n-particle dynamics, where n molecules diffuse in heterogeneous media interacting via their intermolecular potential. Starting from the master equation, we give an algebraic proof that the dynamic MC transition probabilities proposed here produce particle trajectories that satisfy the n-particle diffusion equation with position-dependent diffusion coefficient D0i(ri), free energy F1i(ri), and intermolecular interactions Vij(ri, rj). The MC calculations based on this method are compared to molecular dynamics (MD) calculations for two-dimensional heterogeneous Lennard-Jones test systems, showing excellent agreement of the long-distance global diffusion coefficient between the two cases. Thus, the particle trajectories produced by the present MC transition probabilities satisfy the n-particle diffusion equation, and the diffusion equation well describes the long-distance trajectories produced by the MD calculations. The method is also an extension of the conventional equilibrium Metropolis MC calculation for homogeneous systems with a constant diffusion coefficient to the dynamics in heterogeneous systems with a position-dependent diffusion coefficient and potential. In the present method, interactions and dynamics of the real systems are coarse-grained such that the calculation cost is drastically reduced. This provides an approach for the investigation of particle dynamics in very complex and large systems, where the diffusing length is of sub-micrometer order and the diffusion time is of the order of milliseconds or more.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9857b1c683557c2b6558fbf1edbc1dfdda71a1fb" target='_blank'>
              A new dynamic Monte Carlo method satisfying n-particle diffusion equation with position-dependent diffusion coefficient, free energy, and intermolecular interactions.
              </a>
            </td>
          <td>
            Susumu Okazaki
          </td>
          <td>2024-05-02</td>
          <td>The Journal of chemical physics</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Predicting chemical reaction yields is pivotal for efficient chemical synthesis, an area that focuses on the creation of novel compounds for diverse uses. 
Yield prediction demands accurate representations of reactions for forecasting practical transformation rates. Yet, the uncertainty issues broadcasting in real-world situations prohibit current models to excel in this task owing to the high sensitivity of yield activities and the uncertainty in yield measurements. Existing models often utilize single-modal feature representations, such as molecular fingerprints, SMILES sequences, or molecular graphs, which is not sufficient to capture the complex interactions and dynamic behavior of molecules in reactions. In this paper, we present an advanced Uncertainty-Aware Multimodal model (UAM) to tackle these challenges. Our approach seamlessly integrates data sources from multiple modalities by encompassing sequence representations, molecular graphs, and expert-defined chemical reaction features for a comprehensive representation of reactions. Additionally, we address both the model and data-based uncertainty, refining the model's predictive capability. Extensive experiments on three datasets, including two high throughput experiment (HTE) datasets and one chemist-constructed Amide coupling reaction dataset, demonstrate that UAM outperforms the state-of-the-art methods. The code and used datasets are available at https://github.com/jychen229/Multimodal-reaction-yield-prediction.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/fedccf6c70a7d075753e68deeb4d03f936c7e824" target='_blank'>
              Uncertainty-Aware Yield Prediction with Multimodal Molecular Features
              </a>
            </td>
          <td>
            Jiayuan Chen, Kehan Guo, Zhen Liu, O. Isayev, Xiangliang Zhang
          </td>
          <td>2024-03-24</td>
          <td>DBLP</td>
          <td>0</td>
          <td>40</td>
        </tr>

        <tr id="The popularity of transfer learning stems from the fact that it can borrow information from useful auxiliary datasets. Existing statistical transfer learning methods usually adopt a global similarity measure between the source data and the target data, which may lead to inefficiency when only local information is shared. In this paper, we propose a novel Bayesian transfer learning method named"CONCERT"to allow robust local information transfer for high-dimensional data analysis. A novel conditional spike-and-slab prior is introduced in the joint distribution of target and source parameters for information transfer. By incorporating covariate-specific priors, we can characterize the local similarities and make the sources work collaboratively to help improve the performance on the target. Distinguished from existing work, CONCERT is a one-step procedure, which achieves variable selection and information transfer simultaneously. Variable selection consistency is established for our CONCERT. To make our algorithm scalable, we adopt the variational Bayes framework to facilitate implementation. Extensive experiments and a genetic data analysis demonstrate the validity and the advantage of CONCERT over existing cutting-edge transfer learning methods. We also extend our CONCERT to the logistical models with numerical studies showing its superiority over other methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/cfc99c855e2a8d556309b9ce871e9bf837ae2535" target='_blank'>
              CONCERT: Covariate-Elaborated Robust Local Information Transfer with Conditional Spike-and-Slab Prior
              </a>
            </td>
          <td>
            Ruqian Zhang, Yijiao Zhang, Annie Qu, Zhongyi Zhu, Juan Shen
          </td>
          <td>2024-03-30</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="In this machine learning (ML) study, we delved into the unique properties of liquid lanthanum and the Li4Pb alloy, revealing some unexpected features and also firmly establishing some of the debated characteristics. Leveraging interatomic potentials derived from ab initio calculations, our investigation achieved a level of precision comparable to first-principles methods while at the same time entering the hydrodynamic regime. We compared the structure factors and pair distribution functions to experimental data and unearthed distinctive collective excitations with intriguing features. Liquid lanthanum unveiled two transverse collective excitation branches, each closely tied to specific peaks in the velocity autocorrelation function spectrum. Furthermore, the analysis of the generalized specific heat ratio in the hydrodynamic regime investigated with the ML molecular dynamics simulations uncovered a peculiar behavior, impossible to discern with only ab initio simulations. Liquid Li4Pb, on the other hand, challenged existing claims by showcasing a rich array of branches in its longitudinal dispersion relation, including a high-frequency LiLi mode with a nonhydrodynamic optical character that maintains a finite value as q → 0. Additionally, we conducted an in-depth analysis of various transport coefficients, expanding our understanding of these liquid metallic systems. In summary, our ML approach yielded precise results, offering new and captivating insights into the structural and dynamic aspects of these materials.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8b40ce2d303d6a0b692e3877979e535f2c6fd8c8" target='_blank'>
              Exploring Challenging Properties of Liquid Metallic Systems through Machine Learning: Liquid La and Li4Pb Systems
              </a>
            </td>
          <td>
            Beatriz G. del Rio, Luis E González
          </td>
          <td>2024-04-01</td>
          <td>Journal of Chemical Theory and Computation</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="The discovery of complex concentrated alloys has unveiled materials with diverse atomic environments, prompting the exploration of solute segregation beyond dilute alloys. Data-driven methods offer promising for modeling segregation in such chemically complex environments, and are employed in this study to understand segregation behavior of a refractory complex concentrated alloy, NbMoTaW. A flexible methodology is developed that uses composable computational modules, with different arrangements of these modules employed to obtain site availabilities at absolute zero and the corresponding density of states beyond the dilute limit, resulting in an extremely large dataset containing 10 million data points. The artificial neural network developed here can rely solely on descriptions of local atomic environments to predict behavior at the dilute limit with very small errors, while the addition of negative segregation instance classification allows any solute concentration from zero up to the equiatomic concentration for ternary or quaternary alloys to be modeled at room temperature. The machine learning model thus achieves a significant speed advantage over traditional atomistic simulations, being four orders of magnitude faster, while only experiencing a minimal reduction in accuracy. This efficiency presents a powerful tool for rapid microstructural and interfacial design in unseen domains. Scientifically, our approach reveals a transition in the segregation behavior of Mo from unfavorable in simple systems to favorable in complex environments. Additionally, increasing solute concentration was observed to cause anti-segregation sites to begin to fill, challenging conventional understanding and highlighting the complexity of segregation dynamics in chemically complex environments.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f6b1d7749a6d5a5725861c7a87bfb45e83795dd0" target='_blank'>
              A Machine Learning Framework for the Prediction of Grain Boundary Segregation in Chemically Complex Environments
              </a>
            </td>
          <td>
            Doruk Aksoy, Jian Luo, Penghui Cao, T. Rupert
          </td>
          <td>2024-04-09</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>32</td>
        </tr>

        <tr id="Quasi two-dimensional Coulomb systems have drawn widespread interest. The reduced symmetry of these systems leads to complex collective behaviors, yet simultaneously poses significant challenges for particle-based simulations. In this paper, a novel method is presented for efficiently simulate a collection of charges confined in doubly-periodic slabs, with the extension to scenarios involving dielectric jumps at slab boundaries. Unlike existing methods, the method is insensitive to the aspect ratio of simulation box, and it achieves optimal O(N) complexity and strong scalability, thanks to the random batch Ewald (RBE) approach. Moreover, the additional cost for polarization contributions, represented as image reflection series, is reduced to a negligible cost via combining the RBE with an efficient structure factor coefficient re-calibration technique in k-space. Explicit formulas for optimal parameter choices of the algorithm are provided through error estimates, together with a rigorous proof. Finally, we demonstrate the accuracy, efficiency and scalability of our method, called RBE2D, via numerical tests across a variety of prototype systems. An excellent agreement between the RBE2D and the PPPM method is observed, with a significant reduction in the computational cost and strong scalability, demonstrating that it is a promising method for a broad range of charged systems under quasi-2D confinement.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6613b32b131e521c8bf3ed62d8ba6835ac78270e" target='_blank'>
              Random Batch Ewald Method for Dielectrically Confined Coulomb Systems
              </a>
            </td>
          <td>
            Zecheng Gan, Xuanzhao Gao, Jiuyang Liang, Zhe Xu
          </td>
          <td>2024-05-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="We develop a convergent reaction-drift-diffusion master equation (CRDDME) to facilitate the study of reaction processes in which spatial transport is influenced by drift due to one-body potential fields within general domain geometries. The generalized CRDDME is obtained through two steps. We first derive an unstructured grid jump process approximation for reversible diffusions, enabling the simulation of drift-diffusion processes where the drift arises due to a conservative field that biases particle motion. Leveraging the Edge-Averaged Finite Element method, our approach preserves detailed balance of drift-diffusion fluxes at equilibrium, and preserves an equilibrium Gibbs-Boltzmann distribution for particles undergoing drift-diffusion on the unstructured mesh. We next formulate a spatially-continuous volume reactivity particle-based reaction-drift-diffusion model for reversible reactions of the form $\textrm{A} + \textrm{B} \leftrightarrow \textrm{C}$. A finite volume discretization is used to generate jump process approximations to reaction terms in this model. The discretization is developed to ensure the combined reaction-drift-diffusion jump process approximation is consistent with detailed balance of reaction fluxes holding at equilibrium, along with supporting a discrete version of the continuous equilibrium state. The new CRDDME model represents a continuous-time discrete-space jump process approximation to the underlying volume reactivity model. We demonstrate the convergence and accuracy of the new CRDDME through a number of numerical examples, and illustrate its use on an idealized model for membrane protein receptor dynamics in T cell signaling.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/01125419b7d5796d17809e1815f2c0613ecf33b4" target='_blank'>
              An Unstructured Mesh Reaction-Drift-Diffusion Master Equation with Reversible Reactions
              </a>
            </td>
          <td>
            Samuel A. Isaacson, Ying Zhang
          </td>
          <td>2024-05-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Coarse-grained (CG) molecular models greatly reduce the computational cost of simulations allowing for longer and larger simulations, but come with an artificially increased acceleration of the dynamics when compared to the parent atomistic (AA) simulation. This impedes their use for the quantitative study of dynamical properties. During coarse-graining, grouping several atoms into one CG bead not only reduces the number of degrees of freedom but also reduces the roughness on the molecular surfaces, leading to the acceleration of dynamics. The RoughMob approach [M. K. Meinel and F. Müller-Plathe, J. Phys. Chem. B 126(20), 3737-3747 (2022)] quantifies this change in geometry and correlates it to the acceleration by making use of four so-called roughness volumes. This method was developed using simple one-bead CG models of a set of hydrocarbon liquids. Potentials for pure components are derived by the structure-based iterative Boltzmann inversion. In this paper, we find that, for binary mixtures of simple hydrocarbons, it is sufficient to use simple averaging rules to calculate the roughness volumes in mixtures from the roughness volumes of pure components and add a correction term quadratic in the concentration without the need to perform any calculation on AA or CG trajectories of the mixtures themselves. The acceleration factors of binary diffusion coefficients and both self-diffusion coefficients show a large dependence on the overall acceleration of the system and can be predicted a priori without the need for any AA simulations within a percentage error margin, which is comparable to routine measurement accuracies. Only if a qualitatively accurate description of the concentration dependence of the binary diffusion coefficient is desired, very few additional simulations of the pure components and the equimolar mixture are required.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1759211addcb1fc18c39ebafc3705bc7e25a7d4d" target='_blank'>
              Predicting the artificial dynamical acceleration of binary hydrocarbon mixtures upon coarse-graining with roughness volumes and simple averaging rules.
              </a>
            </td>
          <td>
            Melissa K. Meinel, F. Müller-Plathe
          </td>
          <td>2024-05-02</td>
          <td>The Journal of chemical physics</td>
          <td>0</td>
          <td>59</td>
        </tr>

        <tr id="The motivation behind this study is to overcome the complex mathematical formulation and time-consuming nature of traditional numerical methods used in solving differential equations. It seeks an alternative approach for more efficient and simplified solutions. A Deep Neural Network (DNN) is utilized to understand the intricate correlations between the oscillator’s variables and to precisely capture their dynamics by being trained on a dataset of known oscillator behaviors. In this work, we discuss the main challenge of predicting the behavior of oscillators without depending on complex strategies or time-consuming simulations. The present work proposes a favorable modified form of neural structure to improve the strategy for simulating linear and nonlinear harmonic oscillators from mechanical systems by formulating an ANN as a DNN via an appropriate oscillating activation function. The proposed methodology provides the solutions of linear and nonlinear differential equations (DEs) in differentiable form and is a more accurate approximation as compared to the traditional numerical method. The Van der Pol equation with parametric damping and the Mathieu equation are adopted as illustrations. Experimental analysis shows that our proposed scheme outperforms other numerical methods in terms of accuracy and computational cost. We provide a comparative analysis of the outcomes obtained through our proposed approach and those derived from the LSODA algorithm, utilizing numerical techniques, Adams–Bashforth, and the Backward Differentiation Formula (BDF). The results of this research provide insightful information for engineering applications, facilitating improvements in energy efficiency, and scientific innovation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6535b101b792ba6de30f73af92407e39980aec0b" target='_blank'>
              Oscillator Simulation with Deep Neural Networks
              </a>
            </td>
          <td>
            J. Rahman, Sana Danish, Dianchen Lu
          </td>
          <td>2024-03-23</td>
          <td>Mathematics</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Over the last decade chemical exchange saturation transfer (CEST) NMR methods have emerged as powerful tools to characterize biomolecular conformational dynamics occurring between a visible major state and ‘invisible’ minor states. The ability of the CEST experiment to detect these minor states, and provide precise exchange parameters, hinges on using appropriate B1 field strengths during the saturation period. Typically, a pair of B1 fields with ω1 (= 2πB1) values around the exchange rate kex are chosen. Here we show that the transverse relaxation rate of the minor state resonance (R2,B) also plays a crucial role in determining the B1 fields that lead to the most informative datasets. Using , to guide the choice of B1, instead of kex, leads to data wherefrom substantially more accurate exchange parameters can be derived. The need for higher B1 fields, guided by K, is demonstrated by studying the conformational exchange in two mutants of the 71 residue FF domain with kex ∼11 s-1 and ∼72 s-1, respectively. In both cases analysis of CEST datasets recorded using B1 field values guided by kex lead to imprecise exchange parameters, whereas using B1 values guided by K resulted in precise site-specific exchange parameters. The conclusions presented here will be valuable while using CEST to study slow processes at sites with large intrinsic relaxation rates, including carbonyl sites in small to medium sized proteins, amide 15N sites in large proteins and when the minor state dips are broadened due to exchange among the minor states.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/668fe0e21745e3710c67c4b8dd215991ff531274" target='_blank'>
              Increasing the accuracy of exchange parameters reporting on slow dynamics by performing CEST experiments with high B1 fields
              </a>
            </td>
          <td>
            Nihar Pradeep Khandave, D. F. Hansen, P. Vallurupalli, Flemming Hansen, AF Eq
          </td>
          <td>2024-04-03</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>27</td>
        </tr>

        <tr id="Double descent presents a counter-intuitive aspect within the machine learning domain, and researchers have observed its manifestation in various models and tasks. While some theoretical explanations have been proposed for this phenomenon in specific contexts, an accepted theory for its occurring mechanism in deep learning remains yet to be established. In this study, we revisited the phenomenon of double descent and discussed the conditions of its occurrence. This paper introduces the concept of class-activation matrices and a methodology for estimating the effective complexity of functions, on which we unveil that over-parameterized models exhibit more distinct and simpler class patterns in hidden activations compared to under-parameterized ones. We further looked into the interpolation of noisy labelled data among clean representations and demonstrated overfitting w.r.t. expressive capacity. By comprehensively analysing hypotheses and presenting corresponding empirical evidence that either validates or contradicts these hypotheses, we aim to provide fresh insights into the phenomenon of double descent and benign over-parameterization and facilitate future explorations. By comprehensively studying different hypotheses and the corresponding empirical evidence either supports or challenges these hypotheses, our goal is to offer new insights into the phenomena of double descent and benign over-parameterization, thereby enabling further explorations in the field. The source code is available at https://github.com/Yufei-Gu-451/sparse-generalization.git.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3e78c3949c265e680727c71aceb69ac0685b16e9" target='_blank'>
              Class-wise Activation Unravelling the Engima of Deep Double Descent
              </a>
            </td>
          <td>
            Yufei Gu
          </td>
          <td>2024-05-13</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="The theory of forward–backward stochastic differential equations occupies an important position in stochastic analysis and practical applications. However, the numerical solution of forward–backward stochastic differential equations, especially for high-dimensional cases, has stagnated. The development of deep learning provides ideas for its high-dimensional solution. In this paper, our focus lies on the fully coupled forward–backward stochastic differential equation. We design a neural network structure tailored to the characteristics of the equation and develop a hybrid BiGRU model for solving it. We introduce the time dimension based on the sequence nature after discretizing the FBSDE. By considering the interactions between preceding and succeeding time steps, we construct the BiGRU hybrid model. This enables us to effectively capture both long- and short-term dependencies, thus mitigating issues such as gradient vanishing and explosion. Residual learning is introduced within the neural network at each time step; the structure of the loss function is adjusted according to the properties of the equation. The model established above can effectively solve fully coupled forward–backward stochastic differential equations, effectively avoiding the effects of dimensional catastrophe, gradient vanishing, and gradient explosion problems, with higher accuracy, stronger stability, and stronger model interpretability.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1d32d25aac2bcd65681733e96d381206b94f4846" target='_blank'>
              Hybrid Neural Networks for Solving Fully Coupled, High-Dimensional Forward–Backward Stochastic Differential Equations
              </a>
            </td>
          <td>
            Mingcan Wang, Xiangjun Wang
          </td>
          <td>2024-04-03</td>
          <td>Mathematics</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The quest to understand structure-function relationships in networks across scientific disciplines has intensified. However, the optimal network architecture remains elusive, particularly for complex information processing. Therefore, we investigate how optimal and specific network structures form to efficiently solve distinct tasks using a novel framework of performance-dependent network evolution, leveraging reservoir computing principles. Our study demonstrates that task-specific minimal network structures obtained through this framework consistently outperform networks generated by alternative growth strategies and Erd\H{o}s-R\'enyi random networks. Evolved networks exhibit unexpected sparsity and adhere to scaling laws in node-density space while showcasing a distinctive asymmetry in input and information readout nodes distribution. Consequently, we propose a heuristic for quantifying task complexity from performance-dependently evolved networks, offering valuable insights into the evolutionary dynamics of network structure-function relationships. Our findings not only advance the fundamental understanding of process-specific network evolution but also shed light on the design and optimization of complex information processing mechanisms, notably in machine learning.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9d53f3475f9e443e270a3d84cae60b6817ec3497" target='_blank'>
              Evolution beats random chance: Performance-dependent network evolution for enhanced computational capacity
              </a>
            </td>
          <td>
            Manish Yadav, Sudeshna Sinha, M. Stender
          </td>
          <td>2024-03-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>11</td>
        </tr>

    </tbody>
    <tfoot>
      <tr>
          <th>Abstract</th>
          <th>Title</th>
          <th>Authors</th>
          <th>Publication Date</th>
          <th>Journal/Conference</th>
          <th>Citation count</th>
          <th>Highest h-index</th>
      </tr>
    </tfoot>
    </table>
    </p>
  </div>

</body>

<script>

  function create_author_list(author_list) {
    let td_author_element = document.getElementById();
    for (let i = 0; i < author_list.length; i++) {
          // tdElements[i].innerHTML = greet(tdElements[i].innerHTML);
          alert (author_list[i]);
      }
  }

  var trace1 = {
    x: ['2023', '2024'],
    y: [1, 22],
    name: 'Num of citations',
    yaxis: 'y1',
    type: 'scatter'
  };

  var data = [trace1];

  var layout = {
    yaxis: {
      title: 'Num of citations',
      }
  };
  Plotly.newPlot('myDiv1', data, layout);
</script>
<script>
var dataTableOptions = {
        initComplete: function () {
        this.api()
            .columns()
            .every(function () {
                let column = this;

                // Create select element
                let select = document.createElement('select');
                select.add(new Option(''));
                column.footer().replaceChildren(select);

                // Apply listener for user change in value
                select.addEventListener('change', function () {
                    column
                        .search(select.value, {exact: true})
                        .draw();
                });

                // keep the width of the select element same as the column
                select.style.width = '100%';

                // Add list of options
                column
                    .data()
                    .unique()
                    .sort()
                    .each(function (d, j) {
                        select.add(new Option(d));
                    });
            });
    },
    scrollX: true,
    scrollCollapse: true,
    paging: true,
    fixedColumns: true,
    columnDefs: [
        {"className": "dt-center", "targets": "_all"},
        // set width for both columns 0 and 1 as 25%
        { width: '3%', targets: 0 },
        { width: '35%', targets: 1 },
        { width: '25%', targets: 2 },
        { width: '15%', targets: 4 }

      ],
    pageLength: 10,
    layout: {
        topStart: {
            buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
        }
    }
  }
  new DataTable('#table1', dataTableOptions);
  new DataTable('#table2', dataTableOptions);

  var table1 = $('#table1').DataTable();
  $('#table1 tbody').on('click', 'td:first-child', function () {
    var tr = $(this).closest('tr');
    var row = table1.row( tr );

    var rowId = tr.attr('id');
    // alert(rowId);

    if (row.child.isShown()) {
      // This row is already open - close it.
      row.child.hide();
      tr.removeClass('shown');
      tr.find('td:first-child').html('<i class="material-icons">visibility_off</i>');
    } else {
      // Open row.
      // row.child('foo').show();
      tr.find('td:first-child').html('<i class="material-icons">visibility</i>');
      var content = '<div class="child-row-content"><strong>Abstract:</strong> ' + rowId + '</div>';
      row.child(content).show();
      tr.addClass('shown');
    }
  });
  var table2 = $('#table2').DataTable();
  $('#table2 tbody').on('click', 'td:first-child', function () {
    var tr = $(this).closest('tr');
    var row = table2.row( tr );

    var rowId = tr.attr('id');
    // alert(rowId);

    if (row.child.isShown()) {
      // This row is already open - close it.
      row.child.hide();
      tr.removeClass('shown');
      tr.find('td:first-child').html('<i class="material-icons">visibility_off</i>');
    } else {
      // Open row.
      // row.child('foo').show();
      var content = '<div class="child-row-content"><strong>Abstract:</strong> ' + rowId + '</div>';
      row.child(content).show();
      tr.addClass('shown');
      tr.find('td:first-child').html('<i class="material-icons">visibility</i>');
    }
  });
</script>
<style>
  .child-row-content {
    text-align: justify;
    text-justify: inter-word;
    word-wrap: break-word; /* Ensure long words are broken */
    white-space: normal; /* Ensure text wraps to the next line */
    max-width: 100%; /* Ensure content does not exceed the table width */
    padding: 10px; /* Optional: add some padding for better readability */
    /* font size */
    font-size: small;
  }
</style>
</html>







  
  




  



                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.top", "navigation.tabs"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    

      <script src="../assets/javascripts/bundle.c8d2eff1.min.js"></script>
      
    
<script>
  // Execute intro.js when a button with id 'intro' is clicked
  function startIntro(){
      introJs().setOptions({
          tooltipClass: 'customTooltip'
      }).start();
  }
</script>
<script>
  

  // new DataTable('#table1', {
  //   order: [[5, 'desc']],
  //   "columnDefs": [
  //       {"className": "dt-center", "targets": "_all"},
  //       { width: '30%', targets: 0 }
  //     ],
  //   pageLength: 10,
  //   layout: {
  //       topStart: {
  //           buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
  //       }
  //   }
  // });

  // new DataTable('#table2', {
  //   order: [[3, 'desc']],
  //   "columnDefs": [
  //       {"className": "dt-center", "targets": "_all"},
  //       { width: '30%', targets: 0 }
  //     ],
  //   pageLength: 10,
  //   layout: {
  //       topStart: {
  //           buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
  //       }
  //   }
  // });
  new DataTable('#table3', {
    initComplete: function () {
        this.api()
            .columns()
            .every(function () {
                let column = this;
 
                // Create select element
                let select = document.createElement('select');
                select.add(new Option(''));
                column.footer().replaceChildren(select);
 
                // Apply listener for user change in value
                select.addEventListener('change', function () {
                    column
                        .search(select.value, {exact: true})
                        .draw();
                });

                // keep the width of the select element same as the column
                select.style.width = '100%';
 
                // Add list of options
                column
                    .data()
                    .unique()
                    .sort()
                    .each(function (d, j) {
                        select.add(new Option(d));
                    });
            });
    },
    // order: [[3, 'desc']],
    "columnDefs": [
        {"className": "dt-center", "targets": "_all"},
        { width: '30%', targets: 0 }
      ],
    pageLength: 10,
    layout: {
        topStart: {
            buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
        }
    }
  });
  new DataTable('#table4', {
    initComplete: function () {
        this.api()
            .columns()
            .every(function () {
                let column = this;
 
                // Create select element
                let select = document.createElement('select');
                select.add(new Option(''));
                column.footer().replaceChildren(select);
 
                // Apply listener for user change in value
                select.addEventListener('change', function () {
                    column
                        .search(select.value, {exact: true})
                        .draw();
                });

                // keep the width of the select element same as the column
                select.style.width = '100%';
 
                // Add list of options
                column
                    .data()
                    .unique()
                    .sort()
                    .each(function (d, j) {
                        select.add(new Option(d));
                    });
            });
    },
    // order: [[3, 'desc']],
    "columnDefs": [
        {"className": "dt-center", "targets": "_all"},
        { width: '30%', targets: 0 }
      ],
    pageLength: 10,
    layout: {
        topStart: {
            buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
        }
    }
  });
</script>


  </body>
</html>