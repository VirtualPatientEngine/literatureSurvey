---
hide:
 - navigation
---
<!DOCTYPE html>
#
<html lang="en">
<head>
  <meta charset="utf-8">
</head>

<body>
  <p>
  <i class="footer">This page was last updated on 2024-10-14 06:05:41 UTC</i>
  </p>
  
  <div class="note info" onclick="startIntro()">
    <p>
      <button type="button" class="buttons">
        <div style="display: flex; align-items: center;">
        Click here for a quick intro of the page! <i class="material-icons">help</i>
        </div>
      </button>
    </p>
  </div>

  <p>
  <h3 data-intro='Recommendations for the article'>
    Recommendations for the article <i>Robust learning from noisy, incomplete, high-dimensional experimental data via physically constrained symbolic regression</i>
  </h3>
  <table id="table1" class="display wrap" style="width:100%">
  <thead>
    <tr>
        <th data-intro='Click to view the abstract (if available)'>Abstract</th>
        <th>Title</th>
        <th>Authors</th>
        <th>Publication Date</th>
        <th>Journal/ Conference</th>
        <th>Citation count</th>
        <th data-intro='Highest h-index among the authors'>Highest h-index</th>
    </tr>
  </thead>
  <tbody>
    
        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f51873e0fe8affb3e33af0c8a2ca9594a3b393a1" target='_blank'>Automated discovery of fundamental variables hidden in experimental data</a></td>
          <td>
            Boyuan Chen, Kuang Huang, Sunand Raghupathi, I. Chandratreya, Qi Du, H. Lipson
          </td>
          <td>2022-07-01</td>
          <td>Nature Computational Science</td>
          <td>70</td>
          <td>21</td>
        </tr>
    
        <tr id="Technological advancements have substantially increased computational power and data availability, enabling the application of powerful machine-learning (ML) techniques across various fields. However, our ability to leverage ML methods for scientific discovery, {\it i.e.} to obtain fundamental and formalized knowledge about natural processes, is still in its infancy. In this review, we explore how the scientific community can increasingly leverage ML techniques to achieve scientific discoveries. We observe that the applicability and opportunity of ML depends strongly on the nature of the problem domain, and whether we have full ({\it e.g.}, turbulence), partial ({\it e.g.}, computational biochemistry), or no ({\it e.g.}, neuroscience) {\it a-priori} knowledge about the governing equations and physical properties of the system. Although challenges remain, principled use of ML is opening up new avenues for fundamental scientific discoveries. Throughout these diverse fields, there is a theme that ML is enabling researchers to embrace complexity in observational data that was previously intractable to classic analysis and numerical investigations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f7214e1640b55a726c771c629c873920245e0839" target='_blank'>Opportunities for machine learning in scientific discovery</a></td>
          <td>
            Ricardo Vinuesa, Jean Rabault, Hossein Azizpour, Stefan Bauer, Bingni W. Brunton, Arne Elofsson, Elias Jarlebring, Hedvig Kjellstrom, Stefano Markidis, David Marlevi, Paola Cinnella, S. Brunton
          </td>
          <td>2024-05-07</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>66</td>
        </tr>
    
        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/84d75025e7a847d86cd0bf6308cce4d9a3883c7c" target='_blank'>DeepMoD: Deep learning for model discovery in noisy data</a></td>
          <td>
            G. Both, Subham Choudhury, P. Sens, R. Kusters
          </td>
          <td>2019-04-20</td>
          <td>J. Comput. Phys.</td>
          <td>101</td>
          <td>34</td>
        </tr>
    
        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/899995e30820d657b2e2feb791025cd6b2027e22" target='_blank'>Discovering sparse interpretable dynamics from partial observations</a></td>
          <td>
            Peter Y. Lu, Joan Ariño Bernad, M. Soljačić
          </td>
          <td>2021-07-22</td>
          <td>Communications Physics</td>
          <td>18</td>
          <td>94</td>
        </tr>
    
        <tr id="The extraction of models from data (in a sense, the “understanding” of the physical laws giving rise to the data) is a fundamental cognitive as well as scientific challenge. We show a geometric/analytic learning algorithm capable of creating minimal descriptions of parametrically dependent unknown nonlinear dynamical systems. This is accomplished by the data-driven discovery of useful intrinsic-state variables and parameters in terms of which one can empirically model the underlying dynamics. We discuss an informed observation geometry that enables us to formulate models without first principles as well as without closed form equations. (See pp. E7865–E7874.)">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d2df6b9b2ee1bdef1834c343bb952182a7807bda" target='_blank'>PNAS Plus Significance Statements</a></td>
          <td>
            Ronald R. Coifman, David A. Kessler, A. Goodkind
          </td>
          <td>2017-09-19</td>
          <td>Proceedings of the National Academy of Sciences</td>
          <td>40</td>
          <td>13</td>
        </tr>
    
        <tr id="All physical laws are described as relationships between state variables that give a complete and non-redundant description of the relevant system dynamics. However, despite the prevalence of computing power and AI, the process of identifying the hidden state variables themselves has resisted automation. Most data-driven methods for modeling physical phenomena still assume that observed data streams already correspond to relevant state variables. A key challenge is to identify the possible sets of state variables from scratch, given only high-dimensional observational data. Here we propose a new principle for determining how many state variables an observed system is likely to have, and what these variables might be, directly from video streams. We demonstrate the effectiveness of this approach using video recordings of a variety of physical dynamical systems, ranging from elastic double pendulums to fire flames. Without any prior knowledge of the underlying physics, our algorithm discovers the intrinsic dimension of the observed dynamics and identifies candidate sets of state variables. We suggest that this approach could help catalyze the understanding, prediction and control of increasingly complex systems. Project website is at: https://www.cs.columbia.edu/~bchen/neural-state-variables">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a0d7a5cfc804f90ba8ae80f8cf786d0ad7fe1d17" target='_blank'>Discovering State Variables Hidden in Experimental Data</a></td>
          <td>
            Boyuan Chen, Kuang Huang, Sunand Raghupathi, I. Chandratreya, Qi Du, Hod Lipson
          </td>
          <td>2021-12-20</td>
          <td>ArXiv</td>
          <td>13</td>
          <td>73</td>
        </tr>
    
        <tr id="High-resolution reconstruction of flow-field data from low-resolution and noisy measurements is of interest due to the prevalence of such problems in experimental fluid mechanics, where the measurement data are in general sparse, incomplete and noisy. Deep-learning approaches have been shown suitable for such super-resolution tasks. However, a high number of high-resolution examples is needed, which may not be available for many cases. Moreover, the obtained predictions may lack in complying with the physical principles, e.g. mass and momentum conservation. Physics-informed deep learning provides frameworks for integrating data and physical laws for learning. In this study, we apply physics-informed neural networks (PINNs) for super-resolution of flow-field data both in time and space from a limited set of noisy measurements without having any high-resolution reference data. Our objective is to obtain a continuous solution of the problem, providing a physically-consistent prediction at any point in the solution domain. We demonstrate the applicability of PINNs for the super-resolution of flow-field data in time and space through three canonical cases: Burgers’ equation, two-dimensional vortex shedding behind a circular cylinder and the minimal turbulent channel flow. The robustness of the models is also investigated by adding synthetic Gaussian noise. Furthermore, we show the capabilities of PINNs to improve the resolution and reduce the noise in a real experimental dataset consisting of hot-wire-anemometry measurements. Our results show the adequate capabilities of PINNs in the context of data augmentation for experiments in fluid mechanics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ecf61b26615fc12f9edc4826dd81a23ac0d72f37" target='_blank'>Physics-informed deep-learning applications to experimental fluid mechanics</a></td>
          <td>
            Hamidreza Eivazi, Yuning Wang, R. Vinuesa
          </td>
          <td>2022-03-29</td>
          <td>Measurement Science and Technology</td>
          <td>25</td>
          <td>39</td>
        </tr>
    
        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/606824bebf4e444fca9b988823883f1ec99f19ec" target='_blank'>A physics-informed operator regression framework for extracting data-driven continuum models</a></td>
          <td>
            Ravi G. Patel, N. Trask, M. Wood, E. Cyr
          </td>
          <td>2020-09-25</td>
          <td>ArXiv</td>
          <td>90</td>
          <td>17</td>
        </tr>
    
        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/138138aeee75f8f5a6f2f22575bc4d0354138e5d" target='_blank'>Data-Driven Discovery of Coarse-Grained Equations</a></td>
          <td>
            Joseph Bakarji, D. Tartakovsky
          </td>
          <td>2020-01-30</td>
          <td>J. Comput. Phys.</td>
          <td>33</td>
          <td>47</td>
        </tr>
    
  </tbody>
  <tfoot>
    <tr>
        <th>Abstract</th>
        <th>Title</th>
        <th>Authors</th>
        <th>Publication Date</th>
        <th>Journal/Conference</th>
        <th>Citation count</th>
        <th>Highest h-index</th>
    </tr>
  </tfoot>
  </table>
  </p>

</body>

<script>
var dataTableOptions = {
        initComplete: function () {
        this.api()
            .columns()
            .every(function () {
                let column = this;
 
                // Create select element
                let select = document.createElement('select');
                select.add(new Option(''));
                column.footer().replaceChildren(select);
 
                // Apply listener for user change in value
                select.addEventListener('change', function () {
                    column
                        .search(select.value, {exact: true})
                        .draw();
                });

                // keep the width of the select element same as the column
                select.style.width = '100%';
 
                // Add list of options
                column
                    .data()
                    .unique()
                    .sort()
                    .each(function (d, j) {
                        select.add(new Option(d));
                    });
            });
    },
    scrollX: false,
    scrollCollapse: true,
    paging: true,
    fixedColumns: true,
    columnDefs: [
        {"className": "dt-center", "targets": "_all"},
        // set width for both columns 0 and 1 as 25%
        { width: '5%', targets: 0 },
        { width: '25%', targets: 1 },
        { width: '20%', targets: 2 },
        { width: '10%', targets: 3 },
        { width: '20%', targets: 4 }

      ],
    pageLength: 10,
    layout: {
        topStart: {
            buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
        }
    }
  }
  new DataTable('#table1', dataTableOptions);
  
  var table = $('#table1').DataTable();
  $('#table1 tbody').on('click', 'td:first-child', function () {
    var tr = $(this).closest('tr');
    var row = table.row( tr );

    var rowId = tr.attr('id');
    // alert(rowId);

    if (row.child.isShown()) {
      // This row is already open - close it.
      row.child.hide();
      tr.removeClass('shown');
      tr.find('td:first-child').html('<i class="material-icons">visibility_off</i>');
    } else {
      // Open row.
      // row.child('foo').show();
      var content = '<div class="child-row-content"><strong>Abstract:</strong> ' + rowId + '</div>';
      row.child(content).show();
      tr.addClass('shown');
      tr.find('td:first-child').html('<i class="material-icons">visibility</i>');
    }
  });
</script>
<style>
  .child-row-content {
    text-align: justify;
    text-justify: inter-word;
    word-wrap: break-word; /* Ensure long words are broken */
    white-space: normal; /* Ensure text wraps to the next line */
    max-width: 100%; /* Ensure content does not exceed the table width */
    padding: 10px; /* Optional: add some padding for better readability */
    /* font size */
    font-size: small;
  }
</style>
</html>