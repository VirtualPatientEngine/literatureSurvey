<!DOCTYPE html>

<html lang="en">


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="..">
      
      
        <link rel="next" href="../Symbolic%20regression/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.12">
    
    
<title>Literature Survey (VPE)</title>

    
      <link rel="stylesheet" href="../assets/stylesheets/main.7e359304.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
  <!-- Add scripts that need to run before here -->
  <!-- Add jquery script -->
  <script src="https://code.jquery.com/jquery-3.7.1.js"></script>
  <!-- Add data table libraries -->
  <script src="https://cdn.datatables.net/2.0.1/js/dataTables.js"></script>
  <link rel="stylesheet" href="https://cdn.datatables.net/2.0.1/css/dataTables.dataTables.css">
  <!-- Load plotly.js into the DOM -->
	<script src='https://cdn.plot.ly/plotly-2.29.1.min.js'></script>
  <link rel="stylesheet" href="https://cdn.datatables.net/buttons/3.0.1/css/buttons.dataTables.css">
  <!-- fixedColumns -->
  <script src="https://cdn.datatables.net/fixedcolumns/5.0.0/js/dataTables.fixedColumns.js"></script>
  <script src="https://cdn.datatables.net/fixedcolumns/5.0.0/js/fixedColumns.dataTables.js"></script>
  <link rel="stylesheet" href="https://cdn.datatables.net/fixedcolumns/5.0.0/css/fixedColumns.dataTables.css">
  <!-- Already specified in mkdocs.yml -->
  <!-- <link rel="stylesheet" href="../docs/custom.css"> -->
  <script src="https://cdn.datatables.net/buttons/3.0.1/js/dataTables.buttons.js"></script>
  <script src="https://cdn.datatables.net/buttons/3.0.1/js/buttons.dataTables.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.1/jszip.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdfmake/0.2.7/pdfmake.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdfmake/0.2.7/vfs_fonts.js"></script>
  <script src="https://cdn.datatables.net/buttons/3.0.1/js/buttons.html5.min.js"></script>
  <script src="https://cdn.datatables.net/buttons/3.0.1/js/buttons.print.min.js"></script>
  <!-- Google fonts -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
  <!-- Intro.js -->
  <script src="https://cdn.jsdelivr.net/npm/intro.js@7.2.0/intro.min.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/intro.js@7.2.0/minified/introjs.min.css">


  <!-- 
      
     -->
  <!-- Add scripts that need to run afterwards here -->

    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../custom.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="black">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Literature Survey (VPE)" class="md-header__button md-logo" aria-label="Literature Survey (VPE)" data-md-component="logo">
      
  <img src="../assets/VPE.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Literature Survey (VPE)
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Time-series forecasting
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="black"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="white" data-md-color-accent="black"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/VirtualPatientEngine/literatureSurvey" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    VPE/LiteratureSurvey
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href=".." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
    
  
  
    <li class="md-tabs__item md-tabs__item--active">
      <a href="./" class="md-tabs__link">
        
  
    
  
  Time-series forecasting

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../Symbolic%20regression/" class="md-tabs__link">
        
  
    
  
  Symbolic regression

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
                
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" hidden>
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Literature Survey (VPE)" class="md-nav__button md-logo" aria-label="Literature Survey (VPE)" data-md-component="logo">
      
  <img src="../assets/VPE.png" alt="logo">

    </a>
    Literature Survey (VPE)
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/VirtualPatientEngine/literatureSurvey" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    VPE/LiteratureSurvey
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Time-series forecasting
  </span>
  

      </a>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Symbolic%20regression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Symbolic regression
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
                
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>Time-series forecasting</h1>

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
</head>

<body>
  <p>
  <i class="footer">This page was last updated on 2024-08-19 06:05:19 UTC</i>
  </p>

  <div class="note info" onclick="startIntro()">
    <p>
      <button type="button" class="buttons">
        <div style="display: flex; align-items: center;">
        Click here for a quick intro of the page! <i class="material-icons">help</i>
        </div>
      </button>
    </p>
  </div>

  <!--
  <div data-intro='Table of contents'>
    <p>
    <h3>Table of Contents</h3>
      <a href="#plot1">1. Citations over time on Time-series forecasting</a><br>
      <a href="#manually_curated_articles">2. Manually curated articles on Time-series forecasting</a><br>
      <a href="#recommended_articles">3. Recommended articles on Time-series forecasting</a><br>
    <p>
  </div>

  <div data-intro='Plot displaying number of citations over time 
                  on the given topic based on recommended articles'>
    <p>
    <h3 id="plot1">1. Citations over time on Time-series forecasting</h3>
      <div id='myDiv1'>
      </div>
    </p>
  </div>
  -->

  <div data-intro='Manually curated articles on the given topic'>
    <p>
    <h3 id="manually_curated_articles">Manually curated articles on <i>Time-series forecasting</i></h3>
    <table id="table1" class="display" style="width:100%">
    <thead>
      <tr>
          <th data-intro='Click to view the abstract (if available)'>Abstract</th>
          <th>Title</th>
          <th>Authors</th>
          <th>Publication Date</th>
          <th>Journal/ Conference</th>
          <th>Citation count</th>
          <th data-intro='Highest h-index among the authors'>Highest h-index</th>
          <th data-intro='Recommended articles extracted by considering
                          only the given article'>
              View recommendations
              </th>
      </tr>
    </thead>
    <tbody>

        <tr id="Time series are the primary data type used to record dynamic system measurements and generated in great volume by both physical sensors and online processes (virtual sensors). Time series analytics is therefore crucial to unlocking the wealth of information implicit in available data. With the recent advancements in graph neural networks (GNNs), there has been a surge in GNN-based approaches for time series analysis. These approaches can explicitly model inter-temporal and inter-variable relationships, which traditional and other deep neural network-based methods struggle to do. In this survey, we provide a comprehensive review of graph neural networks for time series analysis (GNN4TS), encompassing four fundamental dimensions: forecasting, classification, anomaly detection, and imputation. Our aim is to guide designers and practitioners to understand, build applications, and advance research of GNN4TS. At first, we provide a comprehensive task-oriented taxonomy of GNN4TS. Then, we present and discuss representative research works and introduce mainstream applications of GNN4TS. A comprehensive discussion of potential future research directions completes the survey. This survey, for the first time, brings together a vast array of knowledge on GNN-based time series research, highlighting foundations, practical applications, and opportunities of graph neural networks for time series analysis.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d3dbbd0f0de51b421a6220bd6480b8d2e99a88e9" target='_blank'>
                A Survey on Graph Neural Networks for Time Series: Forecasting, Classification, Imputation, and Anomaly Detection
                </a>
              </td>
          <td>
            Ming Jin, Huan Yee Koh, Qingsong Wen, Daniele Zambon, C. Alippi, G. I. Webb, Irwin King, Shirui Pan
          </td>
          <td>2023-07-07</td>
          <td>IEEE transactions on pattern analysis and machine intelligence</td>
          <td>61</td>
          <td>50</td>

            <td><a href='../recommendations/d3dbbd0f0de51b421a6220bd6480b8d2e99a88e9' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="In many domains, including healthcare, biology, and climate science, time series are irregularly sampled with varying time intervals between successive readouts and different subsets of variables (sensors) observed at different time points. Here, we introduce RAINDROP, a graph neural network that embeds irregularly sampled and multivariate time series while also learning the dynamics of sensors purely from observational data. RAINDROP represents every sample as a separate sensor graph and models time-varying dependencies between sensors with a novel message passing operator. It estimates the latent sensor graph structure and leverages the structure together with nearby observations to predict misaligned readouts. This model can be interpreted as a graph neural network that sends messages over graphs that are optimized for capturing time-varying dependencies among sensors. We use RAINDROP to classify time series and interpret temporal dynamics on three healthcare and human activity datasets. RAINDROP outperforms state-of-the-art methods by up to 11.4% (absolute F1-score points), including techniques that deal with irregular sampling using fixed discretization and set functions. RAINDROP shows superiority in diverse setups, including challenging leave-sensor-out settings.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/455bfc515eb279cc09023faa1f78c6efb61224ba" target='_blank'>
                Graph-Guided Network for Irregularly Sampled Multivariate Time Series
                </a>
              </td>
          <td>
            Xiang Zhang, M. Zeman, Theodoros Tsiligkaridis, M. Zitnik
          </td>
          <td>2021-10-11</td>
          <td>ArXiv, International Conference on Learning Representations</td>
          <td>70</td>
          <td>47</td>

            <td><a href='../recommendations/455bfc515eb279cc09023faa1f78c6efb61224ba' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Spatiotemporal graph neural networks have shown to be effective in time series forecasting applications, achieving better performance than standard univariate predictors in several settings. These architectures take advantage of a graph structure and relational inductive biases to learn a single (global) inductive model to predict any number of the input time series, each associated with a graph node. Despite the gain achieved in computational and data efficiency w.r.t. fitting a set of local models, relying on a single global model can be a limitation whenever some of the time series are generated by a different spatiotemporal stochastic process. The main objective of this paper is to understand the interplay between globality and locality in graph-based spatiotemporal forecasting, while contextually proposing a methodological framework to rationalize the practice of including trainable node embeddings in such architectures. We ascribe to trainable node embeddings the role of amortizing the learning of specialized components. Moreover, embeddings allow for 1) effectively combining the advantages of shared message-passing layers with node-specific parameters and 2) efficiently transferring the learned model to new node sets. Supported by strong empirical evidence, we provide insights and guidelines for specializing graph-based models to the dynamics of each time series and show how this aspect plays a crucial role in obtaining accurate predictions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e2a83369383aff37224170c1ae3d3870d5d9e419" target='_blank'>
                Taming Local Effects in Graph-based Spatiotemporal Forecasting
                </a>
              </td>
          <td>
            Andrea Cini, Ivan Marisca, Daniele Zambon, C. Alippi
          </td>
          <td>2023-02-08</td>
          <td>Neural Information Processing Systems, ArXiv</td>
          <td>15</td>
          <td>50</td>

            <td><a href='../recommendations/e2a83369383aff37224170c1ae3d3870d5d9e419' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Outstanding achievements of graph neural networks for spatiotemporal time series analysis show that relational constraints introduce an effective inductive bias into neural forecasting architectures. Often, however, the relational information characterizing the underlying data-generating process is unavailable and the practitioner is left with the problem of inferring from data which relational graph to use in the subsequent processing stages. We propose novel, principled - yet practical - probabilistic score-based methods that learn the relational dependencies as distributions over graphs while maximizing end-to-end the performance at task. The proposed graph learning framework is based on consolidated variance reduction techniques for Monte Carlo score-based gradient estimation, is theoretically grounded, and, as we show, effective in practice. In this paper, we focus on the time series forecasting problem and show that, by tailoring the gradient estimators to the graph learning problem, we are able to achieve state-of-the-art performance while controlling the sparsity of the learned graph and the computational scalability. We empirically assess the effectiveness of the proposed method on synthetic and real-world benchmarks, showing that the proposed solution can be used as a stand-alone graph identification procedure as well as a graph learning component of an end-to-end forecasting architecture.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0d01d21137a5af9f04e4b16a55a0f732cb8a540b" target='_blank'>
                Sparse Graph Learning from Spatiotemporal Time Series
                </a>
              </td>
          <td>
            Andrea Cini, Daniele Zambon, C. Alippi
          </td>
          <td>2022-05-26</td>
          <td>J. Mach. Learn. Res., Journal of machine learning research</td>
          <td>11</td>
          <td>50</td>

            <td><a href='../recommendations/0d01d21137a5af9f04e4b16a55a0f732cb8a540b' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Graph-based deep learning methods have become popular tools to process collections of correlated time series. Differently from traditional multivariate forecasting methods, neural graph-based predictors take advantage of pairwise relationships by conditioning forecasts on a (possibly dynamic) graph spanning the time series collection. The conditioning can take the form of an architectural inductive bias on the neural forecasting architecture, resulting in a family of deep learning models called spatiotemporal graph neural networks. Such relational inductive biases enable the training of global forecasting models on large time-series collections, while at the same time localizing predictions w.r.t. each element in the set (i.e., graph nodes) by accounting for local correlations among them (i.e., graph edges). Indeed, recent theoretical and practical advances in graph neural networks and deep learning for time series forecasting make the adoption of such processing frameworks appealing and timely. However, most of the studies in the literature focus on proposing variations of existing neural architectures by taking advantage of modern deep learning practices, while foundational and methodological aspects have not been subject to systematic investigation. To fill the gap, this paper aims to introduce a comprehensive methodological framework that formalizes the forecasting problem and provides design principles for graph-based predictive models and methods to assess their performance. At the same time, together with an overview of the field, we provide design guidelines, recommendations, and best practices, as well as an in-depth discussion of open challenges and future research directions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ccea298edb788edf821aef58f0952c3e8debc25a" target='_blank'>
                Graph Deep Learning for Time Series Forecasting
                </a>
              </td>
          <td>
            Andrea Cini, Ivan Marisca, Daniele Zambon, C. Alippi
          </td>
          <td>2023-10-24</td>
          <td>arXiv.org, ArXiv</td>
          <td>4</td>
          <td>50</td>

            <td><a href='../recommendations/ccea298edb788edf821aef58f0952c3e8debc25a' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="By encoding time series as a string of numerical digits, we can frame time series forecasting as next-token prediction in text. Developing this approach, we find that large language models (LLMs) such as GPT-3 and LLaMA-2 can surprisingly zero-shot extrapolate time series at a level comparable to or exceeding the performance of purpose-built time series models trained on the downstream tasks. To facilitate this performance, we propose procedures for effectively tokenizing time series data and converting discrete distributions over tokens into highly flexible densities over continuous values. We argue the success of LLMs for time series stems from their ability to naturally represent multimodal distributions, in conjunction with biases for simplicity, and repetition, which align with the salient features in many time series, such as repeated seasonal trends. We also show how LLMs can naturally handle missing data without imputation through non-numerical text, accommodate textual side information, and answer questions to help explain predictions. While we find that increasing model size generally improves performance on time series, we show GPT-4 can perform worse than GPT-3 because of how it tokenizes numbers, and poor uncertainty calibration, which is likely the result of alignment interventions such as RLHF.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/123acfbccca0460171b6b06a4012dbb991cde55b" target='_blank'>
                Large Language Models Are Zero-Shot Time Series Forecasters
                </a>
              </td>
          <td>
            Nate Gruver, Marc Finzi, Shikai Qiu, Andrew Gordon Wilson
          </td>
          <td>2023-10-11</td>
          <td>Neural Information Processing Systems, ArXiv</td>
          <td>123</td>
          <td>14</td>

            <td><a href='../recommendations/123acfbccca0460171b6b06a4012dbb991cde55b' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Attention mechanisms have been widely used to capture long-range dependencies among nodes in Graph Transformers. Bottlenecked by the quadratic computational cost, attention mechanisms fail to scale in large graphs. Recent improvements in computational efficiency are mainly achieved by attention sparsification with random or heuristic-based graph subsampling, which falls short in data-dependent context reasoning. State space models (SSMs), such as Mamba, have gained prominence for their effectiveness and efficiency in modeling long-range dependencies in sequential data. However, adapting SSMs to non-sequential graph data presents a notable challenge. In this work, we introduce Graph-Mamba, the first attempt to enhance long-range context modeling in graph networks by integrating a Mamba block with the input-dependent node selection mechanism. Specifically, we formulate graph-centric node prioritization and permutation strategies to enhance context-aware reasoning, leading to a substantial improvement in predictive performance. Extensive experiments on ten benchmark datasets demonstrate that Graph-Mamba outperforms state-of-the-art methods in long-range graph prediction tasks, with a fraction of the computational cost in both FLOPs and GPU memory consumption. The code and models are publicly available at https://github.com/bowang-lab/Graph-Mamba.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1df04f33a8ef313cc2067147dbb79c3ca7c5c99f" target='_blank'>
                Graph-Mamba: Towards Long-Range Graph Sequence Modeling with Selective State Spaces
                </a>
              </td>
          <td>
            Chloe X. Wang, Oleksii Tsepa, Jun Ma, Bo Wang
          </td>
          <td>2024-02-01</td>
          <td>arXiv.org, ArXiv</td>
          <td>47</td>
          <td>5</td>

            <td><a href='../recommendations/1df04f33a8ef313cc2067147dbb79c3ca7c5c99f' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Motivated by recent advances in large language models for Natural Language Processing (NLP), we design a time-series foundation model for forecasting whose out-of-the-box zero-shot performance on a variety of public datasets comes close to the accuracy of state-of-the-art supervised forecasting models for each individual dataset. Our model is based on pretraining a patched-decoder style attention model on a large time-series corpus, and can work well across different forecasting history lengths, prediction lengths and temporal granularities.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f45f85fa1beaa795c24c4ff86f1f2deece72252f" target='_blank'>
                A decoder-only foundation model for time-series forecasting
                </a>
              </td>
          <td>
            Abhimanyu Das, Weihao Kong, Rajat Sen, Yichen Zhou
          </td>
          <td>2023-10-14</td>
          <td>arXiv.org, ArXiv</td>
          <td>48</td>
          <td>14</td>

            <td><a href='../recommendations/f45f85fa1beaa795c24c4ff86f1f2deece72252f' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Deep learning for time series forecasting has traditionally operated within a one-model-per-dataset framework, limiting its potential to leverage the game-changing impact of large pre-trained models. The concept of universal forecasting, emerging from pre-training on a vast collection of time series datasets, envisions a single Large Time Series Model capable of addressing diverse downstream forecasting tasks. However, constructing such a model poses unique challenges specific to time series data: i) cross-frequency learning, ii) accommodating an arbitrary number of variates for multivariate time series, and iii) addressing the varying distributional properties inherent in large-scale data. To address these challenges, we present novel enhancements to the conventional time series Transformer architecture, resulting in our proposed Masked Encoder-based Universal Time Series Forecasting Transformer (Moirai). Trained on our newly introduced Large-scale Open Time Series Archive (LOTSA) featuring over 27B observations across nine domains, Moirai achieves competitive or superior performance as a zero-shot forecaster when compared to full-shot models. Code, data, and model weights can be found at https://github.com/SalesforceAIResearch/uni2ts.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4a111f7a3b56d0468f13104999844885157ef17d" target='_blank'>
                Unified Training of Universal Time Series Forecasting Transformers
                </a>
              </td>
          <td>
            Gerald Woo, Chenghao Liu, Akshat Kumar, Caiming Xiong, Silvio Savarese, Doyen Sahoo
          </td>
          <td>2024-02-04</td>
          <td>arXiv.org, ArXiv</td>
          <td>28</td>
          <td>22</td>

            <td><a href='../recommendations/4a111f7a3b56d0468f13104999844885157ef17d' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Time series forecasting holds significant importance in many real-world dynamic systems and has been extensively studied. Unlike natural language process (NLP) and computer vision (CV), where a single large model can tackle multiple tasks, models for time series forecasting are often specialized, necessitating distinct designs for different tasks and applications. While pre-trained foundation models have made impressive strides in NLP and CV, their development in time series domains has been constrained by data sparsity. Recent studies have revealed that large language models (LLMs) possess robust pattern recognition and reasoning abilities over complex sequences of tokens. However, the challenge remains in effectively aligning the modalities of time series data and natural language to leverage these capabilities. In this work, we present Time-LLM, a reprogramming framework to repurpose LLMs for general time series forecasting with the backbone language models kept intact. We begin by reprogramming the input time series with text prototypes before feeding it into the frozen LLM to align the two modalities. To augment the LLM's ability to reason with time series data, we propose Prompt-as-Prefix (PaP), which enriches the input context and directs the transformation of reprogrammed input patches. The transformed time series patches from the LLM are finally projected to obtain the forecasts. Our comprehensive evaluations demonstrate that Time-LLM is a powerful time series learner that outperforms state-of-the-art, specialized forecasting models. Moreover, Time-LLM excels in both few-shot and zero-shot learning scenarios.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/16f01c1b3ddd0b2abd5ddfe4fdb3f74767607277" target='_blank'>
                Time-LLM: Time Series Forecasting by Reprogramming Large Language Models
                </a>
              </td>
          <td>
            Ming Jin, Shiyu Wang, Lintao Ma, Zhixuan Chu, James Y. Zhang, X. Shi, Pin-Yu Chen, Yuxuan Liang, Yuan-Fang Li, Shirui Pan, Qingsong Wen
          </td>
          <td>2023-10-03</td>
          <td>ArXiv, International Conference on Learning Representations</td>
          <td>120</td>
          <td>9</td>

            <td><a href='../recommendations/16f01c1b3ddd0b2abd5ddfe4fdb3f74767607277' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Large pre-trained models excel in zero/few-shot learning for language and vision tasks but face challenges in multivariate time series (TS) forecasting due to diverse data characteristics. Consequently, recent research efforts have focused on developing pre-trained TS forecasting models. These models, whether built from scratch or adapted from large language models (LLMs), excel in zero/few-shot forecasting tasks. However, they are limited by slow performance, high computational demands, and neglect of cross-channel and exogenous correlations. To address this, we introduce Tiny Time Mixers (TTM), a compact model (starting from 1M parameters) with effective transfer learning capabilities, trained exclusively on public TS datasets. TTM, based on the light-weight TSMixer architecture, incorporates innovations like adaptive patching, diverse resolution sampling, and resolution prefix tuning to handle pre-training on varied dataset resolutions with minimal model capacity. Additionally, it employs multi-level modeling to capture channel correlations and infuse exogenous signals during fine-tuning. TTM outperforms existing popular benchmarks in zero/few-shot forecasting by (4-40\%), while reducing computational requirements significantly. Moreover, TTMs are lightweight and can be executed even on CPU-only machines, enhancing usability and fostering wider adoption in resource-constrained environments. Model weights for our initial variant (TTM-Q) are available at https://huggingface.co/ibm-granite/granite-timeseries-ttm-v1. Model weights for more sophisticated variants (TTM-B, TTM-E, and TTM-A) will be shared soon. The source code for TTM can be accessed at https://github.com/ibm-granite/granite-tsfm/tree/main/tsfm_public/models/tinytimemixer.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e2e1f1b8e6c1b7f4f166e15b7c674945856a51b6" target='_blank'>
                Tiny Time Mixers (TTMs): Fast Pre-trained Models for Enhanced Zero/Few-Shot Forecasting of Multivariate Time Series
                </a>
              </td>
          <td>
            Vijay Ekambaram, Arindam Jati, Nam H. Nguyen, Pankaj Dayama, Chandra Reddy, Wesley M. Gifford, Jayant Kalagnanam
          </td>
          <td>2024-01-08</td>
          <td>arXiv.org, ArXiv</td>
          <td>2</td>
          <td>2</td>

            <td><a href='../recommendations/e2e1f1b8e6c1b7f4f166e15b7c674945856a51b6' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Pre-training on time series poses a unique challenge due to the potential mismatch between pre-training and target domains, such as shifts in temporal dynamics, fast-evolving trends, and long-range and short-cyclic effects, which can lead to poor downstream performance. While domain adaptation methods can mitigate these shifts, most methods need examples directly from the target domain, making them suboptimal for pre-training. To address this challenge, methods need to accommodate target domains with different temporal dynamics and be capable of doing so without seeing any target examples during pre-training. Relative to other modalities, in time series, we expect that time-based and frequency-based representations of the same example are located close together in the time-frequency space. To this end, we posit that time-frequency consistency (TF-C) -- embedding a time-based neighborhood of an example close to its frequency-based neighborhood -- is desirable for pre-training. Motivated by TF-C, we define a decomposable pre-training model, where the self-supervised signal is provided by the distance between time and frequency components, each individually trained by contrastive estimation. We evaluate the new method on eight datasets, including electrodiagnostic testing, human activity recognition, mechanical fault detection, and physical status monitoring. Experiments against eight state-of-the-art methods show that TF-C outperforms baselines by 15.4% (F1 score) on average in one-to-one settings (e.g., fine-tuning an EEG-pretrained model on EMG data) and by 8.4% (precision) in challenging one-to-many settings (e.g., fine-tuning an EEG-pretrained model for either hand-gesture recognition or mechanical fault prediction), reflecting the breadth of scenarios that arise in real-world applications. Code and datasets: https://github.com/mims-harvard/TFC-pretraining.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/648d90b713997a771e2c49f02cd771e8b7b10b37" target='_blank'>
                Self-Supervised Contrastive Pre-Training For Time Series via Time-Frequency Consistency
                </a>
              </td>
          <td>
            Xiang Zhang, Ziyuan Zhao, Theodoros Tsiligkaridis, M. Zitnik
          </td>
          <td>2022-06-17</td>
          <td>Neural Information Processing Systems, ArXiv</td>
          <td>162</td>
          <td>47</td>

            <td><a href='../recommendations/648d90b713997a771e2c49f02cd771e8b7b10b37' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Unsupervised domain adaptation (UDA) enables the transfer of models trained on source domains to unlabeled target domains. However, transferring complex time series models presents challenges due to the dynamic temporal structure variations across domains. This leads to feature shifts in the time and frequency representations. Additionally, the label distributions of tasks in the source and target domains can differ significantly, posing difficulties in addressing label shifts and recognizing labels unique to the target domain. Effectively transferring complex time series models remains a formidable problem. We present Raincoat, the first model for both closed-set and universal domain adaptation on complex time series. Raincoat addresses feature and label shifts by considering both temporal and frequency features, aligning them across domains, and correcting for misalignments to facilitate the detection of private labels. Additionally, Raincoat improves transferability by identifying label shifts in target domains. Our experiments with 5 datasets and 13 state-of-the-art UDA methods demonstrate that Raincoat can improve transfer learning performance by up to 16.33% and can handle both closed-set and universal domain adaptation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5bd2c0acaf58c25f71617db2396188c74d29bf14" target='_blank'>
                Domain Adaptation for Time Series Under Feature and Label Shifts
                </a>
              </td>
          <td>
            Huan He, Owen Queen, Teddy Koker, Consuelo Cuevas, Theodoros Tsiligkaridis, M. Zitnik
          </td>
          <td>2023-02-06</td>
          <td>ArXiv, DBLP</td>
          <td>23</td>
          <td>47</td>

            <td><a href='../recommendations/5bd2c0acaf58c25f71617db2396188c74d29bf14' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="We present the ﬁrst whiteness hypothesis test for graphs, i.e., a whiteness test for multivariate time series associated with the nodes of a dynamic graph; as such, the test represents an important model assessment tool for graph deep learning, e.g., in forecasting setups. The statistical test aims at detecting existing serial dependencies among close-in-time observations, as well as spatial dependencies among neighboring observations given the underlying graph. The proposed AZ-test can be intended as a spatio-temporal extension of traditional tests designed for system identiﬁcation to graph signals. The AZ-test is versatile, allowing the underlying graph to be dynamic, changing in topology and set of nodes over time, and weighted, thus accounting for connections of different strength, as it is the case in many application scenarios like sensor and transportation networks. The asymptotic distribution of the designed test can be derived under the null hypothesis without assuming identically distributed data. We show the effectiveness of the test on both synthetic and real-world problems, and illustrate how it can be employed to assess the quality of spatio-temporal forecasting models by analyzing the prediction residuals appended to the graph stream.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c3c94ccc094dcf546e8e31c9a42506302e837524" target='_blank'>
                AZ-whiteness test: a test for signal uncorrelation on spatio-temporal graphs
                </a>
              </td>
          <td>
            Daniele Zambon, C. Alippi
          </td>
          <td>None</td>
          <td>DBLP</td>
          <td>6</td>
          <td>50</td>

            <td><a href='../recommendations/c3c94ccc094dcf546e8e31c9a42506302e837524' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="State-space models constitute an effective modeling tool to describe multivariate time series and operate by maintaining an updated representation of the system state from which predictions are made. Within this framework, relational inductive biases, e.g., associated with functional dependencies existing among signals, are not explicitly exploited leaving unattended great opportunities for effective modeling approaches. The manuscript aims, for the first time, at filling this gap by matching state-space modeling and spatio-temporal data where the relational information, say the functional graph capturing latent dependencies, is learned directly from data and is allowed to change over time. Within a probabilistic formulation that accounts for the uncertainty in the data-generating process, an encoder-decoder architecture is proposed to learn the state-space model end-to-end on a downstream task. The proposed methodological framework generalizes several state-of-the-art methods and demonstrates to be effective in extracting meaningful relational information while achieving optimal forecasting performance in controlled environments.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/279cd637b7e38bba1dd8915b5ce68cbcacecbe68" target='_blank'>
                Graph state-space models
                </a>
              </td>
          <td>
            Daniele Zambon, Andrea Cini, L. Livi, C. Alippi
          </td>
          <td>2023-01-04</td>
          <td>arXiv.org, ArXiv</td>
          <td>3</td>
          <td>50</td>

            <td><a href='../recommendations/279cd637b7e38bba1dd8915b5ce68cbcacecbe68' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Advances in time series models are driving a shift from conventional deep learning methods to pre-trained foundational models. While pre-trained transformers and reprogrammed text-based LLMs report state-of-the-art results, the best-performing architectures vary significantly across tasks, and models often have limited scope, such as focusing only on time series forecasting. Models that unify predictive and generative time series tasks under a single framework remain challenging to achieve. We introduce UniTS, a multi-task time series model that uses task tokenization to express predictive and generative tasks within a single model. UniTS leverages a modified transformer block designed to obtain universal time series representations. This design induces transferability from a heterogeneous, multi-domain pre-training dataset-often with diverse dynamic patterns, sampling rates, and temporal scales-to many downstream datasets, which can also be diverse in task specifications and data domains. Across 38 datasets spanning human activity sensors, healthcare, engineering, and finance domains, UniTS model performs favorably against 12 forecasting models, 20 classification models, 18 anomaly detection models, and 16 imputation models, including repurposed text-based LLMs. UniTS demonstrates effective few-shot and prompt learning capabilities when evaluated on new data domains and tasks. In the conventional single-task setting, UniTS outperforms strong task-specialized time series models. The source code and datasets are available at https://github.com/mims-harvard/UniTS.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ff1f1cf9df8c413ec7345da7604ba28597da5b90" target='_blank'>
                UNITS: A Unified Multi-Task Time Series Model
                </a>
              </td>
          <td>
            Shanghua Gao, Teddy Koker, Owen Queen, Thomas Hartvigsen, Theodoros Tsiligkaridis, M. Zitnik
          </td>
          <td>2024-02-29</td>
          <td>ArXiv</td>
          <td>2</td>
          <td>47</td>

            <td><a href='../recommendations/bcbcc2e1af8bcf6b07edf866be95116a8ed0bf91' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

    </tbody>
    <tfoot>
      <tr>
          <th>Abstract</th>
          <th>Title</th>
          <th>Authors</th>
          <th>Publication Date</th>
          <th>Journal/ Conference</th>
          <th>Citation count</th>
          <th>Highest h-index</th>
          <th>View recommendations</th>
      </tr>
    </tfoot>
    </table>
    </p>
  </div>

  <div data-intro='Recommended articles extracted by contrasting
                  articles that are relevant against not relevant for Time-series forecasting'>
    <p>
    <h3 id="recommended_articles">Recommended articles on <i>Time-series forecasting</i></h3>
    <table id="table2" class="display" style="width:100%">
    <thead>
      <tr>
          <th>Abstract</th>
          <th>Title</th>
          <th>Authors</th>
          <th>Publication Date</th>
          <th>Journal/Conference</th>
          <th>Citation count</th>
          <th>Highest h-index</th>
      </tr>
    </thead>
    <tbody>

        <tr id="Time series forecasting (TSF) plays a pivotal role in many real-world applications. Recently, the utilization of Large Language Models (LLM) in TSF has demonstrated exceptional predictive performance, surpassing most task-specific forecasting models. The success of LLM-based forecasting methods underscores the importance of causal dependence modeling and pre-trained knowledge transfer. However, challenges persist in directly applying LLM to TSF, i.e., the unacceptable parameter scales for resource-intensive model optimization, and the significant gap of feature space between structural numerical time series and natural language. To this end, we propose LeRet, a Language-empowered Retentive network for TSF. Technically, inspired by the causal extraction in LLM, we propose a causal dependence learner, enhanced by a patch-level pre-training task, to capture sequential causal evolution. To minimize the gap between numeric and language, we initialize a language description protocol for time series and design a TS-related language knowledge extractor to learn from language description, avoiding training with large-scale parameters. Finally, we dedicatedly achieve a Language-TS Modality Integrator for the fusion of two types data, and enable language-empowered sequence forecasting. Extensive evaluations demonstrate the effectiveness of our LeRet, especially reveal superiority on few-shot, and zero-shot forecasting tasks. Code is available at https://github.com/hqh0728/LeRet.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a08b1fc4c1621dc54a57b39a4eb7f9f19abbac63" target='_blank'>
              LeRet: Language-Empowered Retentive Network for Time Series Forecasting
              </a>
            </td>
          <td>
            Qihe Huang, Zhen-Qiang Zhou, Kuo Yang, Gengyu Lin, Zhongchao Yi, Yang Wang
          </td>
          <td>2024-08-01</td>
          <td>Proceedings of the Thirty-ThirdInternational Joint Conference on Artificial Intelligence</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Long time series forecasting aims to utilize historical information to forecast future states over extended horizons. Traditional RNN-based series forecasting methods struggle to effectively address long-term dependencies and gradient issues in long time series problems. Recently, SegRNN has emerged as a leading RNN-based model tailored for long-term series forecasting, demonstrating state-of-the-art performance while maintaining a streamlined architecture through innovative segmentation and parallel decoding techniques. Nevertheless, SegRNN has several limitations: its fixed segmentation disrupts data continuity and fails to effectively leverage information across different segments, the segmentation strategy employed by SegRNN does not fundamentally address the issue of information loss within the recurrent structure. To address these issues, we propose the ISMRNN method with three key enhancements: we introduce an implicit segmentation structure to decompose the time series and map it to segmented hidden states, resulting in denser information exchange during the segmentation phase. Additionally, we incorporate residual structures in the encoding layer to mitigate information loss within the recurrent structure. To extract information more effectively, we further integrate the Mamba architecture to enhance time series information extraction. Experiments on several real-world long time series forecasting datasets demonstrate that our model surpasses the performance of current state-of-the-art models.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9f37604f928c48d5acef8b85dbddb518050f7da9" target='_blank'>
              ISMRNN: An Implicitly Segmented RNN Method with Mamba for Long-Term Time Series Forecasting
              </a>
            </td>
          <td>
            Gaoxiang Zhao, Li Zhou, Xiaoqiang Wang
          </td>
          <td>2024-07-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Recent studies have raised questions about the suitability of the Transformer architecture for long sequence time-series forecasting. These forecasting models leverage Transformers to capture dependencies between multiple time steps in a time series, with embedding tokens composed of data from individual time steps. However, challenges arise when applying Transformers to predict long sequences with strong periodicity, leading to performance degradation and increased computational burden. Furthermore, embedding tokens formed one time step at a time may struggle to reveal meaningful information in long sequences, failing to capture correlations between different time steps. In this study, we propose Skip-Timeformer, a Transformer-based model that utilizes a skip-time interaction for long sequence time-series forecasting. Specifically, we decompose the time series into multiple subsequences based on different time intervals, embedding various time steps into variable tokens across multiple sequences. The skip-time interaction mechanism utilizes these variable tokens to capture dependencies in the skip-time dimension. Additionally, skip-time interaction is employed to learn dependencies between sequences missed by multiple skip time steps. The Skip-Timeformer model demonstrates state-of-the-art performance on various real-world datasets, further enhancing the long sequence forecasting capabilities of the Transformer variations and better adapting to arbitrary lookback windows.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/62917f180f12405293773a5f3689236727699caf" target='_blank'>
              Skip-Timeformer: Skip-Time Interaction Transformer for Long Sequence Time-Series Forecasting
              </a>
            </td>
          <td>
            Wenchang Zhang, Hua Wang, Fan Zhang
          </td>
          <td>2024-08-01</td>
          <td>Proceedings of the Thirty-ThirdInternational Joint Conference on Artificial Intelligence</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Time series, characterized by a sequence of data points arranged in a discrete-time order, are ubiquitous in real-world applications. Different from other modalities, time series present unique challenges due to their complex and dynamic nature, including the entanglement of nonlinear patterns and time-variant trends. Analyzing time series data is of great significance in real-world scenarios and has been widely studied over centuries. Recent years have witnessed remarkable breakthroughs in the time series community, with techniques shifting from traditional statistical methods to advanced deep learning models. In this paper, we delve into the design of deep time series models across various analysis tasks and review the existing literature from two perspectives: basic modules and model architectures. Further, we develop and release Time Series Library (TSLib) as a fair benchmark of deep time series models for diverse analysis tasks, which implements 24 mainstream models, covers 30 datasets from different domains, and supports five prevalent analysis tasks. Based on TSLib, we thoroughly evaluate 12 advanced deep time series models on different tasks. Empirical results indicate that models with specific structures are well-suited for distinct analytical tasks, which offers insights for research and adoption of deep time series models. Code is available at https://github.com/thuml/Time-Series-Library.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/425182f5c96c1d239da5cbe3a24371b2bab6319b" target='_blank'>
              Deep Time Series Models: A Comprehensive Survey and Benchmark
              </a>
            </td>
          <td>
            Yuxuan Wang, Haixu Wu, Jiaxiang Dong, Yong Liu, Mingsheng Long, Jianmin Wang
          </td>
          <td>2024-07-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>66</td>
        </tr>

        <tr id="Multi-variate time series forecasting is an important problem with a wide range of applications. Recent works model the relations between time-series as graphs and have shown that propagating information over the relation graph can improve time series forecasting. However, in many cases, relational information is not available or is noisy and reliable. Moreover, most works ignore the underlying uncertainty of time-series both for structure learning and deriving the forecasts resulting in the structure not capturing the uncertainty resulting in forecast distributions with poor uncertainty estimates. We tackle this challenge and introduce STOIC, that leverages stochastic correlations between time-series to learn underlying structure between time-series and to provide well-calibrated and accurate forecasts. Over a wide-range of benchmark datasets STOIC provides around 16% more accurate and 14% better-calibrated forecasts. STOIC also shows better adaptation to noise in data during inference and captures important and useful relational information in various benchmarks.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7d4b412399f89c9cd66cffc4ab811b74172dcc63" target='_blank'>
              Learning Graph Structures and Uncertainty for Accurate and Calibrated Time-series Forecasting
              </a>
            </td>
          <td>
            Harshavardhan Kamarthi, Lingkai Kong, Alexander Rodríguez, Chao Zhang, B. A. Prakash
          </td>
          <td>2024-07-02</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id="To achieve more accurate prediction results in Time Series Forecasting (TSF), it is essential to distinguish between the valuable patterns (invariant patterns) of the spatial-temporal relationship and the patterns that are prone to generate distribution shift (variant patterns), then combine them for forecasting.The existing works, such as transformer-based models and GNN-based models, focus on capturing main forecasting dependencies whether it is stable or not, and they tend to overlook patterns that carry both useful information and distribution shift. In this paper, we propose a model for better forecasting time series: Decoupled Invariant Attention Network (DIAN), which contains two modules to learn spatial and temporal relationships respectively: 1) Spatial Decoupled Invariant-Variant Learning (SDIVL) to decouple the spatial invariant and variant attention scores, and then leverage convolutional networks to effectively integrate them for subsequent layers; 2) Temporal Augmented Invariant-Variant Learning (TAIVL) to decouple temporal invariant and variant patterns and combine them for further forecasting.In this module, we also design Temporal Intervention Mechanism to create multiple intervened samples by reassembling variant patterns across time stamps to eliminate the spurious impacts of variant patterns.In addition, we propose Joint Optimization to minimize the loss function considering all invariant patterns, variant patterns and intervened patterns so that our model can gain a more stable predictive ability.Extensive experiments on five datasets have demonstrated our superior performance with higher efficiency compared with state-of-the-art methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/08c5216266696b3eea52e8c688f6e7f32711e5a6" target='_blank'>
              Decoupled Invariant Attention Network for Multivariate Time-series Forecasting
              </a>
            </td>
          <td>
            Haihua Xu, Wei Fan, Kun Yi, Pengyang Wang
          </td>
          <td>2024-08-01</td>
          <td>Proceedings of the Thirty-ThirdInternational Joint Conference on Artificial Intelligence</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Long-term time series forecasting in centralized environments poses unique challenges regarding data privacy, communication overhead, and scalability. To address these challenges, we propose FedTime, a federated large language model (LLM) tailored for long-range time series prediction. Specifically, we introduce a federated pre-trained LLM with fine-tuning and alignment strategies. Prior to the learning process, we employ K-means clustering to partition edge devices or clients into distinct clusters, thereby facilitating more focused model training. We also incorporate channel independence and patching to better preserve local semantic information, ensuring that important contextual details are retained while minimizing the risk of information loss. We demonstrate the effectiveness of our FedTime model through extensive experiments on various real-world forecasting benchmarks, showcasing substantial improvements over recent approaches. In addition, we demonstrate the efficiency of FedTime in streamlining resource usage, resulting in reduced communication overhead.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/cfbf583c88970300ba4a74619b02be88524899df" target='_blank'>
              A federated large language model for long-term time series forecasting
              </a>
            </td>
          <td>
            Raed Abdel-Sater, A. B. Hamza
          </td>
          <td>2024-07-30</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Large language models (LLMs) are being applied to time series tasks, particularly time series forecasting. However, are language models actually useful for time series? After a series of ablation studies on three recent and popular LLM-based time series forecasting methods, we find that removing the LLM component or replacing it with a basic attention layer does not degrade the forecasting results -- in most cases the results even improved. We also find that despite their significant computational cost, pretrained LLMs do no better than models trained from scratch, do not represent the sequential dependencies in time series, and do not assist in few-shot settings. Additionally, we explore time series encoders and reveal that patching and attention structures perform similarly to state-of-the-art LLM-based forecasters.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/df0d604b8e8e3b2947d9865d735f204c08635012" target='_blank'>
              Are Language Models Actually Useful for Time Series Forecasting?
              </a>
            </td>
          <td>
            Mingtian Tan, Mike A. Merrill, Vinayak Gupta, Tim Althoff, Tom Hartvigsen
          </td>
          <td>2024-06-22</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="We introduce SiamTST, a novel representation learning framework for multivariate time series. SiamTST integrates a Siamese network with attention, channel-independent patching, and normalization techniques to achieve superior performance. Evaluated on a real-world industrial telecommunication dataset, SiamTST demonstrates significant improvements in forecasting accuracy over existing methods. Notably, a simple linear network also shows competitive performance, achieving the second-best results, just behind SiamTST. The code is available at https://github.com/simenkristoff/SiamTST.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c3dfa12c722cdef05fffd7a51946bec5195f8adf" target='_blank'>
              SiamTST: A Novel Representation Learning Framework for Enhanced Multivariate Time Series Forecasting applied to Telco Networks
              </a>
            </td>
          <td>
            S. Kristoffersen, Peter Skaar Nordby, Sara Malacarne, Massimiliano Ruocco, Pablo Ortiz
          </td>
          <td>2024-07-02</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Deep models for Multivariate Time Series (MTS) forecasting have recently demonstrated significant success. Channel-dependent models capture complex dependencies that channel-independent models cannot capture. However, the number of channels in real-world applications outpaces the capabilities of existing channel-dependent models, and contrary to common expectations, some models underperform the channel-independent models in handling high-dimensional data, which raises questions about the performance of channel-dependent models. To address this, our study first investigates the reasons behind the suboptimal performance of these channel-dependent models on high-dimensional MTS data. Our analysis reveals that two primary issues lie in the introduced noise from unrelated series that increases the difficulty of capturing the crucial inter-channel dependencies, and challenges in training strategies due to high-dimensional data. To address these issues, we propose STHD, the Scalable Transformer for High-Dimensional Multivariate Time Series Forecasting. STHD has three components: a) Relation Matrix Sparsity that limits the noise introduced and alleviates the memory issue; b) ReIndex applied as a training strategy to enable a more flexible batch size setting and increase the diversity of training data; and c) Transformer that handles 2-D inputs and captures channel dependencies. These components jointly enable STHD to manage the high-dimensional MTS while maintaining computational feasibility. Furthermore, experimental results show STHD's considerable improvement on three high-dimensional datasets: Crime-Chicago, Wiki-People, and Traffic. The source code and dataset are publicly available https://github.com/xinzzzhou/ScalableTransformer4HighDimensionMTSF.git.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c2e65d59302efd2605a7b44a9a92f5470b0660fb" target='_blank'>
              Scalable Transformer for High Dimensional Multivariate Time Series Forecasting
              </a>
            </td>
          <td>
            Xin Zhou, Weiqing Wang, W. Buntine, Shilin Qu, Abishek Sriramulu, Weicong Tan, Christoph Bergmeir
          </td>
          <td>2024-08-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>16</td>
        </tr>

        <tr id="In recent years, transformer-based models have gained prominence in multivariate long-term time series forecasting (LTSF), demonstrating significant advancements despite facing challenges such as high computational demands, difficulty in capturing temporal dynamics, and managing long-term dependencies. The emergence of LTSF-Linear, with its straightforward linear architecture, has notably outperformed transformer-based counterparts, prompting a reevaluation of the transformer's utility in time series forecasting. In response, this paper presents an adaptation of a recent architecture termed extended LSTM (xLSTM) for LTSF. xLSTM incorporates exponential gating and a revised memory structure with higher capacity that has good potential for LTSF. Our adopted architecture for LTSF termed as xLSTMTime surpasses current approaches. We compare xLSTMTime's performance against various state-of-the-art models across multiple real-world da-tasets, demonstrating superior forecasting capabilities. Our findings suggest that refined recurrent architectures can offer competitive alternatives to transformer-based models in LTSF tasks, po-tentially redefining the landscape of time series forecasting.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/286a643cebfa8149f02ead76b0be31caa7d8735f" target='_blank'>
              xLSTMTime : Long-term Time Series Forecasting With xLSTM
              </a>
            </td>
          <td>
            Musleh Alharthi, Ausif Mahmood
          </td>
          <td>2024-07-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="In multivariate time-series forecasting (MTSF), extracting the temporal correlations of the input sequences is crucial. While popular Transformer-based predictive models can perform well, their quadratic computational complexity results in inefficiency and high overhead. The recently emerged Mamba, a selective state space model, has shown promising results in many fields due to its strong temporal feature extraction capabilities and linear computational complexity. However, due to the unilateral nature of Mamba, channel-independent predictive models based on Mamba cannot attend to the relationships among all variables in the manner of Transformer-based models. To address this issue, we combine fast-attention with Mamba to introduce a novel framework named FMamba for MTSF. Technically, we first extract the temporal features of the input variables through an embedding layer, then compute the dependencies among input variables via the fast-attention module. Subsequently, we use Mamba to selectively deal with the input features and further extract the temporal dependencies of the variables through the multi-layer perceptron block (MLP-block). Finally, FMamba obtains the predictive results through the projector, a linear layer. Experimental results on eight public datasets demonstrate that FMamba can achieve state-of-the-art performance while maintaining low computational overhead.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3c5ced872aa5d16bf3aa59c40931ed85b54cb3e5" target='_blank'>
              FMamba: Mamba based on Fast-attention for Multivariate Time-series Forecasting
              </a>
            </td>
          <td>
            Shusen Ma, Yu Kang, Peng Bai, Yunan Zhao
          </td>
          <td>2024-07-20</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/68e693e9aa1ac78ccf555d583ee4a4aa8d0f20fb" target='_blank'>
              Sparse transformer with local and seasonal adaptation for multivariate time series forecasting
              </a>
            </td>
          <td>
            Yifan Zhang, Rui Wu, S. Dascalu, Frederick C. Harris
          </td>
          <td>2023-12-11</td>
          <td>Scientific Reports</td>
          <td>0</td>
          <td>18</td>
        </tr>

        <tr id="This technical report describes the Time Series Optimized Transformer for Observability (Toto), a new state of the art foundation model for time series forecasting developed by Datadog. In addition to advancing the state of the art on generalized time series benchmarks in domains such as electricity and weather, this model is the first general-purpose time series forecasting foundation model to be specifically tuned for observability metrics. Toto was trained on a dataset of one trillion time series data points, the largest among all currently published time series foundation models. Alongside publicly available time series datasets, 75% of the data used to train Toto consists of fully anonymous numerical metric data points from the Datadog platform. In our experiments, Toto outperforms existing time series foundation models on observability data. It does this while also excelling at general-purpose forecasting tasks, achieving state-of-the-art zero-shot performance on multiple open benchmark datasets.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/325e7ce8ff734f133cfa379bd8ac1021604c68aa" target='_blank'>
              Toto: Time Series Optimized Transformer for Observability
              </a>
            </td>
          <td>
            Ben Cohen, E. Khwaja, Kan Wang, Charles Masson, Elise Ram'e, Youssef Doubli, Othmane Abou-Amal
          </td>
          <td>2024-07-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="It is challenging to scale time series forecasting models such that they forecast accurately for multiple distinct domains and datasets, all with potentially different underlying collection procedures (e.g., sample resolution), patterns (e.g., periodicity), and prediction requirements (e.g., reconstruction vs. forecasting). We call this general task universal forecasting. Existing methods usually assume that input data is regularly sampled, and they forecast to pre-determined horizons, resulting in failure to generalise outside of the scope of their training. We propose the DAM - a neural model that takes randomly sampled histories and outputs an adjustable basis composition as a continuous function of time for forecasting to non-fixed horizons. It involves three key components: (1) a flexible approach for using randomly sampled histories from a long-tail distribution, that enables an efficient global perspective of the underlying temporal dynamics while retaining focus on the recent history; (2) a transformer backbone that is trained on these actively sampled histories to produce, as representational output, (3) the basis coefficients of a continuous function of time. We show that a single univariate DAM, trained on 25 time series datasets, either outperformed or closely matched existing SoTA models at multivariate long-term forecasting across 18 datasets, including 8 held-out for zero-shot transfer, even though these models were trained to specialise for each dataset-horizon combination. This single DAM excels at zero-shot transfer and very-long-term forecasting, performs well at imputation, is interpretable via basis function composition and attention, can be tuned for different inference-cost requirements, is robust to missing and irregularly sampled data {by design}.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e177ce13d5e3ca4673b2fff9481408cd98bba0d3" target='_blank'>
              DAM: Towards A Foundation Model for Time Series Forecasting
              </a>
            </td>
          <td>
            Luke Darlow, Qiwen Deng, Ahmed Hassan, Martin Asenov, Rajkarn Singh, Artjom Joosen, Adam Barker, A. Storkey
          </td>
          <td>2024-07-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>43</td>
        </tr>

        <tr id="Long-term time series forecasting (LTSF) has been widely applied in finance, traffic prediction, and other domains. Recently, patch-based transformers have emerged as a promising approach, segmenting data into sub-level patches that serve as input tokens. However, existing methods mostly rely on predetermined patch lengths, necessitating expert knowledge and posing challenges in capturing diverse characteristics across various scales. Moreover, time series data exhibit diverse variations and fluctuations across different temporal scales, which traditional approaches struggle to model effectively. In this paper, we propose a dynamic tokenizer with a dynamic sparse learning algorithm to capture diverse receptive fields and sparse patterns of time series data. In order to build hierarchical receptive fields, we develop a multi-scale Transformer model, coupled with multi-scale sequence extraction, capable of capturing multi-resolution features. Additionally, we introduce a group-aware rotary position encoding technique to enhance intra- and inter-group position awareness among representations across different temporal scales. Our proposed model, named DRFormer, is evaluated on various real-world datasets, and experimental results demonstrate its superiority compared to existing methods. Our code is available at: https://github.com/ruixindingECNU/DRFormer.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/93c28e3a8cfde1fbb13658d2f625053edc878a02" target='_blank'>
              DRFormer: Multi-Scale Transformer Utilizing Diverse Receptive Fields for Long Time-Series Forecasting
              </a>
            </td>
          <td>
            Ruixin Ding, Yuqi Chen, Yu-Ting Lan, Wei Zhang
          </td>
          <td>2024-08-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Spatial-temporal forecasting and imputation are important for real-world dynamic systems such as intelligent transportation, urban planning, and public health. Most existing methods are tailored for individual forecasting or imputation tasks but are not designed for both. Additionally, they are less effective for zero-shot and few-shot learning. While large language models (LLMs) have exhibited strong pattern recognition and reasoning abilities across various tasks, including few-shot and zero-shot learning, their development in understanding spatial-temporal data has been constrained by insufficient modeling of complex correlations such as the temporal correlations, spatial connectivity, non-pairwise and high-order spatial-temporal correlations within data. In this paper, we propose STD-LLM for understanding both spatial and temporal properties of \underline{S}patial-\underline{T}emporal \underline{D}ata with \underline{LLM}s, which is capable of implementing both spatial-temporal forecasting and imputation tasks. STD-LLM understands spatial-temporal correlations via explicitly designed spatial and temporal tokenizers as well as virtual nodes. Topology-aware node embeddings are designed for LLMs to comprehend and exploit the topology structure of data. Additionally, to capture the non-pairwise and higher-order correlations, we design a hypergraph learning module for LLMs, which can enhance the overall performance and improve efficiency. Extensive experiments demonstrate that STD-LLM exhibits strong performance and generalization capabilities across the forecasting and imputation tasks on various datasets. Moreover, STD-LLM achieves promising results on both few-shot and zero-shot learning tasks.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/87ddff7927e4489327dc17239e87f040bb86c0ab" target='_blank'>
              STD-LLM: Understanding Both Spatial and Temporal Properties of Spatial-Temporal Data with LLMs
              </a>
            </td>
          <td>
            Yiheng Huang, Xiaowei Mao, S. Guo, Yubin Chen, Youfang Lin, Huaiyu Wan
          </td>
          <td>2024-07-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>18</td>
        </tr>

        <tr id="We propose a transformer architecture for time series forecasting with a focus on time series tokenisation and apply it to a real-world prediction problem from the pricing domain. Our architecture aims to learn effective representations at many scales across all available data simultaneously. The model contains a number of novel modules: a differentiated form of time series patching which employs multiple resolutions, a multiple-resolution module for time-varying known variables, a mixer-based module for capturing cross-series information, and a novel output head with favourable scaling to account for the increased number of tokens. We present an application of this model to a real world prediction problem faced by the markdown team at a very large retailer. On the experiments conducted our model outperforms in-house models and the selected existing deep learning architectures.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d7954d6328e25d15549188da2570cc67407bbd56" target='_blank'>
              Multiple-Resolution Tokenization for Time Series Forecasting with an Application to Pricing
              </a>
            </td>
          <td>
            Egon Persak, Miguel F. Anjos, Sebastian Lautz, Aleksandar Kolev
          </td>
          <td>2024-07-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Recent advancements in language modeling have shown promising results when applied to time series data. In particular, fine-tuning pre-trained large language models (LLMs) for time series classification tasks has achieved state-of-the-art (SOTA) performance on standard benchmarks. However, these LLM-based models have a significant drawback due to the large model size, with the number of trainable parameters in the millions. In this paper, we propose an alternative approach to leveraging the success of language modeling in the time series domain. Instead of fine-tuning LLMs, we utilize a language embedding model to embed time series and then pair the embeddings with a simple classification head composed of convolutional neural networks (CNN) and multilayer perceptron (MLP). We conducted extensive experiments on well-established time series classification benchmark datasets. We demonstrated LETS-C not only outperforms the current SOTA in classification accuracy but also offers a lightweight solution, using only 14.5% of the trainable parameters on average compared to the SOTA model. Our findings suggest that leveraging language encoders to embed time series data, combined with a simple yet effective classification head, offers a promising direction for achieving high-performance time series classification while maintaining a lightweight model architecture.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d55b63343538e0ba5e954542707b90b860dd2e48" target='_blank'>
              LETS-C: Leveraging Language Embedding for Time Series Classification
              </a>
            </td>
          <td>
            Rachneet Kaur, Zhen Zeng, T. Balch, Manuela Veloso
          </td>
          <td>2024-07-09</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="Discrete-Time Dynamic Graphs (DTDGs), which are prevalent in real-world implementations and notable for their ease of data acquisition, have garnered considerable attention from both academic researchers and industry practitioners. The representation learning of DTDGs has been extensively applied to model the dynamics of temporally changing entities and their evolving connections. Currently, DTDG representation learning predominantly relies on GNN+RNN architectures, which manifest the inherent limitations of both Graph Neural Networks (GNNs) and Recurrent Neural Networks (RNNs). GNNs suffer from the over-smoothing issue as the models architecture goes deeper, while RNNs struggle to capture long-term dependencies effectively. GNN+RNN architectures also grapple with scaling to large graph sizes and long sequences. Additionally, these methods often compute node representations separately and focus solely on individual node characteristics, thereby overlooking the behavior intersections between the two nodes whose link is being predicted, such as instances where the two nodes appear together in the same context or share common neighbors. This paper introduces a novel representation learning method DTFormer for DTDGs, pivoting from the traditional GNN+RNN framework to a Transformer-based architecture. Our approach exploits the attention mechanism to concurrently process topological information within the graph at each timestamp and temporal dynamics of graphs along the timestamps, circumventing the aforementioned fundamental weakness of both GNNs and RNNs. Moreover, we enhance the model's expressive capability by incorporating the intersection relationships among nodes and integrating a multi-patching module. Extensive experiments conducted on six public dynamic graph benchmark datasets confirm our model's efficacy, achieving the SOTA performance.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d0d562378884600e23eb9392361a2aa22e512b2e" target='_blank'>
              DTFormer: A Transformer-Based Method for Discrete-Time Dynamic Graph Representation Learning
              </a>
            </td>
          <td>
            Xi Chen, Yun Xiong, Siwei Zhang, Jiawei Zhang, Yao Zhang, Shiyang Zhou, Xixi Wu, Mingyang Zhang, Tengfei Liu, Weiqiang Wang
          </td>
          <td>2024-07-26</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Transformer has gained widespread adoption in modeling time series due to the exceptional ability of its self-attention mechanism in capturing long-range dependencies. However, when processing time series data with numerous variates, the vanilla self-attention mechanism tends to distribute attention weights evenly and smoothly, causing row-homogenization in attention maps and further hampering time series forecasting. To tackle this issue, we propose an advanced Transformer architecture entitled SDformer, which designs two novel modules, Spectral-Filter-Transform (SFT) and Dynamic-Directional-Attention (DDA), and integrates them into the encoder of Transformer to achieve more intensive attention allocation. Specifically, the SFT module utilizes the Fast Fourier Transform to select the most prominent frequencies, along with a Hamming Window to smooth and denoise the filtered series data; The DDA module applies a specialized kernel function to the query and key vectors projected from the denoised data, concentrating this innovative attention mechanism more effectively on the most informative variates to obtain a sharper attention distribution. These two modules jointly enable attention weights to be more salient among numerous variates, which in turn enhances the attention's ability to capture multivariate correlations, improving the performance in forecasting. Extensive experiments on public datasets demonstrate its superior performance over other state-of-the-art models. Code is available at https://github.com/zhouziyu02/SDformer.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2059f2f21fb401de3268af0691764082ba5fdfbd" target='_blank'>
              SDformer: Transformer with Spectral Filter and Dynamic Attention for Multivariate Time Series Long-term Forecasting
              </a>
            </td>
          <td>
            Ziyu Zhou, Gengyu Lyu, Yiming Huang, Zihao Wang, Ziyu Jia, Zhen Yang
          </td>
          <td>2024-08-01</td>
          <td>Proceedings of the Thirty-ThirdInternational Joint Conference on Artificial Intelligence</td>
          <td>0</td>
          <td>11</td>
        </tr>

        <tr id="Exploiting self-supervised learning (SSL) to extract the universal representations of time series could not only capture the natural properties of time series but also offer huge help to the downstream tasks. Nevertheless, existing time series representation learning (TSRL) methods face challenges in attaining universality. Indeed, existing methods relying solely on one SSL strategy (either contrastive learning (CL) or generative) often fall short in capturing rich semantic information for various downstream tasks. Moreover, time series exhibit diverse distributions and inherent characteristics, particularly with the common occurrence of missing values, posing a notable challenge for existing backbones in effectively handling such diverse time series data. To bridge these gaps, we propose CTRL, a framework for universal TSRL. For the first time, we employ Neural Controlled Differential Equation (NCDE) as the backbone for TSRL, which captures the continuous processes and exhibits robustness to missing data. Additionally, a dual-task SSL strategy, integrating both reconstruction and contrasting tasks, is proposed to enrich the semantic information of the learned representations. Furthermore, novel hard negative construction and false negative elimination mechanisms are proposed to improve sampling efficiency and reduce sampling bias in CL. Finally, extensive experiments demonstrate the superiority of CTRL in forecasting, classification, and imputation tasks, particularly its outstanding robustness to missing data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e7373192e3c3277dc2d058d9ba25c19c722df2fb" target='_blank'>
              An NCDE-based Framework for Universal Representation Learning of Time Series
              </a>
            </td>
          <td>
            Zihang Liu, Bowen Du, Junchen Ye, Xianqing Wen, Leilei Sun
          </td>
          <td>2024-08-01</td>
          <td>Proceedings of the Thirty-ThirdInternational Joint Conference on Artificial Intelligence</td>
          <td>0</td>
          <td>25</td>
        </tr>

        <tr id="Accurate workload forecasting is critical for efficient resource management in cloud computing systems, enabling effective scheduling and autoscaling. Despite recent advances with transformer-based forecasting models, challenges remain due to the non-stationary, nonlinear characteristics of workload time series and the long-term dependencies. In particular, inconsistent performance between long-term history and near-term forecasts hinders long-range predictions. This paper proposes a novel framework leveraging self-supervised multiscale representation learning to capture both long-term and near-term workload patterns. The long-term history is encoded through multiscale representations while the near-term observations are modeled via temporal flow fusion. These representations of different scales are fused using an attention mechanism and characterized with normalizing flows to handle non-Gaussian/non-linear distributions of time series. Extensive experiments on 9 benchmarks demonstrate superiority over existing methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/690e772c64d7f67b330d55aa96ffa09ecc7d2ae2" target='_blank'>
              Multiscale Representation Enhanced Temporal Flow Fusion Model for Long-Term Workload Forecasting
              </a>
            </td>
          <td>
            Shiyu Wang, Zhixuan Chu, Yinbo Sun, Yu Liu, Yuliang Guo, Yang Chen, Huiyang Jian, Lintao Ma, Xingyu Lu, Jun Zhou
          </td>
          <td>2024-07-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Spatio-temporal forecasting of traffic flow data represents a typical problem in the field of machine learning, impacting urban traffic management systems. Traditional statistical and machine learning methods cannot adequately handle both the temporal and spatial dependencies in these complex traffic flow datasets. A prevalent approach in the field is to combine graph convolutional networks and multi-head attention mechanisms for spatio-temporal processing. This paper proposes a wavelet-based temporal attention model, namely a wavelet-based dynamic spatio-temporal aware graph neural network (W-DSTAGNN), for tackling the traffic forecasting problem. Benchmark experiments using several statistical metrics confirm that our proposal efficiently captures spatio-temporal correlations and outperforms ten state-of-the-art models on three different real-world traffic datasets. Our proposed ensemble data-driven method can handle dynamic temporal and spatial dependencies and make long-term forecasts in an efficient manner.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ecf52213a2b8371019013a0576959ba3bb3967ef" target='_blank'>
              Wavelet-based Temporal Attention Improves Traffic Forecasting
              </a>
            </td>
          <td>
            Yash Jakhmola, Nitish Kumar Mishra, Kripabandhu Ghosh, Tanujit Chakraborty
          </td>
          <td>2024-07-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>11</td>
        </tr>

        <tr id="This research examines the use of Large Language Models (LLMs) in predicting time series, with a specific focus on the LLMTIME model. Despite the established effectiveness of LLMs in tasks such as text generation, language translation, and sentiment analysis, this study highlights the key challenges that large language models encounter in the context of time series prediction. We assess the performance of LLMTIME across multiple datasets and introduce classical almost periodic functions as time series to gauge its effectiveness. The empirical results indicate that while large language models can perform well in zero-shot forecasting for certain datasets, their predictive accuracy diminishes notably when confronted with diverse time series data and traditional signals. The primary finding of this study is that the predictive capacity of LLMTIME, similar to other LLMs, significantly deteriorates when dealing with time series data that contain both periodic and trend components, as well as when the signal comprises complex frequency components.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/11e794835a1f7d46560666d90c8eab3c24d84c05" target='_blank'>
              An Evaluation of Standard Statistical Models and LLMs on Time Series Forecasting
              </a>
            </td>
          <td>
            Rui Cao, Qiaohua Wang
          </td>
          <td>2024-08-09</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The complexity and heterogeneity of data in many real-world applications pose significant challenges for traditional machine learning and signal processing techniques. For instance, in medicine, effective analysis of diverse physiological signals is crucial for patient monitoring and clinical decision-making and yet highly challenging. We introduce MedTsLLM, a general multimodal large language model (LLM) framework that effectively integrates time series data and rich contextual information in the form of text to analyze physiological signals, performing three tasks with clinical relevance: semantic segmentation, boundary detection, and anomaly detection in time series. These critical tasks enable deeper analysis of physiological signals and can provide actionable insights for clinicians. We utilize a reprogramming layer to align embeddings of time series patches with a pretrained LLM's embedding space and make effective use of raw time series, in conjunction with textual context. Given the multivariate nature of medical datasets, we develop methods to handle multiple covariates. We additionally tailor the text prompt to include patient-specific information. Our model outperforms state-of-the-art baselines, including deep learning models, other LLMs, and clinical methods across multiple medical domains, specifically electrocardiograms and respiratory waveforms. MedTsLLM presents a promising step towards harnessing the power of LLMs for medical time series analysis that can elevate data-driven tools for clinicians and improve patient outcomes.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6ac9e9c8bdd4eebe3cf6adf7187b9ffb16ff5b64" target='_blank'>
              MedTsLLM: Leveraging LLMs for Multimodal Medical Time Series Analysis
              </a>
            </td>
          <td>
            Nimeesha Chan, Felix Parker, William Bennett, Tianyi Wu, Mung Yao Jia, James Fackler, Kimia Ghobadi
          </td>
          <td>2024-08-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Current Transformer methods for Multivariate Time-Series Forecasting (MTSF) are all based on the conventional attention mechanism. They involve sequence embedding and performing a linear projection of Q, K, and V, and then computing attention within this latent space. We have never delved into the attention mechanism to explore whether such a mapping space is optimal for MTSF. To investigate this issue, this study first proposes Frequency Spectrum attention (FSatten), a novel attention mechanism based on the frequency domain space. It employs the Fourier transform for embedding and introduces Multi-head Spectrum Scaling (MSS) to replace the conventional linear mapping of Q and K. FSatten can accurately capture the periodic dependencies between sequences and outperform the conventional attention without changing mainstream architectures. We further design a more general method dubbed Scaled Orthogonal attention (SOatten). We propose an orthogonal embedding and a Head-Coupling Convolution (HCC) based on the neighboring similarity bias to guide the model in learning comprehensive dependency patterns. Experiments show that FSatten and SOatten surpass the SOTA which uses conventional attention, making it a good alternative as a basic attention mechanism for MTSF. The codes and log files will be released at: https://github.com/Joeland4/FSatten-SOatten.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0b4ec3cddfc06c1f060d66a3123f8a9a0b157d23" target='_blank'>
              Revisiting Attention for Multivariate Time Series Forecasting
              </a>
            </td>
          <td>
            Haixiang Wu
          </td>
          <td>2024-07-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Tabular data is ubiquitous in many real-life systems. In particular, time-dependent tabular data, where rows are chronologically related, is typically used for recording historical events, e.g., financial transactions, healthcare records, or stock history. Recently, hierarchical variants of the attention mechanism of transformer architectures have been used to model tabular time-series data. At first, rows (or columns) are encoded separately by computing attention between their fields. Subsequently, encoded rows (or columns) are attended to one another to model the entire tabular time-series. While efficient, this approach constrains the attention granularity and limits its ability to learn patterns at the field-level across separate rows, or columns. We take a first step to address this gap by proposing Fieldy, a fine-grained hierarchical model that contextualizes fields at both the row and column levels. We compare our proposal against state of the art models on regression and classification tasks using public tabular time-series datasets. Our results show that combining row-wise and column-wise attention improves performance without increasing model size. Code and data are available at https://github.com/raphaaal/fieldy.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a9e5c4649872cb3a4b417acdce4fae0ea8d72ebf" target='_blank'>
              Fine-grained Attention in Hierarchical Transformers for Tabular Time-series
              </a>
            </td>
          <td>
            Raphaël Azorin, Zied Ben-Houidi, Massimo Gallo, A. Finamore, Pietro Michiardi
          </td>
          <td>2024-06-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>24</td>
        </tr>

        <tr id="Short fixed-length inputs are the main bottleneck of deep learning methods in long time-series forecasting tasks. Prolonging input length causes overfitting, rapidly deteriorating accuracy. Our research indicates that the overfitting is a combination reaction of the multi-scale pattern coupling in time series and the fixed focusing scale of current models. First, we find that the patterns exhibited by a time series across various scales are reflective of its multi-periodic nature, where each scale corresponds to specific period length. Second, We find that the token size predominantly dictates model behavior, as it determines the scale at which the model focuses and the context size it can accommodate. Our idea is to decouple the multi-scale temporal patterns of time series and to model each pattern with its corresponding period length as token size. We introduced a novel series-decomposition module(MPSD), and a Multi-Token Pattern Recognition neural network(MTPR), enabling the model to handle \textit{inputs up to $10\times$ longer}. Sufficient context enhances performance(\textit{38% maximum precision improvement}), and the decoupling approach offers \textit{Low complexity($0.22\times$ cost)} and \textit{high interpretability}.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/380b86c3909fe3e098a4ec9618f09d59bb9ef626" target='_blank'>
              Long Input Sequence Network for Long Time Series Forecasting
              </a>
            </td>
          <td>
            Chao Ma, Yikai Hou, Xiang Li, Yinggang Sun, Haining Yu
          </td>
          <td>2024-07-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The non-stationary nature of real-world Multivariate Time Series (MTS) data presents forecasting models with a formidable challenge of the time-variant distribution of time series, referred to as distribution shift. Existing studies on the distribution shift mostly adhere to adaptive normalization techniques for alleviating temporal mean and covariance shifts or time-variant modeling for capturing temporal shifts. Despite improving model generalization, these normalization-based methods often assume a time-invariant transition between outputs and inputs but disregard specific intra-/inter-series correlations, while time-variant models overlook the intrinsic causes of the distribution shift. This limits model expressiveness and interpretability of tackling the distribution shift for MTS forecasting. To mitigate such a dilemma, we present a unified Probabilistic Graphical Model to Jointly capturing intra-/inter-series correlations and modeling the time-variant transitional distribution, and instantiate a neural framework called JointPGM for non-stationary MTS forecasting. Specifically, JointPGM first employs multiple Fourier basis functions to learn dynamic time factors and designs two distinct learners: intra-series and inter-series learners. The intra-series learner effectively captures temporal dynamics by utilizing temporal gates, while the inter-series learner explicitly models spatial dynamics through multi-hop propagation, incorporating Gumbel-softmax sampling. These two types of series dynamics are subsequently fused into a latent variable, which is inversely employed to infer time factors, generate final prediction, and perform reconstruction. We validate the effectiveness and efficiency of JointPGM through extensive experiments on six highly non-stationary MTS datasets, achieving state-of-the-art forecasting performance of MTS forecasting.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c259b05da12062cdb1e96cd3994b71a1b4841e89" target='_blank'>
              Robust Multivariate Time Series Forecasting against Intra- and Inter-Series Transitional Shift
              </a>
            </td>
          <td>
            Hui He, Qi Zhang, Kun Yi, Xiaojun Xue, Shoujin Wang, Liang Hu, Longbin Cao
          </td>
          <td>2024-07-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="Learning useful representations for continuous-time dynamic graphs (CTDGs) is challenging, due to the concurrent need to span long node interaction histories and grasp nuanced temporal details. In particular, two problems emerge: (1) Encoding longer histories requires more computational resources, making it crucial for CTDG models to maintain low computational complexity to ensure efficiency; (2) Meanwhile, more powerful models are needed to identify and select the most critical temporal information within the extended context provided by longer histories. To address these problems, we propose a CTDG representation learning model named DyGMamba, originating from the popular Mamba state space model (SSM). DyGMamba first leverages a node-level SSM to encode the sequence of historical node interactions. Another time-level SSM is then employed to exploit the temporal patterns hidden in the historical graph, where its output is used to dynamically select the critical information from the interaction history. We validate DyGMamba experimentally on the dynamic link prediction task. The results show that our model achieves state-of-the-art in most cases. DyGMamba also maintains high efficiency in terms of computational resources, making it possible to capture long temporal dependencies with a limited computation budget.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/aeb6fbef9a2f455a71773488e09f1c4f6686ac55" target='_blank'>
              DyGMamba: Efficiently Modeling Long-Term Temporal Dependency on Continuous-Time Dynamic Graphs with State Space Models
              </a>
            </td>
          <td>
            Zifeng Ding, Yifeng Li, Yuan He, Antonio Norelli, Jingcheng Wu, Volker Tresp, Yunpu Ma, Michael Bronstein
          </td>
          <td>2024-08-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>22</td>
        </tr>

        <tr id="Intelligent transportation systems based on sensor signals are crucial in addressing contemporary transportation issues, accomplishing dynamic traffic management, and facilitating route planning. However, the highly dynamic and intricate nature of traffic sensor signals presents difficulties for traffic prediction, with current models for traffic prediction inadequate in meeting the requirements of both long-term and short-term prediction tasks. In this paper, we propose a novel deep-learning framework called dynamic spatial-temporal correlation learning network (DSTLNet) that jointly leverages dynamical spatial and temporal features of traffic sensor signals to further improve the accuracy of long-and short-term traffic modeling and route planning. Specifically, we leverage the temporal convolutional network to capture long-term correlations. In addition, a spatial graph convolutional network is developed to dynamically model spatial features, and long-and short-term fusion layers are used to fuse the extracted long-and short-term temporal features, respectively. Experimental results on real-world datasets show that DSTLNet is competitive with the state-of-the-art, especially for long-term traffic prediction.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c2ed14c7ddd2366e53463d2401366cc0c6036604" target='_blank'>
              DSTLNet: Dynamic Spatial-Temporal Correlation Learning Network for Traffic Sensor Signal Prediction
              </a>
            </td>
          <td>
            Yuxiang Shan, Hailiang Lu, Weidong Lou
          </td>
          <td>2024-08-08</td>
          <td>Sensors and Materials</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Long-term traffic flow forecasting plays a crucial role in intelligent transportation as it allows traffic managers to adjust their decisions in advance. However, the problem is challenging due to spatio-temporal correlations and complex dynamic patterns in continuous-time stream data. Neural Differential Equations (NDEs) are among the state-of-the-art methods for learning continuous-time traffic dynamics. However, the traditional NDE models face issues in long-term traffic forecasting due to failures in capturing delayed traffic patterns, dynamic edge (location-to-location correlation) patterns, and abrupt trend patterns. To fill this gap, we propose a new NDE architecture called Multi-View Neural Differential Equations. Our model captures current states, delayed states, and trends in different state variables (views) by learning latent multiple representations within Neural Differential Equations. Extensive experiments conducted on several real-world traffic datasets demonstrate that our proposed method outperforms the state-of-the-art and achieves superior prediction accuracy for long-term forecasting and robustness with noisy or missing inputs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/713b5e17e000120673eebab412e9b9ae591db136" target='_blank'>
              Multi-View Neural Differential Equations for Continuous-Time Stream Data in Long-Term Traffic Forecasting
              </a>
            </td>
          <td>
            Zibo Liu, Zhe Jiang, Shigang Chen
          </td>
          <td>2024-08-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Continuous-time dynamic graphs (CTDGs) are essential for modeling interconnected, evolving systems. Traditional methods for extracting knowledge from these graphs often depend on feature engineering or deep learning. Feature engineering is limited by the manual and time-intensive nature of crafting features, while deep learning approaches suffer from high inference latency, making them impractical for real-time applications. This paper introduces Deep-Graph-Sprints (DGS), a novel deep learning architecture designed for efficient representation learning on CTDGs with low-latency inference requirements. We benchmark DGS against state-of-the-art feature engineering and graph neural network methods using five diverse datasets. The results indicate that DGS achieves competitive performance while improving inference speed up to 12x compared to other deep learning approaches on our tested benchmarks. Our method effectively bridges the gap between deep representation learning and low-latency application requirements for CTDGs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e2527f621a171b190f5a8d3aeb83a60fde586df1" target='_blank'>
              Deep-Graph-Sprints: Accelerated Representation Learning in Continuous-Time Dynamic Graphs
              </a>
            </td>
          <td>
            Ahmad Naser Eddin, Jacopo Bono, David Apar'icio, Hugo Ferreira, Pedro Ribeiro, P. Bizarro
          </td>
          <td>2024-07-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>18</td>
        </tr>

        <tr id="Time series models, typically trained on numerical data, are designed to forecast future values. These models often rely on weighted averaging techniques over time intervals. However, real-world time series data is seldom isolated and is frequently influenced by non-numeric factors. For instance, stock price fluctuations are impacted by daily random events in the broader world, with each event exerting a unique influence on price signals. Previously, forecasts in financial markets have been approached in two main ways: either as time-series problems over price sequence or sentiment analysis tasks. The sentiment analysis tasks aim to determine whether news events will have a positive or negative impact on stock prices, often categorizing them into discrete labels. Recognizing the need for a more comprehensive approach to accurately model time series prediction, we propose a collaborative modeling framework that incorporates textual information about relevant events for predictions. Specifically, we leverage the intuition of large language models about future changes to update real number time series predictions. We evaluated the effectiveness of our approach on financial market data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7c2fd193f7d8f4fb40c5f865884bd2b528a475a4" target='_blank'>
              Text2TimeSeries: Enhancing Financial Forecasting through Time Series Prediction Updates with Event-Driven Insights from Large Language Models
              </a>
            </td>
          <td>
            Litton J. Kurisinkel, Pruthwik Mishra, Yue Zhang
          </td>
          <td>2024-07-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="The COVID-19 pandemic and influenza outbreaks have underscored the critical need for predictive models that can effectively integrate spatial and temporal dynamics to enable accurate epidemic forecasting. Traditional time-series analysis approaches have fallen short in capturing the intricate interplay between these factors. Recent advancements have witnessed the incorporation of graph neural networks and machine learning techniques to bridge this gap, enhancing predictive accuracy and providing novel insights into disease spread mechanisms. Notable endeavors include leveraging human mobility data, employing transfer learning, and integrating advanced models such as Transformers and Graph Convolutional Networks (GCNs) to improve forecasting performance across diverse geographies for both influenza and COVID-19. However, these models often face challenges related to data quality, model transferability, and potential overfitting, highlighting the necessity for more adaptable and robust approaches. This paper introduces the Graph Attention-based Spatial Temporal (GAST) model, which employs graph attention networks (GATs) to overcome these limitations by providing a nuanced understanding of epidemic dynamics through a sophisticated spatio-temporal analysis framework. Our contributions include the development and validation of the GAST model, demonstrating its superior forecasting capabilities for influenza and COVID-19 spread, with a particular focus on short-term, daily predictions. The model’s application to both influenza and COVID-19 datasets showcases its versatility and potential to inform public health interventions across a range of infectious diseases.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/628bd28abb35127fc3d4e794dfc8e0860b738427" target='_blank'>
              Modeling epidemic dynamics using Graph Attention based Spatial Temporal networks
              </a>
            </td>
          <td>
            Xiaofeng Zhu, Yi Zhang, Haoru Ying, Huanning Chi, Guanqun Sun, Lingxia Zeng
          </td>
          <td>2024-07-15</td>
          <td>PLOS ONE</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Urban traffic speed prediction aims to estimate the future traffic speed for improving urban transportation services. Enormous efforts have been made to exploit Graph Neural Networks (GNNs) for modeling spatial correlations and temporal dependencies of traffic speed evolving patterns, regularized by graph topology. While achieving promising results, current traffic speed prediction methods still suffer from ignoring topology-free patterns, which cannot be captured by GNNs. To tackle this challenge, we propose a generic model for enabling the current GNN-based methods to preserve topology-free patterns. Specifically, we first develop a Dual Cross-Scale Transformer (DCST) architecture, including a Spatial Transformer and a Temporal Transformer, to preserve the cross-scale topology-free patterns and associated dynamics, respectively. Then, to further integrate both topology-regularized/-free patterns, we propose a distillation-style learning framework, in which the existing GNN-based methods are considered as the teacher model, and the proposed DCST architecture is considered as the student model. The teacher model would inject the learned topology-regularized patterns into the student model for integrating topology-free patterns. The extensive experimental results demonstrated the effectiveness of our methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3911024df853ccf11138d35835572ce863df51bf" target='_blank'>
              Make Graph Neural Networks Great Again: A Generic Integration Paradigm of Topology-Free Patterns for Traffic Speed Prediction
              </a>
            </td>
          <td>
            Yicheng Zhou, P. Wang, Hao Dong, Denghui Zhang, Dingqi Yang, Yanjie Fu, Pengyang Wang
          </td>
          <td>2024-06-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="Representing temporal-structured samples is essential for effective time series analysis tasks. So far, recurrent networks, convolution networks and transformer-style models have been successively applied in temporal data representation, yielding notable results. However, most existing methods primarily focus on modeling and representing the variation patterns within time series in the time domain. As a highly abstracted information entity, 1D time series couples various patterns such as trends, seasonality, and dramatic changes (instantaneous high dynamic), it is difficult to exploit these highly coupled properties merely by analysis tools on purely time domain. To this end, we present Spectrogram Analysis and Representation Network (SpecAR-Net). SpecAR-Net aims at learning more comprehensive representations by modeling raw time series in both time and frequency domain, where an efficient joint extraction of time-frequency features is achieved through a group of learnable 2D multi-scale parallel complex convolution blocks. Experimental results show that the SpecAR-Net achieves excellent performance on 5 major downstream tasks i.e., classification, anomaly detection, imputation, long- and short-term forecasting. Code and appendix are available at https://github.com/Dongyi2go/SpecAR_Net.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1dfaff572dd20e45c52824bd90981982d242c6dc" target='_blank'>
              SpecAR-Net: Spectrogram Analysis and Representation Network for Time Series
              </a>
            </td>
          <td>
            Yi Dong, Liwen Zhang, Youcheng Zhang, Shi Peng, Wen Chen, Zhe Ma
          </td>
          <td>2024-08-01</td>
          <td>Proceedings of the Thirty-ThirdInternational Joint Conference on Artificial Intelligence</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The scaling of large language models (LLMs) has revolutionized their capabilities in various tasks, yet this growth must be matched with efficient computational strategies. The Mixture-of-Experts (MoE) architecture stands out for its ability to scale model size without significantly increasing training costs. Despite their advantages, current MoE models often display parameter inefficiency. For instance, a pre-trained MoE-based LLM with 52 billion parameters might perform comparably to a standard model with 6.7 billion parameters. Being a crucial part of MoE, current routers in different layers independently assign tokens without leveraging historical routing information, potentially leading to suboptimal token-expert combinations and the parameter inefficiency problem. To alleviate this issue, we introduce the Layerwise Recurrent Router for Mixture-of-Experts (RMoE). RMoE leverages a Gated Recurrent Unit (GRU) to establish dependencies between routing decisions across consecutive layers. Such layerwise recurrence can be efficiently parallelly computed for input tokens and introduces negotiable costs. Our extensive empirical evaluations demonstrate that RMoE-based language models consistently outperform a spectrum of baseline models. Furthermore, RMoE integrates a novel computation stage orthogonal to existing methods, allowing seamless compatibility with other MoE architectures. Our analyses attribute RMoE's gains to its effective cross-layer information sharing, which also improves expert selection and diversity. Our code is at https://github.com/qiuzh20/RMoE">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/541773c4cbb30bcdcbc82b8d02eba15af811f739" target='_blank'>
              Layerwise Recurrent Router for Mixture-of-Experts
              </a>
            </td>
          <td>
            Zihan Qiu, Zeyu Huang, Shuang Cheng, Yizhi Zhou, Zili Wang, Ivan Titov, Jie Fu
          </td>
          <td>2024-08-13</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Battery life estimation is critical for optimizing battery performance and guaranteeing minimal degradation for better efficiency and reliability of battery-powered systems. The existing methods to predict the Remaining Useful Life(RUL) of Lithium-ion Batteries (LiBs) neglect the relational dependencies of the battery parameters to model the nonlinear degradation trajectories. We present the Battery GraphNets framework that jointly learns to incorporate a discrete dependency graph structure between battery parameters to capture the complex interactions and the graph-learning algorithm to model the intrinsic battery degradation for RUL prognosis. The proposed method outperforms several popular methods by a significant margin on publicly available battery datasets and achieves SOTA performance. We report the ablation studies to support the efficacy of our approach.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/cb566703033116a6d7a3066560ba85a02a8f83cf" target='_blank'>
              Battery GraphNets : Relational Learning for Lithium-ion Batteries(LiBs) Life Estimation
              </a>
            </td>
          <td>
            Sakhinana Sagar Srinivas, Rajat Kumar Sarkar, Venkataramana Runkana
          </td>
          <td>2024-08-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6fbaa841f1f012a9be06d56da6a1921f5d50f305" target='_blank'>
              MGLEP: Multimodal Graph Learning for Modeling Emerging Pandemics with Big Data
              </a>
            </td>
          <td>
            Khanh-Tung Tran, T. Hy, Lili Jiang, Xuan-Son Vu
          </td>
          <td>2023-10-23</td>
          <td>Scientific Reports</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Traffic flow forecasting is considered a critical task in the field of intelligent transportation systems. In this paper, to address the issue of low accuracy in long-term forecasting of spatial-temporal big data on traffic flow, we propose an innovative model called Spatial-Temporal Retentive Network (ST-RetNet). We extend the Retentive Network to address the task of traffic flow forecasting. At the spatial scale, we integrate a topological graph structure into Spatial Retentive Network(S-RetNet), utilizing an adaptive adjacency matrix to extract dynamic spatial features of the road network. We also employ Graph Convolutional Networks to extract static spatial features of the road network. These two components are then fused to capture dynamic and static spatial correlations. At the temporal scale, we propose the Temporal Retentive Network(T-RetNet), which has been demonstrated to excel in capturing long-term dependencies in traffic flow patterns compared to other time series models, including Recurrent Neural Networks based and transformer models. We achieve the spatial-temporal traffic flow forecasting task by integrating S-RetNet and T-RetNet to form ST-RetNet. Through experimental comparisons conducted on four real-world datasets, we demonstrate that ST-RetNet outperforms the state-of-the-art approaches in traffic flow forecasting.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2ff0fb7e804a47b3a7fc6957f58fb65aa01ba12a" target='_blank'>
              ST-RetNet: A Long-term Spatial-Temporal Traffic Flow Prediction Method
              </a>
            </td>
          <td>
            Baichao Long, Wang Zhu, Jianli Xiao
          </td>
          <td>2024-07-13</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="In the AIOps (Artificial Intelligence for IT Operations) era, accurately forecasting system states is crucial. In microservices systems, this task encounters the challenge of dynamic and complex spatio-temporal relationships among microservice instances, primarily due to dynamic deployments, diverse call paths, and cascading effects among instances. Current time-series forecasting methods, which focus mainly on intrinsic patterns, are insufficient in environments where spatial relationships are critical. Similarly, spatio-temporal graph approaches often neglect the nature of temporal trend, concentrating mostly on message passing between nodes. Moreover, current research in microservices domain frequently underestimates the importance of network metrics and topological structures in capturing the evolving dynamics of systems. This paper introduces STMformer, a model tailored for forecasting system states in microservices environments, capable of handling multi-node and multivariate time series. Our method leverages dynamic network connection data and topological information to assist in modeling the intricate spatio-temporal relationships within the system. Additionally, we integrate the PatchCrossAttention module to compute the impact of cascading effects globally. We have developed a dataset based on a microservices system and conducted comprehensive experiments with STMformer against leading methods. In both short-term and long-term forecasting tasks, our model consistently achieved a 8.6% reduction in MAE(Mean Absolute Error) and a 2.2% reduction in MSE (Mean Squared Error). The source code is available at https://github.com/xuyifeiiie/STMformer.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d0bdfae99d444ac389fd3590ebcd41ac91a7b2f4" target='_blank'>
              System States Forecasting of Microservices with Dynamic Spatio-Temporal Data
              </a>
            </td>
          <td>
            Yifei Xu, Jingguo Ge, Haina Tang, Shuai Ding, Tong Li, Hui Li
          </td>
          <td>2024-08-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Temporal graphs have gained increasing importance due to their ability to model dynamically evolving relationships. These graphs can be represented through either a stream of edge events or a sequence of graph snapshots. Until now, the development of machine learning methods for both types has occurred largely in isolation, resulting in limited experimental comparison and theoretical crosspollination between the two. In this paper, we introduce Unified Temporal Graph (UTG), a framework that unifies snapshot-based and event-based machine learning models under a single umbrella, enabling models developed for one representation to be applied effectively to datasets of the other. We also propose a novel UTG training procedure to boost the performance of snapshot-based models in the streaming setting. We comprehensively evaluate both snapshot and event-based models across both types of temporal graphs on the temporal link prediction task. Our main findings are threefold: first, when combined with UTG training, snapshotbased models can perform competitively with event-based models such as TGN and GraphMixer even on event datasets. Second, snapshot-based models are at least an order of magnitude faster than most event-based models during inference. Third, while event-based methods such as NAT and DyGFormer outperforms snapshotbased methods on both types of temporal graphs, this is because they leverage joint neighborhood structural features thus emphasizing the potential to incorporate these features into snapshot-based models as well. These findings highlight the importance of comparing model architectures independent of the data format and suggest the potential of combining the efficiency of snapshot-based models with the performance of event-based models in the future.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7fff2ad251ff12c30edda0c89831123380698940" target='_blank'>
              UTG: Towards a Unified View of Snapshot and Event Based Models for Temporal Graphs
              </a>
            </td>
          <td>
            Shenyang Huang, Farimah Poursafaei, Reihaneh Rabbany, Guillaume Rabusseau, Emanuele Rossi
          </td>
          <td>2024-07-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="Demand prediction is a crucial task for e-commerce and physical retail businesses, especially during high-stake sales events. However, the limited availability of historical data from these peak periods poses a significant challenge for traditional forecasting methods. In this paper, we propose a novel approach that leverages strategically chosen proxy data reflective of potential sales patterns from similar entities during non-peak periods, enriched by features learned from a graph neural networks (GNNs)-based forecasting model, to predict demand during peak events. We formulate the demand prediction as a meta-learning problem and develop the Feature-based First-Order Model-Agnostic Meta-Learning (F-FOMAML) algorithm that leverages proxy data from non-peak periods and GNN-generated relational metadata to learn feature-specific layer parameters, thereby adapting to demand forecasts for peak events. Theoretically, we show that by considering domain similarities through task-specific metadata, our model achieves improved generalization, where the excess risk decreases as the number of training tasks increases. Empirical evaluations on large-scale industrial datasets demonstrate the superiority of our approach. Compared to existing state-of-the-art models, our method demonstrates a notable improvement in demand prediction accuracy, reducing the Mean Absolute Error by 26.24% on an internal vending machine dataset and by 1.04% on the publicly accessible JD.com dataset.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/fb0749b9bc04914e294f57c89199572e3cb5183c" target='_blank'>
              F-FOMAML: GNN-Enhanced Meta-Learning for Peak Period Demand Forecasting with Proxy Data
              </a>
            </td>
          <td>
            Zexing Xu, Linjun Zhang, Sitan Yang, Rasoul Etesami, Hanghang Tong, Huan Zhang, Jiawei Han
          </td>
          <td>2024-06-23</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>2</td>
        </tr>

        <tr id="In the field of machine learning and artificial intelligence, time series forecasting plays a pivotal role across various domains such as finance, healthcare, and weather. However, the task of selecting the most suitable forecasting method for a given dataset is a complex task due to the diversity of data patterns and characteristics. This research aims to address this challenge by proposing a comprehensive benchmark for evaluating and ranking time series forecasting methods across a wide range of datasets. This study investigates the comparative performance of many methods from two prominent time series forecasting frameworks, AutoGluon-Timeseries, and sktime to shed light on their applicability in different real-world scenarios. This research contributes to the field of time series forecasting by providing a robust benchmarking methodology and facilitating informed decision-making when choosing forecasting methods for achieving optimal prediction.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/52869870f9e404f4e69a10b76ca410b00d19088d" target='_blank'>
              Can time series forecasting be automated? A benchmark and analysis
              </a>
            </td>
          <td>
            Anvitha Thirthapura Sreedhara, Joaquin Vanschoren
          </td>
          <td>2024-07-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="The Variable Subset Forecasting (VSF) problem, where the majority of variables are unavailable in the inference stage of multivariate forecasting, has been an important but under-explored task with broad impacts in many real-world applications. Missing values, absent inter-correlation, and the impracticality of retraining largely hinder the ability of multivariate forecasting models to capture inherent relationships among variables, impacting their performance. However, existing approaches towards these issues either heavily rely on local temporal correlation or face limitations in fully recovering missing information from the unavailable subset, accompanied by notable computational expenses. To address these problems, we propose a novel density estimation solution to recover the information of missing variables via flows-based generative framework. In particular, a novel generative network for time series, namely Time-series Reconstruction Flows (TRF), is proposed to estimate and reconstruct the missing variable subset. In addition, a novel meta-training framework, Variable-Agnostic Meta Learning, has been developed to enhance the generalization ability of TRF, enabling it to adapt to diverse missing variables situations. Finally, extensive experiments are conducted to demonstrate the superiority of our proposed method compared with baseline methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5dcee67fc3a8091cc9cc24057f5c0b9c933f4044" target='_blank'>
              Reconstructing Missing Variables for Multivariate Time Series Forecasting via Conditional Generative Flows
              </a>
            </td>
          <td>
            Xuanming Hu, Wei Fan, Haifeng Chen, Pengyang Wang, Yanjie Fu
          </td>
          <td>2024-08-01</td>
          <td>Proceedings of the Thirty-ThirdInternational Joint Conference on Artificial Intelligence</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Transformer, a deep neural network architecture, has long dominated the field of natural language processing and beyond. Nevertheless, the recent introduction of Mamba challenges its supremacy, sparks considerable interest among researchers, and gives rise to a series of Mamba-based models that have exhibited notable potential. This survey paper orchestrates a comprehensive discussion, diving into essential research dimensions, covering: (i) the functioning of the Mamba mechanism and its foundation on the principles of structured state space models; (ii) the proposed improvements and the integration of Mamba with various networks, exploring its potential as a substitute for Transformers; (iii) the combination of Transformers and Mamba to compensate for each other's shortcomings. We have also made efforts to interpret Mamba and Transformer in the framework of kernel functions, allowing for a comparison of their mathematical nature within a unified context. Our paper encompasses the vast majority of improvements related to Mamba to date.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7343105953d6b67d9b94dc891649fb7197a33776" target='_blank'>
              Venturing into Uncharted Waters: The Navigation Compass from Transformer to Mamba
              </a>
            </td>
          <td>
            Yuchen Zou, Yineng Chen, Z. Li, Lefei Zhang, Hai Zhao
          </td>
          <td>2024-06-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>20</td>
        </tr>

        <tr id="Irregular and asynchronous event sequences are prevalent in many domains, such as social media, finance, and healthcare. Traditional temporal point processes (TPPs), like Hawkes processes, often struggle to model mutual inhibition and nonlinearity effectively. While recent neural network models, including RNNs and Transformers, address some of these issues, they still face challenges with long-term dependencies and computational efficiency. In this paper, we introduce the Mamba Hawkes Process (MHP), which leverages the Mamba state space architecture to capture long-range dependencies and dynamic event interactions. Our results show that MHP outperforms existing models across various datasets. Additionally, we propose the Mamba Hawkes Process Extension (MHP-E), which combines Mamba and Transformer models to enhance predictive capabilities. We present the novel application of the Mamba architecture to Hawkes processes, a flexible and extensible model structure, and a theoretical analysis of the synergy between state space models and Hawkes processes. Experimental results demonstrate the superior performance of both MHP and MHP-E, advancing the field of temporal point process modeling.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/01159bef23c8f357e01445fe63b05caff1959dc5" target='_blank'>
              Mamba Hawkes Process
              </a>
            </td>
          <td>
            Anningzhe Gao, Shan Dai, Yan Hu
          </td>
          <td>2024-07-07</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Hierarchical time-series forecasting (HTSF) is an important problem for many real-world business applications where the goal is to simultaneously forecast multiple time-series that are related to each other via a hierarchical relation. Recent works, however, do not address two important challenges that are typically observed in many demand forecasting applications at large companies. First, many time-series at lower levels of the hierarchy have high sparsity i.e., they have a significant number of zeros. Most HTSF methods do not address this varying sparsity across the hierarchy. Further, they do not scale well to the large size of the real-world hierarchy typically unseen in benchmarks used in literature. We resolve both these challenges by proposing HAILS, a novel probabilistic hierarchical model that enables accurate and calibrated probabilistic forecasts across the hierarchy by adaptively modeling sparse and dense time-series with different distributional assumptions and reconciling them to adhere to hierarchical constraints. We show the scalability and effectiveness of our methods by evaluating them against real-world demand forecasting datasets. We deploy HAILS at a large chemical manufacturing company for a product demand forecasting application with over ten thousand products and observe a significant 8.5\% improvement in forecast accuracy and 23% better improvement for sparse time-series. The enhanced accuracy and scalability make HAILS a valuable tool for improved business planning and customer experience.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e7c76a66b9e8e91e00f152d5a723fd37775613e4" target='_blank'>
              Large Scale Hierarchical Industrial Demand Time-Series Forecasting incorporating Sparsity
              </a>
            </td>
          <td>
            Harshavardhan Kamarthi, Aditya B. Sasanur, Xinjie Tong, Xingyu Zhou, James Peters, Joe Czyzyk, B. A. Prakash
          </td>
          <td>2024-07-02</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Human mobility is intricately influenced by urban contexts spatially and temporally, constituting essential domain knowledge in understanding traffic systems. While existing traffic forecasting models primarily rely on raw traffic data and advanced deep learning techniques, incorporating contextual information remains underexplored due to the lack of effective integration frameworks and the complexity of urban contexts. This study proposes a novel context-aware knowledge graph (CKG) framework to enhance traffic speed forecasting by effectively modeling spatial and temporal contexts. Employing a relation-dependent integration strategy, the framework generates context-aware representations from the spatial and temporal units of CKG to capture spatio-temporal dependencies of urban contexts. A CKG-GNN model, combining the CKG, dual-view multi-head self-attention (MHSA), and graph neural network (GNN), is then designed to predict traffic speed using these context-aware representations. Our experiments demonstrate that CKG's configuration significantly influences embedding performance, with ComplEx and KG2E emerging as optimal for embedding spatial and temporal units, respectively. The CKG-GNN model surpasses benchmark models, achieving an average MAE of $3.46\pm0.01$ and a MAPE of $14.76\pm0.09\%$ for traffic speed predictions from 10 to 120 minutes. The dual-view MHSA analysis reveals the crucial role of relation-dependent features from the context-based view and the model's ability to prioritize recent time slots in prediction from the sequence-based view. The CKG framework's model-agnostic nature suggests its potential applicability in various applications of intelligent transportation systems. Overall, this study underscores the importance of incorporating domain-specific contexts into traffic forecasting and merging context-aware knowledge graphs with neural networks to enhance accuracy.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0865c15082b62b4f18ab6dbdb8fae8daa0b14da6" target='_blank'>
              Context-aware knowledge graph framework for traffic speed forecasting using graph neural network
              </a>
            </td>
          <td>
            Yatao Zhang, Yi Wang, Song Gao, Martin Raubal
          </td>
          <td>2024-07-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Recently, the emerging graph Transformers have made significant advancements for node classification on graphs. In most graph Transformers, a crucial step involves transforming the input graph into token sequences as the model input, enabling Transformer to effectively learn the node representations. However, we observe that existing methods only express partial graph information of nodes through single-type token generation. Consequently, they require tailored strategies to encode additional graph-specific features into the Transformer to ensure the quality of node representation learning, limiting the model flexibility to handle diverse graphs. To this end, we propose a new graph Transformer called NTFormer to address this issue. NTFormer introduces a novel token generator called Node2Par, which constructs various token sequences using different token elements for each node. This flexibility allows Node2Par to generate valuable token sequences from different perspectives, ensuring comprehensive expression of rich graph features. Benefiting from the merits of Node2Par, NTFormer only leverages a Transformer-based backbone without graph-specific modifications to learn node representations, eliminating the need for graph-specific modifications. Extensive experiments conducted on various benchmark datasets containing homophily and heterophily graphs with different scales demonstrate the superiority of NTFormer over representative graph Transformers and graph neural networks for node classification.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/012b888fe3db6a2cd56d30404db3dd58e423b8bd" target='_blank'>
              NTFormer: A Composite Node Tokenized Graph Transformer for Node Classification
              </a>
            </td>
          <td>
            Jinsong Chen, Siyu Jiang, Kun He
          </td>
          <td>2024-06-27</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="While most time series are non-stationary, it is inevitable for models to face the distribution shift issue in time series forecasting. Existing solutions manipulate statistical measures (usually mean and std.) to adjust time series distribution. However, these operations can be theoretically seen as the transformation towards zero frequency component of the spectrum which cannot reveal full distribution information and would further lead to information utilization bottleneck in normalization, thus hindering forecasting performance. To address this problem, we propose to utilize the whole frequency spectrum to transform time series to make full use of data distribution from the frequency perspective. We present a deep frequency derivative learning framework, DERITS, for non-stationary time series forecasting. Specifically, DERITS is built upon a novel reversible transformation, namely Frequency Derivative Transformation (FDT) that makes signals derived in the frequency domain to acquire more stationary frequency representations. Then, we propose the Order-adaptive Fourier Convolution Network to conduct adaptive frequency filtering and learning. Furthermore, we organize DERITS as a parallel-stacked architecture for the multi-order derivation and fusion for forecasting. Finally, we conduct extensive experiments on several datasets which show the consistent superiority in both time series forecasting and shift alleviation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/fa3605455e65d9ad0e7e7cb1252d54167b777e50" target='_blank'>
              Deep Frequency Derivative Learning for Non-stationary Time Series Forecasting
              </a>
            </td>
          <td>
            Wei Fan, Kun Yi, Hangting Ye, Zhiyuan Ning, Qi Zhang, Ning An
          </td>
          <td>2024-06-29</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>4</td>
        </tr>

        <tr id="Implicit graph neural networks have gained popularity in recent years as they capture long-range dependencies while improving predictive performance in static graphs. Despite the tussle between performance degradation due to the oversmoothing of learned embeddings and long-range dependency being more pronounced in dynamic graphs, as features are aggregated both across neighborhood and time, no prior work has proposed an implicit graph neural model in a dynamic setting. In this paper, we present Implicit Dynamic Graph Neural Network (IDGNN) a novel implicit neural network for dynamic graphs which is the first of its kind. A key characteristic of IDGNN is that it demonstrably is well-posed, i.e., it is theoretically guaranteed to have a fixed-point representation. We then demonstrate that the standard iterative algorithm often used to train implicit models is computationally expensive in our dynamic setting as it involves computing gradients, which themselves have to be estimated in an iterative manner. To overcome this, we pose an equivalent bilevel optimization problem and propose an efficient single-loop training algorithm that avoids iterative computation by maintaining moving averages of key components of the gradients. We conduct extensive experiments on real-world datasets on both classification and regression tasks to demonstrate the superiority of our approach over the state-of-the-art baselines. We also demonstrate that our bi-level optimization framework maintains the performance of the expensive iterative algorithm while obtaining up to \textbf{1600x} speed-up.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3093322772df05295e0448968c691f9fa9b30d06" target='_blank'>
              Efficient and Effective Implicit Dynamic Graph Neural Network
              </a>
            </td>
          <td>
            Yongjian Zhong, Hieu Vu, Tianbao Yang, Bijaya Adhikari
          </td>
          <td>2024-06-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Accurate evaluation of forecasting models is essential for ensuring reliable predictions. Current practices for evaluating and comparing forecasting models focus on summarising performance into a single score, using metrics such as SMAPE. We hypothesize that averaging performance over all samples dilutes relevant information about the relative performance of models. Particularly, conditions in which this relative performance is different than the overall accuracy. We address this limitation by proposing a novel framework for evaluating univariate time series forecasting models from multiple perspectives, such as one-step ahead forecasting versus multi-step ahead forecasting. We show the advantages of this framework by comparing a state-of-the-art deep learning approach with classical forecasting techniques. While classical methods (e.g. ARIMA) are long-standing approaches to forecasting, deep neural networks (e.g. NHITS) have recently shown state-of-the-art forecasting performance in benchmark datasets. We conducted extensive experiments that show NHITS generally performs best, but its superiority varies with forecasting conditions. For instance, concerning the forecasting horizon, NHITS only outperforms classical approaches for multi-step ahead forecasting. Another relevant insight is that, when dealing with anomalies, NHITS is outperformed by methods such as Theta. These findings highlight the importance of aspect-based model evaluation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/11c0631ee5b9502a277f7561c809f6a420e0df60" target='_blank'>
              Forecasting with Deep Learning: Beyond Average of Average of Average Performance
              </a>
            </td>
          <td>
            Vítor Cerqueira, Luis Roque, Carlos Soares
          </td>
          <td>2024-06-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>14</td>
        </tr>

        <tr id="While tokenized graph Transformers have demonstrated strong performance in node classification tasks, their reliance on a limited subset of nodes with high similarity scores for constructing token sequences overlooks valuable information from other nodes, hindering their ability to fully harness graph information for learning optimal node representations. To address this limitation, we propose a novel graph Transformer called GCFormer. Unlike previous approaches, GCFormer develops a hybrid token generator to create two types of token sequences, positive and negative, to capture diverse graph information. And a tailored Transformer-based backbone is adopted to learn meaningful node representations from these generated token sequences. Additionally, GCFormer introduces contrastive learning to extract valuable information from both positive and negative token sequences, enhancing the quality of learned node representations. Extensive experimental results across various datasets, including homophily and heterophily graphs, demonstrate the superiority of GCFormer in node classification, when compared to representative graph neural networks (GNNs) and graph Transformers.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e5e10bd5b694099c88e649d9502adecd0acd52f7" target='_blank'>
              Leveraging Contrastive Learning for Enhanced Node Representations in Tokenized Graph Transformers
              </a>
            </td>
          <td>
            Jinsong Chen, Hanpeng Liu, J. Hopcroft, Kun He
          </td>
          <td>2024-06-27</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>75</td>
        </tr>

        <tr id="Link prediction models can benefit from incorporating textual descriptions of entities and relations, enabling fully inductive learning and flexibility in dynamic graphs. We address the challenge of also capturing rich structured information about the local neighbourhood of entities and their relations, by introducing a Transformer-based approach that effectively integrates textual descriptions with graph structure, reducing the reliance on resource-intensive text encoders. Our experiments on three challenging datasets show that our Fast-and-Frugal Text-Graph (FnF-TG) Transformers achieve superior performance compared to the previous state-of-the-art methods, while maintaining efficiency and scalability.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/749af11854db6b02422c6073e34d6bcae5781e0d" target='_blank'>
              Fast-and-Frugal Text-Graph Transformers are Effective Link Predictors
              </a>
            </td>
          <td>
            Andrei Catalin Coman, Christos Theodoropoulos, M. Moens, James Henderson
          </td>
          <td>2024-08-13</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Analyzing time-series data that may contain personal information, particularly in the medical field, presents serious privacy concerns. Sensitive health data from patients is often used to train machine-learning models for diagnostics and ongoing care. Assessing the privacy risk of such models is crucial to making knowledgeable decisions on whether to use a model in production, share it with third parties, or deploy it in patients homes. Membership Inference Attacks (MIA) are a key method for this kind of evaluation, however time-series prediction models have not been thoroughly studied in this context. We explore existing MIA techniques on time-series models, and introduce new features, focusing on the seasonality and trend components of the data. Seasonality is estimated using a multivariate Fourier transform, and a low-degree polynomial is used to approximate trends. We applied these techniques to various types of time-series models, using datasets from the health domain. Our results demonstrate that these new features enhance the effectiveness of MIAs in identifying membership, improving the understanding of privacy risks in medical data applications.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/fc26ca37aef313f1b2c96b71c1f95662bfd7a6e2" target='_blank'>
              Membership Inference Attacks Against Time-Series Models
              </a>
            </td>
          <td>
            Noam Koren, Abigail Goldsteen, Ariel Farkash, Guy Amit
          </td>
          <td>2024-07-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Large language models (LLMs) and their fine-tuning techniques have demonstrated superior performance in various language understanding and generation tasks. This paper explores fine-tuning LLMs for stock return forecasting with financial newsflow. In quantitative investing, return forecasting is fundamental for subsequent tasks like stock picking, portfolio optimization, etc. We formulate the model to include text representation and forecasting modules. We propose to compare the encoder-only and decoder-only LLMs, considering they generate text representations in distinct ways. The impact of these different representations on forecasting performance remains an open question. Meanwhile, we compare two simple methods of integrating LLMs' token-level representations into the forecasting module. The experiments on real news and investment universes reveal that: (1) aggregated representations from LLMs' token-level embeddings generally produce return predictions that enhance the performance of long-only and long-short portfolios; (2) in the relatively large investment universe, the decoder LLMs-based prediction model leads to stronger portfolios, whereas in the small universes, there are no consistent winners. Among the three LLMs studied (DeBERTa, Mistral, Llama), Mistral performs more robustly across different universes; (3) return predictions derived from LLMs' text representations are a strong signal for portfolio construction, outperforming conventional sentiment scores.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f6c0a84ac1f1fe79cfde96f4e163d0d69f9c06cb" target='_blank'>
              Fine-Tuning Large Language Models for Stock Return Prediction Using Newsflow
              </a>
            </td>
          <td>
            Tian Guo, E. Hauptmann
          </td>
          <td>2024-07-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Despite the success of Heterogeneous Graph Neural Networks (HGNNs) in modeling real-world Heterogeneous Information Networks (HINs), challenges such as expressiveness limitations and over-smoothing have prompted researchers to explore Graph Transformers (GTs) for enhanced HIN representation learning. However, research on GT in HINs remains limited, with two key shortcomings in existing work: (1) A node's neighbors at different distances in HINs convey diverse semantics. Unfortunately, existing methods ignore such differences and uniformly treat neighbors within a given distance in a coarse manner, which results in semantic confusion. (2) Nodes in HINs have various types, each with unique semantics. Nevertheless, existing methods mix nodes of different types during neighbor aggregation, hindering the capture of proper correlations between nodes of diverse types. To bridge these gaps, we design an innovative structure named (k,t)-ring neighborhood, where nodes are initially organized by their distance, forming different non-overlapping k-ring neighborhoods for each distance. Within each k-ring structure, nodes are further categorized into different groups according to their types, thus emphasizing the heterogeneity of both distances and types in HINs naturally. Based on this structure, we propose a novel Hierarchical Heterogeneous Graph Transformer (HHGT) model, which seamlessly integrates a Type-level Transformer for aggregating nodes of different types within each k-ring neighborhood, followed by a Ring-level Transformer for aggregating different k-ring neighborhoods in a hierarchical manner. Extensive experiments are conducted on downstream tasks to verify HHGT's superiority over 14 baselines, with a notable improvement of up to 24.75% in NMI and 29.25% in ARI for node clustering task on the ACM dataset compared to the best baseline.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7df2a6f12ecfee64aedb6236102e133b9f02264e" target='_blank'>
              HHGT: Hierarchical Heterogeneous Graph Transformer for Heterogeneous Graph Representation Learning
              </a>
            </td>
          <td>
            Qiuyu Zhu, Liang Zhang, Qianxiong Xu, Kaijun Liu, Cheng Long, Xiaoyang Wang
          </td>
          <td>2024-07-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Time series classification with missing data is a prevalent issue in time series analysis, as temporal data often contain missing values in practical applications. The traditional two-stage approach, which handles imputation and classification separately, can result in sub-optimal performance as label information is not utilized in the imputation process. On the other hand, a one-stage approach can learn features under missing information, but feature representation is limited as imputed errors are propagated in the classification process. To overcome these challenges, this study proposes an end-to-end neural network that unifies data imputation and representation learning within a single framework, allowing the imputation process to take advantage of label information. Differing from previous methods, our approach places less emphasis on the accuracy of imputation data and instead prioritizes classification performance. A specifically designed multi-scale feature learning module is implemented to extract useful information from the noise-imputation data. The proposed model is evaluated on 68 univariate time series datasets from the UCR archive, as well as a multivariate time series dataset with various missing data ratios and 4 real-world datasets with missing information. The results indicate that the proposed model outperforms state-of-the-art approaches for incomplete time series classification, particularly in scenarios with high levels of missing data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5eecace8149eba147315a0809afa377389f6ba24" target='_blank'>
              An End-to-End Model for Time Series Classification In the Presence of Missing Values
              </a>
            </td>
          <td>
            Pengshuai Yao, Mengna Liu, Xu Cheng, Fan Shi, Huan Li, Xiufeng Liu, Shengyong Chen
          </td>
          <td>2024-08-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Message-Passing Neural Networks (MPNNs) are extensively employed in graph learning tasks but suffer from limitations such as the restricted scope of information exchange, by being confined to neighboring nodes during each round of message passing. Various strategies have been proposed to address these limitations, including incorporating virtual nodes to facilitate global information exchange. In this study, we introduce the Hierarchical Support Graph (HSG), an extension of the virtual node concept created through recursive coarsening of the original graph. This approach provides a flexible framework for enhancing information flow in graphs, independent of the specific MPNN layers utilized. We present a theoretical analysis of HSGs, investigate their empirical performance, and demonstrate that HSGs can surpass other methods augmented with virtual nodes, achieving state-of-the-art results across multiple datasets.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/54d09e194436b08c9f64b0123db5f3a917f7a0fd" target='_blank'>
              Next Level Message-Passing with Hierarchical Support Graphs
              </a>
            </td>
          <td>
            Carlos Vonessen, Florian Grötschla, R. Wattenhofer
          </td>
          <td>2024-06-22</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>19</td>
        </tr>

        <tr id="The success of large pretrained models in natural language processing (NLP) and computer vision (CV) has opened new avenues for constructing foundation models for time series forecasting (TSF). Traditional TSF foundation models rely heavily on numerical data fitting. In contrast, the human brain is inherently skilled at processing visual information, prefer predicting future trends by observing visualized sequences. From a biomimetic perspective, utilizing models to directly process numerical sequences might not be the most effective route to achieving Artificial General Intelligence (AGI). This paper proposes ViTime, a novel Visual Intelligence-based foundation model for TSF. ViTime overcomes the limitations of numerical time series data fitting by utilizing visual data processing paradigms and employs a innovative data synthesis method during training, called Real Time Series (RealTS). Experiments on a diverse set of previously unseen forecasting datasets demonstrate that ViTime achieves state-of-the-art zero-shot performance, even surpassing the best individually trained supervised models in some situations. These findings suggest that visual intelligence can significantly enhance time series analysis and forecasting, paving the way for more advanced and versatile models in the field. The code for our framework is accessible at https://github.com/IkeYang/ViTime.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e2db5afb441ca005fd6edc6249af583bf8df0634" target='_blank'>
              ViTime: A Visual Intelligence-Based Foundation Model for Time Series Forecasting
              </a>
            </td>
          <td>
            Luoxiao Yang, Yun Wang, Xinqi Fan, Israel Cohen, Yue Zhao, Zijun Zhang
          </td>
          <td>2024-07-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Time series generation is a crucial research topic in the area of deep learning, which can be used for data augmentation, imputing missing values, and forecasting. Currently, latent diffusion models are ascending to the forefront of generative modeling for many important data representations. Being the most pivotal in the computer vision domain, latent diffusion models have also recently attracted interest in other communities, including NLP, Speech, and Geometric Space. In this work, we propose TimeLDM, a novel latent diffusion model for high-quality time series generation. TimeLDM is composed of a variational autoencoder that encodes time series into an informative and smoothed latent content and a latent diffusion model operating in the latent space to generate latent information. We evaluate the ability of our method to generate synthetic time series with simulated and realistic datasets, benchmark the performance against existing state-of-the-art methods. Qualitatively and quantitatively, we find that the proposed TimeLDM persistently delivers high-quality generated time series. Sores from Context-FID and Discriminative indicate that TimeLDM consistently and significantly outperforms current state-of-the-art benchmarks with an average improvement of 3.4$\times$ and 3.8$\times$, respectively. Further studies demonstrate that our method presents better performance on different lengths of time series data generation. To the best of our knowledge, this is the first study to explore the potential of the latent diffusion model for unconditional time series generation and establish a new baseline for synthetic time series.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c127c4b179c7e5d61f7a4347e0003557a02536f1" target='_blank'>
              TimeLDM: Latent Diffusion Model for Unconditional Time Series Generation
              </a>
            </td>
          <td>
            Jian Qian, Miao Sun, Sifan Zhou, Biao Wan, Minhao Li, Patrick Chiang
          </td>
          <td>2024-07-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Causal discovery from time-series data aims to capture both intra-slice (contemporaneous) and inter-slice (time-lagged) causality between variables within the temporal chain, which is crucial for various scientific disciplines. Compared to causal discovery from non-time-series data, causal discovery from time-series data necessitates more serialized samples with a larger amount of observed time steps. To address the challenges, we propose a novel gradient-based causal discovery approach STIC, which focuses on \textbf{S}hort-\textbf{T}erm \textbf{I}nvariance using \textbf{C}onvolutional neural networks to uncover the causal relationships from time-series data. Specifically, STIC leverages both the short-term time and mechanism invariance of causality within each window observation, which possesses the property of independence, to enhance sample efficiency. Furthermore, we construct two causal convolution kernels, which correspond to the short-term time and mechanism invariance respectively, to estimate the window causal graph. To demonstrate the necessity of convolutional neural networks for causal discovery from time-series data, we theoretically derive the equivalence between convolution and the underlying generative principle of time-series data under the assumption that the additive noise model is identifiable. Experimental evaluations conducted on both synthetic and FMRI benchmark datasets demonstrate that our STIC outperforms baselines significantly and achieves the state-of-the-art performance, particularly when the datasets contain a limited number of observed time steps. Code is available at \url{https://github.com/HITshenrj/STIC}.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/801fe20484b5bf27c8c2899d947656d8aa4dff2e" target='_blank'>
              Causal Discovery from Time-Series Data with Short-Term Invariance-Based Convolutional Neural Networks
              </a>
            </td>
          <td>
            Rujia Shen, Boran Wang, Chao Zhao, Yi Guan, Jingchi Jiang
          </td>
          <td>2024-08-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Time series forecasting has played an important role in different industries, including economics, energy, weather, and healthcare. RNN-based methods have shown promising potential due to their strong ability to model the interaction of time and variables. However, they are prone to gradient issues like gradient explosion and vanishing gradients. And the prediction accuracy is not high. To address the above issues, this paper proposes a Fractional-order Lipschitz Recurrent Neural Network with a Frequency-domain Gated Attention mechanism (FLRNN-FGA). There are three major components: the Fractional-order Lipschitz Recurrent Neural Network (FLRNN), frequency module, and gated attention mechanism. In the FLRNN, fractional-order integration is employed to describe the dynamic systems accurately. It can capture long-term dependencies and improve prediction accuracy. Lipschitz weight matrices are applied to alleviate the gradient issues. In the frequency module, temporal data are transformed into the frequency domain by Fourier transform. Frequency domain processing can reduce the computational complexity of the model. In the gated attention mechanism, the gated structure can regulate attention information transmission to reduce the number of model parameters. Extensive experimental results on five real-world benchmark datasets demonstrate the effectiveness of FLRNN-FGA compared with the state-of-the-art methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/df8abef5d3a79df25da8495db7434b86114030b4" target='_blank'>
              FLRNN-FGA: Fractional-Order Lipschitz Recurrent Neural Network with Frequency-Domain Gated Attention Mechanism for Time Series Forecasting
              </a>
            </td>
          <td>
            Chunna Zhao, Junjie Ye, Zelong Zhu, Yaqun Huang
          </td>
          <td>2024-07-22</td>
          <td>Fractal and Fractional</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Multi-agent trajectory prediction is crucial to autonomous driving and understanding the surrounding environment. Learning-based approaches for multi-agent trajectory prediction, such as primarily relying on graph neural networks, graph transformers, and hypergraph neural networks, have demonstrated outstanding performance on real-world datasets in recent years. However, the hypergraph transformer-based method for trajectory prediction is yet to be explored. Therefore, we present a MultiscAle Relational Transformer (MART) network for multi-agent trajectory prediction. MART is a hypergraph transformer architecture to consider individual and group behaviors in transformer machinery. The core module of MART is the encoder, which comprises a Pair-wise Relational Transformer (PRT) and a Hyper Relational Transformer (HRT). The encoder extends the capabilities of a relational transformer by introducing HRT, which integrates hyperedge features into the transformer mechanism, promoting attention weights to focus on group-wise relations. In addition, we propose an Adaptive Group Estimator (AGE) designed to infer complex group relations in real-world environments. Extensive experiments on three real-world datasets (NBA, SDD, and ETH-UCY) demonstrate that our method achieves state-of-the-art performance, enhancing ADE/FDE by 3.9%/11.8% on the NBA dataset. Code is available at https://github.com/gist-ailab/MART.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6d30fe4d8196a1c8f984e6dc8d8f3783c98168cb" target='_blank'>
              MART: MultiscAle Relational Transformer Networks for Multi-agent Trajectory Prediction
              </a>
            </td>
          <td>
            Seongju Lee, Junseok Lee, Yeonguk Yu, Taeri Kim, Kyoobin Lee
          </td>
          <td>2024-07-31</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>16</td>
        </tr>

        <tr id="Graphs have emerged as critical data structures for content analysis in various domains, such as social network analysis, bioinformatics, and recommendation systems. Node classification, a fundamental task in this context, is typically tackled using graph neural networks (GNNs). Unfortunately, conventional GNNs still face challenges in scenarios with few labeled nodes, despite the prevalence of few-shot node classification tasks in real-world applications. To address this challenge, various approaches have been proposed, including graph meta-learning, transfer learning, and methods based on Large Language Models (LLMs). However, traditional meta-learning and transfer learning methods often require prior knowledge from base classes or fail to exploit the potential advantages of unlabeled nodes. Meanwhile, LLM-based methods may overlook the zero-shot capabilities of LLMs and rely heavily on the quality of generated contexts. In this paper, we propose a novel approach that integrates LLMs and GNNs, leveraging the zero-shot inference and reasoning capabilities of LLMs and employing a Graph-LLM-based active learning paradigm to enhance GNNs' performance. Extensive experiments demonstrate the effectiveness of our model in improving node classification accuracy with considerably limited labeled data, surpassing state-of-the-art baselines by significant margins.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d41329cb9c08fef08379c558db5a09f412a506ad" target='_blank'>
              Enhancing Data-Limited Graph Neural Networks by Actively Distilling Knowledge from Large Language Models
              </a>
            </td>
          <td>
            Quan Li, Tianxiang Zhao, Lingwei Chen, Junjie Xu, Suhang Wang
          </td>
          <td>2024-07-19</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>11</td>
        </tr>

        <tr id="Causal discovery on event sequences holds a pivotal significance across domains such as healthcare, finance, and industrial systems. The crux of this endeavor lies in unraveling causal structures among event types, typically portrayed as directed acyclic graphs (DAGs). Nonetheless, prevailing methodologies often grapple with untenable assumptions and intricate optimization hurdles. To address these challenges, we present a novel model named CausalNET. At the heart of CausalNET is a special prediction module based on the Transformer architecture, which prognosticates forthcoming events by leveraging historical occurrences, with its predictive prowess amplified by a trainable causal graph engineered to fathom causal relationships among event types. Further, to augment the predictive paradigm, we devise a causal decay matrix to encapsulate the reciprocal influence of events upon each other within the topological network. During training, we alternatively refine the prediction module and fine-tune the causal graph. Comprehensive evaluation on a spectrum of real-world and synthetic datasets underscores the superior performance and scalability of CausalNET, which marks a promising step forward in the realm of causal discovery. Code and Appendix are available at https://github.com/CGCL-codes/CausalNET.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7b393ee640bb697584ae62c868cc019ed098b961" target='_blank'>
              CausalNET: Unveiling Causal Structures on Event Sequences by Topology-Informed Causal Attention
              </a>
            </td>
          <td>
            Hua Zhu, Hong Huang, Kehan Yin, Zejun Fan, Hai Jin, Bang Liu
          </td>
          <td>2024-08-01</td>
          <td>Proceedings of the Thirty-ThirdInternational Joint Conference on Artificial Intelligence</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="In this paper, we leverage the power of latent diffusion models to generate synthetic time series tabular data. Along with the temporal and feature correlations, the heterogeneous nature of the feature in the table has been one of the main obstacles in time series tabular data modeling. We tackle this problem by combining the ideas of the variational auto-encoder (VAE) and the denoising diffusion probabilistic model (DDPM). Our model named as \texttt{TimeAutoDiff} has several key advantages including (1) Generality: the ability to handle the broad spectrum of time series tabular data from single to multi-sequence datasets; (2) Good fidelity and utility guarantees: numerical experiments on six publicly available datasets demonstrating significant improvements over state-of-the-art models in generating time series tabular data, across four metrics measuring fidelity and utility; (3) Fast sampling speed: entire time series data generation as opposed to the sequential data sampling schemes implemented in the existing diffusion-based models, eventually leading to significant improvements in sampling speed, (4) Entity conditional generation: the first implementation of conditional generation of multi-sequence time series tabular data with heterogenous features in the literature, enabling scenario exploration across multiple scientific and engineering domains. Codes are in preparation for release to the public, but available upon request.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/78a04be6d94e77047c3251e4480cd08d1194dbd1" target='_blank'>
              TimeAutoDiff: Combining Autoencoder and Diffusion model for time series tabular data synthesizing
              </a>
            </td>
          <td>
            Namjoon Suh, Yuning Yang, Din-Yin Hsieh, Qitong Luan, Shi Xu, Shixiang Zhu, Guang Cheng
          </td>
          <td>2024-06-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Evaluating the contribution of individual data points to a model's prediction is critical for interpreting model predictions and improving model performance. Existing data contribution methods have been applied to various data types, including tabular data, images, and texts; however, their primary focus has been on i.i.d. settings. Despite the pressing need for principled approaches tailored to time series datasets, the problem of estimating data contribution in such settings remains unexplored, possibly due to challenges associated with handling inherent temporal dependencies. This paper introduces TimeInf, a data contribution estimation method for time-series datasets. TimeInf uses influence functions to attribute model predictions to individual time points while preserving temporal structures. Our extensive empirical results demonstrate that TimeInf outperforms state-of-the-art methods in identifying harmful anomalies and helpful time points for forecasting. Additionally, TimeInf offers intuitive and interpretable attributions of data values, allowing us to easily distinguish diverse anomaly patterns through visualizations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3cf948c645144f6d8565608c19f9779114df6df2" target='_blank'>
              TimeInf: Time Series Data Contribution via Influence Functions
              </a>
            </td>
          <td>
            Yizi Zhang, Jingyan Shen, Xiaoxue Xiong, Yongchan Kwon
          </td>
          <td>2024-07-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Temporal causal discovery is a crucial task aimed at uncovering the causal relations within time series data. The latest temporal causal discovery methods usually train deep learning models on prediction tasks to uncover the causality between time series. They capture causal relations by analyzing the parameters of some components of the trained models, e.g., attention weights and convolution weights. However, this is an incomplete mapping process from the model parameters to the causality and fails to investigate the other components, e.g., fully connected layers and activation functions, that are also significant for causal discovery. To facilitate the utilization of the whole deep learning models in temporal causal discovery, we proposed an interpretable transformer-based causal discovery model termed CausalFormer, which consists of the causality-aware transformer and the decomposition-based causality detector. The causality-aware transformer learns the causal representation of time series data using a prediction task with the designed multi-kernel causal convolution which aggregates each input time series along the temporal dimension under the temporal priority constraint. Then, the decomposition-based causality detector interprets the global structure of the trained causality-aware transformer with the proposed regression relevance propagation to identify potential causal relations and finally construct the causal graph. Experiments on synthetic, simulated, and real datasets demonstrate the state-of-the-art performance of CausalFormer on discovering temporal causality. Our code is available at https://github.com/lingbai-kong/CausalFormer.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0298589ffc3502a8f8731583d6ed34241baab0de" target='_blank'>
              CausalFormer: An Interpretable Transformer for Temporal Causal Discovery
              </a>
            </td>
          <td>
            Lingbai Kong, Wengen Li, Hanchen Yang, Yichao Zhang, J. Guan, Shuigeng Zhou
          </td>
          <td>2024-06-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>49</td>
        </tr>

        <tr id="The application of deep learning techniques for predicting stock market prices is a prominent and widely researched topic in the field of data science. To effectively predict market trends, it is essential to utilize a diversified dataset. In this paper, we give a graph neural network based convolutional neural network (CNN) model, that can be applied on diverse source of data, in the attempt to extract features to predict the trends of indices of \text{S}\&\text{P} 500, NASDAQ, DJI, NYSE, and RUSSEL. The experiments show that the associated models improve the performance of prediction in all indices over the baseline algorithms by about $4\% \text{ to } 15\%$, in terms of F-measure. A trading simulation is generated from predictions and gained a Sharpe ratio of over 3.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/db9f0abbc8601da414d831f4eef6626e555a4457" target='_blank'>
              GraphCNNpred: A stock market indices prediction using a Graph based deep learning system
              </a>
            </td>
          <td>
            Yuhui Jin
          </td>
          <td>2024-07-04</td>
          <td>ArXiv</td>
          <td>2</td>
          <td>1</td>
        </tr>

        <tr id="Continuous-Time Dynamic Graph (CTDG) precisely models evolving real-world relationships, drawing heightened interest in dynamic graph learning across academia and industry. However, existing CTDG models encounter challenges stemming from noise and limited historical data. Graph Data Augmentation (GDA) emerges as a critical solution, yet current approaches primarily focus on static graphs and struggle to effectively address the dynamics inherent in CTDGs. Moreover, these methods often demand substantial domain expertise for parameter tuning and lack theoretical guarantees for augmentation efficacy. To address these issues, we propose Conda, a novel latent diffusion-based GDA method tailored for CTDGs. Conda features a sandwich-like architecture, incorporating a Variational Auto-Encoder (VAE) and a conditional diffusion model, aimed at generating enhanced historical neighbor embeddings for target nodes. Unlike conventional diffusion models trained on entire graphs via pre-training, Conda requires historical neighbor sequence embeddings of target nodes for training, thus facilitating more targeted augmentation. We integrate Conda into the CTDG model and adopt an alternating training strategy to optimize performance. Extensive experimentation across six widely used real-world datasets showcases the consistent performance improvement of our approach, particularly in scenarios with limited historical data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/eb15255bdb2698993e5ad0223454abd6a732d2e7" target='_blank'>
              Latent Conditional Diffusion-based Data Augmentation for Continuous-Time Dynamic Graph Model
              </a>
            </td>
          <td>
            Yuxing Tian, Yiyan Qi, Aiwen Jiang, Qi Huang, Jian Guo
          </td>
          <td>2024-07-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Time Series Anomaly Detection (TSAD) finds widespread applications across various domains such as financial markets, industrial production, and healthcare. Its primary objective is to learn the normal patterns of time series data, thereby identifying deviations in test samples. Most existing TSAD methods focus on modeling data from the temporal dimension, while ignoring the semantic information in the spatial dimension. To address this issue, we introduce a novel approach, called Spatial-Temporal Normality learning (STEN). STEN is composed of a sequence Order prediction-based Temporal Normality learning (OTN) module that captures the temporal correlations within sequences, and a Distance prediction-based Spatial Normality learning (DSN) module that learns the relative spatial relations between sequences in a feature space. By synthesizing these two modules, STEN learns expressive spatial-temporal representations for the normal patterns hidden in the time series data. Extensive experiments on five popular TSAD benchmarks show that STEN substantially outperforms state-of-the-art competing methods. Our code is available at https://github.com/mala-lab/STEN.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6136ae3b84b2b1b9e6215a5c67a3153abd0eedc2" target='_blank'>
              Self-Supervised Spatial-Temporal Normality Learning for Time Series Anomaly Detection
              </a>
            </td>
          <td>
            Yutong Chen, Hongzuo Xu, Guansong Pang, Hezhe Qiao, Yuan Zhou, Mingsheng Shang
          </td>
          <td>2024-06-28</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="How to capture dynamic spatial-temporal dependencies remains an open question in multivariate time series (MTS) forecasting. Although recent advanced spatial-temporal graph neural networks (STGNNs) achieve superior forecasting performance, they either consider pre-defined spatial correlations or simply learn static graphs. Some research has tried to learn many adjacent matrices to reveal time-varying spatial correlations, but they generate discrete graphs which cannot encode evolutionary information and also face computational complexity problem. In this paper, we propose two significant plugins to help automatically learn enhanced dynamic spatial-temporal embedding of MTS data: (1) a novel neural conditional random field (CRF) layer. We find that the implicit time-varying spatial dependencies are reflected by the explicit changeable links between edges, and we propose the neural CRF to encode such pairwise changeable evolutionary inter-dependencies; (2) a structure adaptive graph convolution (SAGC) that does not require pre-defined graphs to capture semantically richer spatial correlations. Then, we integrate the neural CRF, SAGC with recurrent neural network to develop a new STGNN paradigm termed Adaptive Spatial-Temporal graph neural network with Conditional Random Field (ASTCRF), which can be trained in an end-to-end fashion. We validate the effectiveness, efficiency and scalability of ASTCRF on five public benchmark MTS datasets.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/667940911f90cfd6980e5e1731731f7c2af49b08" target='_blank'>
              Dynamic Spatial-Temporal Embedding via Neural Conditional Random Field for Multivariate Time Series Forecasting
              </a>
            </td>
          <td>
            Peiyu Yi, Feihu Huang, Jian Peng, Zhifeng Bao
          </td>
          <td>2024-06-27</td>
          <td>ACM Transactions on Spatial Algorithms and Systems</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Modern recurrent layers are emerging as a promising path toward edge deployment of foundation models, especially in the context of large language models (LLMs). Compressing the whole input sequence in a finite-dimensional representation enables recurrent layers to model long-range dependencies while maintaining a constant inference cost for each token and a fixed memory requirement. However, the practical deployment of LLMs in resource-limited environments often requires further model compression, such as quantization and pruning. While these techniques are well-established for attention-based models, their effects on recurrent layers remain underexplored. In this preliminary work, we focus on post-training quantization for recurrent LLMs and show that Mamba models exhibit the same pattern of outlier channels observed in attention-based LLMs. We show that the reason for the difficulty of quantizing SSMs is caused by activation outliers, similar to those observed in transformer-based LLMs. We report baseline results for post-training quantization of Mamba that do not take into account the activation outliers and suggest first steps for outlier-aware quantization.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3d553478d06f751f872a82c774c8262ce66d47fd" target='_blank'>
              Mamba-PTQ: Outlier Channels in Recurrent Large Language Models
              </a>
            </td>
          <td>
            Alessandro Pierro, Steven Abreu
          </td>
          <td>2024-07-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="The modelling of temporal patterns in dynamic graphs is an important current research issue in the development of time-aware GNNs. Whether or not a specific sequence of events in a temporal graph constitutes a temporal pattern not only depends on the frequency of its occurrence. We consider whether it deviates from what is expected in a temporal graph where timestamps are randomly shuffled. While accounting for such a random baseline is important to model temporal patterns, it has mostly been ignored by current temporal graph neural networks. To address this issue we propose HYPA-DBGNN, a novel two-step approach that combines (i) the inference of anomalous sequential patterns in time series data on graphs based on a statistically principled null model, with (ii) a neural message passing approach that utilizes a higher-order De Bruijn graph whose edges capture overrepresented sequential patterns. Our method leverages hypergeometric graph ensembles to identify anomalous edges within both first- and higher-order De Bruijn graphs, which encode the temporal ordering of events. The model introduces an inductive bias that enhances model interpretability. We evaluate our approach for static node classification using benchmark datasets and a synthetic dataset that showcases its ability to incorporate the observed inductive bias regarding over- and under-represented temporal edges. We demonstrate the framework's effectiveness in detecting similar patterns within empirical datasets, resulting in superior performance compared to baseline methods in node classification tasks. To the best of our knowledge, our work is the first to introduce statistically informed GNNs that leverage temporal and causal sequence anomalies. HYPA-DBGNN represents a path for bridging the gap between statistical graph inference and neural graph representation learning, with potential applications to static GNNs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e06e0cb47d2e0afba3b7c9bbfa9d5c33b0375133" target='_blank'>
              Inference of Sequential Patterns for Neural Message Passing in Temporal Graphs
              </a>
            </td>
          <td>
            J. V. Pichowski, Vincenzo Perri, Lisi Qarkaxhija, Ingo Scholtes
          </td>
          <td>2024-06-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Sequential recommendation systems aim to provide personalized recommendations by analyzing dynamic preferences and dependencies within user behavior sequences. Recently, Transformer models can effectively capture user preferences. However, their quadratic computational complexity limits recommendation performance on long interaction sequence data. Inspired by the State Space Model (SSM)representative model, Mamba, which efficiently captures user preferences in long interaction sequences with linear complexity, we find that Mamba's recommendation effectiveness is limited in short interaction sequences, with failing to recall items of actual interest to users and exacerbating the data sparsity cold start problem. To address this issue, we innovatively propose a new model, MaTrRec, which combines the strengths of Mamba and Transformer. This model fully leverages Mamba's advantages in handling long-term dependencies and Transformer's global attention advantages in short-term dependencies, thereby enhances predictive capabilities on both long and short interaction sequence datasets while balancing model efficiency. Notably, our model significantly improves the data sparsity cold start problem, with an improvement of up to 33% on the highly sparse Amazon Musical Instruments dataset. We conducted extensive experimental evaluations on five widely used public datasets. The experimental results show that our model outperforms the current state-of-the-art sequential recommendation models on all five datasets. The code is available at https://github.com/Unintelligentmumu/MaTrRec.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/412e6c60b2d5426ebf3724e770876d116c398984" target='_blank'>
              MaTrRec: Uniting Mamba and Transformer for Sequential Recommendation
              </a>
            </td>
          <td>
            Shun Zhang, Runsen Zhang, Zhirong Yang
          </td>
          <td>2024-07-27</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Recently, Large Language Models (LLMs) have demonstrated great potential in various data mining tasks, such as knowledge question answering, mathematical reasoning, and commonsense reasoning. However, the reasoning capability of LLMs on temporal event forecasting has been under-explored. To systematically investigate their abilities in temporal event forecasting, we conduct a comprehensive evaluation of LLM-based methods for temporal event forecasting. Due to the lack of a high-quality dataset that involves both graph and textual data, we first construct a benchmark dataset, named MidEast-TE-mini. Based on this dataset, we design a series of baseline methods, characterized by various input formats and retrieval augmented generation(RAG) modules. From extensive experiments, we find that directly integrating raw texts into the input of LLMs does not enhance zero-shot extrapolation performance. In contrast, incorporating raw texts in specific complex events and fine-tuning LLMs significantly improves performance. Moreover, enhanced with retrieval modules, LLM can effectively capture temporal relational patterns hidden in historical events. Meanwhile, issues such as popularity bias and the long-tail problem still persist in LLMs, particularly in the RAG-based method. These findings not only deepen our understanding of LLM-based event forecasting methods but also highlight several promising research directions.We consider that this comprehensive evaluation, along with the identified research opportunities, will significantly contribute to future research on temporal event forecasting through LLMs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/425b541ff4168e921c54ca9c3b449c1fcf985c55" target='_blank'>
              A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting
              </a>
            </td>
          <td>
            He Chang, Chenchen Ye, Zhulin Tao, Jie Wu, Zhengmao Yang, Yunshan Ma, Xianglin Huang, Tat-Seng Chua
          </td>
          <td>2024-07-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c6b30fb9799602bf4dfd68fdcf16333cb2b7ff18" target='_blank'>
              CliqueFluxNet: Unveiling EHR Insights with Stochastic Edge Fluxing and Maximal Clique Utilisation Using Graph Neural Networks
              </a>
            </td>
          <td>
            Soheila Molaei, Nima Ghanbari Bousejin, Ghadeer O. Ghosheh, Anshul Thakur, V. Chauhan, Tingting Zhu, David A. Clifton
          </td>
          <td>2024-08-01</td>
          <td>Journal of Healthcare Informatics Research</td>
          <td>0</td>
          <td>11</td>
        </tr>

        <tr id="Time-series classification is vital in health monitoring and human activity recognition, as well as in areas such as financial forecasting, process control, and a wide array of forecasting tasks. Traditional time-series models segment data into windows and assign one label per window, often missing label transitions within those windows. This paper presents a novel many-to-many time-series model and post-processing using hybrid recurrent neural networks with attention mechanisms, which more effectively captures label transitions over traditional many-to-one models. Further, unlike typical other many-to-many models, our approach doesn’t require a decoder. Instead, it employs an RNN, generating a label for every input time step. During inference, a weighted voting scheme consolidates overlapping predictions into one label per time step. Experiments show our model remains effective on time-series with sparse label shifts, but particularly excels in detecting frequent transitions. This model is ideal for tasks demanding accurate pinpointing of rapid label changes in time-series data, such as gesture recognition, making it ideal for fast-paced human activity recognition. 1">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d206e88758c3992f96eaf77f9ddd4f0e63779b32" target='_blank'>
              Many-to-Many Prediction for Effective Modeling of Frequent Label Transitions in Time Series
              </a>
            </td>
          <td>
            Alexander Katrompas, V. Metsis
          </td>
          <td>2024-06-26</td>
          <td>Proceedings of the 17th International Conference on PErvasive Technologies Related to Assistive Environments</td>
          <td>0</td>
          <td>18</td>
        </tr>

        <tr id="Dynamic link prediction is a critical task in the analysis of evolving networks, with applications ranging from recommender systems to economic exchanges. However, the concept of the temporal receptive field, which refers to the temporal context that models use for making predictions, has been largely overlooked and insufficiently analyzed in existing research. In this study, we present a comprehensive analysis of the temporal receptive field in dynamic graph learning. By examining multiple datasets and models, we formalize the role of temporal receptive field and highlight their crucial influence on predictive accuracy. Our results demonstrate that appropriately chosen temporal receptive field can significantly enhance model performance, while for some models, overly large windows may introduce noise and reduce accuracy. We conduct extensive benchmarking to validate our findings, ensuring that all experiments are fully reproducible. Code is available at https://github.com/ykrmm/BenchmarkTW .">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/31f09be25a90f0bff93ee2f78d85164a62f24094" target='_blank'>
              Temporal receptive field in dynamic graph learning: A comprehensive analysis
              </a>
            </td>
          <td>
            Yannis Karmim, Leshanshui Yang, Raphael Fournier S'Niehotta, Cl'ement Chatelain, S'ebastien Adam, Nicolas Thome
          </td>
          <td>2024-07-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Accurate traffic flow forecasting is a crucial component of intelligent transportation systems, playing a pivotal role in enhancing transportation intelligence. The integration of Graph Neural Networks (GNNs) and Transformers in traffic flow forecasting has gained significant adoption for enhancing prediction accuracy. Yet, the complex spatial and temporal dependencies present in traffic data continue to pose substantial challenges: (1) Most GNN-based methods assume that the graph structure reflects the actual dependencies between nodes, overlooking the complex dependencies present in the real-world context. (2) Standard time-series models are unable to effectively model complex temporal dependencies, hindering prediction accuracy. To tackle these challenges, the authors propose a novel Transformer-based Spatiotemporal Graph Diffusion Convolution Network (TSGDC) for Traffic Flow Forecasting, which leverages graph diffusion and transformer to capture the complexity and dynamics of spatial and temporal patterns, thereby enhancing prediction performance. The authors designed an Efficient Channel Attention (ECA) that learns separately from the feature dimensions collected by traffic sensors and the temporal dimensions of traffic data, aiding in spatiotemporal modeling. Chebyshev Graph Diffusion Convolution (GDC) is used to capture the complex dependencies within the spatial distribution. Sequence decomposition blocks, as internal operations of transformers, are employed to gradually extract long-term stable trends from hidden complex variables. Additionally, by integrating multi-scale dependencies, including recent, daily, and weekly patterns, accurate traffic flow predictions are achieved. Experimental results on various public datasets show that TSGDC outperforms conventional traffic forecasting models, particularly in accuracy and robustness.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f28ffc0b410cb4e7b7c33a98e7941875942be67a" target='_blank'>
              Transformer-Based Spatiotemporal Graph Diffusion Convolution Network for Traffic Flow Forecasting
              </a>
            </td>
          <td>
            Siwei Wei, Yang Yang, Donghua Liu, Ke Deng, Chunzhi Wang
          </td>
          <td>2024-08-09</td>
          <td>Electronics</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Many empirical studies of labor market questions rely on estimating relatively simple predictive models using small, carefully constructed longitudinal survey datasets based on hand-engineered features. Large Language Models (LLMs), trained on massive datasets, encode vast quantities of world knowledge and can be used for the next job prediction problem. However, while an off-the-shelf LLM produces plausible career trajectories when prompted, the probability with which an LLM predicts a particular job transition conditional on career history will not, in general, align with the true conditional probability in a given population. Recently, Vafa et al. (2024) introduced a transformer-based"foundation model", CAREER, trained using a large, unrepresentative resume dataset, that predicts transitions between jobs; it further demonstrated how transfer learning techniques can be used to leverage the foundation model to build better predictive models of both transitions and wages that reflect conditional transition probabilities found in nationally representative survey datasets. This paper considers an alternative where the fine-tuning of the CAREER foundation model is replaced by fine-tuning LLMs. For the task of next job prediction, we demonstrate that models trained with our approach outperform several alternatives in terms of predictive performance on the survey data, including traditional econometric models, CAREER, and LLMs with in-context learning, even though the LLM can in principle predict job titles that are not allowed in the survey data. Further, we show that our fine-tuned LLM-based models' predictions are more representative of the career trajectories of various workforce subpopulations than off-the-shelf LLM models and CAREER. We conduct experiments and analyses that highlight the sources of the gains in the performance of our models for representative predictions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8553495cea575792c19bf8e77ac26d3a92afd7c5" target='_blank'>
              LABOR-LLM: Language-Based Occupational Representations with Large Language Models
              </a>
            </td>
          <td>
            Tianyu Du, Ayush Kanodia, Herman Brunborg, Keyon Vafa, Susan Athey
          </td>
          <td>2024-06-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>13</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0084b07c9c1f87776c162af58347aa0ba6767f3d" target='_blank'>
              DyHANE: dynamic heterogeneous attributed network embedding through experience node replay
              </a>
            </td>
          <td>
            Liliana Martirano, D. Ienco, R. Interdonato, Andrea Tagarelli
          </td>
          <td>2024-07-05</td>
          <td>Appl. Netw. Sci.</td>
          <td>0</td>
          <td>29</td>
        </tr>

        <tr id="Stock price forecasting is a challenging area of research, particularly due to the complexity and unpredictability of financial markets. The accuracy of prediction models is influenced by various factors, including nonlinearity, seasonality, and economic shocks. Deep learning has demonstrated better forecasts of stock prices than traditional approaches. This study, therefore, proposed a new approach to improve forecasting system based on an end-to-end convolutional recurrent neural network (CRNN) with attention mechanism. Our approach first investigates local stock price features using 1D convolutional neural network, and then employs a bidirectional long short-term memory (Bi-LSTM) network for forecasting. This model stands out by effectively utilizing contextual data and representing the temporal character of data. The Bi-LSTM is helpful for understanding the history and future contextual information since it uncovers both past and future contexts of stock data. Furthermore, integrating attention mechanism within the CRNN represents a significant improvement. This allows our model to handle long input sequences more effectively and capture the inherent stochasticity in stock prices, which is often missed by traditional models. The effectiveness of our approach is investigated using data on 10 stock indexes from Yahoo Finance. The results show that our method outperforms ARIMA, LSTM, and conventional methods. ">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d308e58a2b17825f4c41dbf390403ee62eb1a34c" target='_blank'>
              An improved convolutional recurrent neural network for stock price forecasting
              </a>
            </td>
          <td>
            Hoang Vuong Pham, Hung Phu Lam, Le Nhat Duy, T. Pham, T. Trinh
          </td>
          <td>2024-09-01</td>
          <td>IAES International Journal of Artificial Intelligence (IJ-AI)</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="An emerging topic in large language models (LLMs) is their application to time series forecasting, characterizing mainstream and patternable characteristics of time series. A relevant but rarely explored and more challenging question is whether LLMs can detect and explain time series anomalies, a critical task across various real-world applications. In this paper, we investigate the capabilities of LLMs, specifically GPT-4 and LLaMA3, in detecting and explaining anomalies in time series. Our studies reveal that: 1) LLMs cannot be directly used for time series anomaly detection. 2) By designing prompt strategies such as in-context learning and chain-of-thought prompting, GPT-4 can detect time series anomalies with results competitive to baseline methods. 3) We propose a synthesized dataset to automatically generate time series anomalies with corresponding explanations. By applying instruction fine-tuning on this dataset, LLaMA3 demonstrates improved performance in time series anomaly detection tasks. In summary, our exploration shows the promising potential of LLMs as time series anomaly detectors.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/12b073694ad8cf460d1e74a34b68d07536e0db14" target='_blank'>
              Can LLMs Serve As Time Series Anomaly Detectors?
              </a>
            </td>
          <td>
            Manqing Dong, Hao Huang, Longbing Cao
          </td>
          <td>2024-08-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Crime forecasting is a critical component of urban analysis and essential for stabilizing society today. Unlike other time series forecasting problems, crime incidents are sparse, particularly in small regions and within specific time periods. Traditional spatial-temporal deep learning models often struggle with this sparsity, as they typically cannot effectively handle the non-Gaussian nature of crime data, which is characterized by numerous zeros and over-dispersed patterns. To address these challenges, we introduce a novel approach termed Spatial Temporal Multivariate Zero-Inflated Negative Binomial Graph Neural Networks (STMGNN-ZINB). This framework leverages diffusion and convolution networks to analyze spatial, temporal, and multivariate correlations, enabling the parameterization of probabilistic distributions of crime incidents. By incorporating a Zero-Inflated Negative Binomial model, STMGNN-ZINB effectively manages the sparse nature of crime data, enhancing prediction accuracy and the precision of confidence intervals. Our evaluation on real-world datasets confirms that STMGNN-ZINB outperforms existing models, providing a more reliable tool for predicting and understanding crime dynamics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/24c426aeaad4d19ac16a0dbe2914166f1ee8d9da" target='_blank'>
              Uncertainty-Aware Crime Prediction With Spatial Temporal Multivariate Graph Neural Networks
              </a>
            </td>
          <td>
            Zepu Wang, Xiaobo Ma, Huajie Yang, Weimin Lvu, Peng Sun, Sharath Chandra Guntuku
          </td>
          <td>2024-08-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>27</td>
        </tr>

        <tr id="In accordance with the findings presented in [34], this study examines the applicability of Machine Learning (ML) models and training strategies from the Natural Language Processing (NLP) domain in addressing time series problems, emphasizing the structural and operational aspects of these models and strategies. Recognizing the structural congruence within the data, we opt for Stock Price Prediction (SPP) as the designated domain to assess the transferability of NLP models and strategies. Building upon initial positive outcomes derived from quantitative SPP models in our ongoing research endeavors, we provide a rationale for exploring a range of additional methods and conducting subsequent research experiments. The outlined research aims to elucidate the efficacy of leveraging NLP models and techniques for addressing time series problems exemplified as SPP.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7c4f1f32caa4d520f1b1d66244227ab9df24a38e" target='_blank'>
              Assessment of the Applicability of Large Language Models for Quantitative Stock Price Prediction
              </a>
            </td>
          <td>
            Frederic Voigt, Kai von Luck, Peer Stelldinger
          </td>
          <td>2024-06-26</td>
          <td>Proceedings of the 17th International Conference on PErvasive Technologies Related to Assistive Environments</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="Graphs are crucial for representing interrelated data and aiding predictive modeling by capturing complex relationships. Achieving high-quality graph representation is important for identifying linked patterns, leading to improvements in Graph Neural Networks (GNNs) to better capture data structures. However, challenges such as data scarcity, high collection costs, and ethical concerns limit progress. As a result, generative models and data augmentation have become more and more popular. This study explores using generated graphs for data augmentation, comparing the performance of combining generated graphs with real graphs, and examining the effect of different quantities of generated graphs on graph classification tasks. The experiments show that balancing scalability and quality requires different generators based on graph size. Our results introduce a new approach to graph data augmentation, ensuring consistent labels and enhancing classification performance.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f4641fc657af2ab1a0c304535fd1f2caa9ccc97f" target='_blank'>
              Data Augmentation in Graph Neural Networks: The Role of Generated Synthetic Graphs
              </a>
            </td>
          <td>
            Sumeyye Bas, Kıymet Kaya, Resul Tugay, S. G. Oguducu
          </td>
          <td>2024-07-20</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Fluctuations in the financial market are influenced by various driving forces and numerous factors. Traditional financial research aims to identify the factors influencing stock prices, and existing works construct a common neural network learning framework that learns temporal dependency using a fixed time window of historical information, such as RNN and LSTM models. However, these models only consider the short-term and point-to-point relationships within stock series. The financial market is a complex and dynamic system with many unobservable temporal patterns. Therefore, we propose an adaptive period-aggregation model called the Latent Period-Aggregated Stock Transformer (LPAST). The model integrates a variational autoencoder (VAE) with a period-to-period attention mechanism for multistep prediction in the financial time series. Additionally, we introduce a self-correlation learning method and routing mechanism to handle complex multi-period aggregations and information distribution. Main contributions include proposing a novel period-aggregation representation scheme, introducing a new attention mechanism, and validating the model’s superiority in long-horizon prediction tasks. The LPAST model demonstrates its potential and effectiveness in financial market prediction, highlighting its relevance in financial research and predictive analytics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c8b56ca8a213a228fe44d00254f0cbca7f9209bd" target='_blank'>
              Period-aggregated transformer for learning latent seasonalities in long-horizon financial time series
              </a>
            </td>
          <td>
            Zhenyang Tang, Jinshui Huang, Denisa Rinprasertmeechai
          </td>
          <td>2024-08-08</td>
          <td>PLOS ONE</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/916b0fd6c75c26229a6b648ba316e3bdb9f99ea6" target='_blank'>
              PMANet: a time series forecasting model for Chinese stock price prediction
              </a>
            </td>
          <td>
            Wenke Zhu, Weisi Dai, Chunling Tang, Guoxiong Zhou, Zewei Liu, Yunjing Zhao
          </td>
          <td>2024-08-07</td>
          <td>Scientific Reports</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Ensemble forecasts from numerical weather prediction models show systematic errors that require correction via post-processing. While there has been substantial progress in flexible neural network-based post-processing methods over the past years, most station-based approaches still treat every input data point separately which limits the capabilities for leveraging spatial structures in the forecast errors. In order to improve information sharing across locations, we propose a graph neural network architecture for ensemble post-processing, which represents the station locations as nodes on a graph and utilizes an attention mechanism to identify relevant predictive information from neighboring locations. In a case study on 2-m temperature forecasts over Europe, the graph neural network model shows substantial improvements over a highly competitive neural network-based post-processing method.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1fe4b1eeac90174d97c76b0869c2c1e6f138febe" target='_blank'>
              Graph Neural Networks and Spatial Information Learning for Post-Processing Ensemble Weather Forecasts
              </a>
            </td>
          <td>
            Moritz Feik, Sebastian Lerch, Jan Stuhmer
          </td>
          <td>2024-07-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a8f0842a1540b91ce53047bb74813c3d07827909" target='_blank'>
              Fine-scale deep learning model for time series forecasting
              </a>
            </td>
          <td>
            Yuwei Chen, Wenjing Jia, Qiang Wu
          </td>
          <td>2024-08-06</td>
          <td>Applied Intelligence</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="We introduce NodeFlow, a flexible framework for probabilistic regression on tabular data that combines Neural Oblivious Decision Ensembles (NODEs) and Conditional Continuous Normalizing Flows (CNFs). It offers improved modeling capabilities for arbitrary probabilistic distributions, addressing the limitations of traditional parametric approaches. In NodeFlow, the NODE captures complex relationships in tabular data through a tree-like structure, while the conditional CNF utilizes the NODE’s output space as a conditioning factor. The training process of NodeFlow employs standard gradient-based learning, facilitating the end-to-end optimization of the NODEs and CNF-based density estimation. This approach ensures outstanding performance, ease of implementation, and scalability, making NodeFlow an appealing choice for practitioners and researchers. Comprehensive assessments on benchmark datasets underscore NodeFlow’s efficacy, revealing its achievement of state-of-the-art outcomes in multivariate probabilistic regression setup and its strong performance in univariate regression tasks. Furthermore, ablation studies are conducted to justify the design choices of NodeFlow. In conclusion, NodeFlow’s end-to-end training process and strong performance make it a compelling solution for practitioners and researchers. Additionally, it opens new avenues for research and application in the field of probabilistic regression on tabular data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7b7ef3bf708e12014b3094d7f3efb36a9d8eb2f4" target='_blank'>
              NodeFlow: Towards End-to-End Flexible Probabilistic Regression on Tabular Data
              </a>
            </td>
          <td>
            Patryk Wielopolski, Oleksii Furman, Maciej Zięba
          </td>
          <td>2024-07-01</td>
          <td>Entropy</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="The prediction of time series is a challenging task relevant in such diverse applications as analyzing financial data, forecasting flow dynamics or understanding biological processes. Especially chaotic time series that depend on a long history pose an exceptionally difficult problem. While machine learning has shown to be a promising approach for predicting such time series, it either demands long training time and much training data when using deep recurrent neural networks. Alternative, when using a reservoir computing approach it comes with high uncertainty and typically a high number of random initializations and extensive hyper-parameter tuning when using a reservoir computing approach. In this paper, we focus on the reservoir computing approach and propose a new mapping of input data into the reservoir's state space. Furthermore, we incorporate this method in two novel network architectures increasing parallelizability, depth and predictive capabilities of the neural network while reducing the dependence on randomness. For the evaluation, we approximate a set of time series from the Mackey-Glass equation, inhabiting non-chaotic as well as chaotic behavior and compare our approaches in regard to their predictive capabilities to echo state networks and gated recurrent units. For the chaotic time series, we observe an error reduction of up to $85.45\%$ and up to $87.90\%$ in contrast to echo state networks and gated recurrent units respectively. Furthermore, we also observe tremendous improvements for non-chaotic time series of up to $99.99\%$ in contrast to existing approaches.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d488897997df288927a73befa218f42726e3f36d" target='_blank'>
              Temporal Convolution Derived Multi-Layered Reservoir Computing
              </a>
            </td>
          <td>
            Johannes Viehweg, Dominik Walther, Patrick Mäder
          </td>
          <td>2024-07-09</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Graph-level anomaly detection (GLAD) has already gained significant importance and has become a popular field of study, attracting considerable attention across numerous downstream works. The core focus of this domain is to capture and highlight the anomalous information within given graph datasets. In most existing studies, anomalies are often the instances of few. The stark imbalance misleads current GLAD methods to focus on learning the patterns of normal graphs more, further impacting anomaly detection performance. Moreover, existing methods predominantly utilize the inherent features of nodes to identify anomalous graph patterns which is approved suboptimal according to our experiments. In this work, we propose an imbalanced GLAD method via counterfactual augmentation and feature learning. Specifically, we first construct anomalous samples based on counterfactual learning, aiming to expand and balance the datasets. Additionally, we construct a module based on Graph Neural Networks (GNNs), which allows us to utilize degree attributes to complement the inherent attribute features of nodes. Then, we design an adaptive weight learning module to integrate features tailored to different datasets effectively to avoid indiscriminately treating all features as equivalent. Furthermore, extensive baseline experiments conducted on public datasets substantiate the robustness and effectiveness. Besides, we apply the model to brain disease datasets, which can prove the generalization capability of our work. The source code of our work is available online.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f75be7b79dc5b02dfc1845486489956beb059786" target='_blank'>
              Imbalanced Graph-Level Anomaly Detection via Counterfactual Augmentation and Feature Learning
              </a>
            </td>
          <td>
            Zitong Wang, Xuexiong Luo, Enfeng Song, Qiuqing Bai, Fu Lin
          </td>
          <td>2024-07-13</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Time series forecasting is an important task in many fields ranging from supply chain management to weather forecasting. Recently, Transformer neural network architectures have shown promising results in forecasting on common time series benchmark datasets. However, application to supply chain demand forecasting, which can have challenging characteristics such as sparsity and cross-series effects, has been limited. In this work, we explore the application of Transformer-based models to supply chain demand forecasting. In particular, we develop a new Transformer-based forecasting approach using a shared, multi-task per-time series network with an initial component applying attention across time series, to capture interactions and help address sparsity. We provide a case study applying our approach to successfully improve demand prediction for a medical device manufacturing company. To further validate our approach, we also apply it to public demand forecasting datasets as well and demonstrate competitive to superior performance compared to a variety of baseline and state-of-the-art forecast methods across the private and public datasets.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c560b5bcb4b68fabfa9a99f94896b217ce52a3f6" target='_blank'>
              Inter-Series Transformer: Attending to Products in Time Series Forecasting
              </a>
            </td>
          <td>
            Rares Cristian, P. Harsha, Clemente Ocejo, Georgia Perakis, Brian Quanz, Ioannis Spantidakis, Hamza Zerhouni
          </td>
          <td>2024-08-07</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="Temporal networks are effective in capturing the evolving interactions of networks over time, such as social networks and e-commerce networks. In recent years, researchers have primarily concentrated on developing specific model architectures for Temporal Graph Neural Networks (TGNNs) in order to improve the representation quality of temporal nodes and edges. However, limited attention has been given to the quality of negative samples during the training of TGNNs. When compared with static networks, temporal networks present two specific challenges for negative sampling: positive sparsity and positive shift. Positive sparsity refers to the presence of a single positive sample amidst numerous negative samples at each timestamp, while positive shift relates to the variations in positive samples across different timestamps. To robustly address these challenges in training TGNNs, we introduce Curriculum Negative Mining (CurNM), a model-aware curriculum learning framework that adaptively adjusts the difficulty of negative samples. Within this framework, we first establish a dynamically updated negative pool that balances random, historical, and hard negatives to address the challenges posed by positive sparsity. Secondly, we implement a temporal-aware negative selection module that focuses on learning from the disentangled factors of recently active edges, thus accurately capturing shifting preferences. Extensive experiments on 12 datasets and 3 TGNNs demonstrate that our method outperforms baseline methods by a significant margin. Additionally, thorough ablation studies and parameter sensitivity experiments verify the usefulness and robustness of our approach. Our code is available at https://github.com/zziyue83/CurNM.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/56efc5b54a9beda670261028d60fe6056619863a" target='_blank'>
              Curriculum Negative Mining For Temporal Networks
              </a>
            </td>
          <td>
            Ziyue Chen, Tongya Zheng, Mingli Song
          </td>
          <td>2024-07-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="We propose a novel data-driven network framework for forecasting problems related to E-mini S\&P 500 and CBOE Volatility Index futures, in which products with different expirations act as distinct nodes. We provide visual demonstrations of the correlation structures of these products in terms of their returns, realized volatility, and trading volume. The resulting networks offer insights into the contemporaneous movements across the different products, illustrating how inherently connected the movements of the future products belonging to these two classes are. These networks are further utilized by a multi-channel Graph Convolutional Network to enhance the predictive power of a Long Short-Term Memory network, allowing for the propagation of forecasts of highly correlated quantities, combining the temporal with the spatial aspect of the term structure.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/250fe7baf3fd0aa1f684eedd3e76aeb1b17f89aa" target='_blank'>
              A GCN-LSTM Approach for ES-mini and VX Futures Forecasting
              </a>
            </td>
          <td>
            N. Michael, Mihai Cucuringu, Sam Howison
          </td>
          <td>2024-08-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="In the realm of event prediction, temporal knowledge graph forecasting (TKGF) stands as a pivotal technique. Previous approaches face the challenges of not utilizing experience during testing and relying on a single short-term history, which limits adaptation to evolving data. In this paper, we introduce the Online Neural-Symbolic Event Prediction (ONSEP) framework, which innovates by integrating dynamic causal rule mining (DCRM) and dual history augmented generation (DHAG). DCRM dynamically constructs causal rules from real-time data, allowing for swift adaptation to new causal relationships. In parallel, DHAG merges short-term and long-term historical contexts, leveraging a bi-branch approach to enrich event prediction. Our framework demonstrates notable performance enhancements across diverse datasets, with significant Hit@k (k=1,3,10) improvements, showcasing its ability to augment large language models (LLMs) for event prediction without necessitating extensive retraining. The ONSEP framework not only advances the field of TKGF but also underscores the potential of neural-symbolic approaches in adapting to dynamic data environments.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0f4e7c0661406c5e4a78a9aa8c2f70648662b630" target='_blank'>
              ONSEP: A Novel Online Neural-Symbolic Framework for Event Prediction Based on Large Language Model
              </a>
            </td>
          <td>
            Xuanqing Yu, Wangtao Sun, Jingwei Li, Kang Liu, Chengbao Liu, JieFu Tan
          </td>
          <td>2024-08-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Accurately predicting PM2.5 is a crucial task for protecting public health and making policy decisions. In the meanwhile, it is also a challenging task, given the complex spatio-temporal patterns of PM2.5 concentrations. Recently, the utilization of graph neural network (GNN) models has emerged as a promising approach, demonstrating significant advantages in capturing the spatial and temporal dependencies associated with PM2.5 concentrations. In this work, we collected a comprehensive dataset spanning 308 cities in China, encompassing data on seven pollutants as well as meteorological variables from January 2015 to September 2022. To effectively predict the PM2.5 concentrations, we propose a graph attention recurrent neural network (GARNN) model by taking into account both meteorological and geographical information. Extensive experiments validated the efficiency of the proposed GARNN model, revealing its superior performance compared to other existing methods in terms of predictive capabilities. This study contributes to advancing the understanding and prediction of PM2.5 concentrations, providing a valuable tool for addressing environmental challenges.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f0d3185a50e22682b8c650ceac52e70dd3a9849f" target='_blank'>
              A Graph Attention Recurrent Neural Network Model for PM2.5 Prediction: A Case Study in China from 2015 to 2022
              </a>
            </td>
          <td>
            Rui Pan, Tuozhen Liu, Lingfei Ma
          </td>
          <td>2024-07-03</td>
          <td>Atmosphere</td>
          <td>0</td>
          <td>19</td>
        </tr>

        <tr id="In this study, we delve into the Structured State Space Model (S4), Change Point Detection methodologies, and the Switching Non-linear Dynamics System (SNLDS). Our central proposition is an enhanced inference technique and long-range dependency method for SNLDS. The cornerstone of our approach is the fusion of S4 and SNLDS, leveraging the strengths of both models to effectively address the intricacies of long-range dependencies in switching time series. Through rigorous testing, we demonstrate that our proposed methodology adeptly segments and reproduces long-range dependencies in both the 1-D Lorenz dataset and the 2-D bouncing ball dataset. Notably, our integrated approach outperforms the standalone SNLDS in these tasks.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/737fccae30a52b719925aa3bdefbccf7758f66f5" target='_blank'>
              Long Range Switching Time Series Prediction via State Space Model
              </a>
            </td>
          <td>
            Jiaming Zhang, Yang Ding, Yunfeng Gao
          </td>
          <td>2024-07-27</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Deep neural networks (DNNs) are prominent in predictive analytics for accurately forecasting target variables. However, inherent uncertainties necessitate constructing prediction intervals for reliability. The existing literature often lacks practical methodologies for creating predictive intervals, especially for time series with trends and seasonal patterns. This paper explicitly details a practical approach integrating dual-output Monte Carlo Dropout (MCDO) with DNNs to approximate predictive means and variances within a Bayesian framework, enabling forecast interval construction. The dual-output architecture employs a custom loss function, combining mean squared error with Softplus-derived predictive variance, ensuring non-negative variance values. Hyperparameter optimization is performed through a grid search exploring activation functions, dropout rates, epochs, and batch sizes. Empirical distributions of predictive means and variances from the MCDO demonstrate the results of the dual-output MCDO DNNs. The proposed method achieves a significant improvement in forecast accuracy, with an RMSE reduction of about 10% compared to the seasonal autoregressive integrated moving average model. Additionally, the method provides more reliable forecast intervals, as evidenced by a higher coverage proportion and narrower interval widths. A case study on Thailand’s durian export data showcases the method’s utility and applicability to other datasets with trends and/or seasonal components.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/48e9c93416cccc0d5c4d1f0646a11cd372d3ec5b" target='_blank'>
              Time-Series Interval Forecasting with Dual-Output Monte Carlo Dropout: A Case Study on Durian Exports
              </a>
            </td>
          <td>
            Unyamanee Kummaraka, Patchanok Srisuradetchai
          </td>
          <td>2024-08-02</td>
          <td>Forecasting</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="With the remarkable success of generative models like ChatGPT, Artificial Intelligence Generated Content (AIGC) is undergoing explosive development. Not limited to text and images, generative models can generate industrial time series data, addressing challenges such as the difficulty of data collection and data annotation. Due to their outstanding generation ability, they have been widely used in Internet of Things, metaverse, and cyber-physical-social systems to enhance the efficiency of industrial production. In this paper, we present a comprehensive overview of generative models for industrial time series from deep generative models (DGMs) to large generative models (LGMs). First, a DGM-based AIGC framework is proposed for industrial time series generation. Within this framework, we survey advanced industrial DGMs and present a multi-perspective categorization. Furthermore, we systematically analyze the critical technologies required to construct industrial LGMs from four aspects: large-scale industrial dataset, LGMs architecture for complex industrial characteristics, self-supervised training for industrial time series, and fine-tuning of industrial downstream tasks. Finally, we conclude the challenges and future directions to enable the development of generative models in industry.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/dc1ce4a6d24e82a1c9c05d41f69b1e606efa4115" target='_blank'>
              AIGC for Industrial Time Series: From Deep Generative Models to Large Generative Models
              </a>
            </td>
          <td>
            Lei Ren, Haiteng Wang, Yang Tang, Chunhua Yang
          </td>
          <td>2024-07-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Conformal prediction provides machine learning models with prediction sets that offer theoretical guarantees, but the underlying assumption of exchangeability limits its applicability to time series data. Furthermore, existing approaches struggle to handle multi-step ahead prediction tasks, where uncertainty estimates across multiple future time points are crucial. We propose JANET (Joint Adaptive predictioN-region Estimation for Time-series), a novel framework for constructing conformal prediction regions that are valid for both univariate and multivariate time series. JANET generalises the inductive conformal framework and efficiently produces joint prediction regions with controlled K-familywise error rates, enabling flexible adaptation to specific application needs. Our empirical evaluation demonstrates JANET's superior performance in multi-step prediction tasks across diverse time series datasets, highlighting its potential for reliable and interpretable uncertainty quantification in sequential data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b21605b67376e0377590d3cdfb99e3c43495b865" target='_blank'>
              JANET: Joint Adaptive predictioN-region Estimation for Time-series
              </a>
            </td>
          <td>
            Eshant English, Eliot Wong-Toi, Matteo Fontana, Stephan Mandt, P. Smyth, Christoph Lippert
          </td>
          <td>2024-07-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Time series forecasting has been an essential field in many different application areas, including economic analysis, meteorology, and so forth. The majority of time series forecasting models are trained using the mean squared error (MSE). However, this training based on MSE causes a limitation known as prediction delay. The prediction delay, which implies the ground-truth precedes the prediction, can cause serious problems in a variety of fields, e.g., finance and weather forecasting -- as a matter of fact, predictions succeeding ground-truth observations are not practically meaningful although their MSEs can be low. This paper proposes a new perspective on traditional time series forecasting tasks and introduces a new solution to mitigate the prediction delay. We introduce a continuous-time gated recurrent unit (GRU) based on the neural ordinary differential equation (NODE) which can supervise explicit time-derivatives. We generalize the GRU architecture in a continuous-time manner and minimize the prediction delay through our time-derivative regularization. Our method outperforms in metrics such as MSE, Dynamic Time Warping (DTW) and Time Distortion Index (TDI). In addition, we demonstrate the low prediction delay of our method in a variety of datasets.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/cb1274dd33e80fab3c983829e9b94abcebe9e2a8" target='_blank'>
              Addressing Prediction Delays in Time Series Forecasting: A Continuous GRU Approach with Derivative Regularization
              </a>
            </td>
          <td>
            Sheo Yon Jhin, Seojin Kim, Noseong Park
          </td>
          <td>2024-06-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Self-supervised Pretrained Models (PTMs) have demonstrated remarkable performance in computer vision and natural language processing tasks. These successes have prompted researchers to design PTMs for time series data. In our experiments, most self-supervised time series PTMs were surpassed by simple supervised models. We hypothesize this undesired phenomenon may be caused by data scarcity. In response, we test six time series generation methods, use the generated data in pretraining in lieu of the real data, and examine the effects on classification performance. Our results indicate that replacing a real-data pretraining set with a greater volume of only generated samples produces noticeable improvement.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bcb109299f76471af99ce2c8c40fc510cec2c1b0" target='_blank'>
              A Systematic Evaluation of Generated Time Series and Their Effects in Self-Supervised Pretraining
              </a>
            </td>
          <td>
            Audrey Der, Chin-Chia Michael Yeh, Xin Dai, Huiyuan Chen, Yan Zheng, Yujie Fan, Zhongfang Zhuang, Vivian Lai, Junpeng Wang, Liang Wang, Wei Zhang, Eamonn J. Keogh
          </td>
          <td>2024-08-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>22</td>
        </tr>

        <tr id="Transformer-based methods have recently demonstrated their potential in time series forecasting problems. However, the mainstream approach, primarily utilizing attention to model inter-step correlation in the time domain, is constrained by two significant issues that lead to ineffective and inefficient multivariate forecasting. The first is that key representations in the time domain are scattered and sparse, resulting in parameter bloat and increased difficulty in capturing time dependencies. The second is that treating time step points as uniformly embedded tokens leads to the erasure of inter-variate correlations. To address these challenges, we propose a frequency-wise and variables-oriented transformer-based method. This method leverages the intrinsic conjugate symmetry in the frequency domain, enabling compact frequency domain representations that naturally mix information across time points while reducing spatio-temporal costs. Multivariate inter-correlations can also be captured from similar frequency domain components, which enhances the variables-oriented attention mechanism modeling capability. Further, we employ both polar and complex domain perspectives to enrich the frequency domain representations and decode complicated temporal patterns. We propose frequency-enhanced independent representation multi-head attention (FIR-Attention) to leverage these advantages for improved multivariate interaction. Techniques such as cutting-off frequency and equivalent mapping are used to ensure the model’s lightweight nature. Extensive experiments on eight mainstream datasets show that our approach achieves first-rate satisfactory results and, importantly, requires only one percent of the spatio-temporal cost of mainstream methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/36f87cbd5187e521184ddb319b132292cb8ae608" target='_blank'>
              Frequency-Enhanced Transformer with Symmetry-Based Lightweight Multi-Representation for Multivariate Time Series Forecasting
              </a>
            </td>
          <td>
            Chenyue Wang, Zhouyuan Zhang, Xin Wang, Mingyang Liu, Lin Chen, Jiatian Pi
          </td>
          <td>2024-06-25</td>
          <td>Symmetry</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="We introduce the Robustness of Hierarchically Organized Time Series (RHiOTS) framework, designed to assess the robustness of hierarchical time series forecasting models and algorithms on real-world datasets. Hierarchical time series, where lower-level forecasts must sum to upper-level ones, are prevalent in various contexts, such as retail sales across countries. Current empirical evaluations of forecasting methods are often limited to a small set of benchmark datasets, offering a narrow view of algorithm behavior. RHiOTS addresses this gap by systematically altering existing datasets and modifying the characteristics of individual series and their interrelations. It uses a set of parameterizable transformations to simulate those changes in the data distribution. Additionally, RHiOTS incorporates an innovative visualization component, turning complex, multidimensional robustness evaluation results into intuitive, easily interpretable visuals. This approach allows an in-depth analysis of algorithm and model behavior under diverse conditions. We illustrate the use of RHiOTS by analyzing the predictive performance of several algorithms. Our findings show that traditional statistical methods are more robust than state-of-the-art deep learning algorithms, except when the transformation effect is highly disruptive. Furthermore, we found no significant differences in the robustness of the algorithms when applying specific reconciliation methods, such as MinT. RHiOTS provides researchers with a comprehensive tool for understanding the nuanced behavior of forecasting algorithms, offering a more reliable basis for selecting the most appropriate method for a given problem.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/525cf42ca049ecd3089189612e74d0df68dbcae0" target='_blank'>
              RHiOTS: A Framework for Evaluating Hierarchical Time Series Forecasting Algorithms
              </a>
            </td>
          <td>
            Luis Roque, Carlos Soares, Luís Torgo
          </td>
          <td>2024-08-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>36</td>
        </tr>

        <tr id="We study an emerging and intriguing problem of multimodal temporal event forecasting with large language models. Compared to using text or graph modalities, the investigation of utilizing images for temporal event forecasting has not been fully explored, especially in the era of large language models (LLMs). To bridge this gap, we are particularly interested in two key questions of: 1) why images will help in temporal event forecasting, and 2) how to integrate images into the LLM-based forecasting framework. To answer these research questions, we propose to identify two essential functions that images play in the scenario of temporal event forecasting, i.e., highlighting and complementary. Then, we develop a novel framework, named MM-Forecast. It employs an Image Function Identification module to recognize these functions as verbal descriptions using multimodal large language models (MLLMs), and subsequently incorporates these function descriptions into LLM-based forecasting models. To evaluate our approach, we construct a new multimodal dataset, MidEast-TE-mm, by extending an existing event dataset MidEast-TE-mini with images. Empirical studies demonstrate that our MM-Forecast can correctly identify the image functions, and further more, incorporating these verbal function descriptions significantly improves the forecasting performance. The dataset, code, and prompts are available at https://github.com/LuminosityX/MM-Forecast.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/881bcfa9a1a54c64991dd08db8ba6dea916b5ef1" target='_blank'>
              MM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models
              </a>
            </td>
          <td>
            Haoxuan Li, Zhengmao Yang, Yunshan Ma, Yi Bin, Yang Yang, Tat-Seng Chua
          </td>
          <td>2024-08-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Message passing graph neural networks (GNNs) would appear to be powerful tools to learn distributed algorithms via gradient descent, but generate catastrophically incorrect predictions when nodes update asynchronously during inference. This failure under asynchrony effectively excludes these architectures from many potential applications, such as learning local communication policies between resource-constrained agents in, e.g., robotic swarms or sensor networks. In this work we explore why this failure occurs in common GNN architectures, and identify"implicitly-defined"GNNs as a class of architectures which is provably robust to partially asynchronous"hogwild"inference, adapting convergence guarantees from work in asynchronous and distributed optimization, e.g., Bertsekas (1982); Niu et al. (2011). We then propose a novel implicitly-defined GNN architecture, which we call an energy GNN. We show that this architecture outperforms other GNNs from this class on a variety of synthetic tasks inspired by multi-agent systems, and achieves competitive performance on real-world datasets.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3d41f9e0bdc43fc19966e67aef4422bfb59a0315" target='_blank'>
              Graph Neural Networks Gone Hogwild
              </a>
            </td>
          <td>
            Olga Solodova, Nick Richardson, Deniz Oktay, Ryan P. Adams
          </td>
          <td>2024-06-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="Attention-based models such as Transformers and recurrent models like state space models (SSMs) have emerged as successful methods for autoregressive sequence modeling. Although both enable parallel training, none enable parallel generation due to their autoregressiveness. We propose the variational SSM (VSSM), a variational autoencoder (VAE) where both the encoder and decoder are SSMs. Since sampling the latent variables and decoding them with the SSM can be parallelized, both training and generation can be conducted in parallel. Moreover, the decoder recurrence allows generation to be resumed without reprocessing the whole sequence. Finally, we propose the autoregressive VSSM that can be conditioned on a partial realization of the sequence, as is common in language generation tasks. Interestingly, the autoregressive VSSM still enables parallel generation. We highlight on toy problems (MNIST, CIFAR) the empirical gains in speed-up and show that it competes with traditional models in terms of generation quality (Transformer, Mamba SSM).">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c788a35c2dcda370161d8beda4525409126416c4" target='_blank'>
              Parallelizing Autoregressive Generation with Variational State Space Models
              </a>
            </td>
          <td>
            Gaspard Lambrechts, Yann Claes, Pierre Geurts, Damien Ernst
          </td>
          <td>2024-07-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Modeling time series data has become a very at tractive research topic due to its wide application, such as human activity recognition, financial forecasting and sensor-based automatic system monitoring. Recently deep learning models have shown great advances in modeling the time series data but they heavily depend on a large amount of labeled data. To avoid costly labeling, this paper explores domain adaptation from a labeled source domain to the unlabeled target domain on time series data. To achieve the goal, we propose a disentangled representation learning framework named CADT to disentangle the domain-invariant features from the domain-specific ones. Particularly, CADT is injected with a novel class-wise hypersphere loss to improve the generalization of the classifier from the source domain to the target domain. Intuitively, it restricts the source data of the same class within the same hypersphere and minimizes the radius of it, which in turn enlarges the margin between different classes and makes the decision boundary of both domains easier. We further devise several kinds of domain-preserving data augmentation methods to better capture the domain-specific patterns. Extensive experiments on two public datasets and two real-world applications demonstrate the effectiveness of the proposed model against several state-of-the-art baselines.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a21870156817614d3af47fda7b03e99e6181a852" target='_blank'>
              Disentangling Domain and General Representations for Time Series Classification
              </a>
            </td>
          <td>
            Youmin Chen, Xinyu Yan, Yang Yang, Jianfeng Zhang, Jing Zhang, Lujia Pan, Juren Li
          </td>
          <td>2024-08-01</td>
          <td>Proceedings of the Thirty-ThirdInternational Joint Conference on Artificial Intelligence</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Long-separated research has been conducted on two highly correlated tracks: traffic and incidents. Traffic track witnesses complicating deep learning models, e.g., to push the prediction a few percent more accurate, and the incident track only studies the incidents alone, e.g., to infer the incident risk. We, for the first time, spatiotemporally aligned the two tracks in a large-scale region (16,972 traffic nodes) over the whole year of 2023: our XTraffic dataset includes traffic, i.e., time-series indexes on traffic flow, lane occupancy, and average vehicle speed, and incidents, whose records are spatiotemporally-aligned with traffic data, with seven different incident classes. Additionally, each node includes detailed physical and policy-level meta-attributes of lanes. Our data can revolutionalize traditional traffic-related tasks towards higher interpretability and practice: instead of traditional prediction or classification tasks, we conduct: (1) post-incident traffic forecasting to quantify the impact of different incidents on traffic indexes; (2) incident classification using traffic indexes to determine the incidents types for precautions measures; (3) global causal analysis among the traffic indexes, meta-attributes, and incidents to give high-level guidance of the interrelations of various factors; (4) local causal analysis within road nodes to examine how different incidents affect the road segments' relations. The dataset is available at http://xaitraffic.github.io.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5b7ebd41f1ed8a8a78309e7df817ed2ca8c6f1fa" target='_blank'>
              XTraffic: A Dataset Where Traffic Meets Incidents with Explainability and More
              </a>
            </td>
          <td>
            Xiaochuan Gou, Ziyue Li, Tian Lan, Junpeng Lin, Zhishuai Li, Bingyu Zhao, Chen Zhang, Di Wang, Xiangliang Zhang
          </td>
          <td>2024-07-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="In multivariate and multistep time series prediction research, we often face the problems of insufficient spatial feature extraction and insufficient time-dependent mining of historical series data, which also brings great challenges to multivariate time series analysis and prediction. Inspired by the attention mechanism and residual module, this study proposes a multivariate time series prediction method based on a convolutional-residual gated recurrent hybrid model (CNN-DA-RGRU) with a two-layer attention mechanism to solve the multivariate time series prediction problem in these two stages. Specifically, the convolution module of the proposed model is used to extract the relational features among the sequences, and the two-layer attention mechanism can pay more attention to the relevant variables and give them higher weights to eliminate the irrelevant features, while the residual gated loop module is used to extract the time-varying features of the sequences, in which the residual block is used to achieve the direct connectivity to enhance the expressive power of the model, to solve the gradient explosion and vanishing scenarios, and to facilitate gradient propagation. Experiments were conducted on two public datasets using the proposed model to determine the model hyperparameters, and ablation experiments were conducted to verify the effectiveness of the model; by comparing it with several models, the proposed model was found to achieve good results in multivariate time series-forecasting tasks.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5b50ae3b720af720b3168b475e54d37b97e5e669" target='_blank'>
              A Multivariate Time Series Prediction Method Based on Convolution-Residual Gated Recurrent Neural Network and Double-Layer Attention
              </a>
            </td>
          <td>
            Chuxin Cao, Jianhong Huang, Man Wu, Zhizhe Lin, Yan Sun
          </td>
          <td>2024-07-18</td>
          <td>Electronics</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/debe0ee50d9dc6388d2e21ad87cbf672e2865ff3" target='_blank'>
              Randomnet: clustering time series using untrained deep neural networks
              </a>
            </td>
          <td>
            Xiaosheng Li, Wenjie Xi, Jessica Lin
          </td>
          <td>2024-06-22</td>
          <td>Data Mining and Knowledge Discovery</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="
 Traffic forecasting problems involve jointly modeling the non-linear spatio-temporal dependencies at different scales. While Graph Neural Network models have been effectively used to capture the non-linear spatial dependencies, capturing the dynamic spatial dependencies between the locations remains a major challenge. The errors in capturing such dependencies propagate in modeling the temporal dependencies between the locations, thereby severely affecting the performance of long-term predictions. While transformer-based mechanisms have been recently proposed for capturing the dynamic spatial dependencies, these methods are susceptible to fluctuations in data brought on by unforeseen events like traffic congestion and accidents. To mitigate these issues we propose an improvised Spatio-temporal parallel transformer (STPT) based model for traffic prediction that uses multiple adjacency graphs passed through a pair of coupled graph transformer-convolution network units, operating in parallel, to generate more noise-resilient embeddings. We conduct extensive experiments on 4 real-world traffic datasets and compare the performance of STPT with several state-of-the-art baselines, in terms of measures like RMSE, MAE, and MAPE. We find that using STPT improves the performance by around

 \(10-34\%\)

 as compared to the baselines. We also investigate the applicability of the model on other spatio-temporal data in other domains. We use a covid-19 dataset to predict the number of future occurrences in different regions from a given set of historical occurrences. The results demonstrate the superiority of our model for such datasets.
">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d890dbf3502df2b73e7403abca6b1585a2a7bdd4" target='_blank'>
              Spatio-Temporal Parallel Transformer based model for Traffic Prediction
              </a>
            </td>
          <td>
            Rahul Kumar, João Mendes‐Moreira, Joydeep Chandra
          </td>
          <td>2024-07-19</td>
          <td>ACM Transactions on Knowledge Discovery from Data</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="Large Language Models (LLMs) have been shown to perform well for many downstream tasks. Transfer learning can enable LLMs to acquire skills that were not targeted during pre-training. In financial contexts, LLMs can sometimes beat well-established benchmarks. This paper investigates how well LLMs perform in the task of forecasting corporate credit ratings. We show that while LLMs are very good at encoding textual information, traditional methods are still very competitive when it comes to encoding numeric and multimodal data. For our task, current LLMs perform worse than a more traditional XGBoost architecture that combines fundamental and macroeconomic data with high-density text-based embedding features.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/95e12933c0081864ec2a7b4cc64d936843bb0493" target='_blank'>
              Traditional Methods Outperform Generative LLMs at Forecasting Credit Ratings
              </a>
            </td>
          <td>
            Felix Drinkall, J. Pierrehumbert, Stefan Zohren
          </td>
          <td>2024-07-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>45</td>
        </tr>

        <tr id=": Sales forecasting is crucial for business planning and resource allocation. Data-driven approaches have become popular in this field. This study compares the performance of three forecasting models: Autoregressive Integrated Moving Average (ARIMA), Long Short-Term Memory (LSTM) and Prophet within the context of specific sales categories derived from acquiring data provided by a bank. This study uses a time series dataset provided by Tink off data, which covers various sales categories and time intervals. These categories, including pharmacies, railway tickets, books, sporting goods and fuel stations, present unique forecasting challenges because of their distinct demand patterns and potential for high volatility. Through a comparative analysis focusing on accuracy, robustness and computational efficiency, the study reveals that while all models demonstrate efficacy in certain scenarios, their performance varies depending on the specific category and forecasting horizon. ARIMA exhibits consistent accuracy across categories, particularly for daily predictions, aligning with its strength in capturing trends and seasonality. LSTM, on the other hand, shows promise for hourly predictions in categories like fuel stations, leveraging its ability to learn long-term dependencies. However, the LSTM model shows inconsistent results, sometimes outperforming others, but with varying performance across runs. This study provides insights for practitioners within the banking and financial sectors seeking to select the most appropriate forecasting model based on their specific sales categories and forecasting needs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d18133f1dde33c5c7df061aac195fad8e9eac107" target='_blank'>
              Sales Forecasting Models: Comparison between ARIMA, LSTM and Prophet
              </a>
            </td>
          <td>
            Dmitry Brykin
          </td>
          <td>2024-10-01</td>
          <td>Journal of Computer Science</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f5525624998a69eda4aa0ec2d507973f15dabde2" target='_blank'>
              SeeMore: a spatiotemporal predictive model with bidirectional distillation and level-specific meta-adaptation
              </a>
            </td>
          <td>
            Yuqing Ma, Wei Liu, Yajun Gao, Yang Yuan, Shihao Bai, Haotong Qin, Xianglong Liu
          </td>
          <td>2024-07-22</td>
          <td>Science China Information Sciences</td>
          <td>0</td>
          <td>15</td>
        </tr>

        <tr id="Accurate stock market predictions following earnings reports are crucial for investors. Traditional methods, particularly classical machine learning models, struggle with these predictions because they cannot effectively process and interpret extensive textual data contained in earnings reports and often overlook nuances that influence market movements. This paper introduces an advanced approach by employing Large Language Models (LLMs) instruction fine-tuned with a novel combination of instruction-based techniques and quantized low-rank adaptation (QLoRA) compression. Our methodology integrates 'base factors', such as financial metric growth and earnings transcripts, with 'external factors', including recent market indices performances and analyst grades, to create a rich, supervised dataset. This comprehensive dataset enables our models to achieve superior predictive performance in terms of accuracy, weighted F1, and Matthews correlation coefficient (MCC), especially evident in the comparison with benchmarks such as GPT-4. We specifically highlight the efficacy of the llama-3-8b-Instruct-4bit model, which showcases significant improvements over baseline models. The paper also discusses the potential of expanding the output capabilities to include a 'Hold' option and extending the prediction horizon, aiming to accommodate various investment styles and time frames. This study not only demonstrates the power of integrating cutting-edge AI with fine-tuned financial data but also paves the way for future research in enhancing AI-driven financial analysis tools.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/31e6b91ed8eb6f5fe8703301fc439fd1af160132" target='_blank'>
              Harnessing Earnings Reports for Stock Predictions: A QLoRA-Enhanced LLM Approach
              </a>
            </td>
          <td>
            Haowei Ni, Shuchen Meng, Xupeng Chen, Ziqing Zhao, Andi Chen, Panfeng Li, Shiyao Zhang, Qifu Yin, Yuanqing Wang, Yuxi Chan
          </td>
          <td>2024-08-13</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Distribution shift over time occurs in many settings. Leveraging historical data is necessary to learn a model for the last time point when limited data is available in the final period, yet few methods have been developed specifically for this purpose. In this work, we construct a benchmark with different sequences of synthetic shifts to evaluate the effectiveness of 3 classes of methods that 1) learn from all data without adapting to the final period, 2) learn from historical data with no regard to the sequential nature and then adapt to the final period, and 3) leverage the sequential nature of historical data when tailoring a model to the final period. We call this benchmark Seq-to-Final to highlight the focus on using a sequence of time periods to learn a model for the final time point. Our synthetic benchmark allows users to construct sequences with different types of shift and compare different methods. We focus on image classification tasks using CIFAR-10 and CIFAR-100 as the base images for the synthetic sequences. We also evaluate the same methods on the Portraits dataset to explore the relevance to real-world shifts over time. Finally, we create a visualization to contrast the initializations and updates from different methods at the final time step. Our results suggest that, for the sequences in our benchmark, methods that disregard the sequential structure and adapt to the final time point tend to perform well. The approaches we evaluate that leverage the sequential nature do not offer any improvement. We hope that this benchmark will inspire the development of new algorithms that are better at leveraging sequential historical data or a deeper understanding of why methods that disregard the sequential nature are able to perform well.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/dff5247f9c46cb7745eb5c8b20a4225f15cd7d8a" target='_blank'>
              Seq-to-Final: A Benchmark for Tuning from Sequential Distributions to a Final Time Point
              </a>
            </td>
          <td>
            Christina X. Ji, Ahmed M. Alaa, David Sontag
          </td>
          <td>2024-07-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="In the rapidly evolving field of real estate economics, the prediction of house prices continues to be a complex challenge, intricately tied to a multitude of socio-economic factors. Traditional predictive models often overlook spatial interdependencies that significantly influence housing prices. The objective of this study is to leverage Graph Neural Networks (GNNs) on open statistics knowledge graphs to model these spatial dependencies and predict house prices across Scotland’s 2011 data zones. The methodology involves retrieving integrated statistical indicators from the official Scottish Open Government Data portal and applying three representative GNN algorithms: ChebNet, GCN, and GraphSAGE. These GNNs are compared against traditional models, including the tabular-based XGBoost and a simple Multi-Layer Perceptron (MLP), demonstrating superior prediction accuracy. Innovative contributions of this study include the use of GNNs to model spatial dependencies in real estate economics and the application of local and global explainability techniques to enhance transparency and trust in the predictions. The global feature importance is determined by a logistic regression surrogate model while the local, region-level understanding of the GNN predictions is achieved through the use of GNNExplainer. Explainability results are compared with those from a previous work that applied the XGBoost machine learning algorithm and the SHapley Additive exPlanations (SHAP) explainability framework on the same dataset. Interestingly, both the global surrogate model and the SHAP approach underscored the comparative illness factor, a health indicator, and the ratio of detached dwellings as the most crucial features in the global explainability. In the case of local explanations, while both methods showed similar results, the GNN approach provided a richer, more comprehensive understanding of the predictions for two specific data zones.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/615cab34abada51059e7bf812011aa18b664bad3" target='_blank'>
              Explainable Graph Neural Networks: An Application to Open Statistics Knowledge Graphs for Estimating House Prices
              </a>
            </td>
          <td>
            Areti Karamanou, Petros Brimos, E. Kalampokis, K. Tarabanis
          </td>
          <td>2024-08-06</td>
          <td>Technologies</td>
          <td>0</td>
          <td>36</td>
        </tr>

        <tr id="Multivariate time series modeling has been essential in sensor-based data mining tasks. However, capturing complex dynamics caused by intra-variable (temporal) and inter-variable (spatial) relationships while simultaneously taking into account evolving data distributions is a non-trivial task, which faces accumulated computational overhead and multiple temporal patterns or distribution modes. Most existing methods focus on the former direction without adaptive task-specific learning ability. To this end, we developed a holistic spatial-temporal meta-learning probabilistic inference framework, entitled ST-MeLaPI, for the efficient and versatile learning of complex dynamics. Specifically, first, a multivariate relationship recognition module is utilized to learn task-specific inter-variable dependencies. Then, a multiview meta-learning and probabilistic inference strategy was designed to learn shared parameters while enabling the fast and flexible learning of task-specific parameters for different batches. At the core are spatial dependency-oriented and temporal pattern-oriented meta-learning approximate probabilistic inference modules, which can quickly adapt to changing environments via stochastic neurons at each timestamp. Finally, a gated aggregation scheme is leveraged to realize appropriate information selection for the generative style prediction. We benchmarked our approach against state-of-the-art methods with real-world data. The experimental results demonstrate the superiority of our approach over the baselines.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4dea55e0f4c4c2f82b1128047a54ec3d4fccaa7f" target='_blank'>
              Multiview Spatial-Temporal Meta-Learning for Multivariate Time Series Forecasting
              </a>
            </td>
          <td>
            Liang Zhang, Jianping Zhu, Bo Jin, Xiaopeng Wei
          </td>
          <td>2024-07-01</td>
          <td>Sensors (Basel, Switzerland)</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Conformal prediction offers a practical framework for distribution-free uncertainty quantification, providing finite-sample coverage guarantees under relatively mild assumptions on data exchangeability. However, these assumptions cease to hold for time series due to their temporally correlated nature. In this work, we present a novel use of conformal prediction for time series forecasting that incorporates time series decomposition. This approach allows us to model different temporal components individually. By applying specific conformal algorithms to each component and then merging the obtained prediction intervals, we customize our methods to account for the different exchangeability regimes underlying each component. Our decomposition-based approach is thoroughly discussed and empirically evaluated on synthetic and real-world data. We find that the method provides promising results on well-structured time series, but can be limited by factors such as the decomposition step for more complex data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/378cd3711a8103879551b49650e1ffcd928c112a" target='_blank'>
              Conformal time series decomposition with component-wise exchangeability
              </a>
            </td>
          <td>
            Derck W. E. Prinzhorn, Thijmen Nijdam, Putri A. van der Linden, Alexander Timans
          </td>
          <td>2024-06-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Summarizing web graphs is challenging due to the heterogeneity of the modeled information and its changes over time. We investigate the use of neural networks for lifelong graph summarization. Assuming we observe the web graph at a certain time, we train the networks to summarize graph vertices. We apply this trained network to summarize the vertices of the changed graph at the next point in time. Subsequently, we continue training and evaluating the network to perform lifelong graph summarization. We use the GNNs Graph-MLP and GraphSAINT, as well as an MLP baseline, to summarize the temporal graphs. We compare $1$-hop and $2$-hop summaries. We investigate the impact of reusing parameters from a previous snapshot by measuring the backward and forward transfer and the forgetting rate of the neural networks. Our extensive experiments on ten weekly snapshots of a web graph with over $100$M edges, sampled in 2012 and 2022, show that all networks predominantly use $1$-hop information to determine the summary, even when performing $2$-hop summarization. Due to the heterogeneity of web graphs, in some snapshots, the $2$-hop summary produces over ten times more vertex summaries than the $1$-hop summary. When using the network trained on the last snapshot from 2012 and applying it to the first snapshot of 2022, we observe a strong drop in accuracy. We attribute this drop over the ten-year time warp to the strongly increased heterogeneity of the web graph in 2022.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/39a9e812343d7550486a8b525adf2fcc87cd162e" target='_blank'>
              Lifelong Graph Summarization with Neural Networks: 2012, 2022, and a Time Warp
              </a>
            </td>
          <td>
            Jonatan Frank, Marcel Hoffmann, N. Lell, David Richerby, A. Scherp
          </td>
          <td>2024-07-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>28</td>
        </tr>

        <tr id="We explore various neural network architectures for modeling the dynamics of the cryptocurrency market. Traditional linear models often fall short in accurately capturing the unique and complex dynamics of this market. In contrast, Deep Neural Networks (DNNs) have demonstrated considerable proficiency in time series forecasting. This papers introduces novel neural network framework that blend the principles of econometric state space models with the dynamic capabilities of Recurrent Neural Networks (RNNs). We propose state space models using Long Short Term Memory (LSTM), Gated Residual Units (GRU) and Temporal Kolmogorov-Arnold Networks (TKANs). According to the results, TKANs, inspired by Kolmogorov-Arnold Networks (KANs) and LSTM, demonstrate promising outcomes.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f2be9285dd976d1dd4c063f13369b73af652e881" target='_blank'>
              Deep State Space Recurrent Neural Networks for Time Series Forecasting
              </a>
            </td>
          <td>
            Hugo Inzirillo
          </td>
          <td>2024-07-21</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>1</td>
        </tr>

        <tr id="Despite the massive attention given to time-series explanations due to their extensive applications, a notable limitation in existing approaches is their primary reliance on the time-domain. This overlooks the inherent characteristic of time-series data containing both time and frequency features. In this work, we present Spectral eXplanation (SpectralX), an XAI framework that provides time-frequency explanations for time-series black-box classifiers. This easily adaptable framework enables users to"plug-in"various perturbation-based XAI methods for any pre-trained time-series classification models to assess their impact on the explanation quality without having to modify the framework architecture. Additionally, we introduce Feature Importance Approximations (FIA), a new perturbation-based XAI method. These methods consist of feature insertion, deletion, and combination techniques to enhance computational efficiency and class-specific explanations in time-series classification tasks. We conduct extensive experiments in the generated synthetic dataset and various UCR Time-Series datasets to first compare the explanation performance of FIA and other existing perturbation-based XAI methods in both time-domain and time-frequency domain, and then show the superiority of our FIA in the time-frequency domain with the SpectralX framework. Finally, we conduct a user study to confirm the practicality of our FIA in SpectralX framework for class-specific time-frequency based time-series explanations. The source code is available in https://github.com/gustmd0121/Time_is_not_Enough">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a9a442393d869ce8529cda8dfa179e2d54425503" target='_blank'>
              Time is Not Enough: Time-Frequency based Explanation for Time-Series Black-Box Models
              </a>
            </td>
          <td>
            Hyunseung Chung, Sumin Jo, Yeonsu Kwon, Edward Choi
          </td>
          <td>2024-08-07</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Dynamic graphs (DG) are often used to describe evolving interactions between nodes in real-world applications. Temporal patterns are a natural feature of DGs and are also key to representation learning. However, existing dynamic GCN models are mostly composed of static GCNs and sequence modules, which results in the separation of spatiotemporal information and cannot effectively capture complex temporal patterns in DGs. To address this problem, this study proposes a spatial-temporal graph convolutional networks with diversified transformation (STGCNDT), which includes three aspects: a) constructing a unified graph tensor convolutional network (GTCN) using tensor M-products without the need to represent spatiotemporal information separately; b) introducing three transformation schemes in GTCN to model complex temporal patterns to aggregate temporal information; and c) constructing an ensemble of diversified transformation schemes to obtain higher representation capabilities. Empirical studies on four DGs that appear in communication networks show that the proposed STGCNDT significantly outperforms state-of-the-art models in solving link weight estimation tasks due to the diversified transformations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/645c7ccb4c62510922512fdba7088d9493b9fd62" target='_blank'>
              Spatial-temporal Graph Convolutional Networks with Diversified Transformation for Dynamic Graph Representation Learning
              </a>
            </td>
          <td>
            Ling Wang, Yixiang Huang, Hao Wu
          </td>
          <td>2024-08-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Recently, the incorporation of both temporal features and the correlation across time series has become an effective approach in time series prediction. Spatio-Temporal Graph Neural Networks (STGNNs) demonstrate good performance on many Temporal-correlation Forecasting Problem. However, when applied to tasks lacking periodicity, such as stock data prediction, the effectiveness and robustness of STGNNs are found to be unsatisfactory. And STGNNs are limited by memory savings so that cannot handle problems with a large number of nodes. In this paper, we propose a novel approach called the Temporal-Correlation Graph Pre-trained Network (TCGPN) to address these limitations. TCGPN utilize Temporal-correlation fusion encoder to get a mixed representation and pre-training method with carefully designed temporal and correlation pre-training tasks. Entire structure is independent of the number and order of nodes, so better results can be obtained through various data enhancements. And memory consumption during training can be significantly reduced through multiple sampling. Experiments are conducted on real stock market data sets CSI300 and CSI500 that exhibit minimal periodicity. We fine-tune a simple MLP in downstream tasks and achieve state-of-the-art results, validating the capability to capture more robust temporal correlation patterns.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1184b61fe584f056e3f7156ed3fe740a346b75a1" target='_blank'>
              TCGPN: Temporal-Correlation Graph Pre-trained Network for Stock Forecasting
              </a>
            </td>
          <td>
            Wenbo Yan, Ying Tan
          </td>
          <td>2024-07-26</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Weather forecasting refers to learning evolutionary patterns of some key upper-air and surface variables which is of great significance. Recently, deep learning-based methods have been increasingly applied in the field of weather forecasting due to their powerful feature learning capabilities. However, prediction methods based on the original space iteration struggle to effectively and efficiently utilize large number of weather variables. Therefore, we propose an 'encoding-prediction-decoding' prediction network. This network can efficiently benefit to more related input variables with key variables, that is, it can adaptively extract key variable-related low-dimensional latent feature from much more input atmospheric variables for iterative prediction. And we construct a loss function to guide the iteration of latent feature by utilizing multiple atmospheric variables in corresponding lead times. The obtained latent features through iterative prediction are then decoded to obtain the predicted values of key variables in multiple lead times. In addition, we improve the HTA algorithm in \cite{bi2023accurate} by inputting more time steps to enhance the temporal correlation between the prediction results and input variables. Both qualitative and quantitative prediction results on ERA5 dataset validate the superiority of our method over other methods. (The code will be available at https://github.com/rs-lsl/Kvp-lsi)">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/11cc8cb84dcb1157d6fac95012b48b1ab2b7d05d" target='_blank'>
              Efficiently improving key weather variables forecasting by performing the guided iterative prediction in latent space
              </a>
            </td>
          <td>
            Shuangliang Li, Siwei Li
          </td>
          <td>2024-07-27</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="This paper presents Diffusion Forcing, a new training paradigm where a diffusion model is trained to denoise a set of tokens with independent per-token noise levels. We apply Diffusion Forcing to sequence generative modeling by training a causal next-token prediction model to generate one or several future tokens without fully diffusing past ones. Our approach is shown to combine the strengths of next-token prediction models, such as variable-length generation, with the strengths of full-sequence diffusion models, such as the ability to guide sampling to desirable trajectories. Our method offers a range of additional capabilities, such as (1) rolling-out sequences of continuous tokens, such as video, with lengths past the training horizon, where baselines diverge and (2) new sampling and guiding schemes that uniquely profit from Diffusion Forcing's variable-horizon and causal architecture, and which lead to marked performance gains in decision-making and planning tasks. In addition to its empirical success, our method is proven to optimize a variational lower bound on the likelihoods of all subsequences of tokens drawn from the true joint distribution. Project website: https://boyuan.space/diffusion-forcing">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/40d63dc2b465c9081e4efc5a19514da151e97fe7" target='_blank'>
              Diffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion
              </a>
            </td>
          <td>
            Boyuan Chen, Diego Marti Monso, Yilun Du, Max Simchowitz, Russ Tedrake, Vincent Sitzmann
          </td>
          <td>2024-07-01</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>3</td>
        </tr>

        <tr id="We present a knowledge-guided machine learning (KGML) framework for modeling multi-scale processes, and study its performance in the context of streamflow forecasting in hydrology. Specifically, we propose a novel hierarchical recurrent neural architecture that factorizes the system dynamics at multiple temporal scales and captures their interactions. This framework consists of an inverse and a forward model. The inverse model is used to empirically resolve the system's temporal modes from data (physical model simulations, observed data, or a combination of them from the past), and these states are then used in the forward model to predict streamflow. In a hydrological system, these modes can represent different processes, evolving at different temporal scales (e.g., slow: groundwater recharge and baseflow vs. fast: surface runoff due to extreme rainfall). A key advantage of our framework is that once trained, it can incorporate new observations into the model's context (internal state) without expensive optimization approaches (e.g., EnKF) that are traditionally used in physical sciences for data assimilation. Experiments with several river catchments from the NWS NCRFC region show the efficacy of this ML-based data assimilation framework compared to standard baselines, especially for basins that have a long history of observations. Even for basins that have a shorter observation history, we present two orthogonal strategies of training our FHNN framework: (a) using simulation data from imperfect simulations and (b) using observation data from multiple basins to build a global model. We show that both of these strategies (that can be used individually or together) are highly effective in mitigating the lack of training data. The improvement in forecast accuracy is particularly noteworthy for basins where local models perform poorly because of data sparsity.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/520332f72d1a6deaabdd7dd965c0cf76e89053b5" target='_blank'>
              Hierarchically Disentangled Recurrent Network for Factorizing System Dynamics of Multi-scale Systems
              </a>
            </td>
          <td>
            Rahul Ghosh, Zac McEachran, Arvind Renganathan, Kelly Lindsay, Somya Sharma, M. Steinbach, John L. Nieber, Christopher J. Duffy, Vipin Kumar
          </td>
          <td>2024-07-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>44</td>
        </tr>

        <tr id="Concept Bottleneck Models (CBMs) have emerged as a promising interpretable method whose final prediction is based on intermediate, human-understandable concepts rather than the raw input. Through time-consuming manual interventions, a user can correct wrongly predicted concept values to enhance the model's downstream performance. We propose Stochastic Concept Bottleneck Models (SCBMs), a novel approach that models concept dependencies. In SCBMs, a single-concept intervention affects all correlated concepts, thereby improving intervention effectiveness. Unlike previous approaches that model the concept relations via an autoregressive structure, we introduce an explicit, distributional parameterization that allows SCBMs to retain the CBMs' efficient training and inference procedure. Additionally, we leverage the parameterization to derive an effective intervention strategy based on the confidence region. We show empirically on synthetic tabular and natural image datasets that our approach improves intervention effectiveness significantly. Notably, we showcase the versatility and usability of SCBMs by examining a setting with CLIP-inferred concepts, alleviating the need for manual concept annotations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/aeef1c8046f93d178a091e733fe0d2c8c8c0ca3a" target='_blank'>
              Stochastic Concept Bottleneck Models
              </a>
            </td>
          <td>
            Moritz Vandenhirtz, Sonia Laguna, Ricards Marcinkevics, Julia E. Vogt
          </td>
          <td>2024-06-27</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Accurate short-term forecasting of power load is essential for the reliable operation of the comprehensive energy systems of ports and for effectively reducing energy consumption. Owing to the complexity of port systems, traditional load forecasting methods often struggle to capture the non-linearity and multifactorial interactions within the factors creating power load. To address these challenges, this study combines variational mode decomposition (VMD), temporal convolutional network (TCN), and long short-term memory (LSTM) network to develop a multi-feature-based VMD-TCN-LSTM model for the short-term forecasting of the power load of ports. VMD is first used to decompose the power load series of ports into multiple, relatively stable components to mitigate volatility. Furthermore, meteorological and temporal features are introduced into the TCN-LSTM model, which combines the temporal feature extraction capability of the TCN and the long term-dependent learning capability of the LSTM. Comparative analyses with other common forecasting models using the observed power load data from a coastal port in China demonstrate that the proposed forecasting model achieves a higher prediction accuracy, with an R-squared value of 0.94, mean squared error of 3.59 MW, and a mean absolute percentage error of 2.36%.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0ede2faa5546cfbefa083cdef9bfe4e7663ea5a1" target='_blank'>
              Multifeature-Based Variational Mode Decomposition–Temporal Convolutional Network–Long Short-Term Memory for Short-Term Forecasting of the Load of Port Power Systems
              </a>
            </td>
          <td>
            Guang Chen, Xiaofeng Ma, Lin Wei
          </td>
          <td>2024-06-22</td>
          <td>Sustainability</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Graph Neural Networks (GNNs)-based recommendation algorithms typically assume that training and testing data are drawn from independent and identically distributed (IID) spaces. However, this assumption often fails in the presence of out-of-distribution (OOD) data, resulting in significant performance degradation. In this study, we construct a Structural Causal Model (SCM) to analyze interaction data, revealing that environmental confounders (e.g., the COVID-19 pandemic) lead to unstable correlations in GNN-based models, thus impairing their generalization to OOD data. To address this issue, we propose a novel approach, graph representation learning via causal diffusion (CausalDiffRec) for OOD recommendation. This method enhances the model's generalization on OOD data by eliminating environmental confounding factors and learning invariant graph representations. Specifically, we use backdoor adjustment and variational inference to infer the real environmental distribution, thereby eliminating the impact of environmental confounders. This inferred distribution is then used as prior knowledge to guide the representation learning in the reverse phase of the diffusion process to learn the invariant representation. In addition, we provide a theoretical derivation that proves optimizing the objective function of CausalDiffRec can encourage the model to learn environment-invariant graph representations, thereby achieving excellent generalization performance in recommendations under distribution shifts. Our extensive experiments validate the effectiveness of CausalDiffRec in improving the generalization of OOD data, and the average improvement is up to 10.69% on Food, 18.83% on KuaiRec, 22.41% on Yelp2018, and 11.65% on Douban datasets.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ce6c02c791a420b29ba47ebbf6ece6010fd1a289" target='_blank'>
              Graph Representation Learning via Causal Diffusion for Out-of-Distribution Recommendation
              </a>
            </td>
          <td>
            Chu Zhao, Enneng Yang, Yuliang Liang, Pengxiang Lan, Yuting Liu, Jianzhe Zhao, Guibing Guo, Xingwei Wang
          </td>
          <td>2024-08-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Accurate traffic forecasting is more necessary than ever for transportation departments, especially given its significant role in traffic planning, management, and control. However, most existing methods struggle to address complex spatial correlations on road networks, nonlinear temporal dynamics, and difficult long‐term prediction. This article proposes a novel spatial temporal graph gated transformer (STGGT) to overcome these challenges. The suggested model differs from Google's transformer because it uses a hybrid architecture that integrates graph convolutional networks (GCNs), attention, and gated recurrent units (GRUs) instead of solely relying on attention. Specifically, STGGT uses GCNs to extract spatial dependencies, utilizes attention and GRUs to extract temporal dependencies, and handle long‐term prediction. Experiments indicate that STGGT outperforms the state‐of‐the‐art baseline models on two real‐world traffic datasets of 9%–40%. The proposed model offers a promising solution for accurate traffic forecasting, simultaneously addressing the challenges of complex spatial correlations, nonlinear temporal dynamics, and long‐term prediction.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/64e802ce9b30e768f218018adb39b56cd14ee339" target='_blank'>
              A spatial-temporal graph gated transformer for traffic forecasting
              </a>
            </td>
          <td>
            Haroun Bouchemoukha, M. Zennir, Ahmed Alioua
          </td>
          <td>2024-06-26</td>
          <td>Trans. Emerg. Telecommun. Technol.</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Dynamic Quality-of-Service (QoS) data capturing temporal variations in user-service interactions, are essential source for service selection and user behavior understanding. Approaches based on Latent Feature Analysis (LFA) have shown to be beneficial for discovering effective temporal patterns in QoS data. However, existing methods cannot well model the spatiality and temporality implied in dynamic interactions in a unified form, causing abundant accuracy loss for missing QoS estimation. To address the problem, this paper presents a novel Graph Convolutional Networks (GCNs)-based dynamic QoS estimator namely Spatiotemporal Coupling GCN (SCG) model with the three-fold ideas as below. First, SCG builds its dynamic graph convolution rules by incorporating generalized tensor product framework, for unified modeling of spatial and temporal patterns. Second, SCG combines the heterogeneous GCN layer with tensor factorization, for effective representation learning on bipartite user-service graphs. Third, it further simplifies the dynamic GCN structure to lower the training difficulties. Extensive experiments have been conducted on two large-scale widely-adopted QoS datasets describing throughput and response time. The results demonstrate that SCG realizes higher QoS estimation accuracy compared with the state-of-the-arts, illustrating it can learn powerful representations to users and cloud services.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/53de573b22bccc67f4c62494a24ad6245cd7246a" target='_blank'>
              A Novel Spatiotemporal Coupling Graph Convolutional Network
              </a>
            </td>
          <td>
            Fanghui Bi
          </td>
          <td>2024-08-09</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Industrial time-series, as a structural data responds to production process information, can be utilized to perform data-driven decision-making for effective monitoring of industrial production process. However, there are some challenges for time-series forecasting in industry, e.g., predicting few-shot caused by data shortage, and decision-confusing caused by unknown treatment policy. To cope with the problems, we propose a novel causal domain adaptation framework, Causal Domain Adaptation (CDA) forecaster to improve the performance on the interested domain with limited data (target). Firstly, we analyze the causality existing along with treatments, and thus ensure the shared causality over time. Subsequently, we propose an answer-based attention mechanism to achieve domain-invariant representation by the shared causality in both domains. Then, a novel domain-adaptation is built to model treatments and outcomes jointly training on source and target domain. The main insights are that our designed answer-based attention mechanism allows the target domain to leverage the existed causality in source time-series even with different treatments, and our forecaster can predict the counterfactual outcome of industrial time-series, meaning a guidance in production process. Compared with commonly baselines, our method on real-world and synthetic oilfield datasets demonstrates the effectiveness in across-domain prediction and the practicality in guiding production process">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/156edecae87bbcc79ee4253c37525b426f87a42a" target='_blank'>
              Domain Adaptation for Industrial Time-series Forecasting via Counterfactual Inference
              </a>
            </td>
          <td>
            Chao Min, Guo-quan Wen, Jiangru Yuan, Jun Yi, Xing Guo
          </td>
          <td>2024-07-19</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Graph Neural Networks (GNNs) have emerged as powerful tools for supervised machine learning over graph-structured data, while sampling-based node representation learning is widely utilized in unsupervised learning. However, scalability remains a major challenge in both supervised and unsupervised learning for large graphs (e.g., those with over 1 billion nodes). The scalability bottleneck largely stems from the mini-batch sampling phase in GNNs and the random walk sampling phase in unsupervised methods. These processes often require storing features or embeddings in memory. In the context of distributed training, they require frequent, inefficient random access to data stored across different workers. Such repeated inter-worker communication for each mini-batch leads to high communication overhead and computational inefficiency. We propose GraphScale, a unified framework for both supervised and unsupervised learning to store and process large graph data distributedly. The key insight in our design is the separation of workers who store data and those who perform the training. This separation allows us to decouple computing and storage in graph training, thus effectively building a pipeline where data fetching and data computation can overlap asynchronously. Our experiments show that GraphScale outperforms state-of-the-art methods for distributed training of both GNNs and node embeddings. We evaluate GraphScale both on public and proprietary graph datasets and observe a reduction of at least 40% in end-to-end training times compared to popular distributed frameworks, without any loss in performance. While most existing methods don't support billion-node graphs for training node embeddings, GraphScale is currently deployed in production at TikTok enabling efficient learning over such large graphs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e5115bc6bf426026833b4f7fb72ae6282f678143" target='_blank'>
              GraphScale: A Framework to Enable Machine Learning over Billion-node Graphs
              </a>
            </td>
          <td>
            Vipul Gupta, Xin Chen, Ruoyun Huang, Fanlong Meng, Jianjun Chen, Yujun Yan
          </td>
          <td>2024-07-22</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Deep learning models are widely used in multivariate time series forecasting, yet, they have high computational costs. One way to reduce this cost is by reducing data dimensionality, which involves removing unimportant or low importance information with the proper method. This work presents a study on an explainability feature selection framework composed of four methods (IMV‐LSTM Tensor, LIME‐LSTM, Average SHAP‐LSTM, and Instance SHAP‐LSTM) aimed at using the LSTM black‐box model complexity to its favour, with the end goal of improving the error metrics and reducing the computational cost on a forecast task. To test the framework, three datasets with a total of 101 multivariate time series were used, with the explainability methods outperforming the baseline methods in most of the data, be it in error metrics or computation time for the LSTM model training.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c38a287f4c56c37be6a1916bb90ba43b4504c73a" target='_blank'>
              KDBI special issue: Explainability feature selection framework application for LSTM multivariate time‐series forecast self optimization
              </a>
            </td>
          <td>
            Eduardo M. Rodrigues, Yassine Baghoussi, João Mendes‐Moreira
          </td>
          <td>2024-07-04</td>
          <td>Expert Systems</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Time series forecasting (TSF) is immensely important in extensive applications, such as electricity transformation, financial trade, medical monitoring, and smart agriculture. Although Transformer-based methods can handle time series data, their ability to predict long-term time series is limited due to the ``anti-order"nature of the self-attention mechanism. To address this problem, we focus on frequency domain to weaken the impact of order in TSF and propose the FreqBlock, where we first obtain frequency representations through the Frequency Transform Module. Subsequently, a newly designed Frequency Cross Attention is used to obtian enhanced frequency representations between the real and imaginary parts, thus establishing a link between the attention mechanism and the inherent Kramer-Kronig relations (KKRs). Our backbone network, FreqTSF, adopts a residual structure by concatenating multiple FreqBlocks to simulate KKRs in the frequency domain and avoid degradation problems. On a theoretical level, we demonstrate that the proposed two modules can significantly reduce the time and memory complexity from $\mathcal{O}(L^2)$ to $\mathcal{O}(L)$ for each FreqBlock computation. Empirical studies on four benchmark datasets show that FreqTSF achieves an overall relative MSE reduction of 15\% and an overall relative MAE reduction of 11\% compared to the state-of-the-art methods. The code will be available soon.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c7a597bc1188e94cf4e9583a7acbceb292b7f71f" target='_blank'>
              FreqTSF: Time Series Forecasting Via Simulating Frequency Kramer-Kronig Relations
              </a>
            </td>
          <td>
            Rujia Shen, Liangliang Liu, Boran Wang, Yi Guan, Yang Yang, Jingchi Jiang
          </td>
          <td>2024-07-31</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>11</td>
        </tr>

        <tr id="Track reconstruction is a crucial task in particle experiments and is traditionally very computationally expensive due to its combinatorial nature. Recently, graph neural networks (GNNs) have emerged as a promising approach that can improve scalability. Most of these GNN-based methods, including the edge classification (EC) and the object condensation (OC) approach, require an input graph that needs to be constructed beforehand. In this work, we consider a one-shot OC approach that reconstructs particle tracks directly from a set of hits (point cloud) by recursively applying graph attention networks with an evolving graph structure. This approach iteratively updates the graphs and can better facilitate the message passing across each graph. Preliminary studies on the TrackML dataset show better track performance compared to the methods that require a fixed input graph.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/398108b585c483e0611513c7746467f7cd38df17" target='_blank'>
              EggNet: An Evolving Graph-based Graph Attention Network for Particle Track Reconstruction
              </a>
            </td>
          <td>
            P. Calafiura, Jay Chan, Loic Delabrouille, Brandon Wang
          </td>
          <td>2024-07-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>48</td>
        </tr>

        <tr id="The effectiveness of univariate forecasting models is often hampered by conditions that cause them stress. A model is considered to be under stress if it shows a negative behaviour, such as higher-than-usual errors or increased uncertainty. Understanding the factors that cause stress to forecasting models is important to improve their reliability, transparency, and utility. This paper addresses this problem by contributing with a novel framework called MAST (Meta-learning and data Augmentation for Stress Testing). The proposed approach aims to model and characterize stress in univariate time series forecasting models, focusing on conditions where they exhibit large errors. In particular, MAST is a meta-learning approach that predicts the probability that a given model will perform poorly on a given time series based on a set of statistical time series features. MAST also encompasses a novel data augmentation technique based on oversampling to improve the metadata concerning stress. We conducted experiments using three benchmark datasets that contain a total of 49.794 time series to validate the performance of MAST. The results suggest that the proposed approach is able to identify conditions that lead to large errors. The method and experiments are publicly available in a repository.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/21df316c9190406997a7ddcf7668a9d6a38d85cf" target='_blank'>
              Meta-learning and Data Augmentation for Stress Testing Forecasting Models
              </a>
            </td>
          <td>
            Ricardo In'acio, Vítor Cerqueira, Mar'ilia Barandas, Carlos Soares
          </td>
          <td>2024-06-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>14</td>
        </tr>

        <tr id="Multivariate time series anomaly detection is a crucial data mining technique with a wide range of applications in areas such as IT applications. Currently, the majority of anomaly detection methods for time series data rely on unsupervised approaches due to the rarity of anomaly labels. However, in real-world scenarios, obtaining a limited number of anomaly labels is feasible and affordable. Effective usage of these labels can offer valuable insights into the temporal characteristics of anomalies and play a pivotal role in guiding anomaly detection efforts. To improve the performance of multivariate time series anomaly detection, we proposed a novel deep learning model named EDD (Encoder-Decoder-Discriminator) that leverages limited anomaly samples. The EDD model innovatively integrates a graph attention network with long short term memory (LSTM) to extract spatial and temporal features from multivariate time series data. This integrated approach enables the model to capture complex patterns and dependencies within the data. Additionally, the model skillfully maps series data into a latent space, utilizing a carefully crafted loss function to cluster normal data tightly in the latent space while dispersing abnormal data randomly. This innovative design results in distinct probability distributions for normal and abnormal data in the latent space, enabling precise identification of anomalous data. To evaluate the performance of our EDD model, we conducted extensive experimental validation across three diverse datasets. The results demonstrate the significant superiority of our model in multivariate time series anomaly detection. Specifically, the average F1-Score of our model outperformed the second-best method by 2.7% and 73.4% in both evaluation approaches, respectively, highlighting its superior detection capabilities. These findings validate the effectiveness of our proposed EDD model in leveraging limited anomaly samples for accurate and robust anomaly detection in multivariate time series data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6a0b2af4fae72e31c61e9b23f7aa121732e8dfa5" target='_blank'>
              An anomaly detection model for multivariate time series with anomaly perception
              </a>
            </td>
          <td>
            Dong Wei, Wu Sun, Xiaofeng Zou, Dan Ma, Huarong Xu, Panfeng Chen, Chaoshu Yang, Mei Chen, Hui Li
          </td>
          <td>2024-07-31</td>
          <td>PeerJ Comput. Sci.</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The increasing adoption of rooftop photovoltaic (PV) power generation systems in residential areas necessitates accurate monitoring and disaggregation of behind-the-meter (BTM) load and PV power. Despite recent advancements, existing BTM disaggregation approaches suffer from three major drawbacks: neglecting task-relevant spatiotemporal features, overfitting, and lack of a sparse neural architecture which leads to high sample complexity. This paper addresses them by introducing a deep sparse attention graph recurrent framework. This framework conceptualizes a set of neighboring residential units as a graph where the nodes are the net load values of the units and the edges show the mutual information (MI) of these measurements. We develop an Attention Gated Recurrent Unit (AGRU) to capture enhanced temporal characteristics of the net load. We employ a novel low-rank Dictionary Learning (DL) method to discern spatiotemporal features of these measurements and further utilize a Rectified Linear Unit (ReLU) neural network that incorporates an MI-based dropout to provide a sparse model for the estimation of the BTM load and PV. Experimental results validate the effectiveness of our proposed model, exhibiting superior performance on the Ausgrid dataset in BTM load and PV power estimation compared to state-of-the-art methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ba52197a4d7f5071efd214b6546a45314b15bb13" target='_blank'>
              Sparse Attention Graph Gated Recurrent Unit for Spatiotemporal Behind-The-Meter Load and PV Disaggregation
              </a>
            </td>
          <td>
            Mahdi Khodayar, Ali Farajzadeh Bavil, M. Saffari
          </td>
          <td>2024-06-27</td>
          <td>2024 16th International Conference on Electronics, Computers and Artificial Intelligence (ECAI)</td>
          <td>0</td>
          <td>14</td>
        </tr>

        <tr id="In the era of rapid globalization and digitalization, accurate identification of similar stocks has become increasingly challenging due to the non-stationary nature of financial markets and the ambiguity in conventional regional and sector classifications. To address these challenges, we examine SimStock, a novel temporal self-supervised learning framework that combines techniques from self-supervised learning (SSL) and temporal domain generalization to learn robust and informative representations of financial time series data. The primary focus of our study is to understand the similarities between stocks from a broader perspective, considering the complex dynamics of the global financial landscape. We conduct extensive experiments on four real-world datasets with thousands of stocks and demonstrate the effectiveness of SimStock in finding similar stocks, outperforming existing methods. The practical utility of SimStock is showcased through its application to various investment strategies, such as pairs trading, index tracking, and portfolio optimization, where it leads to superior performance compared to conventional methods. Our findings empirically examine the potential of data-driven approach to enhance investment decision-making and risk management practices by leveraging the power of temporal self-supervised learning in the face of the ever-changing global financial landscape.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c259bc9adf3019870613cbb7888ea4fac4e1929f" target='_blank'>
              Temporal Representation Learning for Stock Similarities and Its Applications in Investment Management
              </a>
            </td>
          <td>
            Yoon-Jeong Hwang, Stefan Zohren, Yongjae Lee
          </td>
          <td>2024-07-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="This article describes the methods that achieved 4th and 6th place in the forecasting and investment challenges, respectively, of the M6 competition, ultimately securing the 1st place in the overall duathlon ranking. In the forecasting challenge, we tested a novel meta-learning model that utilizes hypernetworks to design a parametric model tailored to a specific family of forecasting tasks. This approach allowed us to leverage similarities observed across individual forecasting tasks while also acknowledging potential heterogeneity in their data generating processes. The model's training can be directly performed with backpropagation, eliminating the need for reliance on higher-order derivatives and is equivalent to a simultaneous search over the space of parametric functions and their optimal parameter values. The proposed model's capabilities extend beyond M6, demonstrating superiority over state-of-the-art meta-learning methods in the sinusoidal regression task and outperforming conventional parametric models on time-series from the M4 competition. In the investment challenge, we adjusted portfolio weights to induce greater or smaller correlation between our submission and that of other participants, depending on the current ranking, aiming to maximize the probability of achieving a good rank.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/79c059ff368b1797f8ebcd428512691d3f6bcd34" target='_blank'>
              Designing Time-Series Models With Hypernetworks&Adversarial Portfolios
              </a>
            </td>
          <td>
            Filip Stanvek
          </td>
          <td>2024-07-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="This study introduces an innovative deep learning approach for predicting the remaining useful life (RUL) of industrial machinery. Accurate RUL forecasts play a crucial role in enabling proactive maintenance and enhancing operational efficiency within the contexts of Industry 4.0 and 5.0. However, current data-driven models face challenges when dealing with complex, high-dimensional time-series sensor data. To address these obstacles, we present a framework for predicting RUL of industrial equipment, employing variational recurrent neural networks (VRNNs). By harnessing the expressive power of recurrent neural networks and variational inference, VRNNs demonstrate proficiency in modeling temporal relationships and managing intricate, high-dimensional time-series sensor data. This deep learning model represents a significant advancement in data-driven prognostics, providing more robust and interpretable RUL forecasts derived from intricate time-series sensor data. Potential applications encompass predictive maintenance and asset management in industries embracing Industry 4.0 and 5.0 paradigms.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4411fb5e68889eaebadb3fe36a16107e207404ff" target='_blank'>
              Variational Recurrent Neural Networks (VRNN) for RUL Estimation
              </a>
            </td>
          <td>
            Amal Ayadi, M. Benatia, Ramzi Chaieb, Anne Louis
          </td>
          <td>2024-07-08</td>
          <td>2024 16th International Conference on Human System Interaction (HSI)</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Identification of critical nodes is a prominent topic in the study of complex networks. Numerous methods have been proposed, yet most exhibit inherent limitations. Traditional approaches primarily analyze specific structural features of the network; however, node influence is typically the result of a combination of multiple factors. Machine learning-based methods struggle to effectively represent the complex characteristics of network structures through suitable embedding techniques and require substantial data for training, rendering them prohibitively costly for large-scale networks. To address these challenges, this paper presents an active learning model based on GraphSAGE and Transformer, named GNNTAL. This model is initially pre-trained on random or synthetic networks and subsequently fine-tuned on real-world networks by selecting a few representative nodes using K-Means clustering and uncertainty sampling. This approach offers two main advantages: (1) it significantly reduces training costs; (2) it simultaneously incorporates both local and global features. A series of comparative experiments conducted on twelve real-world networks demonstrate that GNNTAL achieves superior performance. Additionally, this paper proposes an influence maximization method based on the predictions of the GNNTAL model, which achieves optimal performance without the need for complex computations. Finally, the paper analyses certain limitations of the GNNTAL model and suggests potential solutions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f2c2569fd1bd2320230e824c982a501344641e9c" target='_blank'>
              GNNTAL:A Novel Model for Identifying Critical Nodes in Complex Networks
              </a>
            </td>
          <td>
            Hao Wang, Ting Luo, Shuang-ping Yang, Ming Jing, Jian Wang, Na Zhao
          </td>
          <td>2024-06-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Time series analysis is pivotal for business and financial decision making, especially with the increasing integration of the Internet of Things (IoT). However, leveraging time series data for forecasting requires extensive preprocessing to address challenges such as missing values, heteroscedasticity, seasonality, outliers, and noise. Different approaches are necessary for univariate and multivariate time series, Gaussian and non-Gaussian time series, and stationary versus non-stationary time series. Handling missing data alone is complex, demanding unique solutions for each type. Extracting statistical features, identifying data quality issues, and selecting appropriate cleaning and forecasting techniques require significant effort, time, and expertise. To streamline this process, we propose an automated strategy called Preptimize, which integrates statistical and machine learning techniques and recommends prediction model blueprints, suggesting the most suitable approaches for a given dataset as an initial step towards further analysis. Preptimize reads a sample from a large dataset and recommends the blueprint model based on optimization, making it easy to use even for non-experts. The results of various experiments indicated that Preptimize either outperformed or had comparable performance to benchmark models across multiple sectors, including stock prices, cryptocurrency, and power consumption prediction. This demonstrates the framework’s effectiveness in recommending suitable prediction models for various time series datasets, highlighting its broad applicability across different domains in time series forecasting.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/228a2e2a0f2984f0be41b8a4718860d9d8b020d5" target='_blank'>
              Preptimize: Automation of Time Series Data Preprocessing and Forecasting
              </a>
            </td>
          <td>
            Mehak Usmani, Z. Memon, Adil Zulfiqar, Rizwan Qureshi
          </td>
          <td>2024-08-01</td>
          <td>Algorithms</td>
          <td>0</td>
          <td>18</td>
        </tr>

        <tr id="We conducted extensive experiments on domain adaptation of the Meta-Llama-3-70B-Instruct model on SEC data, exploring its performance on both general and domain-specific benchmarks. Our focus included continual pre-training (CPT) and model merging, aiming to enhance the model's domain-specific capabilities while mitigating catastrophic forgetting. Through this study, we evaluated the impact of integrating financial regulatory data into a robust language model and examined the effectiveness of our model merging techniques in preserving and improving the model's instructive abilities. The model is accessible at hugging face: https://huggingface.co/arcee-ai/Llama-3-SEC-Base, arcee-ai/Llama-3-SEC-Base. This is an intermediate checkpoint of our final model, which has seen 20B tokens so far. The full model is still in the process of training. This is a preprint technical report with thorough evaluations to understand the entire process.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c6cc3ff91538d584ddfd0c07506ebaf195e5f5ca" target='_blank'>
              Domain Adaptation of Llama3-70B-Instruct through Continual Pre-Training and Model Merging: A Comprehensive Evaluation
              </a>
            </td>
          <td>
            Shamane Siriwardhana, Mark McQuade, Thomas Gauthier, Lucas Atkins, Fernando Fernandes Neto, Luke Meyers, Anneketh Vij, Tyler Odenthal, Charles Goddard, Mary MacCarthy, Jacob Solawetz
          </td>
          <td>2024-06-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="With the advancement of deep learning techniques, the performance of Automatic Program Repair(APR) techniques has reached a new level. Previous deep learning-based APR techniques essentially modified program sentences in the Autoregressive(AR) manner, which predicts future values based on past values. Due to the manner of word-by-word generation, the AR-based APR technique has a huge time delay. This negative consequence overshadows the widespread adoption of APR techniques in real-life software development. To address the issue, we aim to apply the Non-Autoregressive(NAR) method to the APR task, which can output target code in a parallel manner to avoid huge inference delays. To effectively adapt the NAR manner for the APR task, we in this paper propose NARRepair, the first customized NAR code generation model for the APR task. The NARRepair features three major novelties, including 1) using repair actions to alleviate the over-correction issue, 2) extracting dependency information from AST to alleviate the issue of lacking inter-word dependency information, 3) employing two-stage decoding to alleviate the issue of lacking contextual information. We evaluated NARRepair on three widely used datasets in the APR community, and the results show that our technique can significantly improve the inference speed while maintaining high repair accuracy.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/385934bd633b36326faa9d91a3be7c7bdd4ef956" target='_blank'>
              NARRepair: Non-Autoregressive Code Generation Model for Automatic Program Repair
              </a>
            </td>
          <td>
            Zhen Yang, Zhen Yang, Zhongxing Yu
          </td>
          <td>2024-06-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="The growing demand for air travel requires technological advancements in air traffic management as well as mechanisms for monitoring and ensuring safe and efficient operations. In terminal airspaces, predictive models of future movements and traffic flows can help with proactive planning and efficient coordination; however, varying airport topologies, and interactions with other agents, among other factors, make accurate predictions challenging. Data-driven predictive models have shown promise for handling numerous variables to enable various downstream tasks, including collision risk assessment, taxi-out time prediction, departure metering, and emission estimations. While data-driven methods have shown improvements in these tasks, prior works lack large-scale curated surface movement datasets within the public domain and the development of generalizable trajectory forecasting models. In response to this, we propose two contributions: (1) Amelia-48, a large surface movement dataset collected using the System Wide Information Management (SWIM) Surface Movement Event Service (SMES). With data collection beginning in Dec 2022, the dataset provides more than a year's worth of SMES data (~30TB) and covers 48 airports within the US National Airspace System. In addition to releasing this data in the public domain, we also provide post-processing scripts and associated airport maps to enable research in the forecasting domain and beyond. (2) Amelia-TF model, a transformer-based next-token-prediction large multi-agent multi-airport trajectory forecasting model trained on 292 days or 9.4 billion tokens of position data encompassing 10 different airports with varying topology. The open-sourced model is validated on unseen airports with experiments showcasing the different prediction horizon lengths, ego-agent selection strategies, and training recipes to demonstrate the generalization capabilities.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/fe29091a5f28ae9c53d07479551f034ed3c2e387" target='_blank'>
              Amelia: A Large Model and Dataset for Airport Surface Movement Forecasting
              </a>
            </td>
          <td>
            Ingrid Navarro, Pablo Ortega-Kral, Jay Patrikar, Haichuan Wang, Zelin Ye, Jong Hoon Park, Jean Oh, Sebastian Scherer
          </td>
          <td>2024-07-30</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Dynamic graph learning aims to uncover evolutionary laws in real-world systems, enabling accurate social recommendation (link prediction) or early detection of cancer cells (classification). Inspired by the success of state space models, e.g., Mamba, for efficiently capturing long-term dependencies in language modeling, we propose DyG-Mamba, a new continuous state space model (SSM) for dynamic graph learning. Specifically, we first found that using inputs as control signals for SSM is not suitable for continuous-time dynamic network data with irregular sampling intervals, resulting in models being insensitive to time information and lacking generalization properties. Drawing inspiration from the Ebbinghaus forgetting curve, which suggests that memory of past events is strongly correlated with time intervals rather than specific details of the events themselves, we directly utilize irregular time spans as control signals for SSM to achieve significant robustness and generalization. Through exhaustive experiments on 12 datasets for dynamic link prediction and dynamic node classification tasks, we found that DyG-Mamba achieves state-of-the-art performance on most of the datasets, while also demonstrating significantly improved computation and memory efficiency.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3cc84a5a1e02661fc3681d8be4134205b0b09954" target='_blank'>
              DyG-Mamba: Continuous State Space Modeling on Dynamic Graphs
              </a>
            </td>
          <td>
            Dongyuan Li, Shiyin Tan, Ying Zhang, Ming Jin, Shirui Pan, Manabu Okumura, Renhe Jiang
          </td>
          <td>2024-08-13</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Reliable gas price forecasts are an essential information for gas and energy traders, for risk managers and also economists. However, ahead of the war in Ukraine Europe began to suffer from substantially increased and volatile gas prices which culminated in the aftermath of the North Stream 1 explosion. This shock changed both trend and volatility structure of the prices and has considerable effects on forecasting models. In this study we investigate whether modern machine learning methods such as neural networks are more resilient against such changes than statistical models such as autoregressive moving average (ARMA) models with conditional heteroskedasticity, or copula-based time series models. Thereby the focus lies on interval forecasting and applying respective evaluation measures. As data, the Front Month prices from the Dutch Title Transfer Facility, currently the predominant European exchange, are used. We see that, during the shock period, most models underestimate the variance while overestimating the variance in the after-shock period. Furthermore, we recognize that, during the shock, the simpler models, i.e. an ARMA model with conditional heteroskedasticity and the multilayer perceptron (a neural network), perform best with regards to prediction interval coverage. Interestingly, the widely-used long-short term neural network is outperformed by its competitors.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/85754bf41e34f87a3356a090d97ccc44867749ef" target='_blank'>
              Interval Forecasts for Gas Prices in the Face of Structural Breaks -- Statistical Models vs. Neural Networks
              </a>
            </td>
          <td>
            Stephan Schluter, Sven Pappert, Martin Neumann
          </td>
          <td>2024-07-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="In this paper, we apply a supervised machine-learning approach to solve a fundamental problem in queueing theory: estimating the transient distribution of the number in the system for a G(t)/GI/1. We develop a neural network mechanism that provides a fast and accurate predictor of these distributions for moderate horizon lengths and practical settings. It is based on using a Recurrent Neural Network (RNN) architecture based on the first several moments of the time-dependant inter-arrival and the stationary service time distributions; we call it the Moment-Based Recurrent Neural Network (RNN) method (MBRNN ). Our empirical study suggests MBRNN requires only the first four inter-arrival and service time moments. We use simulation to generate a substantial training dataset and present a thorough performance evaluation to examine the accuracy of our method using two different test sets. We show that even under the configuration with the worst performance errors, the mean number of customers over the entire timeline has an error of less than 3%. While simulation modeling can achieve high accuracy, the advantage of the MBRNN over simulation is runtime, while the MBRNN analyzes hundreds of systems within a fraction of a second. This paper focuses on a G(t)/GI/1; however, the MBRNN approach demonstrated here can be extended to other queueing systems, as the training data labeling is based on simulations (which can be applied to more complex systems) and the training is based on deep learning, which can capture very complex time sequence tasks. In summary, the MBRNN can potentially revolutionize our ability to perform transient analyses of queueing systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f691dfd4dff3b3fb9b91bf5e89d6572368165f58" target='_blank'>
              Approximating G(t)/GI/1 queues with deep learning
              </a>
            </td>
          <td>
            Eliran Sherzer, Opher Baron, Dmitry Krass, Yehezkel S. Resheff
          </td>
          <td>2024-07-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>14</td>
        </tr>

        <tr id="Generating synthetic financial time series data that accurately reflects real-world market dynamics holds tremendous potential for various applications, including portfolio optimization, risk management, and large scale machine learning. We present an approach for training generative models for financial time series using the maximum mean discrepancy (MMD) with a signature kernel. Our method leverages the expressive power of the signature transform to capture the complex dependencies and temporal structures inherent in financial data. We employ a moving average model to model the variance of the noise input, enhancing the model's ability to reproduce stylized facts such as volatility clustering. Through empirical experiments on S&P 500 index data, we demonstrate that our model effectively captures key characteristics of financial time series and outperforms a comparable GAN-based approach. In addition, we explore the application of the synthetic data generated to train a reinforcement learning agent for portfolio management, achieving promising results. Finally, we propose a method to add robustness to the generative model by tweaking the noise input so that the generated sequences can be adjusted to different market environments with minimal data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/492d244da8647554a7439883786cfe931ec4c342" target='_blank'>
              Generative model for financial time series trained with MMD using a signature kernel
              </a>
            </td>
          <td>
            Chung I Lu, Julian Sester
          </td>
          <td>2024-07-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Continual Test-Time Adaptation (CTTA) involves adapting a pre-trained source model to continually changing unsupervised target domains. In this paper, we systematically analyze the challenges of this task: online environment, unsupervised nature, and the risks of error accumulation and catastrophic forgetting under continual domain shifts. To address these challenges, we reshape the online data buffering and organizing mechanism for CTTA. We propose an uncertainty-aware buffering approach to identify and aggregate significant samples with high certainty from the unsupervised, single-pass data stream. Based on this, we propose a graph-based class relation preservation constraint to overcome catastrophic forgetting. Furthermore, a pseudo-target replay objective is used to mitigate error accumulation. Extensive experiments demonstrate the superiority of our method in both segmentation and classification CTTA tasks. Code is available at https://github.com/z1358/OBAO.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/255e2aee4d754b98a3c9ead9618e48e3d9906ffe" target='_blank'>
              Reshaping the Online Data Buffering and Organizing Mechanism for Continual Test-Time Adaptation
              </a>
            </td>
          <td>
            Zhilin Zhu, Xiaopeng Hong, Zhiheng Ma, Weijun Zhuang, Yaohui Ma, Yong Dai, Yaowei Wang
          </td>
          <td>2024-07-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>20</td>
        </tr>

        <tr id="Clinical trials need to recruit a sufficient number of volunteer patients to demonstrate the statistical power of the treatment (e.g., a new drug) in curing a certain disease. Clinical trial recruitment has a significant impact on trial success. Forecasting whether the recruitment process would be successful before we run the trial would save many resources and time. This paper develops a novel deep&cross network with large language model (LLM)-augmented text feature that learns semantic information from trial eligibility criteria and predicts enrollment success. The proposed method enables interpretability by understanding which sentence/word in eligibility criteria contributes heavily to prediction. We also demonstrate the empirical superiority of the proposed method (0.7002 PR-AUC) over a bunch of well-established machine learning methods. The code and curated dataset are publicly available at https://anonymous.4open.science/r/TrialEnroll-7E12.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8b0084ee93fc8c700058b3d5d2d7c58de05f753a" target='_blank'>
              TrialEnroll: Predicting Clinical Trial Enrollment Success with Deep&Cross Network and Large Language Models
              </a>
            </td>
          <td>
            Ling Yue, Sixue Xing, Jintai Chen, Tianfan Fu
          </td>
          <td>2024-07-18</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>3</td>
        </tr>

        <tr id="Modern vehicles rely on a myriad of electronic control units (ECUs) interconnected via controller area networks (CANs) for critical operations. Despite their ubiquitous use and reliability, CANs are susceptible to sophisticated cyberattacks, particularly masquerade attacks, which inject false data that mimic legitimate messages at the expected frequency. These attacks pose severe risks such as unintended acceleration, brake deactivation, and rogue steering. Traditional intrusion detection systems (IDS) often struggle to detect these subtle intrusions due to their seamless integration into normal traffic. This paper introduces a novel framework for detecting masquerade attacks in the CAN bus using graph machine learning (ML). We hypothesize that the integration of shallow graph embeddings with time series features derived from CAN frames enhances the detection of masquerade attacks. We show that by representing CAN bus frames as message sequence graphs (MSGs) and enriching each node with contextual statistical attributes from time series, we can enhance detection capabilities across various attack patterns compared to using only graph-based features. Our method ensures a comprehensive and dynamic analysis of CAN frame interactions, improving robustness and efficiency. Extensive experiments on the ROAD dataset validate the effectiveness of our approach, demonstrating statistically significant improvements in the detection rates of masquerade attacks compared to a baseline that uses only graph-based features, as confirmed by Mann-Whitney U and Kolmogorov-Smirnov tests (p<0.05).">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/31a90fb5c4f3760898c538549095797acfa7f429" target='_blank'>
              Detecting Masquerade Attacks in Controller Area Networks Using Graph Machine Learning
              </a>
            </td>
          <td>
            William Marfo, P. Moriano, Deepak K. Tosh, Shirley V. Moore
          </td>
          <td>2024-08-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Accurate modeling of car-following behaviors is essential for various applications in traffic management and autonomous driving systems. However, current approaches often suffer from limitations like high sensitivity to data quality and lack of interpretability. In this study, we propose GenFollower, a novel zero-shot prompting approach that leverages large language models (LLMs) to address these challenges. We reframe car-following behavior as a language modeling problem and integrate heterogeneous inputs into structured prompts for LLMs. This approach achieves improved prediction performance and interpretability compared to traditional baseline models. Experiments on the Waymo Open datasets demonstrate GenFollower's superior performance and ability to provide interpretable insights into factors influencing car-following behavior. This work contributes to advancing the understanding and prediction of car-following behaviors, paving the way for enhanced traffic management and autonomous driving systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3c2dc1a2b947f863938dfbf2e05352e7bff43498" target='_blank'>
              GenFollower: Enhancing Car-Following Prediction with Large Language Models
              </a>
            </td>
          <td>
            Xianda Chen, Mingxing Peng, PakHin Tiu, Yuanfei Wu, Junjie Chen, Meixin Zhu, Xinhu Zheng
          </td>
          <td>2024-07-08</td>
          <td>ArXiv</td>
          <td>2</td>
          <td>5</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/24a196d9ee7fda6754365bee42a89aa1d9add80b" target='_blank'>
              Generalized spatial–temporal regression graph convolutional transformer for traffic forecasting
              </a>
            </td>
          <td>
            Lang Xiong, Liyun Su, Shiyi Zeng, Xiangjing Li, Tong Wang, Feng Zhao
          </td>
          <td>2024-08-10</td>
          <td>Complex &amp; Intelligent Systems</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4ccc940a891f74aa82e4a858d918d21d59774433" target='_blank'>
              A binary-domain recurrent-like architecture-based dynamic graph neural network
              </a>
            </td>
          <td>
            Zi-chao Chen, Sui Lin
          </td>
          <td>2024-06-25</td>
          <td>Auton. Intell. Syst.</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The dynamic characteristics of multiphase industrial processes present significant challenges in the field of industrial big data modeling. Traditional soft sensing models frequently neglect the process dynamics and have difficulty in capturing transient phenomena like phase transitions. To address this issue, this article introduces a causality-driven sequence segmentation (CDSS) model. This model first identifies the local dynamic properties of the causal relationships between variables, which are also referred to as causal mechanisms. It then segments the sequence into different phases based on the sudden shifts in causal mechanisms that occur during phase transitions. Additionally, a novel metric, similarity distance, is designed to evaluate the temporal consistency of causal mechanisms, which includes both causal similarity distance and stable similarity distance. The discovered causal relationships in each phase are represented as a temporal causal graph (TCG). Furthermore, a soft sensing model called temporal-causal graph convolutional network (TC-GCN) is trained for each phase, by using the time-extended data and the adjacency matrix of TCG. The numerical examples are utilized to validate the proposed CDSS model, and the segmentation results demonstrate that CDSS has excellent performance on segmenting both stable and unstable multiphase series. Especially, it has higher accuracy in separating non-stationary time series compared to other methods. The effectiveness of the proposed CDSS model and the TC-GCN model is also verified through a penicillin fermentation process. Experimental results indicate that the breakpoints discovered by CDSS align well with the reaction mechanisms and TC-GCN significantly has excellent predictive accuracy.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f4b2b1a8bce30a394b4fb8eac0b13365c9a406b2" target='_blank'>
              Causality-driven Sequence Segmentation for Enhancing Multiphase Industrial Process Data Analysis and Soft Sensing
              </a>
            </td>
          <td>
            Yimeng He, Le Yao, Xinmin Zhang, Xiangyin Kong, Zhihuan Song
          </td>
          <td>2024-06-30</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="
 One of the core assumptions of most deep-learning-based data-driven models is that samples are independent. However, this assumption poses a key challenge in production forecasting—performance is influenced by well interference and reservoir connectivity. Most shale gas wells are hydraulically fractured and exist in complex fracture systems, and the neighboring well characteristics should also be considered when constructing data-driven forecast models. Researchers have explored using the graph convolutional network (GCN) to address this issue by incorporating neighboring well characteristics into production forecasting models. However, applying GCN to field-scale studies is problematic, as it requires training on a full batch, leading to gigantic cache allocation. In addition, the transductive nature of GCN poses challenges for direct generalization to unseen nodes. To overcome these limitations, we adopt the graph sampling and aggregation (GraphSAGE) network architecture, which allows training large graphs with batches and generalizing predictions for previously unseen nodes. By utilizing the gated recurrent unit (GRU) network, the proposed spatial-temporal (ST)-GraphSAGE model can capture cross-time relationships between the target and the neighboring wells and generate promising prediction time series for the target wells, even if they are newly drilled wells.
 The proposed approach is validated and tested using the field data from 2,240 Montney shale gas wells, including formation properties, hydraulic fracture parameters, production history, and operational data. The algorithm aggregates the first-hop information to the target node for each timestep. The encoder-decoder (ED) architecture is used to generate forecasts for the subsequent 3-year production rate by using the 1-year production history of the wells. The trained model enables the evaluation of production predictions for newly developed wells at any location. We evaluate the model’s performance using P10, P50, and P90 of the test data set’s root mean square error (RMSE). Our method preserves the topological characteristics of wells and generalizes the prediction to unseen nodes while significantly reducing training complexity, making it applicable to larger data sets. By incorporating information from adjacent wells and integrating ST data, our ST-GraphSAGE model outperforms the traditional GRU-ED model and shows enhanced interpretability.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3acb14c12dea5fe005f993df58cb0487b23127f2" target='_blank'>
              Shale Gas Production Forecasting with Well Interference Based on Spatial-Temporal Graph Convolutional Network
              </a>
            </td>
          <td>
            Ziming Xu, Juliana Y. Leung
          </td>
          <td>2024-07-01</td>
          <td>SPE Journal</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Understanding causal relationships between machines is crucial for fault diagnosis and optimization in manufacturing processes. Real-world datasets frequently exhibit up to 90% missing data and high dimensionality from hundreds of sensors. These datasets also include domain-specific expert knowledge and chronological order information, reflecting the recording order across different machines, which is pivotal for discerning causal relationships within the manufacturing data. However, previous methods for handling missing data in scenarios akin to real-world conditions have not been able to effectively utilize expert knowledge. Conversely, prior methods that can incorporate expert knowledge struggle with datasets that exhibit missing values. Therefore, we propose COKE to construct causal graphs in manufacturing datasets by leveraging expert knowledge and chronological order among sensors without imputing missing data. Utilizing the characteristics of the recipe, we maximize the use of samples with missing values, derive embeddings from intersections with an initial graph that incorporates expert knowledge and chronological order, and create a sensor ordering graph. The graph-generating process has been optimized by an actor-critic architecture to obtain a final graph that has a maximum reward. Experimental evaluations in diverse settings of sensor quantities and missing proportions demonstrate that our approach compared with the benchmark methods shows an average improvement of 39.9% in the F1-score. Moreover, the F1-score improvement can reach 62.6% when considering the configuration similar to real-world datasets, and 85.0% in real-world semiconductor datasets. The source code is available at https://github.com/OuTingYun/COKE.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/01c7381bbb5f5ffdc2ffb14208944e6202b5a8e9" target='_blank'>
              COKE: Causal Discovery with Chronological Order and Expert Knowledge in High Proportion of Missing Manufacturing Data
              </a>
            </td>
          <td>
            Ting-Yun Ou, Ching Chang, Wen-Chih Peng
          </td>
          <td>2024-07-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Long-term time series forecasting is a long-standing challenge in various applications. A central issue in time series forecasting is that methods should expressively capture long-term dependency. Furthermore, time series forecasting methods should be flexible when applied to different scenarios. Although Fourier analysis offers an alternative to effectively capture reusable and periodic patterns to achieve long-term forecasting in different scenarios, existing methods often assume high-frequency components represent noise and should be discarded in time series forecasting. However, we conduct a series of motivation experiments and discover that the role of certain frequencies varies depending on the scenarios. In some scenarios, removing high-frequency components from the original time series can improve the forecasting performance, while in others scenarios, removing them is harmful to forecasting performance. Therefore, it is necessary to treat the frequencies differently according to specific scenarios. To achieve this, we first reformulate the time series forecasting problem as learning a transfer function of each frequency in the Fourier domain. Further, we design Frequency Dynamic Fusion (FreDF), which individually predicts each Fourier component, and dynamically fuses the output of different frequencies. Moreover, we provide a novel insight into the generalization ability of time series forecasting and propose the generalization bound of time series forecasting. Then we prove FreDF has a lower bound, indicating that FreDF has better generalization ability. Extensive experiments conducted on multiple benchmark datasets and ablation studies demonstrate the effectiveness of FreDF.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/180860f60e6655bebc9757b695b4fbc18a0c39ee" target='_blank'>
              Not All Frequencies Are Created Equal:Towards a Dynamic Fusion of Frequencies in Time-Series Forecasting
              </a>
            </td>
          <td>
            Xingyu Zhang, Siyu Zhao, Zeen Song, Huijie Guo, Jianqi Zhang, Changwen Zheng, Wenwen Qiang
          </td>
          <td>2024-07-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="We present working notes for DS@GT team in the eRisk 2024 for Tasks 1 and 3. We propose a ranking system for Task 1 that predicts symptoms of depression based on the Beck Depression Inventory (BDI-II) questionnaire using binary classifiers trained on question relevancy as a proxy for ranking. We find that binary classifiers are not well calibrated for ranking, and perform poorly during evaluation. For Task 3, we use embeddings from BERT to predict the severity of eating disorder symptoms based on user post history. We find that classical machine learning models perform well on the task, and end up competitive with the baseline models. Representation of text data is crucial in both tasks, and we find that sentence transformers are a powerful tool for downstream modeling. Source code and models are available at \url{https://github.com/dsgt-kaggle-clef/erisk-2024}.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ca43005a97c3f1e83533ca7844c05d8888da1f70" target='_blank'>
              DS@GT eRisk 2024: Sentence Transformers for Social Media Risk Assessment
              </a>
            </td>
          <td>
            David Guecha, Aaryan Potdar, Anthony Miyaguchi
          </td>
          <td>2024-07-10</td>
          <td>ArXiv, DBLP</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Visual analytics is essential for studying large time series due to its ability to reveal trends, anomalies, and insights. DeepVATS is a tool that merges Deep Learning (Deep) with Visual Analytics (VA) for the analysis of large time series data (TS). It has three interconnected modules. The Deep Learning module, developed in R, manages the load of datasets and Deep Learning models from and to the Storage module. This module also supports models training and the acquisition of the embeddings from the latent space of the trained model. The Storage module operates using the Weights and Biases system. Subsequently, these embeddings can be analyzed in the Visual Analytics module. This module, based on an R Shiny application, allows the adjustment of the parameters related to the projection and clustering of the embeddings space. Once these parameters are set, interactive plots representing both the embeddings, and the time series are shown. This paper introduces the tool and examines its scalability through log analytics. The execution time evolution is examined while the length of the time series is varied. This is achieved by resampling a large data series into smaller subsets and logging the main execution and rendering times for later analysis of scalability.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4512438def79546a16c0581fc3e2b73339d52b93" target='_blank'>
              Exploring Scalability in Large-Scale Time Series in DeepVATS framework
              </a>
            </td>
          <td>
            Inmaculada Santamaria-Valenzuela, V. Rodríguez-Fernández, David Camacho
          </td>
          <td>2024-08-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="Macroeconomic data are crucial for monitoring countries' performance and driving policy. However, traditional data acquisition processes are slow, subject to delays, and performed at a low frequency. We address this 'ragged-edge' problem with a two-step framework. The first step is a supervised learning model predicting observed low-frequency figures. We propose a neural-network-based nowcasting model that exploits mixed-frequency, high-dimensional data. The second step uses the elasticities derived from the previous step to interpolate unobserved high-frequency figures. We apply our method to nowcast countries' yearly research and development (R&D) expenditure series. These series are collected through infrequent surveys, making them ideal candidates for this task. We exploit a range of predictors, chiefly Internet search volume data, and document the relevance of these data in improving out-of-sample predictions. Furthermore, we leverage the high frequency of our data to derive monthly estimates of R&D expenditures, which are currently unobserved. We compare our results with those obtained from the classical regression-based and the sparse temporal disaggregation methods. Finally, we validate our results by reporting a strong correlation with monthly R&D employment data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/755d4e35574496bb86e54a9124bcf609f8663ce7" target='_blank'>
              Nowcasting R&D Expenditures: A Machine Learning Approach
              </a>
            </td>
          <td>
            Atin Aboutorabi, Gaétan de Rassenfosse
          </td>
          <td>2024-07-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>23</td>
        </tr>

        <tr id="Modeling count-valued time sequences has been receiving growing interests because count time sequences naturally arise in physical and social domains. Poisson gamma dynamical systems (PGDSs) are newly-developed methods, which can well capture the expressive latent transition structure and bursty dynamics behind count sequences. In particular, PGDSs demonstrate superior performance in terms of data imputation and prediction, compared with canonical linear dynamical system (LDS) based methods. Despite these advantages, PGDS cannot capture the heterogeneous overdispersed behaviours of the underlying dynamic processes. To mitigate this defect, we propose a negative-binomial-randomized gamma Markov process, which not only significantly improves the predictive performance of the proposed dynamical system, but also facilitates the fast convergence of the inference algorithm. Moreover, we develop methods to estimate both factor-structured and graph-structured transition dynamics, which enable us to infer more explainable latent structure, compared with PGDSs. Finally, we demonstrate the explainable latent structure learned by the proposed method, and show its superior performance in imputing missing data and forecasting future observations, compared with the related models.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d6fa589fdaa2383d6e9edb62b53fd8d71ec793f5" target='_blank'>
              Negative-Binomial Randomized Gamma Dynamical Systems for Heterogeneous Overdispersed Count Time Sequences
              </a>
            </td>
          <td>
            Rui Huang, Sikun Yang, Heinz Koeppl
          </td>
          <td>2024-08-01</td>
          <td>Proceedings of the Thirty-ThirdInternational Joint Conference on Artificial Intelligence</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="An overview of various open-source Python libraries for time series analysis and forecasting is presented. It covers such tools as Prophet, Kats, Merlion, as well as ARIMA, LSTM algorithms, which allow to study seasonality, trends and anomalies in time series data. The capabilities of each library, their advantages and applications in time series data analysis are discussed in detail.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7bdeb61d1e26117d5e63a3cb3e86b8b03e7303b1" target='_blank'>
              Review of Open-Source Libraries for Solving Time Series Forecasting Problems
              </a>
            </td>
          <td>
            E.A. Svekolnikova, V.N. Panovskiy
          </td>
          <td>2024-07-01</td>
          <td>Моделирование и анализ данных</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Stock price forecasting has been an important area of interest for economists and computer scientists. In addition to traditional statistical methods, advanced artificial intelligence techniques such as machine learning can stand out with their ability to process complex data sets and adapt to historical data. In recent years, hybrid models combining deep learning and time series methods have demonstrated superior performance in stock selection and portfolio optimisation. This study comparatively analyses the performance of LSTM and ARIMA models in time series forecasting. In the study, the stock prices of Oracle company are predicted using two different models, LSTM and ARIMA. Model performance is evaluated using metrics like MSE, MAE, RMSE, and MAPE. Both models have been found to be successful in different metrics. The LSTM model has lower error values; meanwhile, the ARIMA model produced proportionally more accurate forecasts. The study concludes that given the potential offered by deep learning, models such as LSTM are essential for time series forecasting. The flexibility of deep learning allows the development of customized models for different data types and time series problems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7fa13189dabbbc094e6e28d8bc9e13d6f6bccac1" target='_blank'>
              Comparative Analysis of LSTM and ARIMA Models in Stock Price Prediction: A Technology Company Example
              </a>
            </td>
          <td>
            Y. Kırelli
          </td>
          <td>2024-07-30</td>
          <td>Black Sea Journal of Engineering and Science</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Local natural gas distribution companies (LDCs) require accurate demand forecasts across various time periods, geographic regions, and customer class hierarchies. Achieving coherent forecasts across these hierarchies is challenging but crucial for optimal decision making, resource allocation, and operational efficiency. This work introduces a method that structures the gas distribution system into cross-temporal hierarchies to produce accurate and coherent forecasts. We apply our method to a case study involving three operational regions, forecasting at different geographical levels and analyzing both hourly and daily frequencies. Trained on five years of data and tested on one year, our model achieves a 10% reduction in hourly mean absolute scaled error and a 3% reduction in daily mean absolute scaled error.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/737511869f437a80c5594b5ce945f660699fd7a2" target='_blank'>
              Cross-Temporal Hierarchical Forecast Reconciliation of Natural Gas Demand
              </a>
            </td>
          <td>
            Colin O. Quinn, G. Corliss, Richard J. Povinelli
          </td>
          <td>2024-06-21</td>
          <td>Energies</td>
          <td>0</td>
          <td>27</td>
        </tr>

        <tr id="Accurate transfer time prediction and future transfer time information are important for both public transport operators and passengers. However, existing studies cannot effectively manage high-dimensional transfer time data, capture the complex nonlinearity of transfer time, or provide accurate transfer time information. This study provides a reliable prediction model called low-rank Bayesian temporal matrix factorization (LBTMF) to address these challenges. First, on the basis of a high-dimensional spatiotemporal matrix of transfer time data, we develop a low-rank temporal-regularized matrix factorization-based imputation module to capture spatial and temporal characteristics to replace missing transfer time data. Second, to further predict the transfer time with the imputation of missing data, we propose the spatiotemporal-based Bayesian temporal matrix factorization prediction module to recover hourly and daily regular characteristics to predict the transfer time at different metro stations during various periods. Finally, the comprehensive experimental findings suggest that the LBTMF model outperforms other excellent approaches in terms of imputation efficiency, prediction accuracy, and robustness.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3d330ce1319f0da72418d383026426b3a3674268" target='_blank'>
              A Low-Rank Bayesian Temporal Matrix Factorization for the Transfer Time Prediction Between Metro and Bus Systems
              </a>
            </td>
          <td>
            Pan Wu, Mingyang Pei, Tao Wang, Yang Liu, Zhiyuan Liu, Lingshu Zhong
          </td>
          <td>2024-07-01</td>
          <td>IEEE Transactions on Intelligent Transportation Systems</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="The recurring neural network is a deep learning algorithm that is commonly used to develop prediction systems. There are many variants of RNN such as RNN itself, long-short-term memory (LSTM), and gated recurring unit, so it is frequently debatable which algorithm from the RNN family has the most optimal efficiency and computation time. When developing a prediction system, sequential or time series data is required so that an accurate prediction can be made. Sequential or time series data involve data arranged in a time sequence, such as weather data, financial data, carbon emission data, and traffic data recorded over time. This research will be carried out by predicting the three RNN models against historical Bitcoin value data. The research method used is Experimental Design by comparing the performance between the three models on bitcoin value time series data, testing is done by involving hyperparameters such as Tanh, Sigmoid, and ReLU activation functions, batch size, and epochs. The aim of this research is to find out which RNN model can produce the most optimal performance and find out what performance measures can be used to evaluate and compare the performance between the three models. The results of the study show that LSTM is the most effective model with RMSE 0.012441 and MSE 0.000155 but inefficient because it takes 3 minutes 24 seconds to run the computation; in the meantime, the Tanh activation function gives the most optimal prediction than Sigmoid and RelU and therefore should be the main candidate to be used with RNN models when predicting Bitcoin prices.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2db311833b4fea063c64e56f36d23366568c488b" target='_blank'>
              Comparative Analysis of Recurrent Neural Network Models Performance in Predicting Bitcoin Prices
              </a>
            </td>
          <td>
            Zidane Ikkoy Ramadhan, H. Widiputra
          </td>
          <td>2024-06-21</td>
          <td>Jurnal RESTI (Rekayasa Sistem dan Teknologi Informasi)</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id="Accurate traffic flow forecasting is vital for intelligent transportation systems, especially with urbanization worsening traffic congestion, which affects daily life, economic growth, and the environment. Precise forecasts aid in managing and optimizing transportation systems, reducing congestion, and improving air quality by cutting emissions. However, predicting outcomes is difficult due to intricate spatial relationships, nonlinear temporal patterns, and the challenges associated with long-term forecasting. Current research often uses static graph structures, overlooking dynamic and long-range dependencies. To tackle these issues, we introduce the spatiotemporal dynamic multi-hop network (ST-DMN), a Seq2Seq framework. This model incorporates spatiotemporal convolutional blocks (ST-Blocks) with residual connections in the encoder to condense historical traffic data into a fixed-dimensional vector. A dynamic graph represents time-varying inter-segment relationships, and multi-hop operation in the encoder’s spatial convolutional layer and the decoder’s diffusion multi-hop graph convolutional gated recurrent units (DMGCGRUs) capture long-range dependencies. Experiments on two real-world datasets METR-LA and PEMS-BAY show that ST-DMN surpasses existing models in three metrics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a95e1e501ec2f4452c161c53c744ae576c08979c" target='_blank'>
              Spatiotemporal Dynamic Multi-Hop Network for Traffic Flow Forecasting
              </a>
            </td>
          <td>
            Wenguang Chai, Qingfeng Luo, Zhizhe Lin, Jingwen Yan, Jinglin Zhou, Teng Zhou
          </td>
          <td>2024-07-09</td>
          <td>Sustainability</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="Objectives. To build neural network models of time series (LSTM, GRU, RNN) and compare the results of forecasting with their mutual help and the results of standard models (ARIMA, ETS), in order to ascertain in which cases a certain group of models should be used.Methods. The paper provides a review of neural network models and considers the structure of RNN, LSTM, and GRU models. They are used for modeling time series in Russian macroeconomic statistics. The quality of model adjustment to the data and the quality of forecasts are compared experimentally. Neural network and standard models can be used both for the entire series and for its parts (trend and seasonality). When building a forecast for several time intervals in the future, two approaches are considered: building a forecast for the entire interval at once, and step-by-step forecasting. In this way there are several combinations of models that can be used for forecasting. These approaches are analyzed in the computational experiment.Results. Several experiments have been conducted in which standard (ARIMA, ETS, LOESS) and neural network models (LSTM, GRU, RNN) are built and compared in terms of proximity of the forecast to the series data in the test period.Conclusions. In the case of seasonal time series, models based on neural networks surpassed the standard ARIMA and ETS models in terms of forecast accuracy for the test period. The single-step forecast is computationally less efficient than the integral forecast for the entire target period. However, it is not possible to accurately indicate which approach is the best in terms of quality for a given series. Combined models (neural networks for trend, ARIMA for seasonality) almost always give good results. When forecasting a non-seasonal heteroskedastic series of share price, the standard approaches (LOESS method and ETS model) showed the best results.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/18b38c6aa6bc97b32d3a4d813c85a98d07c92494" target='_blank'>
              Neural network analysis in time series forecasting
              </a>
            </td>
          <td>
            B. Pashshoev, D. Petrusevich
          </td>
          <td>2024-08-05</td>
          <td>Russian Technological Journal</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="A dynamic weighted directed graph (DWDG) is commonly encountered in various application scenarios. It involves extensive dynamic interactions among numerous nodes. Most existing approaches explore the intricate temporal patterns hidden in a DWDG from the purely data-driven perspective, which suffers from accuracy loss when a DWDG exhibits strong fluctuations over time. To address this issue, this study proposes a novel Extended-Kalman-Filter-Incorporated Latent Feature (EKLF) model to represent a DWDG from the model-driven perspective. Its main idea is divided into the following two-fold ideas: a) adopting a control model, i.e., the Extended Kalman Filter (EKF), to track the complex temporal patterns precisely with its nonlinear state-transition and observation functions; and b) introducing an alternating least squares (ALS) algorithm to train the latent features (LFs) alternatively for precisely representing a DWDG. Empirical studies on DWDG datasets demonstrate that the proposed EKLF model outperforms state-of-the-art models in prediction accuracy and computational efficiency for missing edge weights of a DWDG. It unveils the potential for precisely representing a DWDG by incorporating a control model.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8a67cf8783fcc0ce6aba4d219506d923562461ab" target='_blank'>
              An Extended Kalman Filter Integrated Latent Feature Model on Dynamic Weighted Directed Graphs
              </a>
            </td>
          <td>
            Hongxun Zhou, Xiangyu Chen, Ye Yuan
          </td>
          <td>2024-07-31</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Time series forecasting plays a crucial role in various fields, including economics, finance, and weather prediction. This study explores the application of time series forecasting techniques to predict future values based on historical data patterns. Different models, such as ARIMA, SARIMA, and exponential smoothing, are commonly employed to capture the underlying trends, seasonality, and irregularities in time series data. The accuracy of the forecasts depends on selecting the appropriate model and fine-tuning its parameters. Regular validation and refinement of the forecasting models are essential to ensure their reliability and adaptability to changing conditions. Overall, time series forecasting serves as a valuable tool for decision-making, resource allocation, and planning in numerous domains. The Autoregressive Integrated Moving Average (ARIMA) model was used in this research to predict Albanian exports. The ARIMA models provided reliable forecasts for the near future and placed more importance on recent observations rather than distant past data. However, a limitation of this study is the lack of using multiple models on new data to improve future forecasts. Considering the significance of exports in Albania, it is crucial to periodically validate and refine the model-building exercises. Based on the findings, the study recommends using the ARIMA (3,2,3) model for forecasting. Furthermore, the forecast errors were statistically tested and validated, confirming the model's strong predictive ability. It is important to note that a forecasting technique that performs well in one situation may not be suitable for another. Therefore, the validation of a specific model should be regularly assessed as time progresses. For the purpose of forecasting the annual exports of Albania, researchers can employ these models.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0d8ae00de95edb0226fad574129969bcb6e56842" target='_blank'>
              FORECASTING EXPORTS IN ALBANIA
              </a>
            </td>
          <td>
            Brikena Sulejmani
          </td>
          <td>2024-07-30</td>
          <td>PEOPLE: International Journal of Social Sciences</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Large Language Models (LLMs) excel in diverse tasks but often underperform in specialized fields due to limited domain-specific or proprietary corpus. Continual pre-training (CPT) enhances LLM capabilities by imbuing new domain-specific or proprietary knowledge while replaying general corpus to prevent catastrophic forgetting. The data mixture ratio of general corpus and domain-specific corpus, however, has been chosen heuristically, leading to sub-optimal training efficiency in practice. In this context, we attempt to re-visit the scaling behavior of LLMs under the hood of CPT, and discover a power-law relationship between loss, mixture ratio, and training tokens scale. We formalize the trade-off between general and domain-specific capabilities, leading to a well-defined Critical Mixture Ratio (CMR) of general and domain data. By striking the balance, CMR maintains the model's general ability and achieves the desired domain transfer, ensuring the highest utilization of available resources. Therefore, if we value the balance between efficiency and effectiveness, CMR can be consider as the optimal mixture ratio.Through extensive experiments, we ascertain the predictability of CMR, and propose CMR scaling law and have substantiated its generalization. These findings offer practical guidelines for optimizing LLM training in specialized domains, ensuring both general and domain-specific performance while efficiently managing training resources.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/fce434329773bdec3deb7e5985c1780492f8cd6f" target='_blank'>
              CMR Scaling Law: Predicting Critical Mixture Ratios for Continual Pre-training of Language Models
              </a>
            </td>
          <td>
            Jiawei Gu, Zacc Yang, Chuanghao Ding, Rui Zhao, Fei Tan
          </td>
          <td>2024-07-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="Learning spatio-temporal patterns of polar ice layers is crucial for monitoring the change in ice sheet balance and evaluating ice dynamic processes. While a few researchers focus on learning ice layer patterns from echogram images captured by airborne snow radar sensors via different convolutional neural networks, the noise in the echogram images proves to be a major obstacle. Instead, we focus on geometric deep learning based on graph neural networks to learn the spatio-temporal patterns from thickness information of shallow ice layers and make predictions for deep layers. In this paper, we propose a physics-informed hybrid graph neural network that combines the GraphSAGE framework for graph feature learning with the long short-term memory (LSTM) structure for learning temporal changes, and introduce measurements of physical ice properties from Model Atmospheric Regional (MAR) weather model as physical node features. We found that our proposed network can consistently outperform the current non-inductive or non-physical model in predicting deep ice layer thickness.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/14283719423d1b3a94963bf3dac91b3889050624" target='_blank'>
              Learning Spatio-Temporal Patterns of Polar Ice Layers With Physics-Informed Graph Neural Network
              </a>
            </td>
          <td>
            Zesheng Liu, Maryam Rahnemoonfar
          </td>
          <td>2024-06-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Temporal data modelling techniques with neural networks are useful in many domain applications, including time-series forecasting and control engineering. This paper aims at developing a recurrent version of stochastic configuration networks (RSCNs) for problem solving, where we have no underlying assumption on the dynamic orders of the input variables. Given a collection of historical data, we first build an initial RSCN model in the light of a supervisory mechanism, followed by an online update of the output weights by using a projection algorithm. Some theoretical results are established, including the echo state property, the universal approximation property of RSCNs for both the offline and online learnings, and the convergence of the output weights. The proposed RSCN model is remarkably distinguished from the well-known echo state networks (ESNs) in terms of the way of assigning the input random weight matrix and a special structure of the random feedback matrix. A comprehensive comparison study among the long short-term memory (LSTM) network, the original ESN, and several state-of-the-art ESN methods such as the simple cycle reservoir (SCR), the polynomial ESN (PESN), the leaky-integrator ESN (LIESN) and RSCN is carried out. Numerical results clearly indicate that the proposed RSCN performs favourably over all of the datasets.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/46e3c55f0b0e77192fb6cc422ecf599a47334d73" target='_blank'>
              Recurrent Stochastic Configuration Networks for Temporal Data Analytics
              </a>
            </td>
          <td>
            Dianhui Wang, Gang Dang
          </td>
          <td>2024-06-21</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>1</td>
        </tr>

        <tr id="Abstract Predicting the strength of promoters and guiding their directed evolution is a crucial task in synthetic biology. This approach significantly reduces the experimental costs in conventional promoter engineering. Previous studies employing machine learning or deep learning methods have shown some success in this task, but their outcomes were not satisfactory enough, primarily due to the neglect of evolutionary information. In this paper, we introduce the Chaos-Attention net for Promoter Evolution (CAPE) to address the limitations of existing methods. We comprehensively extract evolutionary information within promoters using merged chaos game representation and process the overall information with modified DenseNet and Transformer structures. Our model achieves state-of-the-art results on two kinds of distinct tasks related to prokaryotic promoter strength prediction. The incorporation of evolutionary information enhances the model’s accuracy, with transfer learning further extending its adaptability. Furthermore, experimental results confirm CAPE’s efficacy in simulating in silico directed evolution of promoters, marking a significant advancement in predictive modeling for prokaryotic promoter strength. Our paper also presents a user-friendly website for the practical implementation of in silico directed evolution on promoters. The source code implemented in this study and the instructions on accessing the website can be found in our GitHub repository https://github.com/BobYHY/CAPE.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/04f78ff241635d6b984404fb6a2df4fcea90938f" target='_blank'>
              CAPE: a deep learning framework with Chaos-Attention net for Promoter Evolution
              </a>
            </td>
          <td>
            Ruohan Ren, Hongyu Yu, Jiahao Teng, Sihui Mao, Zixuan Bian, Yangtianze Tao, Stephen S.-T. Yau
          </td>
          <td>2024-07-25</td>
          <td>Briefings in Bioinformatics</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="
 Time series data prediction holds a significant importance in various applications. In this study, we specifically concentrate on long-time series data prediction. Recurrent Neural Networks are widely recognized as a fundamental neural network architecture for processing effectively time-series data. Recurrent Neural Network models encounter the gradient disappearance or gradient explosion challenge in long series data. To resolve the gradient problem and improve accuracy, the Fractional Order Lipschitz Recurrent Neural Network (FOLRNN) model is proposed to predict long time series in this paper. The proposed method uses the Lipschitz continuity to alleviate the gradient problem. The fractional order integration is applied to compute the hidden states of the Recurrent Neural Network in the proposed method. The intricate dynamics of long-time series data can be captured by fractional order calculus. It has more accurate predictions compared with Lipschitz Recurrent Neural Networks models. Then self-attention is used to improve feature representation. It can describe the correlation of features and improve predict performance. Some experiments show that the FOLRNN model achieves better results than other methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/50bdbfa75458c6d63dead6aa6573849b191fe2ec" target='_blank'>
              Fractional order Lipschitz recurrent neural network with attention for long time series prediction
              </a>
            </td>
          <td>
            Zelong Zhu, Chunna Zhao, Yaqun Huang
          </td>
          <td>2024-08-01</td>
          <td>Journal of Physics: Conference Series</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="ABSTRACT The rebalancing of bikes and demand prediction at the station level plays a fundamental role in the regular operation and maintenance of bike-sharing systems (BSSs). In this paper, a novel model which incorporates discrete wavelet transform (DWT), autoregressive integrated moving average (ARIMA), and long-short term memory neural network (LSTM NN), is proposed for BSS station-level check-in/out demand prediction. This study adopts the wavelet analysis method to denoise the raw BSS demand series firstly. Then, DWT is developed to decompose the denoised sequence into three high-frequency components (i.e. details) and one low-frequency component (i.e. approximation). ARIMA and LSTM are employed to forecast the detailed components and one approximation component, respectively. The predicted results of each model are reconstructed into the final outputs by DWT. An experiment on a real-world trip dataset showed that the proposed approach consistently outperforms the standard ARIMA model and LSTM model.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d3df2f965dd2a9f63b2f94e55287bae82e6e6b12" target='_blank'>
              Discrete wavelet transform application for bike sharing system check-in/out demand prediction
              </a>
            </td>
          <td>
            Yu Chen, Wei Wang, Xuedong Hua, Weijie Yu, Jialiang Xiao
          </td>
          <td>2024-07-02</td>
          <td>Transportation Letters</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ca70c38270fe1f47a4e82ae81496c70c0e541ccf" target='_blank'>
              Multivariate Bayesian Time-Series Model with Multi-temporal Convolution Network for Forecasting Stock Market During COVID-19 Pandemic
              </a>
            </td>
          <td>
            Paramita Ray, B. Ganguli, Amlan Chakrabarti
          </td>
          <td>2024-06-27</td>
          <td>Int. J. Comput. Intell. Syst.</td>
          <td>0</td>
          <td>13</td>
        </tr>

        <tr id="Evaluating the performance of causal discovery algorithms that aim to find causal relationships between time-dependent processes remains a challenging topic. In this paper, we show that certain characteristics of datasets, such as varsortability (Reisach et al. 2021) and $R^2$-sortability (Reisach et al. 2023), also occur in datasets for autocorrelated stationary time series. We illustrate this empirically using four types of data: simulated data based on SVAR models and Erd\H{o}s-R\'enyi graphs, the data used in the 2019 causality-for-climate challenge (Runge et al. 2019), real-world river stream datasets, and real-world data generated by the Causal Chamber of (Gamella et al. 2024). To do this, we adapt var- and $R^2$-sortability to time series data. We also investigate the extent to which the performance of score-based causal discovery methods goes hand in hand with high sortability. Arguably, our most surprising finding is that the investigated real-world datasets exhibit high varsortability and low $R^2$-sortability indicating that scales may carry a significant amount of causal information.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e3d479da542a4353c2379183fe7b1a2c9e34e919" target='_blank'>
              Sortability of Time Series Data
              </a>
            </td>
          <td>
            Christopher Lohse, Jonas Wahl
          </td>
          <td>2024-07-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="This paper proposes a new self-organizing interval type-2 fuzzy neural network with multiple outputs (SOIT2FNN-MO) for multi-step time series prediction. Differing from the traditional six-layer IT2FNN, a nine-layer network is developed to improve prediction accuracy, uncertainty handling and model interpretability. First, a new co-antecedent layer and a modified consequent layer are devised to improve the interpretability of the fuzzy model for multi-step predictions. Second, a new transformation layer is designed to address the potential issues in the vanished rule firing strength caused by highdimensional inputs. Third, a new link layer is proposed to build temporal connections between multi-step predictions. Furthermore, a two-stage self-organizing mechanism is developed to automatically generate the fuzzy rules, in which the first stage is used to create the rule base from empty and perform the initial optimization, while the second stage is to fine-tune all network parameters. Finally, various simulations are carried out on chaotic and microgrid time series prediction problems, demonstrating the superiority of our approach in terms of prediction accuracy, uncertainty handling and model interpretability.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/966cd74254d10e689fc476d8fb5dfec5e7e234b6" target='_blank'>
              A New Self-organizing Interval Type-2 Fuzzy Neural Network for Multi-Step Time Series Prediction
              </a>
            </td>
          <td>
            Fulong Yao, Wanqing Zhao, Matthew Forshaw, Yang Song
          </td>
          <td>2024-07-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c6f317b12417c129221d4d1696f5c5b193bef61a" target='_blank'>
              Discrete-time graph neural networks for transaction prediction in Web3 social platforms
              </a>
            </td>
          <td>
            Manuel Dileo, Matteo Zignani
          </td>
          <td>2024-06-25</td>
          <td>Mach. Learn.</td>
          <td>0</td>
          <td>15</td>
        </tr>

        <tr id="Generative pretrained models represent a significant advancement in natural language processing and computer vision, which can generate coherent and contextually relevant content based on the pre-training on large general datasets and fine-tune for specific tasks. Building foundation models using large scale omic data is promising to decode and understand the complex signaling language patterns within cells. Different from existing foundation models of omic data, we build a foundation model, mosGraphGPT, for multi-omic signaling (mos) graphs, in which the multi-omic data was integrated and interpreted using a multi-level signaling graph. The model was pretrained using multi-omic data of cancers in The Cancer Genome Atlas (TCGA), and fine-turned for multi-omic data of Alzheimer’s Disease (AD). The experimental evaluation results showed that the model can not only improve the disease classification accuracy, but also is interpretable by uncovering disease targets and signaling interactions. And the model code are uploaded via GitHub with link: https://github.com/mosGraph/mosGraphGPT">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/921061abb7058296f902de2f988608493d126a30" target='_blank'>
              mosGraphGPT: a foundation model for multi-omic signaling graphs using generative AI
              </a>
            </td>
          <td>
            Heming Zhang, Di Huang, Emily Chen, Dekang Cao, Tim Xu, Ben Dizdar, Guangfu Li, Yixin Chen, Philip R. O. Payne, Michael Province, Fuhai Li
          </td>
          <td>2024-08-06</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="The balance between model capacity and generalization has been a key focus of recent discussions in long-term time series forecasting. Two representative channel strategies are closely associated with model expressivity and robustness, including channel independence (CI) and channel dependence (CD). The former adopts individual channel treatment and has been shown to be more robust to distribution shifts, but lacks sufficient capacity to model meaningful channel interactions. The latter is more expressive for representing complex cross-channel dependencies, but is prone to overfitting. To balance the two strategies, we present a channel-aware low-rank adaptation method to condition CD models on identity-aware individual components. As a plug-in solution, it is adaptable for a wide range of backbone architectures. Extensive experiments show that it can consistently and significantly improve the performance of both CI and CD models with demonstrated efficiency and flexibility. The code is available at https://github.com/tongnie/C-LoRA.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/99eb0dde01b9d4215864beae7111853843550b8a" target='_blank'>
              Channel-Aware Low-Rank Adaptation in Time Series Forecasting
              </a>
            </td>
          <td>
            Tong Nie, Yuewen Mei, Guoyang Qin, Jiangming Sun, Wei Ma
          </td>
          <td>2024-07-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="In many situations, the measurements of a studied phenomenon are provided sequentially, and the prediction of its class needs to be made as early as possible so as not to incur too high a time penalty, but not too early and risk paying the cost of misclassification. This problem has been particularly studied in the case of time series, and is known as Early Classification of Time Series (ECTS). Although it has been the subject of a growing body of literature, there is still a lack of a systematic, shared evaluation protocol to compare the relative merits of the various existing methods. This document begins by situating these methods within a principle-based taxonomy. It defines dimensions for organizing their evaluation, and then reports the results of a very extensive set of experiments along these dimensions involving nine state-of-the art ECTS algorithms. In addition, these and other experiments can be carried out using an open-source library in which most of the existing ECTS algorithms have been implemented (see \url{https://github.com/ML-EDM/ml_edm}).">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b398a7a69b9500f231044e06baa20805f2eb5afd" target='_blank'>
              Early Classification of Time Series: Taxonomy and Benchmark
              </a>
            </td>
          <td>
            Aurélien Renault, A. Bondu, Antoine Cornu'ejols, Vincent Lemaire
          </td>
          <td>2024-06-26</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="This paper presents a new method to determine the optimal batch size for applying deep learning models with time series data. A set of batch sizes is determined by considering the length of the repetition pattern of the data using the Fast Fourier Transform (FFT). A comparative analysis is conducted to identify the impact of varying batch sizes on prediction errors for the three deep learning models. The results show that the RNN model has the optimal batch size that produces the minimum prediction error. In the DNN and CNN models, the optimal batch size is not correlated with the repetition pattern of time series data. Therefore, it is not recommended to apply CNN and DNN models of time series data. However, if used, a small batch size can be selected to reduce training time. In addition, the range of prediction error according to batch size is significantly larger for RNN models compared to DNN and CNN models.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d1d9bac2cd18ff1641bc3ec0c44bcff2270a3253" target='_blank'>
              Determination of Optimal Batch Size of Deep Learning Models with Time Series Data
              </a>
            </td>
          <td>
            J. Hwang, Sang-Soo Lee, Jeong-Won Gil, Choul-Ki Lee
          </td>
          <td>2024-07-12</td>
          <td>Sustainability</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="In the financial industry, the ability to predict financial metrics accurately and in a timely manner can significantly impact investment decisions, risk management, and strategic planning. In recent years, machine learning has emerged as a powerful tool for such predictions. This study aims to explore the heretofore underexplored predictive potential of ChatGPT by predicting positive or negative changes in quarterly financial metrics, such as revenue and sales numbers, using textual data from social media. The performance of ChatGPT is compared against Long Short-Term Memory (LSTM) neural network models developed as part of this research. The methodology involves preprocessing large datasets from Twitter concerning major companies such as Amazon, Google, and Tesla, training LSTM models, and prompt engineering for ChatGPT-based predictions. Initial findings indicate that LSTM models can predict quarterly financial metric changes with up to 87% accuracy, significantly outperforming ChatGPT, which achieves a maximum accuracy of 67%. Therefore, at the current time, ChatGPT cannot be considered a reliable predictive tool for changes in quarterly financial metrics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8b4e2a6ac5ac0110e5991ee0a5cd2260ead16e09" target='_blank'>
              Comparing ChatGPT And LSTM In Predicting Changes In Quarterly Financial Metrics
              </a>
            </td>
          <td>
            Vitali Chaiko
          </td>
          <td>2024-06-30</td>
          <td>Business &amp; Management Compass</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Capturing long-term dependency from historical behaviors is the key to the success of sequential recommendation; however, existing methods focus on extracting global sequential information while neglecting to obtain deep representations from subsequences. Previous research has revealed that the restricted inter-item transfer is fundamental to sequential modeling, and some potential substructures of sequences can help models learn more effective long-term dependency compared to the whole sequence. To automatically find better subsequences and perform efficient learning, we propose a sequential recommendation model with a gated recurrent unit and Transformers, abbreviated as GAT4Rec, which employs Transformers with shared parameters across layers to model users’ historical interaction sequences. The representation learned by the gated recurrent unit is used as the gating signal to identify the optimal substructure in user sequences. The fused representation of the subsequence and edge information is extracted by the encoding layer to make the corresponding recommendations. Experimental results on four well-known publicly available datasets demonstrate that our GAT4Rec model outperforms other recommendation models, achieving performance improvements of 5.77%, 1.35%, 11.58%, and 1.79% in the normalized discounted cumulative gain metric (NDCG@10), respectively.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/79a52d00fb976862ea5711ed640577ec503068bd" target='_blank'>
              GAT4Rec: Sequential Recommendation with a Gated Recurrent Unit and Transformers
              </a>
            </td>
          <td>
            Huaiwen He, Xiangdong Yang, Feng Huang, Feng Yi, Shangsong Liang
          </td>
          <td>2024-07-12</td>
          <td>Mathematics</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="The prediction of vacant parking spaces (VPSs) can reduce the time drivers spend searching for parking, thus alleviating traffic congestion. However, previous studies have mostly focused on modeling the temporal features of VPSs using historical data, neglecting the complex and extensive spatial characteristics of different parking lots within the transportation network. This is mainly due to the lack of direct physical connections between parking lots, making it challenging to quantify the spatio-temporal features among them. To address this issue, we propose a dynamic spatio-temporal adaptive graph convolutional recursive network (DSTAGCRN) for VPS prediction. Specifically, DSTAGCRN divides VPS data into seasonal and periodic trend components and combines daily and weekly information with node embeddings using the dynamic parameter-learning module (DPLM) to generate dynamic graphs. Then, by integrating gated recurrent units (GRUs) with the parameter-learning graph convolutional recursive module (PLGCRM) of DPLM, we infer the spatio-temporal dependencies for each time step. Furthermore, we introduce a multihead attention mechanism to effectively capture and fuse the spatio-temporal dependencies and dynamic changes in the VPS data, thereby enhancing the prediction performance. Finally, we evaluate the proposed DSTAGCRN on three real parking datasets. Extensive experiments and analyses demonstrate that the DSTAGCRN model proposed in this study not only improves the prediction accuracy but can also better extract the dynamic spatio-temporal characteristics of available parking space data in multiple parking lots.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/eca0d5f95593149c00ab5b7ac8b7112a781351ba" target='_blank'>
              Dynamic Spatio-Temporal Adaptive Graph Convolutional Recurrent Networks for Vacant Parking Space Prediction
              </a>
            </td>
          <td>
            Liangpeng Gao, Wenli Fan, Wenliang Jian
          </td>
          <td>2024-07-07</td>
          <td>Applied Sciences</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="In this paper, we explore advanced modifications to the Tweedie regression model in order to address its limitations in modeling aggregate claims for various types of insurance such as automobile, health, and liability. Traditional Tweedie models, while effective in capturing the probability and magnitude of claims, usually fall short in accurately representing the large incidence of zero claims. Our recommended approach involves a refined modeling of the zero-claim process, together with the integration of boosting methods in order to help leverage an iterative process to enhance predictive accuracy. Despite the inherent slowdown in learning algorithms due to this iteration, several efficient implementation techniques that also help precise tuning of parameter like XGBoost, LightGBM, and CatBoost have emerged. Nonetheless, we chose to utilize CatBoost, a efficient boosting approach that effectively handles categorical and other special types of data. The core contribution of our paper is the assembly of separate modeling for zero claims and the application of tree-based boosting ensemble methods within a CatBoost framework, assuming that the inflated probability of zero is a function of the mean parameter. The efficacy of our enhanced Tweedie model is demonstrated through the application of an insurance telematics dataset, which presents the additional complexity of compositional feature variables. Our modeling results reveal a marked improvement in model performance, showcasing its potential to deliver more accurate predictions suitable for insurance claim analytics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5af74d76d784bacfe974c20112cdcad54eedeb64" target='_blank'>
              Zero-Inflated Tweedie Boosted Trees with CatBoost for Insurance Loss Analytics
              </a>
            </td>
          <td>
            Banghee So, Emiliano A. Valdez
          </td>
          <td>2024-06-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>27</td>
        </tr>

        <tr id="Industrial processes generate vast amounts of time series data, yet extracting meaningful relationships and insights remains challenging. This paper introduces a framework for automated knowledge graph learning from time series data, specifically tailored for industrial applications. Our framework addresses the complexities inherent in industrial datasets, transforming them into knowledge graphs that improve decision-making, process optimization, and knowledge discovery. Additionally, it employs Granger causality to identify key attributes that can inform the design of predictive models. To illustrate the practical utility of our approach, we also present a motivating use case demonstrating the benefits of our framework in a real-world industrial scenario. Further, we demonstrate how the automated conversion of time series data into knowledge graphs can identify causal influences or dependencies between important process parameters.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/97316fa9b00e993db090c916509994ba4b2d0b70" target='_blank'>
              Automated Knowledge Graph Learning in Industrial Processes
              </a>
            </td>
          <td>
            Lolitta Ammann, Jorge Martínez Gil, Michael Mayr, Georgios C. Chasparis
          </td>
          <td>2024-07-02</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="Time series data is widely available in a variety of industries. By forecasting time series, decision-makers can better grasp future trends and make more effective decisions. Financial time series data exhibit non-stationarity and high volatility. High-frequency fluctuations in financial products such as exchange rates, bonds and equities may reflect external shocks and risks in global financial markets, which are potentially dangerous and may threaten national economic security or even trigger financial crises. For financial time series data, a deep recurrent neural network first progressively processes each data point in the time series through its recurrent unit. Each recurring unit can adjust its own weights to better predict or analyze future values. Over time, these recurrent units continuously update their internal state, resulting in a comprehensive understanding of the characteristics of the entire data sequence. In addition, we add a gating mechanism to further improve the network's ability to control the flow of information, so that the model is more effective when retaining long-term dependencies, so as to improve the accuracy of prediction and the stability of the model. Experimental results show that our recurrent neural network model shows higher prediction accuracy and stability than other baseline models on financial time series datasets.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6f5f866e6e62fae9396ebd199496590a68d45ac8" target='_blank'>
              Research on time-series financial data prediction and analysis based on deep recurrent neural network
              </a>
            </td>
          <td>
            Feng Yuan
          </td>
          <td>2024-07-25</td>
          <td>Applied and Computational Engineering</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Graph data structures offer a versatile and powerful means to model relationships and interconnections in various domains, promising substantial advantages in data representation, analysis, and visualization. In games, graph-based data structures are omnipresent and represent, for example, game economies, skill trees or complex, branching quest lines. With this paper, we propose G-PCGRL, a novel and controllable method for the procedural generation of graph data using reinforcement learning. Therefore, we frame this problem as manipulating a graph's adjacency matrix to fulfill a given set of constraints. Our method adapts and extends the Procedural Content Generation via Reinforcement Learning (PCGRL) framework and introduces new representations to frame the problem of graph data generation as a Markov decision process. We compare the performance of our method with the original PCGRL, the run time with a random search and evolutionary algorithm, and evaluate G-PCGRL on two graph data domains in games: game economies and skill trees. The results show that our method is capable of generating graph-based content quickly and reliably to support and inspire designers in the game creation process. In addition, trained models are controllable in terms of the type and number of nodes to be generated.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/da8186d9c837b3b5140555e1d9904967ed9b8441" target='_blank'>
              G-PCGRL: Procedural Graph Data Generation via Reinforcement Learning
              </a>
            </td>
          <td>
            Florian Rupp, Kai Eckert
          </td>
          <td>2024-07-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="This paper introduces a new addition to the SPINEX (Similarity-based Predictions with Explainable Neighbors Exploration) family, tailored specifically for time series and forecasting analysis. This new algorithm leverages the concept of similarity and higher-order temporal interactions across multiple time scales to enhance predictive accuracy and interpretability in forecasting. To evaluate the effectiveness of SPINEX, we present comprehensive benchmarking experiments comparing it against 18 algorithms and across 49 synthetic and real datasets characterized by varying trends, seasonality, and noise levels. Our performance assessment focused on forecasting accuracy and computational efficiency. Our findings reveal that SPINEX consistently ranks among the top 5 performers in forecasting precision and has a superior ability to handle complex temporal dynamics compared to commonly adopted algorithms. Moreover, the algorithm's explainability features, Pareto efficiency, and medium complexity (on the order of O(log n)) are demonstrated through detailed visualizations to enhance the prediction and decision-making process. We note that integrating similarity-based concepts opens new avenues for research in predictive analytics, promising more accurate and transparent decision making.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/eb8311e78efe8332c0928c44bc76694e1d771836" target='_blank'>
              SPINEX-TimeSeries: Similarity-based Predictions with Explainable Neighbors Exploration for Time Series and Forecasting Problems
              </a>
            </td>
          <td>
            Ahmed Z Naser, MZ Naser
          </td>
          <td>2024-08-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Inventory prediction is concerned with the forecasting of future demand for products in order to optimize inventory levels and supply chain management. The challenges include demand volatility, data quality, multi-dimensional interactions, lead time variability, seasonal trends, and dynamic pricing. Nevertheless, these models suffer from numerous shortcomings, and in this research, we propose a new model, MMCW-BiLSTM (modified multi-dimensional collaboratively wrapped BiLSTM), for inventory prediction. The MMCW-BiLSTM model reflects a considerable leap in inventory forecasting by combining a number of components in order to consider intricate temporal dependencies and incorporate feature interactions. The MMCW-BiLSTM makes use of BiLSTM layers, collaborative attention mechanisms, and a multi-dimensional attention approach to learn from augmented datasets consisting of the original features and the extracted time series data. Moreover, adding a Taylor series transformation allows for a more precise description of the features in the model, thus improving the prediction precision. The results show that the models make the least mistakes when they use the AV demand forecasting dataset, with MAE values of 1.75, MAPE values of 2.89, MSE values of 6.76, and RMSE values of 2.6. Similarly, when utilizing the product demand dataset, the model also achieves the lowest error values for these metrics at 1.97, 3.91, 8.76, and 2.96. Likewise, when utilizing the dairy goods sales dataset, the model also achieves the lowest error values for these metrics at 2.54, 3.69, 10.39, and 3.22.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/cccb2c220a6df8c844c4317f0b7f000d6fa902b8" target='_blank'>
              Inventory Prediction Using a Modified Multi-Dimensional Collaborative Wrapped Bi-Directional Long Short-Term Memory Model
              </a>
            </td>
          <td>
            Said Abualuroug, A. Alzubi, Kolawole Iyiola
          </td>
          <td>2024-07-03</td>
          <td>Applied Sciences</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Dynamic multi-objective optimization problems (DMOPs) exhibit variations in constraints, decision parameter quantities, and the number of objectives over time, leading to changes in their optimal solutions. Prediction-based methods currently stand as the prevailing paradigm for handling DMOPs. Implicit correlations among solutions ob-tained at consecutive time steps while solving DMOPs con-tinuously can guide predictions for future time increments in the time series. Most existing methods rely on a single linear or nonlinear model to capture the correlations of historical optimal solutions. However, a linear model struggles with the nonlinear scenario, and using a nonlinear model to fit the linear relationship of the historical optimal solutions increases the training time because the nonlinear model has more parameters. This paper proposes a novel framework for time series ensemble prediction based on correlation type detection TSEPFCTD. The framework leverages correlation type detection strategy to identify the autocorrelation types in the time series of historical solutions. Subsequently, distinct prediction models are applied for different types, enhancing prediction accuracy. We implement this prediction framework on MOEA/D-DE, constructing a novel algorithm for solving DMOPs. Experimental results on a series of test suites demonstrate the effectiveness of our algorithm in providing robust solution outcomes.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3ecb29b1ac7c61b9f51aefcec3ff68083f359042" target='_blank'>
              Dynamic Multi-Objective Optimization Time Series Ensemble Prediction Framework Based on Correlation Type Detection
              </a>
            </td>
          <td>
            Lele Xie, Xiaoming Zhang, Ran Hu, Shun Zhang
          </td>
          <td>2024-06-30</td>
          <td>2024 IEEE Congress on Evolutionary Computation (CEC)</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Unsupervised Domain Adaptation (UDA) has emerged as a key solution in data-driven fault diagnosis, addressing domain shift where models underperform in changing environments. However, under the realm of continually changing environments, UDA tends to underperform on previously seen domains when adapting to new ones - a problem known as catastrophic forgetting. To address this limitation, we introduce the EverAdapt framework, specifically designed for continuous model adaptation in dynamic environments. Central to EverAdapt is a novel Continual Batch Normalization (CBN), which leverages source domain statistics as a reference point to standardize feature representations across domains. EverAdapt not only retains statistical information from previous domains but also adapts effectively to new scenarios. Complementing CBN, we design a class-conditional domain alignment module for effective integration of target domains, and a Sample-efficient Replay strategy to reinforce memory retention. Experiments on real-world datasets demonstrate EverAdapt superiority in maintaining robust fault diagnosis in dynamic environments. Our code is available: https://github.com/mohamedr002/EverAdapt">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0ac47f70a5e647f647faa7b42263e7b8c29cd85a" target='_blank'>
              EverAdapt: Continuous Adaptation for Dynamic Machine Fault Diagnosis Environments
              </a>
            </td>
          <td>
            Edward, Mohamed Ragab, Yuecong Xu, Min Wu, Zhenghua Chen, Abdulla Alseiari, Xiaoli Li
          </td>
          <td>2024-07-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>37</td>
        </tr>

        <tr id="As a pivotal component of the global economic system, the stock market is subject to a multitude of influences, including the macroeconomic environment, market sentiment, and policy changes. Consequently, the ability to forecast stock prices is of paramount importance. Conventional time series forecasting techniques, such asARIMA and GARCH, are ill-equipped to handle complex nonlinear relationships. In contrast, recurrent neural networks, particularly Long Short-Term Memory (LSTM) networks, are particularly adept at handling time-dependent data. In light of recent advances in machine learning and deep learning, this study aims to assess and compare the efficacy of LSTM neural networks and Informer models in stock price forecasting. The objectives of this research are twofold: first, to compare the prediction accuracy using metrics such as Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and R²; and second, to explore fusion strategies to enhance overall prediction performance and computational efficiency. The methodology includes the following steps: data collection and preprocessing, model construction, feature engineering, and model training and evaluation. This study presents a systematic comparison of the effectiveness of LSTM and Informer models in stock price prediction. The findings indicate that a fusion strategy combining the advantages of both models is expected to enhance prediction accuracy and computational efficiency.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1bbcb0bc1d7ecdbcbdff3b237621c2e470bbdce1" target='_blank'>
              Advanced Stock Price Prediction Using LSTM and Informer Models
              </a>
            </td>
          <td>
            Chuyang Duan, Wenjun Ke
          </td>
          <td>2024-06-27</td>
          <td>Journal of Artificial Intelligence General science (JAIGS) ISSN:3006-4023</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Time series classification stands as a pivotal and intricate challenge across various domains, including finance, healthcare, and industrial systems. In contemporary research, there has been a notable upsurge in exploring feature extraction through random sampling. Unlike deep convolutional networks, these methods sidestep elaborate training procedures, yet they often necessitate generating a surplus of features to comprehensively encapsulate time series nuances. Consequently, some features may lack relevance to labels or exhibit multi-collinearity with others. In this paper, we propose a novel hierarchical feature selection method aided by ANOVA variance analysis to address this challenge. Through meticulous experimentation, we demonstrate that our method substantially reduces features by over 94% while preserving accuracy -- a significant advancement in the field of time series analysis and feature selection.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5c07ba99c8d7ae5a1590ce850bbbbc596fbc4609" target='_blank'>
              HIERVAR: A Hierarchical Feature Selection Method for Time Series Analysis
              </a>
            </td>
          <td>
            Alireza Keshavarzian, S. Valaee
          </td>
          <td>2024-07-22</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>44</td>
        </tr>

        <tr id="We developed DyGETViz, a novel framework for effectively visualizing dynamic graphs (DGs) that are ubiquitous across diverse real-world systems. This framework leverages recent advancements in discrete-time dynamic graph (DTDG) models to adeptly handle the temporal dynamics inherent in dynamic graphs. DyGETViz effectively captures both micro- and macro-level structural shifts within these graphs, offering a robust method for representing complex and massive dynamic graphs. The application of DyGETViz extends to a diverse array of domains, including ethology, epidemiology, finance, genetics, linguistics, communication studies, social studies, and international relations. Through its implementation, DyGETViz has revealed or confirmed various critical insights. These include the diversity of content sharing patterns and the degree of specialization within online communities, the chronological evolution of lexicons across decades, and the distinct trajectories exhibited by aging-related and non-related genes. Importantly, DyGETViz enhances the accessibility of scientific findings to non-domain experts by simplifying the complexities of dynamic graphs. Our framework is released as an open-source Python package for use across diverse disciplines. Our work not only addresses the ongoing challenges in visualizing and analyzing DTDG models but also establishes a foundational framework for future investigations into dynamic graph representation and analysis across various disciplines.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/09cb3de3028ed37e10c48ae40a5a59f3c2e8d14c" target='_blank'>
              Empowering Interdisciplinary Insights with Dynamic Graph Embedding Trajectories
              </a>
            </td>
          <td>
            Yiqiao Jin, Andrew Zhao, Yeon-Chang Lee, Meng Ye, Ajay Divakaran, Srijan Kumar
          </td>
          <td>2024-06-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Learning effective representations for Continuous-Time Dynamic Graphs (CTDGs) has garnered significant research interest, largely due to its powerful capabilities in modeling complex interactions between nodes. A fundamental and crucial requirement for representation learning in CTDGs is the appropriate estimation and preservation of proximity. However, due to the sparse and evolving characteristics of CTDGs, the spatial-temporal properties inherent in high-order proximity remain largely unexplored. Despite its importance, this property presents significant challenges due to the computationally intensive nature of personalized interaction intensity estimation and the dynamic attributes of CTDGs. To this end, we propose a novel Correlated Spatial-Temporal Positional encoding that incorporates a parameter-free personalized interaction intensity estimation under the weak assumption of the Poisson Point Process. Building on this, we introduce the Dynamic Graph Transformer with \Correlated Spatial-Temporal Positional Encoding (CorDGT), which efficiently retains the evolving spatial-temporal high-order proximity for effective node representation learning in CTDGs. Extensive experiments on seven small and two large-scale datasets demonstrate the superior performance and scalability of the proposed CorDGT.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ca3d24ba002ecd938e42d65b10b2f394232325dd" target='_blank'>
              Dynamic Graph Transformer with Correlated Spatial-Temporal Positional Encoding
              </a>
            </td>
          <td>
            Zhe Wang, Sheng Zhou, Jiawei Chen, Zhen Zhang, Binbin Hu, Yan Feng, Chun Chen, Can Wang
          </td>
          <td>2024-07-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>18</td>
        </tr>

        <tr id="This study addresses the prediction of CAN bus data, a lesser-explored aspect within unsupervised anomaly detection research. We propose the Fast-Gated Attention (FGA) Transformer, a novel approach designed for accurate and efficient prediction of CAN bus data. This model utilizes a cross-attention window to optimize computational scale and feature extraction, a gated single-head attention mechanism in place of multi-head attention, and shared parameters to minimize model size. Additionally, a generalized unbiased linear attention approximation technique speeds up attention block computation. On three datasets—Car-Hacking, SynCAN, and Automotive Sensors—the FGA Transformer achieves predicted root mean square errors of 1.86 × 10−3, 3.03 × 10−3, and 30.66 × 10−3, with processing speeds of 2178, 2768, and 3062 frames per second, respectively. The FGA Transformer provides the best or comparable accuracy with a speed improvement ranging from 6 to 170 times over existing methods, underscoring its potential for CAN bus data prediction.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/29ae49c10fdafb110a22645dbea2e2c775a56ed9" target='_blank'>
              A Multivariate Time Series Prediction Method for Automotive Controller Area Network Bus Data
              </a>
            </td>
          <td>
            Dan Yang, Shuya Yang, Junsuo Qu, Ke Wang
          </td>
          <td>2024-07-10</td>
          <td>Electronics</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Predictive analytics with machine learning approaches has widely penetrated and shown great success in system health management over the decade. However, how to convert the prediction to an actionable plan for maintenance is still far from mature. This study investigates how to narrow the gapbetween predictive outcomes and prescriptive descriptions for system maintenance using an agentic approach based on the large language model (LLM). Additionally, with the retrieval-augmented generation (RAG) technique and tool usage capability, the LLM can be context-aware when making decisions in maintenance strategy proposals considering predictions from machine learning. In this way, the proposed method can push forward the boundary of current machine-learning methods from a predictor to an advisor for decision-making workload offload. For verification, a case study on linear actuator fault diagnosis is conducted with the GPT-4 model. The result demonstrates that the proposed method can perform fault detection without extra training or fine-tuning with comparable performance to baseline methods and deliver more informatic diagnosis analysis and suggestions. This research can shed light on the application of large language models in the construction of versatile and flexible artificial intelligence agents for maintenance tasks.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/40776e2aba7dd99d2dadc993e370a0592a750cb3" target='_blank'>
              From Prediction to Prescription: Large Language Model Agent for Context-Aware Maintenance Decision Support
              </a>
            </td>
          <td>
            Haoxuan Deng, Bernadin Namoano, Bohao Zheng, Samir Khan, John Ahmet Erkoyuncu
          </td>
          <td>2024-06-27</td>
          <td>PHM Society European Conference</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Building prediction intervals for time series forecasting problems presents a complex challenge, particularly when relying solely on point predictors, a common scenario for practitioners in the industry. While research has primarily focused on achieving increasingly efficient valid intervals, we argue that, when evaluating a set of intervals, traditional measures alone are insufficient. There are additional crucial characteristics: the intervals must vary in length, with this variation directly linked to the difficulty of the prediction, and the coverage of the interval must remain independent of the difficulty of the prediction for practical utility. We propose the Heteroscedastic Quantile Regression (HQR) model and the Width-Adaptive Conformal Inference (WACI) method, providing theoretical coverage guarantees, to overcome those issues, respectively. The methodologies are evaluated in the context of Electricity Price Forecasting and Wind Power Forecasting, representing complex scenarios in time series forecasting. The results demonstrate that HQR and WACI not only improve or achieve typical measures of validity and efficiency but also successfully fulfil the commonly ignored mentioned characteristics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9c18bfd83fa9808cc2d8310863d5b8bcc05f3b70" target='_blank'>
              Enhancing reliability in prediction intervals using point forecasters: Heteroscedastic Quantile Regression and Width-Adaptive Conformal Inference
              </a>
            </td>
          <td>
            Carlos Sebasti'an, Carlos E. Gonz'alez-Guill'en, Jes'us Juan
          </td>
          <td>2024-06-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="In recent years, deep learning has increasingly gained attention in the field of traffic prediction. Existing traffic prediction models often rely on GCNs or attention mechanisms with O(N^2) complexity to dynamically extract traffic node features, which lack efficiency and are not lightweight. Additionally, these models typically only utilize historical data for prediction, without considering the impact of the target information on the prediction. To address these issues, we propose a Pattern-Matching Dynamic Memory Network (PM-DMNet). PM-DMNet employs a novel dynamic memory network to capture traffic pattern features with only O(N) complexity, significantly reducing computational overhead while achieving excellent performance. The PM-DMNet also introduces two prediction methods: Recursive Multi-step Prediction (RMP) and Parallel Multi-step Prediction (PMP), which leverage the time features of the prediction targets to assist in the forecasting process. Furthermore, a transfer attention mechanism is integrated into PMP, transforming historical data features to better align with the predicted target states, thereby capturing trend changes more accurately and reducing errors. Extensive experiments demonstrate the superiority of the proposed model over existing benchmarks. The source codes are available at: https://github.com/wengwenchao123/PM-DMNet.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/27093b45b377c53bb3e2360dcde0bd4cae7da8df" target='_blank'>
              Pattern-Matching Dynamic Memory Network for Dual-Mode Traffic Prediction
              </a>
            </td>
          <td>
            Wenchao Weng, Mei Wu, Hanyu Jiang, Wanzeng Kong, Xiangjie Kong, Feng Xia
          </td>
          <td>2024-08-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>42</td>
        </tr>

        <tr id="Fuzzy neural network (FNN) is regarded as a prominent approach in application of time-series modeling. With the capability of fuzzy reasoning, FNN can capture temporal patterns from the time-series samples. However, the existing FNNs may suffer from the temporal pattern distortion because possibly multiscale features cannot be explored sufficiently. To address this problem, a time-aware fuzzy neural network, based on the frequency-enhanced modulation mechanism (FEM-TAFNN), is developed for time-series prediction in this article. First, a Fourier-based decoder is established to extract the multiscale features. This decoder employs the frequency-domain model to orthogonally separate the time-scale features with different frequencies into independent temporal patterns based on the Fourier basis, which prevents the overlap of temporal patterns using time-domain analysis. Second, a frequency-enhanced modulation mechanism is designed to shape fuzzy rules of FNN based on the contribution of different temporal patterns in the frequency spectrum. It enables FEM-TAFNN to modulate out the realistic multiscale temporal patterns. Finally, the proposed FEM-TAFNN is tested on four multiscale time-series datasets. The empirical results confirm its superior prediction performance than other methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ce803c3df8b377a910569d38f5c6288c1fad84ce" target='_blank'>
              Time-Aware Fuzzy Neural Network Based on Frequency-Enhanced Modulation Mechanism
              </a>
            </td>
          <td>
            Hong-gui Han, Zecheng Tang, Xiaolong Wu, Hongyan Yang, Jun-Li Qiao
          </td>
          <td>2024-08-01</td>
          <td>IEEE Transactions on Fuzzy Systems</td>
          <td>0</td>
          <td>40</td>
        </tr>

        <tr id="Forecast reconciliation has become a prominent topic in recent forecasting literature, with a primary distinction made between cross-sectional and temporal hierarchies. This work focuses on temporal hierarchies, such as aggregating monthly time series data to annual data. We explore the impact of various forecast reconciliation methods on temporally aggregated ARIMA models, thereby bridging the fields of hierarchical forecast reconciliation and temporal aggregation both theoretically and experimentally. Our paper is the first to theoretically examine the effects of temporal hierarchical forecast reconciliation, demonstrating that the optimal method aligns with a bottom-up aggregation approach. To assess the practical implications and performance of the reconciled forecasts, we conduct a series of simulation studies, confirming that the findings extend to more complex models. This result helps explain the strong performance of the bottom-up approach observed in many prior studies. Finally, we apply our methods to real data examples, where we observe similar results.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/985e5918331ffab3f0ab26045d8e9e749f6655c6" target='_blank'>
              Rediscovering Bottom-Up: Effective Forecasting in Temporal Hierarchies
              </a>
            </td>
          <td>
            Lukas Neubauer, Peter Filzmoser
          </td>
          <td>2024-07-02</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="In an era where machine learning permeates every facet of human existence, and data evolves incessantly, the application of machine learning models transcends mere data processing. It involves navigating constant changes exemplified by the phenomenon of concept drift, which often affects model performance.

These drifts can be recurrent due to the cyclic nature of the underlying data generation processes, which could be influenced by recurrent phenomena such as weather and time of the day. 

Stream Learning on data streams with recurrent concept drifts attempts to learn from such streams of data.

The survey underscores the significance of the field and its practical applications, delving into nuanced definitions of machine learning for data streams afflicted by recurrent concept drifts. It explores diverse methodological approaches, elucidating their key design components. Additionally, it examines various evaluation techniques, benchmark datasets, and available software tailored for simulating and analysing data streams with recurrent concept drifts. Concluding, the survey offers insights into potential avenues for future research in the field.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/cf06b11f144b00a4ce791a494e6563e109b2d5e9" target='_blank'>
              Recurrent Concept Drifts on Data Streams
              </a>
            </td>
          <td>
            N. Gunasekara, Bernhard Pfahringer, Heitor Murilo Gomes, A. Bifet, Yun Sing Koh
          </td>
          <td>2024-08-01</td>
          <td>Proceedings of the Thirty-ThirdInternational Joint Conference on Artificial Intelligence</td>
          <td>0</td>
          <td>50</td>
        </tr>

        <tr id="Deep learning (DL) has been widely applied to forecast the sales volume of household appliances with high accuracy. Unfortunately, in small towns, due to the limited amount of historical sales data, it is difficult to forecast household appliance sales accurately. To overcome the above-mentioned challenge, we propose a novel household appliance sales forecasting algorithm based on transfer learning, temporal convolutional network (TCN), long short-term memory (LSTM), and attention mechanism (called “TransTLA”). Firstly, we combine TCN and LSTM to exploit the spatiotemporal correlation of sales data. Secondly, we utilize the attention mechanism to make full use of the features of sales data. Finally, in order to mitigate the impact of data scarcity and regional differences, a transfer learning technique is used to improve the predictive performance in small towns, with the help of the learning experience from the megacity. The experimental outcomes reveal that the proposed TransTLA model significantly outperforms traditional forecasting methods in predicting small town household appliance sales volumes. Specifically, TransTLA achieves an average mean absolute error (MAE) improvement of 27.60% over LSTM, 9.23% over convolutional neural networks (CNN), and 11.00% over the CNN-LSTM-Attention model across one to four step-ahead predictions. This study addresses the data scarcity problem in small town sales forecasting, helping businesses improve inventory management, enhance customer satisfaction, and contribute to a more efficient supply chain, benefiting the overall economy.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0b9ca38d56c22558ee1fb94ba33b348585bf6d14" target='_blank'>
              TransTLA: A Transfer Learning Approach with TCN-LSTM-Attention for Household Appliance Sales Forecasting in Small Towns
              </a>
            </td>
          <td>
            Zhijie Huang, Jianfeng Liu
          </td>
          <td>2024-07-28</td>
          <td>Applied Sciences</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1e7d935a1fd72ec0c78f76e9366ac22a96bd7a77" target='_blank'>
              A Meta-learner approach to multistep-ahead time series prediction
              </a>
            </td>
          <td>
            Fouad Bahrpeyma, V. M. Ngo, M. Roantree, A. Mccarren
          </td>
          <td>2024-07-09</td>
          <td>International Journal of Data Science and Analytics</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="Solar energy has become a promising renewable energy source, offering significant opportunities for photovoltaic (PV) systems. Accurate and reliable PV generation forecasts are crucial for efficient grid integration and optimized system planning. However, the complexity of environmental factors, including seasonal and daily patterns, as well as social behaviors and user habits, presents significant challenges. Traditional prediction models often struggle with capturing the complex nonlinear dynamics in multivariate time series, leading to low prediction accuracy. To address this issue, this paper proposes a new PV power prediction method that considers factors such as light, air pressure, wind direction, and social behavior, assigning different weights to them to accurately extract nonlinear feature relationships. The framework integrates long short-term memory (LSTM) and gated recurrent units (GRU) to capture local time features, while bidirectional LSTM (BiLSTM) and an attention mechanism extract global spatiotemporal relationships, effectively capturing key features related to historical output. This improves the accuracy of multi-step predictions. To verify the feasibility of the method for multivariate time series, we conducted experiments using PV power prediction as a scenario and compared the results with LSTM, CNN, BiLSTM, CNN-LSTM and GRU models. The experimental results show that the proposed method outperforms these models, with a mean absolute error (MAE) of 12.133, root mean square error (RMSE) of 14.234, mean absolute percentage error (MAPE) of 2.1%, and a coefficient of determination (R2) of 0.895. These results indicate the effectiveness and potential of the method in PV prediction tasks.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5cd0c75b48f548d60683a1e8ab48e8b00609e962" target='_blank'>
              A Photovoltaic Prediction Model with Integrated Attention Mechanism
              </a>
            </td>
          <td>
            Xiangshu Lei
          </td>
          <td>2024-07-04</td>
          <td>Mathematics</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="
 Data-driven methodologies have been used in reservoir management and production forecasting, particularly demonstrating remarkable efficacy in short-term oil production forecasts. However, there is space to improve its prediction, especially in tackling the complexities of challenging reservoirs, such as the heterogeneous carbonate reservoirs from Brazilian Pre-salt fields. Methods for oil production forecasting in the petroleum literature generally consider linear correlations or recurrent neural networks (RNNs). In this paper, we propose a new strategy to improve short-term forecasting for oil production through attention mechanisms that boost state-of-the-art methods. Traditional data-driven techniques generally do not consider static data or planned activities. However, we address this critical gap by leveraging the Temporal Fusion Transformer (TFT) to integrate such information into our short-term forecasting. Transformers, the architectural inspiration behind ChatGPT, employ attention mechanisms to establish relationships between different time series data points, assigning weights to these connections. We jointly explore oil, gas, and water production, pressure, and the ratios between them. This method includes static data (e.g., geographical coordinates) as well as known side reservoir information. Such side information can be, for instance, another predicted future production or planned well shut-ins. We also investigate which side information improves the obtained forecasting. This paper presents two main findings. First, it shows how using certain side information can improve the overall predictive capability of a model. For example, using predicted gas production as side information can significantly improve the oil production forecast. This is logical and in line with expectations, as there is an intimate connection between oil and gas production. In the second application of TFT, we considered well closures as the side information. We used an anomaly detection tool to identify well closures in the history period and converted it to usable side information for the TFT model. The distribution of these well closures is used as a guide to predict our target oil production. As we considered the distribution of well closures as side information, we framed our results in terms of cumulative oil production rather than daily forecast rates. The results of this work show that the cumulative production gets very close to the ground-truth data, better than linear and proposed baselines. In summary, the second key result shows and underscores the significance of incorporating side information within our TFT approach.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/28c1d2d657f6cc3f0791a67fb06a1d435e895eea" target='_blank'>
              Watch the Reservoir! Improving Short-Term Production Forecast Through Transformers
              </a>
            </td>
          <td>
            R. Werneck, L. A. Lusquino Filho, A. Lustosa, A. Loomba, M. M. Gonçalves, A. Esmin, S. Salavati, E. Morais, P. R. Mendes Junior, M. Zampieri, M. Amaral, O. C. Linares, M. Castro, R. Moura, D. J. Schiozer, A. M. Ferreira, A. Davolio, A. Rocha
          </td>
          <td>2024-06-26</td>
          <td>Day 3 Fri, June 28, 2024</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="With the rapid digitization of the world, an increasing number of real-world applications are turning to non-Euclidean data, modeled as graphs. Due to their intrinsic high complexity and irregularity, learning from graph data demands tremendous computational power. Recently, CMOS-compatible Ising machines, i.e., dynamical systems fabricated with CMOS technologies, have emerged as a new approach that harnesses the inherent power of nature within dynamical systems to efficiently resolve binary optimization problems and have been adopted for traditional graph computation, such as max-cut. However, when performing complex Graph Learning (GL) tasks, Ising machines face significant hurdles: (i) they are binary and thus ill-suited for real-valued problems; (ii) their expensive all-to-all coupling network that guarantees generality for optimization problems poses daunting scalability concerns.To address these challenges, this paper proposes a nature-powered graph learning framework dubbed DS-GL, which is the first effort to transform the process of solving graph learning problems into the natural annealing process within a parameterized dynamical system embodied as a CMOS chip. To tackle the two major hurdles, DS-GL first augments the Ising machine architecture to modify the self-reaction term of its Hamiltonian function from linear to quadratic, effectively serving as an energy regulator. This adjustment maintains the system’s original physical interpretation while enabling it to process continuous, real-valued data. Second, to address the scaling issue, DS-GL further upgrades the real-valued dense Ising machine by decomposing it into a mesh-based multi-PE dynamical system that supports efficient distributed spatial-temporal co-annealing across different PEs through sparse interconnects. By exploiting the inherent sparsity and community structures in real-world graphs, DS-GL is able to map complex graph learning tasks onto the scalable dynamical system while maintaining high accuracy. Evaluations with four diverse GL applications across seven real-world datasets, including traffic flow and COVID-19 prediction, show that DS-GL can deliver from 103 × to 105 × speedups over Graph Neural Networks on GPUs while operating at a power 2 orders of magnitude lower than GPUs, with 5% – 30% accuracy enhancement.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f5c8f2bb9d71e3bd5704dfdfc3c6c83338cf48fc" target='_blank'>
              DS-GL: Advancing Graph Learning via Harnessing Nature’s Power within Scalable Dynamical Systems
              </a>
            </td>
          <td>
            Ruibing Song, Chunshu Wu, Chuan Liu, Ang Li, Michael C. Huang, Tong Geng
          </td>
          <td>2024-06-29</td>
          <td>2024 ACM/IEEE 51st Annual International Symposium on Computer Architecture (ISCA)</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="In the modern transport industry, vast and diverse information arrays, particularly those including time series data, are rapidly expanding. This growth presents an opportunity to improve the quality of forecasting. Researchers and practitioners are continuously developing innovative tools to predict their future values. The goal of the research is to improve the performance of automated forecasting environments in a systematic and structured way. This paper investigates the effect of substituting the initial time series with another of a similar nature, during the training phase of the model’s development. A financial data set and the Prophet model are employed for this objective. It is observed that the impact on the accuracy of the predicted future values is promising, albeit not significant. Based on the obtained results, valuable conclusions are drawn, and recommendations for further improvements are provided. By highlighting the importance of diverse data incorporation, this research assists in making informed choices and leveraging the full potential of available information for more precise forecasting outcomes.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c8cdf9821562b0563c9797fb5821a5a46f40c681" target='_blank'>
              Time Series Cross-Sequence Prediction
              </a>
            </td>
          <td>
            K. Koparanov, E. Antonova, D. Minkovska, K. Georgiev
          </td>
          <td>2024-07-19</td>
          <td>WSEAS TRANSACTIONS ON BUSINESS AND ECONOMICS</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a983ac7de996a0c2a264e2986905402146c015e0" target='_blank'>
              Unlocking Online Insights: LSTM Exploration and Transfer Learning Prospects
              </a>
            </td>
          <td>
            Muhammad Tahir, Sufyan Ali, A. Sohail, Ying Zhang, Xiaohua Jin
          </td>
          <td>2024-07-08</td>
          <td>Annals of Data Science</td>
          <td>0</td>
          <td>21</td>
        </tr>

        <tr id="Change point detection in time series seeks to identify times when the probability distribution of time series changes. It is widely applied in many areas, such as human-activity sensing and medical science. In the context of multivariate time series, this typically involves examining the joint distribution of high-dimensional data: If any one variable changes, the whole time series is assumed to have changed. However, in practical applications, we may be interested only in certain components of the time series, exploring abrupt changes in their distributions in the presence of other time series. Here, assuming an underlying structural causal model that governs the time-series data generation, we address this problem by proposing a two-stage non-parametric algorithm that first learns parts of the causal structure through constraint-based discovery methods. The algorithm then uses conditional relative Pearson divergence estimation to identify the change points. The conditional relative Pearson divergence quantifies the distribution disparity between consecutive segments in the time series, while the causal discovery method enables a focus on the causal mechanism, facilitating access to independent and identically distributed (IID) samples. Theoretically, the typical assumption of samples being IID in conventional change point detection methods can be relaxed based on the Causal Markov Condition. Through experiments on both synthetic and real-world datasets, we validate the correctness and utility of our approach.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/010ab97fc0f4c786a8c27a35f6bd53cf9efb60a2" target='_blank'>
              Causal Discovery-Driven Change Point Detection in Time Series
              </a>
            </td>
          <td>
            Shanyun Gao, Raghavendra Addanki, Tong Yu, Ryan Rossi, Murat Kocaoglu
          </td>
          <td>2024-07-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Background: Biomedical data are usually collections of longitudinal data assessed at certain points in time. Clinical observations assess the presences and severity of symptoms, which are the basis for the description and modeling of disease progression. Deciphering potential underlying unknowns from the distinct observation would substantially improve the understanding of pathological cascades. Hidden Markov Models (HMMs) have been successfully applied to the processing of possibly noisy continuous signals. We apply ensembles of HMMs to categorically distributed multivariate time series data, leaving space for expert domain knowledge in the prediction process. Methods: We use an ensemble of HMMs to predict the loss of free walking ability as one major clinical deterioration in the most common autosomal dominantly inherited ataxia disorder worldwide. Results: We present a prediction pipeline that processes data paired with a configuration file, enabling us to train, validate and query an ensemble of HMMs. In particular, we provide a theoretical and practical framework for multivariate time-series inference based on HMMs that includes constructing multiple HMMs, each to predict a particular observable variable. Our analysis is conducted on pseudo-data, but also on biomedical data based on Spinocerebellar ataxia type 3 disease. Conclusions: We find that the model shows promising results for the data we tested. The strength of this approach is that HMMs are well understood, probabilistic and interpretable models, setting it apart from most Deep Learning approaches. We publish all code and evaluation pseudo-data in an open-source repository.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/75eb137d735a965284db79b60d1396e83205c3ac" target='_blank'>
              Ensemble of HMMs for Sequence Prediction on Multivariate Biomedical Data
              </a>
            </td>
          <td>
            Richard Fechner, Jens Dörpinghaus, R. Rockenfeller, J. Faber
          </td>
          <td>2024-07-03</td>
          <td>BioMedInformatics</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id="Constructing accurate spatiotemporal correlations is a challenging task in joint prediction of multiple photovoltaic sites. Some advanced algorithms for incorporating other surrounding site information have been proposed, such as graph neural network-based methods, which are usually based on static or dynamic graphs to build spatial dependencies between sites. However, the possibility of the simultaneous existence of multiple spatial dependencies is not considered. This paper establishes a spatiotemporal prediction model based on hybrid spatiotemporal graph neural network. In this model, we apply adaptive hybrid graph learning to learn composite spatial correlations among multiple sites. A temporal convolution module with multi-subsequence temporal data input is used to extract local semantic information to better predict future nonlinear temporal dependencies. A spatiotemporal adaptive fusion module is added to address the issue of integrating diverse spatiotemporal trends among multiple sites. To assess the model's predictive performance, nine solar radiation observation stations were selected in two different climatic environments. The average root mean square error (RMSE) of the constructed model was 38.51 and 49.90 W/m2, with average mean absolute error (MAE) of 14.72 and 23.06 W/m2, respectively. Single-site and multi-site prediction models were selected as baseline models. Compared with the baseline models, the RMSE and MAE reduce by 3.1%–20.8% and 8.9%–32.8%, respectively, across all sites. The proposed model demonstrates the effectiveness of improving accuracy in forecasting solar irradiance through multi-site predictions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9f5975f5f85d9f8b58520410f9d2fb8ae33faa1d" target='_blank'>
              Multi-site solar irradiance prediction based on hybrid spatiotemporal graph neural network
              </a>
            </td>
          <td>
            Yunjun Yu, Zejie Cheng, Biao Xiong, Qian Li
          </td>
          <td>2024-07-01</td>
          <td>Journal of Renewable and Sustainable Energy</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="Studying low-likelihood high-impact extreme weather events in a warming world is a significant and challenging task for current ensemble forecasting systems. While these systems presently use up to 100 members, larger ensembles could enrich the sampling of internal variability. They may capture the long tails associated with climate hazards better than traditional ensemble sizes. Due to computational constraints, it is infeasible to generate huge ensembles (comprised of 1,000-10,000 members) with traditional, physics-based numerical models. In this two-part paper, we replace traditional numerical simulations with machine learning (ML) to generate hindcasts of huge ensembles. In Part I, we construct an ensemble weather forecasting system based on Spherical Fourier Neural Operators (SFNO), and we discuss important design decisions for constructing such an ensemble. The ensemble represents model uncertainty through perturbed-parameter techniques, and it represents initial condition uncertainty through bred vectors, which sample the fastest growing modes of the forecast. Using the European Centre for Medium-Range Weather Forecasts Integrated Forecasting System (IFS) as a baseline, we develop an evaluation pipeline composed of mean, spectral, and extreme diagnostics. Using large-scale, distributed SFNOs with 1.1 billion learned parameters, we achieve calibrated probabilistic forecasts. As the trajectories of the individual members diverge, the ML ensemble mean spectra degrade with lead time, consistent with physical expectations. However, the individual ensemble members' spectra stay constant with lead time. Therefore, these members simulate realistic weather states, and the ML ensemble thus passes a crucial spectral test in the literature. The IFS and ML ensembles have similar Extreme Forecast Indices, and we show that the ML extreme weather forecasts are reliable and discriminating.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/de58dea585a06935529ae1f31353338f254df5af" target='_blank'>
              Huge Ensembles Part I: Design of Ensemble Weather Forecasts using Spherical Fourier Neural Operators
              </a>
            </td>
          <td>
            Ankur Mahesh, William Collins, B. Bonev, Noah D. Brenowitz, Y. Cohen, Joshua Elms, Peter Harrington, K. Kashinath, Thorsten Kurth, Joshua North, Travis OBrien, Michael S. Pritchard, David Pruitt, Mark Risser, Shashank Subramanian, Jared Willard
          </td>
          <td>2024-08-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>25</td>
        </tr>

        <tr id="Graph neural networks (GNNs) have gained significant attention in diverse domains, ranging from urban planning to pandemic management. Ensuring both accuracy and robustness in GNNs remains a challenge due to insufficient quality data that contains sufficient features. With sufficient training data where all spatiotemporal patterns are well-represented, existing GNN models can make reasonably accurate predictions. However, existing methods fail when the training data are drawn from different circumstances (e.g., traffic patterns on regular days) than test data (e.g., traffic patterns after a natural disaster). Such challenges are usually classified under domain generalization. In this work, we show that one way to address this challenge in the context of spatiotemporal prediction is by incorporating domain differential equations into graph convolutional networks (GCNs). We theoretically derive conditions where GCNs incorporating such domain differential equations are robust to mismatched training and testing data compared to baseline domain agnostic models. To support our theory, we propose two domain-differential-equation-informed networks: Reaction-Diffusion Graph Convolutional Network (RDGCN), which incorporates differential equations for traffic speed evolution, and the Susceptible-Infectious-Recovered Graph Convolutional Network (SIRGCN), which incorporates a disease propagation model. Both RDGCN and SIRGCN are based on reliable and interpretable domain differential equations that allow the models to generalize to unseen patterns. We experimentally show that RDGCN and SIRGCN are more robust with mismatched testing data than state-of-the-art deep learning methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0ce74ab023edbff0d9a6fad7e1a98a69c76287cb" target='_blank'>
              On the generalization discrepancy of spatiotemporal dynamics-informed graph convolutional networks
              </a>
            </td>
          <td>
            Yue Sun, Chao Chen, Yuesheng Xu, Sihong Xie, Rick S. Blum, Parv Venkitasubramaniam
          </td>
          <td>2024-07-12</td>
          <td>Frontiers in Mechanical Engineering</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="With the vigorous development of e-commerce, accurately modeling and predicting user behavior has become a key factor in improving business efficiency. Precisely understanding user behavior not only enables companies to provide personalized services but also allows them to stand out in the intense market competition. This study aims to explore the effectiveness of applying end-to-end models, Long Short-Term Memory (LSTM), and attention mechanisms in time series modeling to enhance the performance of modeling and predicting user behavior in e-commerce. In the methodology section, we first introduce the basic principles of the end-to-end model, which extracts features directly from raw data for prediction, avoiding the need for intricate feature engineering. Simultaneously, we introduce Long Short-Term Memory (LSTM) to better capture long-term dependencies in time series data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0da5e0a0f8f43013d568bfc235ed44504eef00ce" target='_blank'>
              End-to-End Modeling and Long Short-Term Memory Application in Time Series Modeling
              </a>
            </td>
          <td>
            Guodong Yang, Kuangyu Li, Yunfan Zhang, Qindi Feng
          </td>
          <td>2024-07-30</td>
          <td>Journal of Organizational and End User Computing</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The COVID-19 pandemic has posed significant chal-lenges to global health, economies, and social structures since its emergence in late 2019. Southern California, a region with unique characteristics and diverse communities, has experienced difficul-ties in controlling the virus's spread. Understanding the factors that influence COVID-19 transmission in Southern California is crucial for informing public health policies and mitigating the virus's impact on the communities. In this study, we collected weekly zip code level data from March to December 2020 in Southern California and applied various machine learning algorithms, such as graph neural networks (GNN), multi-layer perceptrons (MLP), and gradient boosting trees (XGBoost), to model the spread of COVID-19. Our main contributions include the development of various COVID-19 forecasting models that incorporate socioeconomically significant variables and zip code level mobility data, coupled with variable impact assessments to provide valuable insights for informing future public health policies and strategies. Our predictive model not only attains high levels of accuracy in forecasting but also facilitates the understanding of how each variable contributes to the final outcome. These findings have the potential to enhance our understanding of COVID-19 transmission patterns and inform targeted mitigation strategies in the region.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e3a3a205cede5dc9ee960274ff3f51815bbca1ea" target='_blank'>
              Predicting COVID-19 Transmission in Southern California with Machine Learning Methods
              </a>
            </td>
          <td>
            Han Li, Ran Wei, Wenyu Wang, Nanpeng Yu
          </td>
          <td>2024-03-16</td>
          <td>2024 9th International Conference on Big Data Analytics (ICBDA)</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Most state-of-the-art AI applications in atmospheric science are based on classic deep learning approaches. However, such approaches cannot automatically integrate multiple complicated procedures to construct an intelligent agent, since each functionality is enabled by a separate model learned from independent climate datasets. The emergence of foundation models, especially multimodal foundation models, with their ability to process heterogeneous input data and execute complex tasks, offers a substantial opportunity to overcome this challenge. In this report, we want to explore a central question - how the state-of-the-art foundation model, i.e., GPT-4o, performs various atmospheric scientific tasks. Toward this end, we conduct a case study by categorizing the tasks into four main classes, including climate data processing, physical diagnosis, forecast and prediction, and adaptation and mitigation. For each task, we comprehensively evaluate the GPT-4o's performance along with a concrete discussion. We hope that this report may shed new light on future AI applications and research in atmospheric science.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/18a501f9bccb6fcfbb0d37e1ac9f7d535942b340" target='_blank'>
              On the Opportunities of (Re)-Exploring Atmospheric Science by Foundation Models: A Case Study
              </a>
            </td>
          <td>
            Lujia Zhang, Hanzhe Cui, Yurong Song, Chenyue Li, Binhang Yuan, Mengqian Lu
          </td>
          <td>2024-07-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="The cinematic metaverse aims to create a virtual space with the context of a film. Users can enter this space in the form of avatars, experiencing the cinematic plot firsthand in an immersive manner. This requires us to design a rational computation resource allocation and synchronization algorithm to meet the demands of multi‐objective joint optimization, such as low latency and high throughput, which ensures that users can seamlessly switch between virtual and real worlds and acquire immersive experiences. Unfortunately, the explosive growth in the number of users makes it difficult to jointly optimize multiple objectives. Predicting traffic generated by the users' avatars in the cinematic metaverse is significant for the optimization process. Although graph neural networks‐based traffic prediction models achieve superior prediction accuracy, these methods rely only on physical distances‐based topological graph information, while failing to comprehensively reflect the real relationships between avatars in the cinematic metaverse. To address this issue, we present a novel Multi‐Graph Representation Spatio‐Temporal Attention Networks (MGRSTANet) for traffic prediction in the cinematic metaverse. Specifically, based on multiple topological graph information (e.g., physical distances, centerity, and similarity), we first design Multi‐Graph Embedding (MGE) module to generate multiple graph representations, thus reflecting on the real relationships between avatars more comprehensively. The Spatio‐Temporal Attention (STAtt) module is then proposed to extract spatio‐temporal correlations in each graph representations, thus improving prediction accuracy. We conduct simulation experiments to evaluate the effectiveness of MGRSTANet. The experimental results demonstrate that our proposed model outperforms the state‐of‐the‐art baselines in terms of prediction accuracy, making it appropriate for traffic forecasting in the cinematic metaverse.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7a17e82d53c5d1ce27349fc52790d7c9df247a47" target='_blank'>
              Multi-graph representation spatio-temporal attention networks for traffic forecasting in the cinematic metaverse
              </a>
            </td>
          <td>
            Ke Li, Xiaoming He, Yinqiu Liu, Meng Chen
          </td>
          <td>2024-07-01</td>
          <td>Trans. Emerg. Telecommun. Technol.</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Diffusion Transformer, the backbone of Sora for video generation, successfully scales the capacity of diffusion models, pioneering new avenues for high-fidelity sequential data generation. Unlike static data such as images, sequential data consists of consecutive data frames indexed by time, exhibiting rich spatial and temporal dependencies. These dependencies represent the underlying dynamic model and are critical to validate the generated data. In this paper, we make the first theoretical step towards bridging diffusion transformers for capturing spatial-temporal dependencies. Specifically, we establish score approximation and distribution estimation guarantees of diffusion transformers for learning Gaussian process data with covariance functions of various decay patterns. We highlight how the spatial-temporal dependencies are captured and affect learning efficiency. Our study proposes a novel transformer approximation theory, where the transformer acts to unroll an algorithm. We support our theoretical results by numerical experiments, providing strong evidence that spatial-temporal dependencies are captured within attention layers, aligning with our approximation theory.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/29e9034e1e9a82b3bffe33d3460d002e29d5958c" target='_blank'>
              Diffusion Transformer Captures Spatial-Temporal Dependencies: A Theory for Gaussian Process Data
              </a>
            </td>
          <td>
            Hengyu Fu, Zehao Dou, Jiawei Guo, Mengdi Wang, Minshuo Chen
          </td>
          <td>2024-07-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Continual graph learning (CGL) is an important and challenging task that aims to extend static GNNs to dynamic task flow scenarios. As one of the mainstream CGL methods, the experience replay (ER) method receives widespread attention due to its superior performance. However, existing ER methods focus on identifying samples by feature significance or topological relevance, which limits their utilization of comprehensive graph data. In addition, the topology-based ER methods only consider local topological information and add neighboring nodes to the buffer, which ignores the global topological information and increases memory overhead. To bridge these gaps, we propose a novel method called Feature-Topology Fusion-based Experience Replay (FTF-ER) to effectively mitigate the catastrophic forgetting issue with enhanced efficiency. Specifically, from an overall perspective to maximize the utilization of the entire graph data, we propose a highly complementary approach including both feature and global topological information, which can significantly improve the effectiveness of the sampled nodes. Moreover, to further utilize global topological information, we propose Hodge Potential Score (HPS) as a novel module to calculate the topological importance of nodes. HPS derives a global node ranking via Hodge decomposition on graphs, providing more accurate global topological information compared to neighbor sampling. By excluding neighbor sampling, HPS significantly reduces buffer storage costs for acquiring topological information and simultaneously decreases training time. Compared with state-of-the-art methods, FTF-ER achieves a significant improvement of 3.6% in AA and 7.1% in AF on the OGB-Arxiv dataset, demonstrating its superior performance in the class-incremental learning setting.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5a0f6d19e56c93eb398b62ebfdf9a94a5c5b4bed" target='_blank'>
              FTF-ER: Feature-Topology Fusion-Based Experience Replay Method for Continual Graph Learning
              </a>
            </td>
          <td>
            Jinhui Pang, Changqing Lin, Xiaoshuai Hao, Rong Yin, Zixuan Wang, Zhihui Zhang, Jinglin He, Huang Tai Sheng
          </td>
          <td>2024-07-28</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Accurate streamflow forecasting is crucial for effectively managing water resources, particularly in countries like Colombia, where hydroelectric power generation significantly contributes to the national energy grid. Although highly interpretable, traditional deterministic, physically-driven models often suffer from complexity and require extensive parameterization. Data-driven models like Linear Autoregressive (LAR) and Long Short-Term Memory (LSTM) networks offer simplicity and performance but cannot quantify uncertainty. This work introduces Sparse Variational Gaussian Processes (SVGPs) for forecasting streamflow contributions. The proposed SVGP model reduces computational complexity compared to traditional Gaussian Processes, making it highly scalable for large datasets. The methodology employs optimal hyperparameters and shared inducing points to capture short-term and long-term relationships among reservoirs. Training, validation, and analysis of the proposed approach consider the streamflow dataset from 23 geographically dispersed reservoirs recorded during twelve years in Colombia. Performance assessment reveals that the proposal outperforms baseline Linear Autoregressive (LAR) and Long Short-Term Memory (LSTM) models in three key aspects: adaptability to changing dynamics, provision of informative confidence intervals through Bayesian inference, and enhanced forecasting accuracy. Therefore, the SVGP-based forecasting methodology offers a scalable and interpretable solution for multi-output streamflow forecasting, thereby contributing to more effective water resource management and hydroelectric planning.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/82ecf0c70aa07f89d48d8aa7c5d4ec1674f0475d" target='_blank'>
              Scalable and Interpretable Forecasting of Hydrological Time Series Based on Variational Gaussian Processes
              </a>
            </td>
          <td>
            J. D. Pastrana-Cortés, J. Gil-González, A. Álvarez-Meza, D. Cárdenas-Peña, Á. Orozco-Gutiérrez
          </td>
          <td>2024-07-15</td>
          <td>Water</td>
          <td>0</td>
          <td>15</td>
        </tr>

        <tr id="In recent years, sequential recommendation has received widespread attention for its role in enhancing user experience and driving personalized content recommendations. However, it also encounters challenges, including the limitations of modeling information and the variability of user preferences. A novel time-aware Long-Short Term Transformer (TLSTSRec) for sequential recommendation is introduced in this paper to address these challenges. TLSTSRec has two major innovative features. (1) Accurate modeling of users is achieved by fully leveraging temporal information. Time information is modeled by creating a trainable timestamp matrix from both the perspectives of time duration and time spectrum. (2) A novel time-aware Transformer model is proposed. To address the inherent variability of user preferences over time, the model combines long-term and short-term temporal information and adjusts the personalized trade-offs between long-term and short-term sequences using adaptive fusion layers. Subsequently, newly designed encoders and decoders are employed to model timestamps and interaction items. Finally, extensive experiments substantiate the effectiveness of TLSTSRec relative to various state-of-the-art sequential recommendation models based on MC/RNN/GNN/SA across a spectrum of widely used metrics. Furthermore, experiments are conducted to validate the rationality of the TLSTSRec structure.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/417f89b6992377e3e5d706672bfa4da837f011df" target='_blank'>
              TLSTSRec: Time-aware long short-term attention neural network for sequential recommendation
              </a>
            </td>
          <td>
            Hongwei Chen, Luanxuan Liu, Zexi Chen
          </td>
          <td>2024-08-01</td>
          <td>Intelligent Data Analysis</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Literature abounds with various statistical and machine learning techniques for stock market forecasting. However, Reinforcement Learning (RL) is conspicuous by its absence in this field and is little explored despite its potential to address the dynamic and uncertain nature of the stock market. In a first-of-its-kind study, this research precisely bridges this gap, by forecasting stock prices using RL, in the static as well as streaming contexts using deep RL techniques. In the static context, we employed three deep RL algorithms for forecasting the stock prices: Deep Deterministic Policy Gradient (DDPG), Proximal Policy Optimisation (PPO) and Recurrent Deterministic Policy Gradient (RDPG) and compared their performance with Multi-Layer Perceptron (MLP), Support Vector Regression (SVR) and General Regression Neural Network (GRNN). In addition, we proposed a generic streaming analytics-based forecasting approach leveraging the real-time processing capabilities of Spark streaming for all six methods. This approach employs a sliding window technique for real-time forecasting or nowcasting using the above-mentioned algorithms. We demonstrated the effectiveness of the proposed approach on the daily closing prices of four different financial time series dataset as well as the Mackey–Glass time series, a benchmark chaotic time series dataset. We evaluated the performance of these methods using three metrics: Symmetric Mean Absolute Percentage (SMAPE), Directional Symmetry statistic (DS) and Theil’s U Coefficient. The results are promising for DDPG in the static context and GRNN turned out to be the best in streaming context. We performed the Diebold–Mariano (DM) test to assess the statistical significance of the best-performing models.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/399a8108ea6cff24099de6a2388ecbb9069a00fa" target='_blank'>
              Deep Reinforcement Learning for Financial Forecasting in Static and Streaming Cases
              </a>
            </td>
          <td>
            Aravilli Atchuta Ram, Sandarbh Yadav, Yelleti Vivek, V. Ravi
          </td>
          <td>2024-06-27</td>
          <td>Journal of Information &amp; Knowledge Management</td>
          <td>0</td>
          <td>40</td>
        </tr>

        <tr id="High precision in forecasting travel demand for online car-hailing is crucial for traffic management to schedule vehicles, hence reducing energy consumption and achieving sustainable development. Netflix demand forecasting relies on the capture of spatiotemporal correlations. To extract the spatiotemporal information more fully, this study designs and develops a novel spatiotemporal prediction model with multidimensional inputs (MSACL) by embedding a self-attention memory (SAM) module into a convolutional long short-term memory neural network (ConvLSTM). The SAM module can extract features with long-range spatiotemporal dependencies. The experimental data are derived from the Chengdu City online car-hailing trajectory data set and the external factors data set. Comparative experiments demonstrate that the proposed model has higher accuracy. The proposed model outperforms the Sa-ConvLSTM model and has the highest prediction accuracy, shows a reduction in the mean absolute error (MAE) by 1.72, a reduction in the mean squared error (MSE) by 0.43, and an increase in the R-squared (R2) by 4%. In addition, ablation experiments illustrate the effectiveness of each component, where the external factor inputs have the least impact on the model accuracy, but the removal of the SAM module results in the most significant decrease in model accuracy.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ea2c249a41fa5eff75101cd3187bb7f3b33e1f26" target='_blank'>
              Prediction on Demand for Regional Online Car-Hailing Travel Based on Self-Attention Memory and ConvLSTM
              </a>
            </td>
          <td>
            Jianqi Li, Wenbao Zeng, Weiqi Liu, Rongjun Cheng
          </td>
          <td>2024-07-04</td>
          <td>Sustainability</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Echo state network (ESN) implements an alternative paradigm called reservoir computing to train recurrent neural networks (RNNs), where internal weights are randomly generated and kept fixed, and only readout weights need to be trained, which greatly reduces the training complexity of RNNs. ESN not only facilitates the practical implementation of RNNs but also shows superior performance over fully trained RNNs across a range of applications. However, the conventional ESN suffers from the drawbacks of stringent conditions for weight convergence and slow convergence speed. This paper proposes a memory regressor extended learning method to update the readout weights of ESNs. By constructing and incorporating a generalized prediction error based on regressor extension and filtering, the capacity of ESN to utilize historical data can be greatly improved. In the discrete-time domain, it is proven that exponential convergence of readout weights is achieved under a condition termed interval excitation that is strictly weaker than the classical condition of persistent excitation. Simulation results on modeling a 10th-order nonlinear autoregressive moving-average (NARMA) system have revealed that the proposed approach accelerates weight convergence speed almost ten times higher compared to the conventional ESN.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4e0fa7b7dfe357970b3e72acb8d86266f028d299" target='_blank'>
              Memory Regressor Extended Echo State Networks for Nonlinear Dynamics Modeling
              </a>
            </td>
          <td>
            Kai Hu, Qian Wang, Tian Shi, Kohei Nakajima, Yongping Pan
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="With technological advancements, much data is being captured by sensors, smartphones, wearable devices, and so forth. These vast datasets are stored in data centres and utilized to forge data‐driven models for the condition monitoring of infrastructures and systems through future data mining tasks. However, these datasets often surpass the processing capabilities of traditional information systems and methodologies due to their significant size. Additionally, not all samples within these datasets contribute valuable information during the model training phase, leading to inefficiencies. The processing and training of Machine Learning algorithms become time‐consuming, and storing all the data demands excessive space, contributing to the Big Data challenge. In this paper, we propose two novel techniques to reduce large time‐series datasets into more compact versions without undermining the predictive performance of the resulting models. These methods also aim to decrease the time required for training the models and the storage space needed for the condensed datasets. We evaluated our techniques on five public datasets, employing three Machine Learning algorithms: Holt‐Winters, SARIMA, and LSTM. The outcomes indicate that for most of the datasets examined, our techniques maintain, and in several instances enhance, the forecasting accuracy of the models. Moreover, we significantly reduced the time required to train the Machine Learning algorithms employed.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/33d3e765763fbda62c139a833d2484281eec1ade" target='_blank'>
              Sampling approaches to reduce very frequent seasonal time series
              </a>
            </td>
          <td>
            Afonso Baldo, Paulo J. S. Ferreira, João Mendes‐Moreira
          </td>
          <td>2024-07-25</td>
          <td>Expert Systems</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Climaate prediction plays a vital role in various sectors, including agriculture, disaster management, and urban planning. Traditional methods for climate forecasting often rely on complex physical models, which require substantial computational resources and may not accurately capture local weather patterns. This study explores the potential of Long Short-Term Memory (LSTM) networks, a type of recurrent neural network, for predicting daily climate variables such as temperature, precipitation, and humidity. Utilizing historical climate data from the city of Delhi, we developed an LSTM model to forecast short-term climate trends. The model consists of two LSTM layers followed by three Dense layers and is compiled with the Adam optimizer, mean squared error loss, and mean absolute error as a metric. Our results demonstrate the model's capability to capture temporal dependencies in climate data, achieving a satisfactory level of accuracy in temperature forecasting. This research underscores the potential of machine learning techniques, particularly LSTM networks, in enhancing climate prediction and contributing to more informed decision-making in weather-sensitive sectors.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3b6d06cad165e6e886fa69a86af54e02218c3b53" target='_blank'>
              Prediction of Daily Climate Using Long Short-Term Memory (LSTM) Model
              </a>
            </td>
          <td>
            Jinxin Xu, Zhuoyue Wang, Xinjin Li, Zichao Li, Zhenglin Li
          </td>
          <td>2024-07-12</td>
          <td>International Journal of Innovative Science and Research Technology (IJISRT)</td>
          <td>2</td>
          <td>2</td>
        </tr>

        <tr id="Out-of-stock prediction refers to the activity of forecasting the time when a product will not be available for purchase because of an inventory deficiency. Due to difficulties, out-of-stock forecasting models now face certain challenges. Incorrect demand forecasting may result in a lack or excess of goods in stock, a factor that affects client satisfaction and the profitability of companies. Accordingly, the new approach BCHO-TCN LightGBM, which is based on Buzzard Coney Hawk Optimization with a deep temporal convolutional neural network and the Light Gradient-Boosting Machine framework, is developed to deal with all challenges in the existing models in the field of out-of-stock prediction. The role that BCHO plays in the LightGBM-based deep temporal CNNis rooted in modifying the classifier to improve both accuracy and speed. Integrating BCHO into the model training process allows us to optimize and adjust the hyperparameters and the weights of the CNN linked with the temporal DNN, which, in turn, makes the model perform better in the extraction of temporal features from time-series data. This optimization strategy, which derives from the cooperative behaviors and evasion tactics of BCHO, is a powerful source of information for the computational optimization agent. This leads to a faster convergence of the model towards optimal solutions and therefore improves the overall accuracy and predictive abilities of the temporal CNN with the LightGBM algorithm. The results indicate that when using data from Amazon India’s product listings, the model shows a high degree of accuracy, as well as excellent net present value (NPV), present discounted value (PDV), and threat scores, with values reaching 94.52%, 95.16%, 94.81%, and 95.76%, respectively. Likewise, in a k-fold 10 scenario, the model achieves values of 94.81%, 95.60%, 96.28%, and 95.86% for the same metrics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/96cb7b1001e9b5ba05e22ee7aaa6f6de94c16dcd" target='_blank'>
              Out-of-Stock Prediction Model Using Buzzard Coney Hawk Optimization-Based LightGBM-Enabled Deep Temporal Convolutional Neural Network
              </a>
            </td>
          <td>
            Ahmed Elghadghad, A. Alzubi, Kolawole Iyiola
          </td>
          <td>2024-07-05</td>
          <td>Applied Sciences</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="This paper presents a novel neuro-fuzzy model, termed fuzzy recurrent stochastic configuration networks (F-RSCNs), for industrial data analytics. Unlike the original recurrent stochastic configuration network (RSCN), the proposed F-RSCN is constructed by multiple sub-reservoirs, and each sub-reservoir is associated with a Takagi-Sugeno-Kang (TSK) fuzzy rule. Through this hybrid framework, first, the interpretability of the model is enhanced by incorporating fuzzy reasoning to embed the prior knowledge into the network. Then, the parameters of the neuro-fuzzy model are determined by the recurrent stochastic configuration (RSC) algorithm. This scheme not only ensures the universal approximation property and fast learning speed of the built model but also overcomes uncertain problems, such as unknown dynamic orders, arbitrary structure determination, and the sensitivity of learning parameters in modelling nonlinear dynamics. Finally, an online update of the output weights is performed using the projection algorithm, and the convergence analysis of the learning parameters is given. By integrating TSK fuzzy inference systems into RSCNs, F-RSCNs have strong fuzzy inference capability and can achieve sound performance for both learning and generalization. Comprehensive experiments show that the proposed F-RSCNs outperform other classical neuro-fuzzy and non-fuzzy models, demonstrating great potential for modelling complex industrial systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/011103f067ff8221c76b025cca9c174b3d93244b" target='_blank'>
              Fuzzy Recurrent Stochastic Configuration Networks for Industrial Data Analytics
              </a>
            </td>
          <td>
            Dianhui Wang, Gang Dang
          </td>
          <td>2024-07-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="PurposeTo optimize train operations, dispatchers currently rely on experience for quick adjustments when delays occur. However, delay predictions often involve imprecise shifts based on known delay times. Real-time and accurate train delay predictions, facilitated by data-driven neural network models, can significantly reduce dispatcher stress and improve adjustment plans. Leveraging current train operation data, these models enable swift and precise predictions, addressing challenges posed by train delays in high-speed rail networks during unforeseen events.Design/methodology/approachThis paper proposes CBLA-net, a neural network architecture for predicting late arrival times. It combines CNN, Bi-LSTM, and attention mechanisms to extract features, handle time series data, and enhance information utilization. Trained on operational data from the Beijing-Tianjin line, it predicts the late arrival time of a target train at the next station using multidimensional input data from the target and preceding trains.FindingsThis study evaluates our model's predictive performance using two data approaches: one considering full data and another focusing only on late arrivals. Results show precise and rapid predictions. Training with full data achieves a MAE of approximately 0.54 minutes and a RMSE of 0.65 minutes, surpassing the model trained solely on delay data (MAE: is about 1.02 min, RMSE: is about 1.52 min). Despite superior overall performance with full data, the model excels at predicting delays exceeding 15 minutes when trained exclusively on late arrivals. For enhanced adaptability to real-world train operations, training with full data is recommended.Originality/valueThis paper introduces a novel neural network model, CBLA-net, for predicting train delay times. It innovatively compares and analyzes the model's performance using both full data and delay data formats. Additionally, the evaluation of the network's predictive capabilities considers different scenarios, providing a comprehensive demonstration of the model's predictive performance.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e57a492ae484333d79b26e0ab06d19a0ae256575" target='_blank'>
              Short-term train arrival delay prediction: a data-driven approach
              </a>
            </td>
          <td>
            Qingyun Fu, Shuxin Ding, Tao Zhang, Rongsheng Wang, Ping Hu, Cunlai Pu
          </td>
          <td>2024-07-02</td>
          <td>Railway Sciences</td>
          <td>0</td>
          <td>14</td>
        </tr>

        <tr id="This paper proposes a deep recurrent neural network (DRNN) approach to model the one-hour-ahead wind speed forecasting by using various meteorological sensory data from the North Wyke farm platform (NWFP). To refine model input, mutual information analysis is applied to eliminate irrelevant sensory data. The DRNN architecture employs three recurrent layers Long-Short Term Memory (LSTM), Gated Recurrent Unit (GRU), and simple Recurrent Neural Network (RNN) to capture temporal relationships. The proposed networks are tested using real-life, one-year data from the NWFP. The results showed a strong correlation between the actual and predicted wind speed for LSTM, GRU, and RNN layers-based DRNN, however, simple RNN slightly outperformed the other two recurrent layers. The distribution of the network errors over the year is also analyzed. Although the observed meteorological data between the years was from different distributions, the proposed network generalized well even though these data were altered due to global warming.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/85208f740e1c9925156ec820fb1175b1cb13df77" target='_blank'>
              Wind Speed Prediction Using Deep Recurrent Neural Networks and Farm Platform Features for One-Hour-Ahead Forecast
              </a>
            </td>
          <td>
            Emre Özbilge, Yonal Kırsal
          </td>
          <td>2024-06-27</td>
          <td>Çukurova Üniversitesi Mühendislik Fakültesi Dergisi</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id="The Path-dependent Neural Jump ODE (PD-NJ-ODE) is a model for online prediction of generic (possibly non-Markovian) stochastic processes with irregular (in time) and potentially incomplete (with respect to coordinates) observations. It is a model for which convergence to the $L^2$-optimal predictor, which is given by the conditional expectation, is established theoretically. Thereby, the training of the model is solely based on a dataset of realizations of the underlying stochastic process, without the need of knowledge of the law of the process. In the case where the underlying process is deterministic, the conditional expectation coincides with the process itself. Therefore, this framework can equivalently be used to learn the dynamics of ODE or PDE systems solely from realizations of the dynamical system with different initial conditions. We showcase the potential of our method by applying it to the chaotic system of a double pendulum. When training the standard PD-NJ-ODE method, we see that the prediction starts to diverge from the true path after about half of the evaluation time. In this work we enhance the model with two novel ideas, which independently of each other improve the performance of our modelling setup. The resulting dynamics match the true dynamics of the chaotic system very closely. The same enhancements can be used to provably enable the PD-NJ-ODE to learn long-term predictions for general stochastic datasets, where the standard model fails. This is verified in several experiments.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ba851d147a33cf0c6fcf639b5d4990df283a0b23" target='_blank'>
              Learning Chaotic Systems and Long-Term Predictions with Neural Jump ODEs
              </a>
            </td>
          <td>
            F. Krach, Josef Teichmann
          </td>
          <td>2024-07-26</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>13</td>
        </tr>

        <tr id="This paper explores the prediction of the dynamics of piecewise smooth maps using various deep learning models. We have shown various novel ways of predicting the dynamics of piecewise smooth maps using deep learning models. Moreover, we have used machine learning models such as Decision Tree Classifier, Logistic Regression, K-Nearest Neighbor, Random Forest, and Support Vector Machine for predicting the border collision bifurcation in the 1D normal form map and the 1D tent map. Further, we classified the regular and chaotic behaviour of the 1D tent map and the 2D Lozi map using deep learning models like Convolutional Neural Network (CNN), ResNet50, and ConvLSTM via cobweb diagram and phase portraits. We also classified the chaotic and hyperchaotic behaviour of the 3D piecewise smooth map using deep learning models such as the Feed Forward Neural Network (FNN), Long Short-Term Memory (LSTM), and Recurrent Neural Network (RNN). Finally, deep learning models such as Long Short-Term Memory (LSTM) and Recurrent Neural Network (RNN) are used for reconstructing the two parametric charts of 2D border collision bifurcation normal form map.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/aac95c6cb783f8093374db2d5a3d6f429f49bbfd" target='_blank'>
              Deep Learning for Prediction and Classifying the Dynamical behaviour of Piecewise Smooth Maps
              </a>
            </td>
          <td>
            S. VismayaV, Bharath V Nair, S. S. Muni
          </td>
          <td>2024-06-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d1bae805ccd830107d647947cbe64aa0294f9638" target='_blank'>
              A Kernel Attention-based Transformer Model for Survival Prediction of Heart Disease Patients.
              </a>
            </td>
          <td>
            Palak Kaushal, Shailendra Singh, Rajesh Vijayvergiya
          </td>
          <td>2024-08-05</td>
          <td>Journal of cardiovascular translational research</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Graph Neural Networks (GNNs) excel in diverse tasks, yet their applications in high-stakes domains are often hampered by unreliable predictions. Although numerous uncertainty quantification methods have been proposed to address this limitation, they often lack \textit{rigorous} uncertainty estimates. This work makes the first attempt to introduce a distribution-free and model-agnostic uncertainty quantification approach to construct a predictive interval with a statistical guarantee for GNN-based link prediction. We term it as \textit{conformalized link prediction.} Our approach builds upon conformal prediction (CP), a framework that promises to construct statistically robust prediction sets or intervals. We first theoretically and empirically establish a permutation invariance condition for the application of CP in link prediction tasks, along with an exact test-time coverage. Leveraging the important structural information in graphs, we then identify a novel and crucial connection between a graph's adherence to the power law distribution and the efficiency of CP. This insight leads to the development of a simple yet effective sampling-based method to align the graph structure with a power law distribution prior to the standard CP procedure. Extensive experiments demonstrate that for conformalized link prediction, our approach achieves the desired marginal coverage while significantly improving the efficiency of CP compared to baseline methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/046f6abdbf63fbb80d831102e7889c6801ad3545" target='_blank'>
              Conformalized Link Prediction on Graph Neural Networks
              </a>
            </td>
          <td>
            Tianyi Zhao, Jian Kang, Lu Cheng
          </td>
          <td>2024-06-26</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>1</td>
        </tr>

        <tr id="End-of-life vehicle (ELV) forecasting constitutes a crucial aspect of sustainable waste management and resource allocation strategies. While the existing literature predominantly employs time-series forecasting and machine learning methodologies, a dearth of studies leveraging deep learning techniques, particularly Long Short-Term Memory (LSTM) networks, is evident. Moreover, the focus on localized contexts within national or municipal boundaries overlooks the imperative of addressing ELV generation dynamics at an international scale, particularly within entities such as the EU-27. Furthermore, the absence of methodologies to reconcile missing historical data presents a significant limitation in forecasting accuracy. In response to these critical gaps, this study proposes a pioneering framework that integrates grey systems theory (GST)-based backcasting with LSTM-based deep learning methodologies for forecasting ELV generation within the EU until 2040. By introducing this innovative approach, this study not only extends the methodological repertoire within the field but also enhances the applicability of findings to supranational regulatory frameworks. Moreover, the incorporation of backcasting techniques addresses data limitations, ensuring more robust and accurate forecasting outcomes. The results indicate an anticipated decline in the recovery and recycling of ELVs, underscoring the urgent need for intervention by policymakers and stakeholders in the waste management sector. Through these contributions, this study enriches our understanding of ELV generation dynamics and facilitates informed decision-making processes in environmental sustainability and resource management domains.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f77631c5d497447eda2ed5efa6e1eb40e0a25f2e" target='_blank'>
              Forecasting End-of-Life Vehicle Generation in the EU-27: A Hybrid LSTM-Based Forecasting and Grey Systems Theory-Based Backcasting Approach
              </a>
            </td>
          <td>
            Selman Karagoz
          </td>
          <td>2024-07-02</td>
          <td>Pollutants</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="In this paper we introduce a method for significantly improving the signal to noise ratio in financial data. The approach relies on combining a target variable with different context variables and use auto-encoders (AEs) to learn reconstructions of the combined inputs. The objective is to obtain agreement among pairs of AEs which are trained on related but different inputs and for which they are forced to find common ground. The training process is set up as a"conversation"where the models take turns at producing a prediction (speaking) and reconciling own predictions with the output of the other AE (listening), until an agreement is reached. This leads to a new way of constraining the complexity of the data representation generated by the AE. Unlike standard regularization whose strength needs to be decided by the designer, the proposed mutual regularization uses the partner network to detect and amend the lack of generality of the learned representation of the data. The integration of alternative perspectives enhances the de-noising capacity of a single AE and allows us to discover new regularities in financial time-series which can be converted into profitable trading strategies.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/88138df593fb8ebbfe08e9779a37bd6bdc468272" target='_blank'>
              Strong denoising of financial time-series
              </a>
            </td>
          <td>
            Matthias J. Feiler
          </td>
          <td>2024-08-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="To predict the future movements of stock markets, numerous studies concentrate on daily data and employ various machine learning (ML) models as benchmarks that often vary and lack standardization across different research works. This paper tries to solve the problem from a fresh standpoint by aiming to predict the weekly movements, and introducing a novel benchmark of random traders. This benchmark is independent of any ML model, thus making it more objective and potentially serving as a commonly recognized standard. During training process, apart from the basic features such as technical indicators, scaling laws and directional changes are introduced as additional features, furthermore, the training datasets are also adjusted by assigning varying weights to different samples, the weighting approach allows the models to emphasize specific samples. On back-testing, several trained models show good performance, with the multi-layer perception (MLP) demonstrating stability and robustness across extensive and comprehensive data that include upward, downward and cyclic trends. The unique perspective of this work that focuses on weekly movements, incorporates new features and creates an objective benchmark, contributes to the existing literature on stock market prediction.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7a0bb044a3d1045d39d6d28a519d37fb7ac7b36d" target='_blank'>
              Machine learning in weekly movement prediction
              </a>
            </td>
          <td>
            Han Gui
          </td>
          <td>2024-07-13</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

    </tbody>
    <tfoot>
      <tr>
          <th>Abstract</th>
          <th>Title</th>
          <th>Authors</th>
          <th>Publication Date</th>
          <th>Journal/Conference</th>
          <th>Citation count</th>
          <th>Highest h-index</th>
      </tr>
    </tfoot>
    </table>
    </p>
  </div>

</body>

<script>

  function create_author_list(author_list) {
    let td_author_element = document.getElementById();
    for (let i = 0; i < author_list.length; i++) {
          // tdElements[i].innerHTML = greet(tdElements[i].innerHTML);
          alert (author_list[i]);
      }
  }

  var trace1 = {
    x: ['2023', '2024'],
    y: [0, 13],
    name: 'Num of citations',
    yaxis: 'y1',
    type: 'scatter'
  };

  var data = [trace1];

  var layout = {
    yaxis: {
      title: 'Num of citations',
      }
  };
  Plotly.newPlot('myDiv1', data, layout);
</script>
<script>
var dataTableOptions = {
        initComplete: function () {
        this.api()
            .columns()
            .every(function () {
                let column = this;

                // Create select element
                let select = document.createElement('select');
                select.add(new Option(''));
                column.footer().replaceChildren(select);

                // Apply listener for user change in value
                select.addEventListener('change', function () {
                    column
                        .search(select.value, {exact: true})
                        .draw();
                });

                // keep the width of the select element same as the column
                select.style.width = '100%';

                // Add list of options
                column
                    .data()
                    .unique()
                    .sort()
                    .each(function (d, j) {
                        select.add(new Option(d));
                    });
            });
    },
    scrollX: true,
    scrollCollapse: true,
    paging: true,
    fixedColumns: true,
    columnDefs: [
        {"className": "dt-center", "targets": "_all"},
        // set width for both columns 0 and 1 as 25%
        { width: '7%', targets: 0 },
        { width: '30%', targets: 1 },
        { width: '25%', targets: 2 },
        { width: '15%', targets: 4 }

      ],
    pageLength: 10,
    layout: {
        topStart: {
            buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
        }
    }
  }
  new DataTable('#table1', dataTableOptions);
  new DataTable('#table2', dataTableOptions);

  var table1 = $('#table1').DataTable();
  $('#table1 tbody').on('click', 'td:first-child', function () {
    var tr = $(this).closest('tr');
    var row = table1.row( tr );

    var rowId = tr.attr('id');
    // alert(rowId);

    if (row.child.isShown()) {
      // This row is already open - close it.
      row.child.hide();
      tr.removeClass('shown');
      tr.find('td:first-child').html('<i class="material-icons">visibility_off</i>');
    } else {
      // Open row.
      // row.child('foo').show();
      tr.find('td:first-child').html('<i class="material-icons">visibility</i>');
      var content = '<div class="child-row-content"><strong>Abstract:</strong> ' + rowId + '</div>';
      row.child(content).show();
      tr.addClass('shown');
    }
  });
  var table2 = $('#table2').DataTable();
  $('#table2 tbody').on('click', 'td:first-child', function () {
    var tr = $(this).closest('tr');
    var row = table2.row( tr );

    var rowId = tr.attr('id');
    // alert(rowId);

    if (row.child.isShown()) {
      // This row is already open - close it.
      row.child.hide();
      tr.removeClass('shown');
      tr.find('td:first-child').html('<i class="material-icons">visibility_off</i>');
    } else {
      // Open row.
      // row.child('foo').show();
      var content = '<div class="child-row-content"><strong>Abstract:</strong> ' + rowId + '</div>';
      row.child(content).show();
      tr.addClass('shown');
      tr.find('td:first-child').html('<i class="material-icons">visibility</i>');
    }
  });
</script>
<style>
  .child-row-content {
    text-align: justify;
    text-justify: inter-word;
    word-wrap: break-word; /* Ensure long words are broken */
    white-space: normal; /* Ensure text wraps to the next line */
    max-width: 100%; /* Ensure content does not exceed the table width */
    padding: 10px; /* Optional: add some padding for better readability */
    /* font size */
    font-size: small;
  }
</style>
</html>







  
  




  



                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.top", "navigation.tabs"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    

      <script src="../assets/javascripts/bundle.c8d2eff1.min.js"></script>
      
    
<script>
  // Execute intro.js when a button with id 'intro' is clicked
  function startIntro(){
      introJs().setOptions({
          tooltipClass: 'customTooltip'
      }).start();
  }
</script>
<script>
  

  // new DataTable('#table1', {
  //   order: [[5, 'desc']],
  //   "columnDefs": [
  //       {"className": "dt-center", "targets": "_all"},
  //       { width: '30%', targets: 0 }
  //     ],
  //   pageLength: 10,
  //   layout: {
  //       topStart: {
  //           buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
  //       }
  //   }
  // });

  // new DataTable('#table2', {
  //   order: [[3, 'desc']],
  //   "columnDefs": [
  //       {"className": "dt-center", "targets": "_all"},
  //       { width: '30%', targets: 0 }
  //     ],
  //   pageLength: 10,
  //   layout: {
  //       topStart: {
  //           buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
  //       }
  //   }
  // });
  new DataTable('#table3', {
    initComplete: function () {
        this.api()
            .columns()
            .every(function () {
                let column = this;
 
                // Create select element
                let select = document.createElement('select');
                select.add(new Option(''));
                column.footer().replaceChildren(select);
 
                // Apply listener for user change in value
                select.addEventListener('change', function () {
                    column
                        .search(select.value, {exact: true})
                        .draw();
                });

                // keep the width of the select element same as the column
                select.style.width = '100%';
 
                // Add list of options
                column
                    .data()
                    .unique()
                    .sort()
                    .each(function (d, j) {
                        select.add(new Option(d));
                    });
            });
    },
    // order: [[3, 'desc']],
    "columnDefs": [
        {"className": "dt-center", "targets": "_all"},
        { width: '30%', targets: 0 }
      ],
    pageLength: 10,
    layout: {
        topStart: {
            buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
        }
    }
  });
  new DataTable('#table4', {
    initComplete: function () {
        this.api()
            .columns()
            .every(function () {
                let column = this;
 
                // Create select element
                let select = document.createElement('select');
                select.add(new Option(''));
                column.footer().replaceChildren(select);
 
                // Apply listener for user change in value
                select.addEventListener('change', function () {
                    column
                        .search(select.value, {exact: true})
                        .draw();
                });

                // keep the width of the select element same as the column
                select.style.width = '100%';
 
                // Add list of options
                column
                    .data()
                    .unique()
                    .sort()
                    .each(function (d, j) {
                        select.add(new Option(d));
                    });
            });
    },
    // order: [[3, 'desc']],
    "columnDefs": [
        {"className": "dt-center", "targets": "_all"},
        { width: '30%', targets: 0 }
      ],
    pageLength: 10,
    layout: {
        topStart: {
            buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
        }
    }
  });
</script>


  </body>
</html>