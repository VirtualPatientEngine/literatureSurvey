<!DOCTYPE html>

<html lang="en">


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../Time-series%20forecasting/">
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.12">
    
    
<title>Literature Survey (VPE)</title>

    
      <link rel="stylesheet" href="../assets/stylesheets/main.7e359304.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
  <!-- Add scripts that need to run before here -->
  <!-- Add jquery script -->
  <script src="https://code.jquery.com/jquery-3.7.1.js"></script>
  <!-- Add data table libraries -->
  <script src="https://cdn.datatables.net/2.0.1/js/dataTables.js"></script>
  <link rel="stylesheet" href="https://cdn.datatables.net/2.0.1/css/dataTables.dataTables.css">
  <!-- Load plotly.js into the DOM -->
	<script src='https://cdn.plot.ly/plotly-2.29.1.min.js'></script>
  <link rel="stylesheet" href="https://cdn.datatables.net/buttons/3.0.1/css/buttons.dataTables.css">
  <!-- fixedColumns -->
  <script src="https://cdn.datatables.net/fixedcolumns/5.0.0/js/dataTables.fixedColumns.js"></script>
  <script src="https://cdn.datatables.net/fixedcolumns/5.0.0/js/fixedColumns.dataTables.js"></script>
  <link rel="stylesheet" href="https://cdn.datatables.net/fixedcolumns/5.0.0/css/fixedColumns.dataTables.css">
  <!-- Already specified in mkdocs.yml -->
  <!-- <link rel="stylesheet" href="../docs/custom.css"> -->
  <script src="https://cdn.datatables.net/buttons/3.0.1/js/dataTables.buttons.js"></script>
  <script src="https://cdn.datatables.net/buttons/3.0.1/js/buttons.dataTables.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.1/jszip.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdfmake/0.2.7/pdfmake.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdfmake/0.2.7/vfs_fonts.js"></script>
  <script src="https://cdn.datatables.net/buttons/3.0.1/js/buttons.html5.min.js"></script>
  <script src="https://cdn.datatables.net/buttons/3.0.1/js/buttons.print.min.js"></script>
  <!-- Google fonts -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
  <!-- Intro.js -->
  <script src="https://cdn.jsdelivr.net/npm/intro.js@7.2.0/intro.min.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/intro.js@7.2.0/minified/introjs.min.css">


  <!-- 
      
     -->
  <!-- Add scripts that need to run afterwards here -->

    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../custom.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="black">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Literature Survey (VPE)" class="md-header__button md-logo" aria-label="Literature Survey (VPE)" data-md-component="logo">
      
  <img src="../assets/VPE.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Literature Survey (VPE)
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Symbolic regression
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="black"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="white" data-md-color-accent="black"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/VirtualPatientEngine/literatureSurvey" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    VPE/LiteratureSurvey
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href=".." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../Time-series%20forecasting/" class="md-tabs__link">
        
  
    
  
  Time-series forecasting

      </a>
    </li>
  

      
        
  
  
    
  
  
    <li class="md-tabs__item md-tabs__item--active">
      <a href="./" class="md-tabs__link">
        
  
    
  
  Symbolic regression

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
                
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" hidden>
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Literature Survey (VPE)" class="md-nav__button md-logo" aria-label="Literature Survey (VPE)" data-md-component="logo">
      
  <img src="../assets/VPE.png" alt="logo">

    </a>
    Literature Survey (VPE)
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/VirtualPatientEngine/literatureSurvey" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    VPE/LiteratureSurvey
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Time-series%20forecasting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Time-series forecasting
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Symbolic regression
  </span>
  

      </a>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
                
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>Symbolic regression</h1>

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
</head>

<body>
  <p>
  <i class="footer">This page was last updated on 2024-07-29 06:05:55 UTC</i>
  </p>

  <div class="note info" onclick="startIntro()">
    <p>
      <button type="button" class="buttons">
        <div style="display: flex; align-items: center;">
        Click here for a quick intro of the page! <i class="material-icons">help</i>
        </div>
      </button>
    </p>
  </div>

  <!--
  <div data-intro='Table of contents'>
    <p>
    <h3>Table of Contents</h3>
      <a href="#plot1">1. Citations over time on Symbolic regression</a><br>
      <a href="#manually_curated_articles">2. Manually curated articles on Symbolic regression</a><br>
      <a href="#recommended_articles">3. Recommended articles on Symbolic regression</a><br>
    <p>
  </div>

  <div data-intro='Plot displaying number of citations over time 
                  on the given topic based on recommended articles'>
    <p>
    <h3 id="plot1">1. Citations over time on Symbolic regression</h3>
      <div id='myDiv1'>
      </div>
    </p>
  </div>
  -->

  <div data-intro='Manually curated articles on the given topic'>
    <p>
    <h3 id="manually_curated_articles">Manually curated articles on <i>Symbolic regression</i></h3>
    <table id="table1" class="display" style="width:100%">
    <thead>
      <tr>
          <th data-intro='Click to view the abstract (if available)'>Abstract</th>
          <th>Title</th>
          <th>Authors</th>
          <th>Publication Date</th>
          <th>Journal/ Conference</th>
          <th>Citation count</th>
          <th data-intro='Highest h-index among the authors'>Highest h-index</th>
          <th data-intro='Recommended articles extracted by considering
                          only the given article'>
              View recommendations
              </th>
      </tr>
    </thead>
    <tbody>

        <tr id="Significance Understanding dynamic constraints and balances in nature has facilitated rapid development of knowledge and enabled technology, including aircraft, combustion engines, satellites, and electrical power. This work develops a novel framework to discover governing equations underlying a dynamical system simply from data measurements, leveraging advances in sparsity techniques and machine learning. The resulting models are parsimonious, balancing model complexity with descriptive ability while avoiding overfitting. There are many critical data-driven problems, such as understanding cognition from neural recordings, inferring climate patterns, determining stability of financial markets, predicting and suppressing the spread of disease, and controlling turbulence for greener transportation and energy. With abundant data and elusive laws, data-driven discovery of dynamics will continue to play an important role in these efforts. Extracting governing equations from data is a central challenge in many diverse areas of science and engineering. Data are abundant whereas models often remain elusive, as in climate science, neuroscience, ecology, finance, and epidemiology, to name only a few examples. In this work, we combine sparsity-promoting techniques and machine learning with nonlinear dynamical systems to discover governing equations from noisy measurement data. The only assumption about the structure of the model is that there are only a few important terms that govern the dynamics, so that the equations are sparse in the space of possible functions; this assumption holds for many physical systems in an appropriate basis. In particular, we use sparse regression to determine the fewest terms in the dynamic governing equations required to accurately represent the data. This results in parsimonious models that balance accuracy with model complexity to avoid overfitting. We demonstrate the algorithm on a wide range of problems, from simple canonical systems, including linear and nonlinear oscillators and the chaotic Lorenz system, to the fluid vortex shedding behind an obstacle. The fluid example illustrates the ability of this method to discover the underlying dynamics of a system that took experts in the community nearly 30 years to resolve. We also show that this method generalizes to parameterized systems and systems that are time-varying or have external forcing.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5d150cec2775f9bc863760448f14104cc8f42368" target='_blank'>
                Discovering governing equations from data by sparse identification of nonlinear dynamical systems
                </a>
              </td>
          <td>
            S. Brunton, J. Proctor, J. Kutz
          </td>
          <td>2015-09-11</td>
          <td>Proceedings of the National Academy of Sciences, Proceedings of the National Academy of Sciences of the United States of America</td>
          <td>3132</td>
          <td>63</td>

            <td><a href='../recommendations/5d150cec2775f9bc863760448f14104cc8f42368' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/60d0d998fa038182b3b69a57adb9b2f82d40589c" target='_blank'>
                Robust learning from noisy, incomplete, high-dimensional experimental data via physically constrained symbolic regression
                </a>
              </td>
          <td>
            Patrick A. K. Reinbold, Logan Kageorge, M. Schatz, R. Grigoriev
          </td>
          <td>2021-02-24</td>
          <td>Nature Communications</td>
          <td>83</td>
          <td>23</td>

            <td><a href='../recommendations/60d0d998fa038182b3b69a57adb9b2f82d40589c' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Significance Governing equations are essential to the study of physical systems, providing models that can generalize to predict previously unseen behaviors. There are many systems of interest across disciplines where large quantities of data have been collected, but the underlying governing equations remain unknown. This work introduces an approach to discover governing models from data. The proposed method addresses a key limitation of prior approaches by simultaneously discovering coordinates that admit a parsimonious dynamical model. Developing parsimonious and interpretable governing models has the potential to transform our understanding of complex systems, including in neuroscience, biology, and climate science. The discovery of governing equations from scientific data has the potential to transform data-rich fields that lack well-characterized quantitative descriptions. Advances in sparse regression are currently enabling the tractable identification of both the structure and parameters of a nonlinear dynamical system from data. The resulting models have the fewest terms necessary to describe the dynamics, balancing model complexity with descriptive ability, and thus promoting interpretability and generalizability. This provides an algorithmic approach to Occam’s razor for model discovery. However, this approach fundamentally relies on an effective coordinate system in which the dynamics have a simple representation. In this work, we design a custom deep autoencoder network to discover a coordinate transformation into a reduced space where the dynamics may be sparsely represented. Thus, we simultaneously learn the governing equations and the associated coordinate system. We demonstrate this approach on several example high-dimensional systems with low-dimensional behavior. The resulting modeling framework combines the strengths of deep neural networks for flexible representation and sparse identification of nonlinear dynamics (SINDy) for parsimonious models. This method places the discovery of coordinates and models on an equal footing.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3c9961153493370500020c81527b3548c96f81e0" target='_blank'>
                Data-driven discovery of coordinates and governing equations
                </a>
              </td>
          <td>
            Kathleen P. Champion, Bethany Lusch, J. Kutz, S. Brunton
          </td>
          <td>2019-03-29</td>
          <td>Proceedings of the National Academy of Sciences of the United States of America</td>
          <td>591</td>
          <td>63</td>

            <td><a href='../recommendations/3c9961153493370500020c81527b3548c96f81e0' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3df50e9b73cc2937dfd651f4c3344bc99b7ed3f2" target='_blank'>
                Chaos as an intermittently forced linear system
                </a>
              </td>
          <td>
            S. Brunton, Bingni W. Brunton, J. Proctor, E. Kaiser, J. Kutz
          </td>
          <td>2016-08-18</td>
          <td>Nature Communications</td>
          <td>442</td>
          <td>63</td>

            <td><a href='../recommendations/3df50e9b73cc2937dfd651f4c3344bc99b7ed3f2' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Data-driven discovery of dynamics via machine learning is pushing the frontiers of modelling and control efforts, providing a tremendous opportunity to extend the reach of model predictive control (MPC). However, many leading methods in machine learning, such as neural networks (NN), require large volumes of training data, may not be interpretable, do not easily include known constraints and symmetries, and may not generalize beyond the attractor where models are trained. These factors limit their use for the online identification of a model in the low-data limit, for example following an abrupt change to the system dynamics. In this work, we extend the recent sparse identification of nonlinear dynamics (SINDY) modelling procedure to include the effects of actuation and demonstrate the ability of these models to enhance the performance of MPC, based on limited, noisy data. SINDY models are parsimonious, identifying the fewest terms in the model needed to explain the data, making them interpretable and generalizable. We show that the resulting SINDY-MPC framework has higher performance, requires significantly less data, and is more computationally efficient and robust to noise than NN models, making it viable for online training and execution in response to rapid system changes. SINDY-MPC also shows improved performance over linear data-driven models, although linear models may provide a stopgap until enough data is available for SINDY. SINDY-MPC is demonstrated on a variety of dynamical systems with different challenges, including the chaotic Lorenz system, a simple model for flight control of an F8 aircraft, and an HIV model incorporating drug treatment.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b2eb064f432557c59ce99834d7dc7817e4687271" target='_blank'>
                Sparse identification of nonlinear dynamics for model predictive control in the low-data limit
                </a>
              </td>
          <td>
            E. Kaiser, J. Kutz, S. Brunton
          </td>
          <td>2017-11-15</td>
          <td>Proceedings of the Royal Society A, Proceedings. Mathematical, Physical, and Engineering Sciences</td>
          <td>424</td>
          <td>63</td>

            <td><a href='../recommendations/b2eb064f432557c59ce99834d7dc7817e4687271' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Inferring the structure and dynamics of network models is critical to understanding the functionality and control of complex systems, such as metabolic and regulatory biological networks. The increasing quality and quantity of experimental data enable statistical approaches based on information theory for model selection and goodness-of-fit metrics. We propose an alternative data-driven method to infer networked nonlinear dynamical systems by using sparsity-promoting optimization to select a subset of nonlinear interactions representing dynamics on a network. In contrast to standard model selection methods-based upon information content for a finite number of heuristic models (order 10 or less), our model selection procedure discovers a parsimonious model from a combinatorially large set of models, without an exhaustive search. Our particular innovation is appropriate for many biological networks, where the governing dynamical systems have rational function nonlinearities with cross terms, thus requiring an implicit formulation and the equations to be identified in the null-space of a library of mixed nonlinearities, including the state and derivative terms. This method, implicit-SINDy, succeeds in inferring three canonical biological models: 1) Michaelis-Menten enzyme kinetics; 2) the regulatory network for competence in bacteria; and 3) the metabolic network for yeast glycolysis.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/06a0ba437d41a7c82c08a9636a4438c1b5031378" target='_blank'>
                Inferring Biological Networks by Sparse Identification of Nonlinear Dynamics
                </a>
              </td>
          <td>
            N. Mangan, S. Brunton, J. Proctor, J. Kutz
          </td>
          <td>2016-05-26</td>
          <td>IEEE Transactions on Molecular Biological and Multi-Scale Communications, IEEE Transactions on Molecular, Biological and Multi-Scale Communications</td>
          <td>312</td>
          <td>63</td>

            <td><a href='../recommendations/06a0ba437d41a7c82c08a9636a4438c1b5031378' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Accurately modelling the nonlinear dynamics of a system from measurement data is a challenging yet vital topic. The sparse identification of nonlinear dynamics (SINDy) algorithm is one approach to discover dynamical systems models from data. Although extensions have been developed to identify implicit dynamics, or dynamics described by rational functions, these extensions are extremely sensitive to noise. In this work, we develop SINDy-PI (parallel, implicit), a robust variant of the SINDy algorithm to identify implicit dynamics and rational nonlinearities. The SINDy-PI framework includes multiple optimization algorithms and a principled approach to model selection. We demonstrate the ability of this algorithm to learn implicit ordinary and partial differential equations and conservation laws from limited and noisy data. In particular, we show that the proposed approach is several orders of magnitude more noise robust than previous approaches, and may be used to identify a class of ODE and PDE dynamics that were previously unattainable with SINDy, including for the double pendulum dynamics and simplified model for the Belousov–Zhabotinsky (BZ) reaction.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4971f9abd024e40fbbdff2e9492745b68a6bca01" target='_blank'>
                SINDy-PI: a robust algorithm for parallel implicit sparse identification of nonlinear dynamics
                </a>
              </td>
          <td>
            Kadierdan Kaheman, J. Kutz, S. Brunton
          </td>
          <td>2020-04-05</td>
          <td>Proceedings of the Royal Society A, Proceedings. Mathematical, Physical, and Engineering Sciences</td>
          <td>187</td>
          <td>63</td>

            <td><a href='../recommendations/4971f9abd024e40fbbdff2e9492745b68a6bca01' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="A key task in the field of modeling and analyzing nonlinear dynamical systems is the recovery of unknown governing equations from measurement data only. There is a wide range of application areas for this important instance of system identification, ranging from industrial engineering and acoustic signal processing to stock market models. In order to find appropriate representations of underlying dynamical systems, various data-driven methods have been proposed by different communities. However, if the given data sets are high-dimensional, then these methods typically suffer from the curse of dimensionality. To significantly reduce the computational costs and storage consumption, we propose the method multidimensional approximation of nonlinear dynamical systems (MANDy) which combines data-driven methods with tensor network decompositions. The efficiency of the introduced approach will be illustrated with the aid of several high-dimensional nonlinear dynamical systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2b2aa13d4959073f61ad70555bc8c7da7d116196" target='_blank'>
                Multidimensional Approximation of Nonlinear Dynamical Systems
                </a>
              </td>
          <td>
            Patrick Gelß, Stefan Klus, J. Eisert, Christof Schutte
          </td>
          <td>2018-09-07</td>
          <td>Journal of Computational and Nonlinear Dynamics</td>
          <td>61</td>
          <td>76</td>

            <td><a href='../recommendations/2b2aa13d4959073f61ad70555bc8c7da7d116196' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="First principles modeling of physical systems has led to significant technological advances across all branches of science. For nonlinear systems, however, small modeling errors can lead to significant deviations from the true, measured behavior. Even in mechanical systems, where the equations are assumed to be well-known, there are often model discrepancies corresponding to nonlinear friction, wind resistance, etc. Discovering models for these discrepancies remains an open challenge for many complex systems. In this work, we use the sparse identification of nonlinear dynamics (SINDy) algorithm to discover a model for the discrepancy between a simplified model and measurement data. In particular, we assume that the model mismatch can be sparsely represented in a library of candidate model terms. We demonstrate the efficacy of our approach on several examples including experimental data from a double pendulum on a cart. We further design and implement a feed-forward controller in simulations, showing improvement with a discrepancy model.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/73dd9c49f205280991826b2ea4b50344203916b4" target='_blank'>
                Learning Discrepancy Models From Experimental Data
                </a>
              </td>
          <td>
            Kadierdan Kaheman, E. Kaiser, B. Strom, J. Kutz, S. Brunton
          </td>
          <td>2019-09-18</td>
          <td>arXiv.org, ArXiv</td>
          <td>31</td>
          <td>63</td>

            <td><a href='../recommendations/73dd9c49f205280991826b2ea4b50344203916b4' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Machine learning (ML) and artificial intelligence (AI) algorithms are now being used to automate the discovery of physics principles and governing equations from measurement data alone. However, positing a universal physical law from data is challenging without simultaneously proposing an accompanying discrepancy model to account for the inevitable mismatch between theory and measurements. By revisiting the classic problem of modeling falling objects of different size and mass, we highlight a number of nuanced issues that must be addressed by modern data-driven methods for automated physics discovery. Specifically, we show that measurement noise and complex secondary physical mechanisms, like unsteady fluid drag forces, can obscure the underlying law of gravitation, leading to an erroneous model. We use the sparse identification of non-linear dynamics (SINDy) method to identify governing equations for real-world measurement data and simulated trajectories. Incorporating into SINDy the assumption that each falling object is governed by a similar physical law is shown to improve the robustness of the learned models, but discrepancies between the predictions and observations persist due to subtleties in drag dynamics. This work highlights the fact that the naive application of ML/AI will generally be insufficient to infer universal physical laws without further modification.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/35e2571c17246577e0bc1b9de57a314c3b60e220" target='_blank'>
                Discovery of Physics From Data: Universal Laws and Discrepancies
                </a>
              </td>
          <td>
            Brian M. de Silva, D. Higdon, S. Brunton, J. Kutz
          </td>
          <td>2019-06-19</td>
          <td>Frontiers in Artificial Intelligence</td>
          <td>66</td>
          <td>63</td>

            <td><a href='../recommendations/35e2571c17246577e0bc1b9de57a314c3b60e220' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Researchers propose sparse regression for identifying governing partial differential equations for spatiotemporal systems. We propose a sparse regression method capable of discovering the governing partial differential equation(s) of a given system by time series measurements in the spatial domain. The regression framework relies on sparsity-promoting techniques to select the nonlinear and partial derivative terms of the governing equations that most accurately represent the data, bypassing a combinatorially large search through all possible candidate models. The method balances model complexity and regression accuracy by selecting a parsimonious model via Pareto analysis. Time series measurements can be made in an Eulerian framework, where the sensors are fixed spatially, or in a Lagrangian framework, where the sensors move with the dynamics. The method is computationally efficient, robust, and demonstrated to work on a variety of canonical problems spanning a number of scientific domains including Navier-Stokes, the quantum harmonic oscillator, and the diffusion equation. Moreover, the method is capable of disambiguating between potentially nonunique dynamical terms by using multiple time series taken with different initial data. Thus, for a traveling wave, the method can distinguish between a linear wave equation and the Korteweg–de Vries equation, for instance. The method provides a promising new technique for discovering governing equations and physical laws in parameterized spatiotemporal systems, where first-principles derivations are intractable.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0acd117521ef5aafb09fed02ab415523b330b058" target='_blank'>
                Data-driven discovery of partial differential equations
                </a>
              </td>
          <td>
            S. Rudy, S. Brunton, J. Proctor, J. Kutz
          </td>
          <td>2016-09-21</td>
          <td>Science Advances</td>
          <td>1161</td>
          <td>63</td>

            <td><a href='../recommendations/0acd117521ef5aafb09fed02ab415523b330b058' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Sparse model identification enables the discovery of nonlinear dynamical systems purely from data; however, this approach is sensitive to noise, especially in the low-data limit. In this work, we leverage the statistical approach of bootstrap aggregating (bagging) to robustify the sparse identification of the nonlinear dynamics (SINDy) algorithm. First, an ensemble of SINDy models is identified from subsets of limited and noisy data. The aggregate model statistics are then used to produce inclusion probabilities of the candidate functions, which enables uncertainty quantification and probabilistic forecasts. We apply this ensemble-SINDy (E-SINDy) algorithm to several synthetic and real-world datasets and demonstrate substantial improvements to the accuracy and robustness of model discovery from extremely noisy and limited data. For example, E-SINDy uncovers partial differential equations models from data with more than twice as much measurement noise as has been previously reported. Similarly, E-SINDy learns the Lotka Volterra dynamics from remarkably limited data of yearly lynx and hare pelts collected from 1900 to 1920. E-SINDy is computationally efficient, with similar scaling as standard SINDy. Finally, we show that ensemble statistics from E-SINDy can be exploited for active learning and improved model predictive control.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/883547fdbd88552328a6615ec620f96e39c57018" target='_blank'>
                Ensemble-SINDy: Robust sparse model discovery in the low-data, high-noise limit, with active learning and control
                </a>
              </td>
          <td>
            Urban Fasel, J. Kutz, Bingni W. Brunton, S. Brunton
          </td>
          <td>2021-11-22</td>
          <td>Proceedings of the Royal Society A, Proceedings. Mathematical, Physical, and Engineering Sciences</td>
          <td>154</td>
          <td>63</td>

            <td><a href='../recommendations/883547fdbd88552328a6615ec620f96e39c57018' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e6f0a85009481dcfd93aaa43ed3f980e5033b0d8" target='_blank'>
                Learning sparse nonlinear dynamics via mixed-integer optimization
                </a>
              </td>
          <td>
            D. Bertsimas, Wes Gurnee
          </td>
          <td>2022-06-01</td>
          <td>Nonlinear Dynamics</td>
          <td>27</td>
          <td>90</td>

            <td><a href='../recommendations/e6f0a85009481dcfd93aaa43ed3f980e5033b0d8' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Regularized regression problems are ubiquitous in statistical modeling, signal processing, and machine learning. Sparse regression, in particular, has been instrumental in scientific model discovery, including compressed sensing applications, variable selection, and high-dimensional analysis. We propose a broad framework for sparse relaxed regularized regression, called SR3. The key idea is to solve a relaxation of the regularized problem, which has three advantages over the state-of-the-art: 1) solutions of the relaxed problem are superior with respect to errors, false positives, and conditioning; 2) relaxation allows extremely fast algorithms for both convex and nonconvex formulations; and 3) the methods apply to composite regularizers, essential for total variation (TV) as well as sparsity-promoting formulations using tight frames. We demonstrate the advantages of SR3 (computational efficiency, higher accuracy, faster convergence rates, and greater flexibility) across a range of regularized regression problems with synthetic and real data, including applications in compressed sensing, LASSO, matrix completion, TV regularization, and group sparsity. Following standards of reproducible research, we also provide a companion MATLAB package that implements these examples.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c0fc3882a9976f6a9cdc3a724bce184b786503da" target='_blank'>
                A Unified Framework for Sparse Relaxed Regularized Regression: SR3
                </a>
              </td>
          <td>
            P. Zheng, T. Askham, S. Brunton, J. Kutz, A. Aravkin
          </td>
          <td>2018-07-14</td>
          <td>IEEE Access</td>
          <td>114</td>
          <td>63</td>

            <td><a href='../recommendations/c0fc3882a9976f6a9cdc3a724bce184b786503da' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

    </tbody>
    <tfoot>
      <tr>
          <th>Abstract</th>
          <th>Title</th>
          <th>Authors</th>
          <th>Publication Date</th>
          <th>Journal/ Conference</th>
          <th>Citation count</th>
          <th>Highest h-index</th>
          <th>View recommendations</th>
      </tr>
    </tfoot>
    </table>
    </p>
  </div>

  <div data-intro='Recommended articles extracted by contrasting
                  articles that are relevant against not relevant for Symbolic regression'>
    <p>
    <h3 id="recommended_articles">Recommended articles on <i>Symbolic regression</i></h3>
    <table id="table2" class="display" style="width:100%">
    <thead>
      <tr>
          <th>Abstract</th>
          <th>Title</th>
          <th>Authors</th>
          <th>Publication Date</th>
          <th>Journal/Conference</th>
          <th>Citation count</th>
          <th>Highest h-index</th>
      </tr>
    </thead>
    <tbody>

        <tr id="Over the past few years, equation discovery has gained popularity in different fields of science and engineering. However, existing equation discovery algorithms rely on the availability of noisy measurements of the state variables (i.e., displacement {and velocity}). This is a major bottleneck in structural dynamics, where we often only have access to acceleration measurements. To that end, this paper introduces a novel equation discovery algorithm for discovering governing equations of dynamical systems from acceleration-only measurements. The proposed algorithm employs a library-based approach for equation discovery. To enable equation discovery from acceleration-only measurements, we propose a novel Approximate Bayesian Computation (ABC) model that prioritizes parsimonious models. The efficacy of the proposed algorithm is illustrated using {four} structural dynamics examples that include both linear and nonlinear dynamical systems. The case studies presented illustrate the possible application of the proposed approach for equation discovery of dynamical systems from acceleration-only measurements.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f046e6be05e115bc55624ef726d92d6d06303346" target='_blank'>
              Discovering governing equation in structural dynamics from acceleration-only measurements
              </a>
            </td>
          <td>
            Calvin Alvares, Souvik Chakraborty
          </td>
          <td>2024-07-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="This paper proposes a sparse regression strategy for discovery of ordinary and partial differential equations from incomplete and noisy data. Inference is performed over both equation parameters and state variables using a statistically motivated likelihood function. Sparsity is enforced by a selection algorithm which iteratively removes terms and compares models using statistical information criteria. Large scale optimization is performed using a second-order variant of the Levenberg-Marquardt method, where the gradient and Hessian are computed via automatic differentiation. Illustrations involving canonical systems of ordinary and partial differential equations are used to demonstrate the flexibility and robustness of the approach. Accurate reconstruction of systems is found to be possible even in extreme cases of limited data and large observation noise.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3d4419932eaa736ba7230568e3503746b37957c5" target='_blank'>
              Discovery of differential equations using sparse state and parameter regression
              </a>
            </td>
          <td>
            Teddy Meissner, Karl Glasner
          </td>
          <td>2024-06-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The simulation of many complex phenomena in engineering and science requires solving expensive, high-dimensional systems of partial differential equations (PDEs). To circumvent this, reduced-order models (ROMs) have been developed to speed up computations. However, when governing equations are unknown or partially known, typically ROMs lack interpretability and reliability of the predicted solutions. In this work we present a data-driven, non-intrusive framework for building ROMs where the latent variables and dynamics are identified in an interpretable manner and uncertainty is quantified. Starting from a limited amount of high-dimensional, noisy data the proposed framework constructs an efficient ROM by leveraging variational autoencoders for dimensionality reduction along with a newly introduced, variational version of sparse identification of nonlinear dynamics (SINDy), which we refer to as Variational Identification of Nonlinear Dynamics (VINDy). In detail, the method consists of Variational Encoding of Noisy Inputs (VENI) to identify the distribution of reduced coordinates. Simultaneously, we learn the distribution of the coefficients of a pre-determined set of candidate functions by VINDy. Once trained offline, the identified model can be queried for new parameter instances and new initial conditions to compute the corresponding full-time solutions. The probabilistic setup enables uncertainty quantification as the online testing consists of Variational Inference naturally providing Certainty Intervals (VICI). In this work we showcase the effectiveness of the newly proposed VINDy method in identifying interpretable and accurate dynamical system for the R\"ossler system with different noise intensities and sources. Then the performance of the overall method - named VENI, VINDy, VICI - is tested on PDE benchmarks including structural mechanics and fluid dynamics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/85d8b58d1657768ca3e0c17e25857d87f0cc6850" target='_blank'>
              VENI, VINDy, VICI: a variational reduced-order modeling framework with uncertainty quantification
              </a>
            </td>
          <td>
            Paolo Conti, Jonas Kneifl, Andrea Manzoni, A. Frangi, Jörg Fehr, S. Brunton, J. Kutz
          </td>
          <td>2024-05-31</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>63</td>
        </tr>

        <tr id="Enhancing the sparsity of data-driven reduced-order models (ROMs) has gained increasing attention in recent years. In this work, we analyze an efficient approach to identifying skillful ROMs with a sparse structure using an information-theoretic indicator called causation entropy. The causation entropy quantifies in a statistical way the additional contribution of each term to the underlying dynamics beyond the information already captured by all the other terms in the ansatz. By doing so, the causation entropy assesses the importance of each term to the dynamics before a parameter estimation procedure is performed. Thus, the approach can be utilized to eliminate terms with little dynamic impact, leading to a parsimonious structure that retains the essential physics. To circumvent the difficulty of estimating high-dimensional probability density functions (PDFs) involved in the causation entropy computation, we leverage Gaussian approximations for such PDFs, which are demonstrated to be sufficient even in the presence of highly non-Gaussian dynamics. The effectiveness of the approach is illustrated by the Kuramoto-Sivashinsky equation by building sparse causation-based ROMs for various purposes, such as recovering long-term statistics and inferring unobserved dynamics via data assimilation with partial observations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/51343d94516402e35ba4c9c52a62e0d4dd4986ba" target='_blank'>
              Minimum Reduced-Order Models via Causal Inference
              </a>
            </td>
          <td>
            Nan Chen, Honghu Liu
          </td>
          <td>2024-06-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="This paper focuses on the application of experimental data-based system identification of unknown systems utilising sparse identification of nonlinear dynamics (SINDy). SINDy is used to detect the system dynamics in the three well-known nonlinear systems. Analyzed are SINDy’s abilities to accurately represent transient/steady-state behaviour, noise effect, and model structure. A sparse set of basis functions can effectively capture the dynamics of a system, according to the data-driven approach known as SINDy. The coefficients of these basis functions are determined via methods of sparse regression, and the final model is made up of a number of sparse ordinary differential equations. The findings demonstrate that SINDy, with sufficient time-series data, can capture both transient and steady-state phenomena. According to the analysis of the noise effect, SINDy’s performance declines as the system’s noise level rises. The feature library must contain the appropriate model structure in order for SINDy to function effectively. SINDy has the potential to extract unknown system dynamics from experimental data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/315b7c145c5a86b92e656ad174cede9f67bf3f34" target='_blank'>
              Data-driven system identification of unknown systems utilising sparse identification of nonlinear dynamics (SINDy)
              </a>
            </td>
          <td>
            P. Pandey, H. Haddad Khodaparast, M. Friswell, T. Chatterjee, N. Jamia, T. Deighan
          </td>
          <td>2024-06-01</td>
          <td>Journal of Physics: Conference Series</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Modeling complex physical dynamics is a fundamental task in science and engineering. Traditional physics-based models are first-principled, explainable, and sample-efficient. However, they often rely on strong modeling assumptions and expensive numerical integration, requiring significant computational resources and domain expertise. While deep learning (DL) provides efficient alternatives for modeling complex dynamics, they require a large amount of labeled training data. Furthermore, its predictions may disobey the governing physical laws and are difficult to interpret. Physics-guided DL aims to integrate first-principled physical knowledge into data-driven methods. It has the best of both worlds and is well equipped to better solve scientific problems. Recently, this field has gained great progress and has drawn considerable interest across discipline Here, we introduce the framework of physics-guided DL with a special emphasis on learning dynamical systems. We describe the learning pipeline and categorize state-of-the-art methods under this framework. We also offer our perspectives on the open challenges and emerging opportunities.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/60d721e89c2f9c549241a4982b77f9c752b34460" target='_blank'>
              Learning dynamical systems from data: An introduction to physics-guided deep learning
              </a>
            </td>
          <td>
            Rose Yu, Rui Wang
          </td>
          <td>2024-06-24</td>
          <td>Proceedings of the National Academy of Sciences of the United States of America</td>
          <td>1</td>
          <td>1</td>
        </tr>

        <tr id="We present a computational technique for modeling the evolution of dynamical systems in a reduced basis, with a focus on the challenging problem of modeling partially-observed partial differential equations (PDEs) on high-dimensional non-uniform grids. We address limitations of previous work on data-driven flow map learning in the sense that we focus on noisy and limited data to move toward data collection scenarios in real-world applications. Leveraging recent work on modeling PDEs in modal and nodal spaces, we present a neural network structure that is suitable for PDE modeling with noisy and limited data available only on a subset of the state variables or computational domain. In particular, spatial grid-point measurements are reduced using a learned linear transformation, after which the dynamics are learned in this reduced basis before being transformed back out to the nodal space. This approach yields a drastically reduced parameterization of the neural network compared with previous flow map models for nodal space learning. This primarily allows for smaller training data sets, but also enables reduced training times.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/33821b7c0acd5258ca0c60a09ffdc55439ac7ac2" target='_blank'>
              Principal Component Flow Map Learning of PDEs from Incomplete, Limited, and Noisy Data
              </a>
            </td>
          <td>
            Victor Churchill
          </td>
          <td>2024-07-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The quasipotential function allows for comprehension and prediction of the escape mechanisms from metastable states in nonlinear dynamical systems. This function acts as a natural extension of the potential function for non-gradient systems and it unveils important properties such as the maximum likelihood transition paths, transition rates and expected exit times of the system. Here, we leverage on machine learning via the combination of two data-driven techniques, namely a neural network and a sparse regression algorithm, to obtain symbolic expressions of quasipotential functions. The key idea is first to determine an orthogonal decomposition of the vector field that governs the underlying dynamics using neural networks, then to interpret symbolically the downhill and circulatory components of the decomposition. These functions are regressed simultaneously with the addition of mathematical constraints. We show that our approach discovers a parsimonious quasipotential equation for an archetypal model with a known exact quasipotential and for the dynamics of a nanomechanical resonator. The analytical forms deliver direct access to the stability of the metastable states and predict rare events with significant computational advantages. Our data-driven approach is of interest for a wide range of applications in which to assess the fluctuating dynamics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/174f3a662f5a30364246d8cf0f34af33eac8ccfd" target='_blank'>
              Sparse identification of quasipotentials via a combined data-driven method
              </a>
            </td>
          <td>
            Bo Lin, P. Belardinelli
          </td>
          <td>2024-07-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="Interpretable mathematical expressions defining discrete-time dynamical systems (iterated maps) can model many phenomena of scientific interest, enabling a deeper understanding of system behaviors. Since formulating governing expressions from first principles can be difficult, it is of particular interest to identify expressions for iterated maps given only their data streams. In this work, we consider a modified Symbolic Artificial Neural Network-Trained Expressions (SymANNTEx) architecture for this task, an architecture more expressive than others in the literature. We make a modification to the model pipeline to optimize the regression, then characterize the behavior of the adjusted model in identifying several classical chaotic maps. With the goal of parsimony, sparsity-inducing weight regularization and information theory-informed simplification are implemented. We show that our modified SymANNTEx model properly identifies single-state maps and achieves moderate success in approximating a dual-state attractor. These performances offer significant promise for data-driven scientific discovery and interpretation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3502a1e8d5f9351f334ca3982d09f0f0f0433666" target='_blank'>
              Expressive Symbolic Regression for Interpretable Models of Discrete-Time Dynamical Systems
              </a>
            </td>
          <td>
            Adarsh Iyer, N. Boddupalli, Jeff Moehlis
          </td>
          <td>2024-06-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="In order to extract governing equations from time-series data, various approaches are proposed. Among those, sparse identification of nonlinear dynamics (SINDy) stands out as a successful method capable of modeling governing equations with a minimal number of terms, utilizing the principles of compressive sensing. This feature, which relies on a small number of terms, is crucial for interpretability. The effectiveness of SINDy hinges on the choice of candidate functions within its dictionary to extract governing equations of dynamical systems. A larger dictionary allows for more terms, enhancing the quality of approximations. However, the computational complexity scales with dictionary size, rendering SINDy less suitable for high-dimensional datasets, even though it has been successfully applied to low-dimensional datasets. To address this challenge, we introduce iterative SINDy in this paper, where the dictionary undergoes expansion and compression through iterations. We also conduct an analysis of the convergence properties of iterative SINDy. Simulation results validate that iterative SINDy can achieve nearly identical performance to SINDy, while significantly reducing computational complexity. Notably, iterative SINDy demonstrates effectiveness with high-dimensional time-series data without incurring the prohibitively high computational cost associated with SINDy.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8eef598c19783d3b4af9d79aceeda602036da804" target='_blank'>
              Iterative Sparse Identification of Nonlinear Dynamics
              </a>
            </td>
          <td>
            Jinho Choi
          </td>
          <td>2024-06-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Kolmogorov-Arnold networks (KANs) as an alternative to multi-layer perceptrons (MLPs) are a recent development demonstrating strong potential for data-driven modeling. This work applies KANs as the backbone of a neural ordinary differential equation (ODE) framework, generalizing their use to the time-dependent and temporal grid-sensitive cases often seen in dynamical systems and scientific machine learning applications. The proposed KAN-ODEs retain the flexible dynamical system modeling framework of Neural ODEs while leveraging the many benefits of KANs compared to MLPs, including higher accuracy and faster neural scaling, stronger interpretability and generalizability, and lower parameter counts. First, we quantitatively demonstrated these improvements in a comprehensive study of the classical Lotka-Volterra predator-prey model. We then showcased the KAN-ODE framework's ability to learn symbolic source terms and complete solution profiles in higher-complexity and data-lean scenarios including wave propagation and shock formation, the complex Schr\"odinger equation, and the Allen-Cahn phase separation equation. The successful training of KAN-ODEs, and their improved performance compared to traditional Neural ODEs, implies significant potential in leveraging this novel network architecture in myriad scientific machine learning applications for discovering hidden physics and predicting dynamic evolution.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/efeeddb4162e3eefbe1d974d6ce7cd1d32498a6b" target='_blank'>
              KAN-ODEs: Kolmogorov-Arnold Network Ordinary Differential Equations for Learning Dynamical Systems and Hidden Physics
              </a>
            </td>
          <td>
            Benjamin C. Koenig, Suyong Kim, Sili Deng
          </td>
          <td>2024-07-05</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>22</td>
        </tr>

        <tr id="The parametric greedy latent space dynamics identification (gLaSDI) framework has demonstrated promising potential for accurate and efficient modeling of high-dimensional nonlinear physical systems. However, it remains challenging to handle noisy data. To enhance robustness against noise, we incorporate the weak-form estimation of nonlinear dynamics (WENDy) into gLaSDI. In the proposed weak-form gLaSDI (WgLaSDI) framework, an autoencoder and WENDy are trained simultaneously to discover intrinsic nonlinear latent-space dynamics of high-dimensional data. Compared to the standard sparse identification of nonlinear dynamics (SINDy) employed in gLaSDI, WENDy enables variance reduction and robust latent space discovery, therefore leading to more accurate and efficient reduced-order modeling. Furthermore, the greedy physics-informed active learning in WgLaSDI enables adaptive sampling of optimal training data on the fly for enhanced modeling accuracy. The effectiveness of the proposed framework is demonstrated by modeling various nonlinear dynamical problems, including viscous and inviscid Burgers' equations, time-dependent radial advection, and the Vlasov equation for plasma physics. With data that contains 5-10% Gaussian white noise, WgLaSDI outperforms gLaSDI by orders of magnitude, achieving 1-7% relative errors. Compared with the high-fidelity models, WgLaSDI achieves 121 to 1,779x speed-up.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/15fe2e82d4161103b69fe83f184552b9e9774633" target='_blank'>
              Physics-informed active learning with simultaneous weak-form latent space dynamics identification
              </a>
            </td>
          <td>
            Xiaolong He, April Tran, David M. Bortz, Youngsoo Choi
          </td>
          <td>2024-06-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Dynamic Mode Decomposition (DMD) and its variants, such as extended DMD (EDMD), are broadly used to fit simple linear models to dynamical systems known from observable data. As DMD methods work well in several situations but perform poorly in others, a clarification of the assumptions under which DMD is applicable is desirable. Upon closer inspection, existing interpretations of DMD methods based on the Koopman operator are not quite satisfactory: they justify DMD under assumptions that hold only with probability zero for generic observables. Here, we give a justification for DMD as a local, leading-order reduced model for the dominant system dynamics under conditions that hold with probability one for generic observables and non-degenerate observational data. We achieve this for autonomous and for periodically forced systems of finite or infinite dimensions by constructing linearizing transformations for their dominant dynamics within attracting slow spectral submanifolds (SSMs). Our arguments also lead to a new algorithm, data-driven linearization (DDL), which is a higher-order, systematic linearization of the observable dynamics within slow SSMs. We show by examples how DDL outperforms DMD and EDMD on numerical and experimental data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ce624ece7e2f2933c1731bee6e5b03bf7a57c90b" target='_blank'>
              Data-Driven Linearization of Dynamical Systems
              </a>
            </td>
          <td>
            George Haller, B. Kasz'as
          </td>
          <td>2024-07-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="This paper presents a sequence of two approaches for the data-driven control-oriented modeling of networked systems, i.e., the systems that involve many interacting dynamical components. First, a novel deep learning approach named the weak Latent Dynamics Model (wLDM) is developed for learning generic nonlinear dynamics with control. Leveraging the weak form, the wLDM enables more numerically stable and computationally efficient training as well as more accurate prediction, when compared to conventional methods such as neural ordinary differential equations. Building upon the wLDM framework, we propose the weak Graph Koopman Bilinear Form (wGKBF) model, which integrates geometric deep learning and Koopman theory to learn latent space dynamics for networked systems, especially for the challenging cases having multiple timescales. The effectiveness of the wLDM framework and wGKBF model are demonstrated on three example systems of increasing complexity - a controlled double pendulum, the stiff Brusselator dynamics, and an electrified aircraft energy system. These numerical examples show that the wLDM and wGKBF achieve superior predictive accuracy and training efficiency as compared to baseline models. Parametric studies provide insights into the effects of hyperparameters in the weak form. The proposed framework shows the capability to efficiently capture control-dependent dynamics in these systems, including stiff dynamics and multi-physics interactions, offering a promising direction for learning control-oriented models of complex networked systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c2168dc84b931e82498692c0f9277bed180e91df" target='_blank'>
              Learning Networked Dynamical System Models with Weak Form and Graph Neural Networks
              </a>
            </td>
          <td>
            Yin Yu, Daning Huang, Seho Park, H. Pangborn
          </td>
          <td>2024-07-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>11</td>
        </tr>

        <tr id="We introduce a method for constructing reduced-order models directly from videos of dynamical systems. The method uses a non-intrusive tracking to isolate the motion of a user-selected part in the video of an autonomous dynamical system. In the space of delayed observations of this motion, we reconstruct a low-dimensional attracting spectral submanifold (SSM) whose internal dynamics serves as a mathematically justified reduced-order model for nearby motions of the full system. We obtain this model in a simple polynomial form that allows explicit identification of important physical system parameters, such as natural frequencies, linear and nonlinear damping and nonlinear stiffness. Beyond faithfully reproducing attracting steady states and limit cycles, our SSM-reduced models can also uncover hidden motion not seen in the video, such as unstable fixed points and unstable limit cycles forming basin boundaries. We demonstrate all these features on experimental videos of five physical systems: a double pendulum, an inverted flag in counter-flow, water sloshing in tank, a wing exhibiting aeroelastic flutter and a shimmying wheel.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7c0d9c3d71f8076148909574fb1589ce6d2d09d4" target='_blank'>
              Modeling Nonlinear Dynamics from Videos
              </a>
            </td>
          <td>
            Antony Yang, Joar Axaas, Fanni K'ad'ar, G'abor St'ep'an, George Haller
          </td>
          <td>2024-06-13</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>0</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/cabb9ef9934cc450e8873d693c8dd8dfc73087ab" target='_blank'>
              MBD-NODE: physics-informed data-driven modeling and simulation of constrained multibody systems
              </a>
            </td>
          <td>
            Jingquan Wang, Shu Wang, H. Unjhawala, Jinlong Wu, D. Negrut
          </td>
          <td>2024-07-11</td>
          <td>Multibody System Dynamics</td>
          <td>0</td>
          <td>28</td>
        </tr>

        <tr id="The identification of self-similarity is an indispensable tool for understanding and modelling physical phenomena. Unfortunately, this is not always possible to perform formally in highly complex problems. We propose a methodology to extract the similarity variables of a self-similar physical process directly from data, without prior knowledge of the governing equations or boundary conditions, based on an optimization problem and symbolic regression. We analyze the accuracy and robustness of our method in four problems which have been influential in fluid mechanics research: a laminar boundary layer, Burger's equation, a turbulent wake, and a collapsing cavity. Our analysis considers datasets acquired via both numerical and wind-tunnel experiments.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b4e59a9e878c505fc222908a8279de60c32a29db" target='_blank'>
              Extracting self-similarity from data
              </a>
            </td>
          <td>
            Nikos Bempedelis, Luca Magri, Konstantinos Steiros
          </td>
          <td>2024-07-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="In a landscape where scientific discovery is increasingly driven by data, the integration of machine learning (ML) with traditional scientific methodologies has emerged as a transformative approach. This paper introduces a novel, data-driven framework that synergizes physics-based priors with advanced ML techniques to address the computational and practical limitations inherent in first-principle-based methods and brute-force machine learning methods. Our framework showcases four algorithms, each embedding a specific physics-based prior tailored to a particular class of nonlinear systems, including separable and nonseparable Hamiltonian systems, hyperbolic partial differential equations, and incompressible fluid dynamics. The intrinsic incorporation of physical laws preserves the system's intrinsic symmetries and conservation laws, ensuring solutions are physically plausible and computationally efficient. The integration of these priors also enhances the expressive power of neural networks, enabling them to capture complex patterns typical in physical phenomena that conventional methods often miss. As a result, our models outperform existing data-driven techniques in terms of prediction accuracy, robustness, and predictive capability, particularly in recognizing features absent from the training set, despite relying on small datasets, short training periods, and small sample sizes.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6ba424643899decf4b48792c380cc0c66abe63c7" target='_blank'>
              Data-Driven Computing Methods for Nonlinear Physics Systems with Geometric Constraints
              </a>
            </td>
          <td>
            Yunjin Tong
          </td>
          <td>2024-06-20</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Conservation laws are of great theoretical and practical interest. We describe a novel approach to machine learning conservation laws of finite-dimensional dynamical systems using trajectory data. It is the first such approach based on kernel methods instead of neural networks which leads to lower computational costs and requires a lower amount of training data. We propose the use of an"indeterminate"form of kernel ridge regression where the labels still have to be found by additional conditions. We use here a simple approach minimising the length of the coefficient vector to discover a single conservation law.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/035d953b4ff1cf01179827e6f9c08473bca234cc" target='_blank'>
              Machine Learning Conservation Laws of Dynamical systems
              </a>
            </td>
          <td>
            Meskerem Abebaw Mebratie, Rudiger Nather, Guido Falk von Rudorff, Werner M. Seiler
          </td>
          <td>2024-05-31</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="Quadrotor systems are common and beneficial for many fields, but their intricate behavior often makes it challenging to design effective and optimal control strategies. Some traditional approaches to nonlinear control often rely on local linearizations or complex nonlinear models, which can be inaccurate or computationally expensive. We present a data-driven approach to identify the dynamics of a given quadrotor system using Koopman operator theory. Koopman theory offers a framework for representing nonlinear dynamics as linear operators acting on observable functions of the state space. This allows to approximate nonlinear systems with globally linear models in a higher dimensional space, which can be analyzed and controlled using standard linear optimal control techniques. We leverage the method of extended dynamic mode decomposition (EDMD) to identify Koopman operator from data with total least squares. We demonstrate that the identified model can be stabilized and controllable by designing a controller using linear quadratic regulator (LQR).">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ebef83a205c2d98f47337773d95a89f0d8f25c4e" target='_blank'>
              Koopman-LQR Controller for Quadrotor UAVs from Data
              </a>
            </td>
          <td>
            Zeyad M. Manaa, Ayman M. Abdallah, Mohammad A. Abido, Syed S. Azhar Ali
          </td>
          <td>2024-06-25</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>1</td>
        </tr>

        <tr id="Machine learning techniques have recently been of great interest for solving differential equations. Training these models is classically a data-fitting task, but knowledge of the expression of the differential equation can be used to supplement the training objective, leading to the development of physics-informed scientific machine learning. In this article, we focus on one class of models called nonlinear vector autoregression (NVAR) to solve ordinary differential equations (ODEs). Motivated by connections to numerical integration and physics-informed neural networks, we explicitly derive the physics-informed NVAR (piNVAR) which enforces the right-hand side of the underlying differential equation regardless of NVAR construction. Because NVAR and piNVAR completely share their learned parameters, we propose an augmented procedure to jointly train the two models. Then, using both data-driven and ODE-driven metrics, we evaluate the ability of the piNVAR model to predict solutions to various ODE systems, such as the undamped spring, a Lotka-Volterra predator-prey nonlinear model, and the chaotic Lorenz system.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/59096640a40ed6b70acbbfdaca5a505cd1330bb4" target='_blank'>
              Physics-informed nonlinear vector autoregressive models for the prediction of dynamical systems
              </a>
            </td>
          <td>
            James H. Adler, Samuel Hocking, Xiaozhe Hu, Shafiqul Islam
          </td>
          <td>2024-07-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="The identification of a mathematical dynamics model is a crucial step in the designing process of a controller. However, it is often very difficult to identify the system's governing equations, especially in complex environments that combine physical laws of different disciplines. In this paper, we present a new approach that allows identifying an ordinary differential equation by means of a physics-informed machine learning algorithm. Our method introduces a special neural network that allows exploiting prior human knowledge to a certain degree and extends it autonomously, so that the resulting differential equations describe the system as accurately as possible. We validate the method on a Duffing oscillator with simulation data and, additionally, on a cascaded tank example with real-world data. Subsequently, we use the developed algorithm in a model-based reinforcement learning framework by alternately identifying and controlling a system to a target state. We test the performance by swinging-up an inverted pendulum on a cart.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9fb84f2c4de6cf8d43f1207b6c58095273d711f1" target='_blank'>
              Identifying Ordinary Differential Equations for Data-efficient Model-based Reinforcement Learning
              </a>
            </td>
          <td>
            Tobias Nagel, Marco F. Huber
          </td>
          <td>2024-06-28</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0d487b041502645ead57bcc0782fa0256ccec2fc" target='_blank'>
              Development of data-driven modeling method for nonlinear coupling components
              </a>
            </td>
          <td>
            Taesan Ryu, Seunghun Baek
          </td>
          <td>2024-06-27</td>
          <td>Scientific Reports</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Decision formation in perceptual decision-making involves sensory evidence accumulation instantiated by the temporal integration of an internal decision variable towards some decision criterion or threshold, as described by sequential sampling theoretical models. The decision variable can be represented in the form of experimentally observable neural activities. Hence, elucidating the appropriate theoretical model becomes crucial to understanding the mechanisms underlying perceptual decision formation. Existing computational methods are limited to either fitting of choice behavioural data or linear model estimation from neural activity data. In this work, we made use of sparse identification of nonlinear dynamics (SINDy), a data-driven approach, to elucidate the deterministic linear and nonlinear components of often-used stochastic decision models within reaction time task paradigms. Based on the simulated decision variable activities of the models, SINDy, enhanced with a trial-averaging approach, could readily uncover the dynamical equations of the models while predicting the models' choice accuracy and decision time across a range of signal-to-noise ratio values. In particular, SINDy performed relatively better for decision models which have an accelerating dynamical component during decision formation, as expressed by a metastable linear competing accumulator model and a nonlinear bistable model. Taken together, our work suggests that SINDy can be a useful tool for uncovering the dynamics in perceptual decision-making, and more generally, for first-passage time problems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6da667b4777d1fc6625bb8ec370ebee165493251" target='_blank'>
              Uncovering dynamical equations of stochastic decision models using data-driven SINDy algorithm
              </a>
            </td>
          <td>
            Brendan Lenfesty, Saugat Bhattacharyya, KongFatt Wong-Lin
          </td>
          <td>2024-06-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="This paper presents an identification method for the transient dynamics of microgrids that exploits the intrinsic geometric structure of the dynamics, i.e., the high-dimensional states reside on a relatively low-dimensional manifold. In terms of discrete-time dynamics, the increment in states is decomposed into the tangent and normal components using the local geometric information, inferred from the data set of dynamical responses. The sparse identification of nonlinear dynamical systems (SINDy) method and generalized moving least square (GMLS) algorithms are used to estimate the tangent and normal components of increments, respectively, at every time step to constrain the solution onto the manifold of dynamics; this reduces the sensitivity of the SINDy model to candidate function selection and improve the prediction performance. A ten-bus microgrid system with five loads is used to test and verify the effectiveness of the presented method in identifying the system’s nonlinear dynamics. Numerical tests show that the developed method can give a better estimation for the dynamic transients caused by load variation, when compared to the traditional SINDy model. The results imply that the proposed method is a useful tool to model the transient dynamics in power systems, especially when the state space lies on a low-dimensional manifold.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/296994d8631fcb9aaf6f02f26a1fe8d5ec69ee66" target='_blank'>
              Tangent and Normal Space-Based Method for Dynamics Identification in Microgrids
              </a>
            </td>
          <td>
            Hanyang He, John Harlim, Daning Huang, Yan Li
          </td>
          <td>2024-06-19</td>
          <td>2024 IEEE Transportation Electrification Conference and Expo (ITEC)</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="In order to accurately model the dynamics of non-linear electro-mechanical systems, it is imperative to consider the contributions of coupling terms and dissipation. The Lagrangian formulation alone is insufficient to fully capture the holistic behavior of the system. Coupling and dissipation mechanisms play a pivotal role in shaping the system's response. Consequently, to effectively capture the dynamics of inter-coupled electro-mechanical systems with dissipation, we propose an extended Lagrangian-informed deep neural network framework in this paper. Our approach leverages the underlying physics-based knowledge of the system, incorporating it into the neural network architecture. By employing the Euler-Lagrange equations as constraints in the training process, we ensure that the learned dynamics conform to the true behavior of the system. To validate the theoretical framework, we conduct simulation experiments on a DC motor with a cart system, which serves as a representative model of dissipative nonlinear electro-mechanical systems. The experimental results demonstrate the efficacy of our approach in accurately capturing and integrating the dynamics to solve the reference tracking model predictive control design.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9fec77456fc41a426a57f697c4e29a12b83d9962" target='_blank'>
              Extended Lagrangian-Informed Deep Learning and Control for Electro-mechanical Systems
              </a>
            </td>
          <td>
            Nikhil Pagar, Pegah Ghaf-Ghanbari, Atul G. Kelkar, Javad Mohammadpour Velni
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>13</td>
        </tr>

        <tr id="
 We present a tensor-based method for model selection which identifies the unknown partial differential equation that governs a dynamical system using only spatiotemporal measurements. The method circumvents a disadvantage of standard matrix-based methods which typically have large storage consumption. Using a recently developed multidimensional approximation of nonlinear dynamical systems, we collect the nonlinear and partial derivative terms of the measured data and construct a low-rank dictionary tensor in the tensor-train format. A tensor-based linear regression problem is then built, which balances the learning accuracy, model complexity, and computational efficiency. An algebraic expression of the unknown equations can be extracted. Numerical results are demonstrated on datasets generated by the wave equation, the Burgers' equation, and a few parametric partial differential equations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c7f12b781a01ed3dd9a5f51e745426539b84443b" target='_blank'>
              Tensor-Based Data-Driven Identification of Partial Differential Equations
              </a>
            </td>
          <td>
            Wanting Lin, Xiaofan Lu, Linan Zhang
          </td>
          <td>2024-06-10</td>
          <td>Journal of Computational and Nonlinear Dynamics</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Large-scale recordings of neural activity over broad anatomical areas with high spatial and temporal resolution are increasingly common in modern experimental neuroscience. Recently, recurrent switching dynamical systems have been used to tackle the scale and complexity of these data. However, an important challenge remains in providing insights into the existence and structure of recurrent linear dynamics in neural time series data. Here we test a scalable approach to time-varying autoregression with low-rank tensors to recover the recurrent dynamics in stochastic neural mass models with multiple stable attractors. We demonstrate that the sparse representation of time-varying system matrices in terms of temporal modes can recover the attractor structure of simple systems via clustering. We then consider simulations based on a human brain connectivity matrix in high and low global connection strength regimes, and reveal the hierarchical clustering structure of the dynamics. Finally, we explain the impact of the forecast time delay on the estimation of the underlying rank and temporal variability of the time series dynamics. This study illustrates that prediction error minimization is not sufficient to recover meaningful dynamic structure and that it is crucial to account for the three key timescales arising from dynamics, noise processes, and attractor switching.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f088ebb7f9998f3b1ef7d954c5cb202f1bab50bc" target='_blank'>
              Identification of Recurrent Dynamics in Distributed Neural Populations
              </a>
            </td>
          <td>
            R. Osuna-Orozco, Edward Castillo, K. Harris, Samantha R. Santacruz
          </td>
          <td>2024-06-01</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>15</td>
        </tr>

        <tr id="Modeling the dynamics of flexible objects has become an emerging topic in the community as these objects become more present in many applications, e.g., soft robotics. Due to the properties of flexible materials, the movements of soft objects are often highly nonlinear and, thus, complex to predict. Data-driven approaches seem promising for modeling those complex dynamics but often neglect basic physical principles, which consequently makes them untrustworthy and limits generalization. To address this problem, we propose a physics-constrained learning method that combines powerful learning tools and reliable physical models. Our method leverages the data collected from observations by sending them into a Gaussian process that is physically constrained by a distributed Port-Hamiltonian model. Based on the Bayesian nature of the Gaussian process, we not only learn the dynamics of the system, but also enable uncertainty quantification. Furthermore, the proposed approach preserves the compositional nature of Port-Hamiltonian systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/020e63b8b17cdec54c056d8a1edc98770c8fa7ab" target='_blank'>
              Physics-constrained learning for PDE systems with uncertainty quantified port-Hamiltonian models
              </a>
            </td>
          <td>
            Kaiyuan Tan, Peilun Li, Thomas Beckers
          </td>
          <td>2024-06-17</td>
          <td>DBLP, ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="In the context of model-based control of industrial processes, it is a common practice to develop a data-driven linear dynamical model around a specified operating point. However, in applications involving wider operating conditions, representation of the dynamics using a single linear dynamic model is often inadequate, requiring either a nonlinear model or multiple linear models to accommodate the nonlinear behaviour. While the development of the former suffers from the requirements of extensive experiments spanning multiple levels, significant compromise in the nominal product quality and dealing with unmeasured disturbances over wider operating conditions, the latter faces the challenge of model switch scheduling and inadequate description of dynamics for the operating regions in-between. To overcome these challenges, we propose an efficient approach to obtain a parsimonious nonlinear dynamic model by developing multiple linear models from data at multiple operating points, lifting the data features obtained from individual model simulations to adequately accommodate the underlying nonlinear behaviour and finally, sparse optimization techniques to obtain a parsimonious model. The performance and effectiveness of the proposed algorithm is demonstrated through simulation case studies.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/306f086e6a9d38f499cd80678107601e0f0df0b5" target='_blank'>
              Model fusion for efficient learning of nonlinear dynamical systems
              </a>
            </td>
          <td>
            Vatsal Kedia, Vivek S. Pinnamaraju, Dinesh Patil
          </td>
          <td>2024-06-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Data-driven modeling methods are studied for turbulent dynamical systems with extreme events under an unambiguous model framework. New neural network architectures are proposed to effectively learn the key dynamical mechanisms including the multiscale coupling and strong instability, and gain robust skill for long-time prediction resistive to the accumulated model errors from the data-driven approximation. The machine learning model overcomes the inherent limitations in traditional long short-time memory networks by exploiting a conditional Gaussian structure informed of the essential physical dynamics. The model performance is demonstrated under a prototype model from idealized geophysical flow and passive tracers, which exhibits analytical solutions with representative statistical features. Many attractive properties are found in the trained model in recovering the hidden dynamics using a limited dataset and sparse observation time, showing uniformly high skill with persistent numerical stability in predicting both the trajectory and statistical solutions among different statistical regimes away from the training regime. The model framework is promising to be applied to a wider class of turbulent systems with complex structures.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bbfd6c205ba80b0b4c9e84e5d4fbba3b016ab7b3" target='_blank'>
              Unambiguous Models and Machine Learning Strategies for Anomalous Extreme Events in Turbulent Dynamical System
              </a>
            </td>
          <td>
            D. Qi
          </td>
          <td>2024-06-01</td>
          <td>Entropy</td>
          <td>0</td>
          <td>13</td>
        </tr>

        <tr id="Hybrid dynamical systems are prevalent in science and engineering to express complex systems with continuous and discrete states. To learn the laws of systems, all previous methods for equation discovery in hybrid systems follow a two-stage paradigm, i.e. they first group time series into small cluster fragments and then discover equations in each fragment separately through methods in non-hybrid systems. Although effective, these methods do not fully take advantage of the commonalities in the shared dynamics of multiple fragments that are driven by the same equations. Besides, the two-stage paradigm breaks the interdependence between categorizing and representing dynamics that jointly form hybrid systems. In this paper, we reformulate the problem and propose an end-to-end learning framework, i.e. Amortized Equation Discovery (AMORE), to jointly categorize modes and discover equations characterizing the dynamics of each mode by all segments of the mode. Experiments on four hybrid and six non-hybrid systems show that our method outperforms previous methods on equation discovery, segmentation, and forecasting.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f40610f6f31195a8a68f3802b6cc12d6503f9bae" target='_blank'>
              Amortized Equation Discovery in Hybrid Dynamical Systems
              </a>
            </td>
          <td>
            Yongtuo Liu, Sara Magliacane, Miltiadis Kofinas, E. Gavves
          </td>
          <td>2024-06-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>36</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1491d337e12daab70edf38ee62d8f8ee586b8e98" target='_blank'>
              Learning nonlinear operators in latent spaces for real-time predictions of complex dynamics in physical systems
              </a>
            </td>
          <td>
            Katiana Kontolati, S. Goswami, G. Em Karniadakis, Michael D Shields
          </td>
          <td>2024-06-14</td>
          <td>Nature Communications</td>
          <td>3</td>
          <td>19</td>
        </tr>

        <tr id="When neural networks are trained from data to simulate the dynamics of physical systems, they encounter a persistent challenge: the long-time dynamics they produce are often unphysical or unstable. We analyze the origin of such instabilities when learning linear dynamical systems, focusing on the training dynamics. We make several analytical findings which empirical observations suggest extend to nonlinear dynamical systems. First, the rate of convergence of the training dynamics is uneven and depends on the distribution of energy in the data. As a special case, the dynamics in directions where the data have no energy cannot be learned. Second, in the unlearnable directions, the dynamics produced by the neural network depend on the weight initialization, and common weight initialization schemes can produce unstable dynamics. Third, injecting synthetic noise into the data during training adds damping to the training dynamics and can stabilize the learned simulator, though doing so undesirably biases the learned dynamics. For each contributor to instability, we suggest mitigative strategies. We also highlight important differences between learning discrete-time and continuous-time dynamics, and discuss extensions to nonlinear systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2a7fe97785b117217a2f1064f6983b137fe02e06" target='_blank'>
              On instabilities in neural network-based physics simulators
              </a>
            </td>
          <td>
            Daniel Floryan
          </td>
          <td>2024-06-18</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>0</td>
        </tr>

        <tr id="Systems biology tackles the challenge of understanding the high complexity in the internal regulation of homeostasis in the human body through mathematical modelling. These models can aid in the discovery of disease mechanisms and potential drug targets. However, on one hand the development and validation of knowledge-based mechanistic models is time-consuming and does not scale well with increasing features in medical data. On the other hand, more data-driven approaches such as machine learning models require large volumes of data to produce generalizable models. The integration of neural networks and mechanistic models, forming universal differential equation (UDE) models, enables the automated learning of unknown model terms with less data than the neural network alone. Nevertheless, estimating parameters for these hybrid models remains difficult with sparse data and limited sampling durations that are common in biological applications. In this work, we propose the use of physiology-informed regularization, penalizing biologically implausible model behavior to guide the UDE towards more physiologically plausible regions of the solution space. In a simulation study we show that physiology-informed regularization not only results in a more accurate forecasting of model behaviour, but also supports training with less data. We also applied this technique to learn a representation of the rate of glucose appearance in the glucose minimal model using meal response data measured in healthy people. In that case, the inclusion of regularization reduces variability between UDE-embedded neural networks that were trained from different initial parameter guesses. Author summary Systems biology concerns the modelling and analysis of biological processes, by viewing these as interconnected systems. Modelling is typically done either using mechanistic differential equations that are derived from experiments and known biology, or using machine learning on large biological datasets. While mathematical modelling from biological experiments can provide useful insights with limited data, building and validating these models takes a long time and often requires highly invasive measurements in humans. Efforts to combine this classical technique with machine learning have resulted in a framework termed universal differential equations, where the model equations contain a neural network to describe unknown biological interactions. While these methods have shown success in numerous fields, applications in biology are more challenging due to limited data-availability, high data sparsity. In this work, we have introduced physiology-informed regularization to overcome these instabilities and to constrain the model to biologically plausible behavior. Our results show that by using physiology-informed regularization, we can accurately predict future unseen observations in a simulated example, with much more limited data than a similar model without regularization. Additionally, we show an application of this technique on human data, applying a neural network to learn the appearance of glucose in the blood plasma after a meal.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0ddf0dda21d3a8fbe599f98eed4fe943aa342f41" target='_blank'>
              Physiology-informed regularization enables training of universal differential equation systems for biological applications
              </a>
            </td>
          <td>
            Max de Rooij, Balázs Erdős, N. V. van Riel, Shauna D. O’Donovan
          </td>
          <td>2024-06-01</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="The identification of a nonlinear system model given only measurement data is a frequently encountered task. Uncovering the structure of differential equations as system model alongside with the determination of the optimal parameters is still problem under investigation. Assuming a differentially flat system under investigation, an algorithm for single input single output systems is proposed that faces this identification task. To find a proper state space model, an iterative strategy is presented expanding an initial solution in every step. Harnessing only the measurement data and not their time derivatives a criterion is proposed to select promising extensions to the model avoiding extensive simulation studies on possible model structures. Applying a subset selection reduces the complexity of the resulting models and avoids overfitting. To show the capability of the presented approach to identify a nonlinear state space model from data, a simulation example is presented.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2ff4fcc76f9849634c1a641bd0787cff2f7c9419" target='_blank'>
              Flatness-Based Identification of Nonlinear Dynamics
              </a>
            </td>
          <td>
            Alexander M. Kopp, Lisa Fuchs, Christoph Ament
          </td>
          <td>2024-06-11</td>
          <td>2024 32nd Mediterranean Conference on Control and Automation (MED)</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The development of control methods based on data has seen a surge of interest in recent years. When applying data-driven controllers in real-world applications, providing theoretical guarantees for the closed-loop system is of crucial importance to ensure reliable operation. In this review, we provide an overview of data-driven model predictive control (MPC) methods for controlling unknown systems with guarantees on systems-theoretic properties such as stability, robustness, and constraint satisfaction. The considered approaches rely on the Fundamental Lemma from behavioral theory in order to predict input-output trajectories directly from data. We cover various setups, ranging from linear systems and noise-free data to more realistic formulations with noise and nonlinearities, and we provide an overview of different techniques to ensure guarantees for the closed-loop system. Moreover, we discuss avenues for future research that may further improve the theoretical understanding and practical applicability of data-driven MPC.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0cdd1a10dee3630b0a0bcf3b13170dea7e1116bd" target='_blank'>
              An overview of systems-theoretic guarantees in data-driven model predictive control
              </a>
            </td>
          <td>
            J. Berberich, Frank Allgöwer
          </td>
          <td>2024-06-06</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>21</td>
        </tr>

        <tr id="Neural manifolds are an attractive theoretical framework for characterizing the complex behaviors of neural populations. However, many of the tools for identifying these low-dimensional subspaces are correlational and provide limited insight into the underlying dynamics. The ability to precisely control this latent activity would allow researchers to investigate the structure and function of neural manifolds. Employing techniques from the field of optimal control, we simulate controlling the latent dynamics of a neural population using closed-loop, dynamically generated sensory inputs. Using a spiking neural network (SNN) as a model of a neural circuit, we find low-dimensional representations of both the network activity (the neural manifold) and a set of salient visual stimuli. With a data-driven latent dynamics model, we apply model predictive control (MPC) to provide anticipatory, optimal control over the trajectory of the circuit in a latent space. We are able to control the latent dynamics of the SNN to follow several reference trajectories despite observing only a subset of neurons and with a substantial amount of unknown noise injected into the network. These results provide a framework to experimentally test for causal relationships between manifold dynamics and other variables of interest such as organismal behavior and BCI performance.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e2f3319a9926e88582124c34d6157bfd48e1d637" target='_blank'>
              Model Predictive Control of the Neural Manifold
              </a>
            </td>
          <td>
            Christof Fehrman, C. D. Meliza
          </td>
          <td>2024-06-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Machine learning and artificial intelligence algorithms typically require large amount of data for training. This means that for nonlinear aeroelastic applications, where small training budgets are driven by the high computational burden associated with generating data, usability of such methods has been limited to highly simplified aeroelastic systems. This paper presents a novel approach for the identification of optimized sparse higher-order polynomial-based aeroelastic reduced order models (ROM) to significantly reduce the amount of training data needed without sacrificing fidelity. Several sparsity promoting algorithms are considered, including; rigid sparsity, LASSO regression, and Orthogonal Matching Pursuit (OMP). The study demonstrates that through OMP, it is possible to efficiently identify optimized s-sparse nonlinear aerodynamic ROMs using only aerodynamic response information. This approach is exemplified in a three-dimensional aeroelastic stabilator model experiencing high amplitude freeplay-induced limit cycles. The comparison shows excellent agreement between the ROM and the full-order aeroelastic response, including the ability to generalize to new freeplay and velocity index values, with online computational savings of several orders of magnitude. The development of an Optimally Sparse ROM (OS-ROM) extends previous higher-order polynomial-based ROM approaches for feasible application to complex three-dimensional nonlinear aeroelastic problems, without incurring significant computational burdens or loss of accuracy.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/97898fc2c29cd5e9323726a299e4b0395918f8cf" target='_blank'>
              Optimal Sparsity in Nonlinear Non-Parametric Reduced Order Models for Transonic Aeroelastic Systems
              </a>
            </td>
          <td>
            M. Candon, Errol Hale, Maciej Balajewicz, Arturo Delgado-Gutiérrez, Pier Marzocca
          </td>
          <td>2024-07-11</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>7</td>
        </tr>

        <tr id="In this paper, we introduce the neural empirical interpolation method (NEIM), a neural network-based alternative to the discrete empirical interpolation method for reducing the time complexity of computing the nonlinear term in a reduced order model (ROM) for a parameterized nonlinear partial differential equation. NEIM is a greedy algorithm which accomplishes this reduction by approximating an affine decomposition of the nonlinear term of the ROM, where the vector terms of the expansion are given by neural networks depending on the ROM solution, and the coefficients are given by an interpolation of some"optimal"coefficients. Because NEIM is based on a greedy strategy, we are able to provide a basic error analysis to investigate its performance. NEIM has the advantages of being easy to implement in models with automatic differentiation, of being a nonlinear projection of the ROM nonlinearity, of being efficient for both nonlocal and local nonlinearities, and of relying solely on data and not the explicit form of the ROM nonlinearity. We demonstrate the effectiveness of the methodology on solution-dependent and solution-independent nonlinearities, a nonlinear elliptic problem, and a nonlinear parabolic model of liquid crystals.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6a9f14f2184ffdc1fe9bad40a689eaa1a5d44780" target='_blank'>
              Neural empirical interpolation method for nonlinear model reduction
              </a>
            </td>
          <td>
            Max Hirsch, F. Pichi, J. Hesthaven
          </td>
          <td>2024-06-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>64</td>
        </tr>

        <tr id="We present a numerical method for learning unknown nonautonomous stochastic dynamical system, i.e., stochastic system subject to time dependent excitation or control signals. Our basic assumption is that the governing equations for the stochastic system are unavailable. However, short bursts of input/output (I/O) data consisting of certain known excitation signals and their corresponding system responses are available. When a sufficient amount of such I/O data are available, our method is capable of learning the unknown dynamics and producing an accurate predictive model for the stochastic responses of the system subject to arbitrary excitation signals not in the training data. Our method has two key components: (1) a local approximation of the training I/O data to transfer the learning into a parameterized form; and (2) a generative model to approximate the underlying unknown stochastic flow map in distribution. After presenting the method in detail, we present a comprehensive set of numerical examples to demonstrate the performance of the proposed method, especially for long-term system predictions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4edbecee7f2d1381939691be911b0026cab616bb" target='_blank'>
              Modeling Unknown Stochastic Dynamical System Subject to External Excitation
              </a>
            </td>
          <td>
            Yuan Chen, Dongbin Xiu
          </td>
          <td>2024-06-22</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4648ca55b2c3ba80a310409f8b48533ab6d4a66a" target='_blank'>
              Learning interpretable dynamics of stochastic complex systems from experimental data
              </a>
            </td>
          <td>
            Tingting Gao, B. Barzel, Gang Yan
          </td>
          <td>2024-07-17</td>
          <td>Nature Communications</td>
          <td>0</td>
          <td>18</td>
        </tr>

        <tr id="This article is devoted to providing a review of mathematical formulations in which Polynomial Chaos Theory (PCT) has been incorporated into stochastic model predictive control (SMPC). In the past decade, PCT has been shown to provide a computationally tractable way to perform complete and accurate uncertainty propagation through (smooth) nonlinear dynamic systems. As such, it represents a very useful computational tool for accelerating the computations needed in SMPC with time invariant uncertainties. It turns out that it can also be used to reduce complexity of chance constraints, which are an important component of SMPC. In this paper, we provide an overview of PCT and discuss how it can be applied in such time invariant settings.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/97793bc13282813dbb41b1713188675eb03584d1" target='_blank'>
              Polynomial Chaos-based Stochastic Model Predictive Control: An Overview and Future Research Directions
              </a>
            </td>
          <td>
            Prabhat Kumar Mishra, J. Paulson, R. Braatz
          </td>
          <td>2024-06-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>73</td>
        </tr>

        <tr id="In this work, we present a method which determines optimal multi-step dynamic mode decomposition (DMD) models via entropic regression, which is a nonlinear information flow detection algorithm. Motivated by the higher-order DMD (HODMD) method of \cite{clainche}, and the entropic regression (ER) technique for network detection and model construction found in \cite{bollt, bollt2}, we develop a method that we call ERDMD that produces high fidelity time-delay DMD models that allow for nonuniform time space, and the time spacing is discovered by consider most informativity based on ER. These models are shown to be highly efficient and robust. We test our method over several data sets generated by chaotic attractors and show that we are able to build excellent reconstructions using relatively minimal models. We likewise are able to better identify multiscale features via our models which enhances the utility of dynamic mode decomposition.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3bfefac0bfd82ec97ab7068cba3a9ad9a039f752" target='_blank'>
              Entropic Regression DMD (ERDMD) Discovers Informative Sparse and Nonuniformly Time Delayed Models
              </a>
            </td>
          <td>
            Christopher W. Curtis, Erik Bollt, D. J. Alford-Lago
          </td>
          <td>2024-06-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Nonlinear and non-stationary processes are prevalent in various natural and physical phenomena, where system dynamics can change qualitatively due to bifurcation phenomena. Traditional machine learning methods have advanced our ability to learn and predict such systems from observed time series data. However, predicting the behavior of systems with temporal parameter variations without knowledge of true parameter values remains a significant challenge. This study leverages the reservoir computing framework to address this problem by unsupervised extraction of slowly varying system parameters from time series data. We propose a model architecture consisting of a slow reservoir with long timescale internal dynamics and a fast reservoir with short timescale dynamics. The slow reservoir extracts the temporal variation of system parameters, which are then used to predict unknown bifurcations in the fast dynamics. Through experiments using data generated from chaotic dynamical systems, we demonstrate the ability to predict bifurcations not present in the training data. Our approach shows potential for applications in fields such as neuroscience, material science, and weather prediction, where slow dynamics influencing qualitative changes are often unobservable.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1f7ba13092aa22ef11ae95641fe8961d09c8fcd7" target='_blank'>
              Prediction of Unobserved Bifurcation by Unsupervised Extraction of Slowly Time-Varying System Parameter Dynamics from Time Series Using Reservoir Computing
              </a>
            </td>
          <td>
            Keita Tokuda, Yuichi Katori
          </td>
          <td>2024-06-20</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="We introduce a method based on Gaussian process regression to identify discrete variational principles from observed solutions of a field theory. The method is based on the data-based identification of a discrete Lagrangian density. It is a geometric machine learning technique in the sense that the variational structure of the true field theory is reflected in the data-driven model by design. We provide a rigorous convergence statement of the method. The proof circumvents challenges posed by the ambiguity of discrete Lagrangian densities in the inverse problem of variational calculus. Moreover, our method can be used to quantify model uncertainty in the equations of motions and any linear observable of the discrete field theory. This is illustrated on the example of the discrete wave equation and Schr\"odinger equation. The article constitutes an extension of our previous article arXiv:2404.19626 for the data-driven identification of (discrete) Lagrangians for variational dynamics from an ode setting to the setting of discrete pdes.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e38b7de6c7022b28628627bbf045123b665619b4" target='_blank'>
              Machine learning of discrete field theories with guaranteed convergence and uncertainty quantification
              </a>
            </td>
          <td>
            Christian Offen
          </td>
          <td>2024-07-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="In this study, we investigate the effect of reservoir computing training data on the reconstruction of chaotic dynamics. Our findings indicate that a training time series comprising a few periodic orbits of low periods can successfully reconstruct the Lorenz attractor. We also demonstrate that biased training data does not negatively impact reconstruction success. Our method's ability to reconstruct a physical measure is much better than the so-called cycle expansion approach, which relies on weighted averaging. Additionally, we demonstrate that fixed point attractors and chaotic transients can be accurately reconstructed by a model trained from a few periodic orbits, even when using different parameters.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f833e966a95961819f625f1095e380b4cf40eb4f" target='_blank'>
              Data-driven modeling from biased small training data using periodic orbits
              </a>
            </td>
          <td>
            Kengo Nakai, Yoshitaka Saiki
          </td>
          <td>2024-07-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Stability is a basic requirement when studying the behavior of dynamical systems. However, stabilizing dynamical systems via reinforcement learning is challenging because only little data can be collected over short time horizons before instabilities are triggered and data become meaningless. This work introduces a reinforcement learning approach that is formulated over latent manifolds of unstable dynamics so that stabilizing policies can be trained from few data samples. The unstable manifolds are minimal in the sense that they contain the lowest dimensional dynamics that are necessary for learning policies that guarantee stabilization. This is in stark contrast to generic latent manifolds that aim to approximate all -- stable and unstable -- system dynamics and thus are higher dimensional and often require higher amounts of data. Experiments demonstrate that the proposed approach stabilizes even complex physical systems from few data samples for which other methods that operate either directly in the system state space or on generic latent manifolds fail.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/89660d65895827cad089c32e3f1a9f0b892601ff" target='_blank'>
              System stabilization with policy optimization on unstable latent manifolds
              </a>
            </td>
          <td>
            Steffen W. R. Werner, B. Peherstorfer
          </td>
          <td>2024-07-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>27</td>
        </tr>

        <tr id="We introduce a novel neural network structure called Strongly Constrained Theory-Guided Neural Network (SCTgNN), to investigate the behaviours of the localized solutions of the generalized nonlinear Schr\"{o}dinger (NLS) equation. This equation comprises four physically significant nonlinear evolution equations, namely, (i) NLS equation, Hirota equation Lakshmanan-Porsezian-Daniel (LPD) equation and fifth-order NLS equation. The generalized NLS equation demonstrates nonlinear effects up to quintic order, indicating rich and complex dynamics in various fields of physics. By combining concepts from the Physics-Informed Neural Network (PINN) and Theory-Guided Neural Network (TgNN) models, SCTgNN aims to enhance our understanding of complex phenomena, particularly within nonlinear systems that defy conventional patterns. To begin, we employ the TgNN method to predict the behaviours of localized waves, including solitons, rogue waves, and breathers, within the generalized NLS equation. We then use SCTgNN to predict the aforementioned localized solutions and calculate the mean square errors in both SCTgNN and TgNN in predicting these three localized solutions. Our findings reveal that both models excel in understanding complex behaviours and provide predictions across a wide variety of situations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e405cc588c01c3af8b8d5bde5f1526dd7d964ae3" target='_blank'>
              On examining the predictive capabilities of two variants of PINN in validating localised wave solutions in the generalized nonlinear Schr\"{o}dinger equation
              </a>
            </td>
          <td>
            K. Thulasidharan, N. Sinthuja, N. VishnuPriya, M. Senthilvelan
          </td>
          <td>2024-07-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Learning linear and nonlinear dynamical systems from available data is a timely topic in scientific machine learning. Learning must be performed while enforcing the numerical stability of the learned model, the existing knowledge within an informed or augmented setting, or by taking into account the multiscale dynamics—for both linear and nonlinear dynamics. However, when the final objective of such a learned dynamical system is to be used for control purposes, learning transformed dynamics can be advantageous. Therefore, many alternatives exists, and the present paper focuses on two of them: the first based on the discovery and use of the so-called flat control and the second one based on the use of the Koopman theory. The main contributions when addressing the first is the discovery of the flat output transformation by using an original neural framework. Moreover, when using the Koopman theory, this paper proposes an original procedure for learning parametric dynamics in the latent space, which is of particular interest in control-based engineering applications.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bde1af4107f9ee8f6740e26e9c5d03b288c163cb" target='_blank'>
              Learning Transformed Dynamics for Efficient Control Purposes
              </a>
            </td>
          <td>
            C. Ghnatios, Joel Mouterde, Jerome Tomezyk, Joaquim Da Silva, Francisco Chinesta
          </td>
          <td>2024-07-19</td>
          <td>Mathematics</td>
          <td>0</td>
          <td>13</td>
        </tr>

        <tr id="Non-stationary systems are found throughout the world, from climate patterns under the influence of variation in carbon dioxide concentration, to brain dynamics driven by ascending neuromodulation. Accordingly, there is a need for methods to analyze non-stationary processes, and yet most time-series analysis methods that are used in practice, on important problems across science and industry, make the simplifying assumption of stationarity. One important problem in the analysis of non-stationary systems is the problem class that we refer to as Parameter Inference from a Non-stationary Unknown Process (PINUP). Given an observed time series, this involves inferring the parameters that drive non-stationarity of the time series, without requiring knowledge or inference of a mathematical model of the underlying system. Here we review and unify a diverse literature of algorithms for PINUP. We formulate the problem, and categorize the various algorithmic contributions. This synthesis will allow researchers to identify gaps in the literature and will enable systematic comparisons of different methods. We also demonstrate that the most common systems that existing methods are tested on - notably the non-stationary Lorenz process and logistic map - are surprisingly easy to perform well on using simple statistical features like windowed mean and variance, undermining the practice of using good performance on these systems as evidence of algorithmic performance. We then identify more challenging problems that many existing methods perform poorly on and which can be used to drive methodological advances in the field. Our results unify disjoint scientific contributions to analyzing non-stationary systems and suggest new directions for progress on the PINUP problem and the broader study of non-stationary phenomena.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/585c3c4f3b30a814bc05e6f9e38a5a28b702ee79" target='_blank'>
              Parameter inference from a non-stationary unknown process
              </a>
            </td>
          <td>
            Kieran S. Owens, Ben D. Fulcher
          </td>
          <td>2024-07-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Dynamical systems provide a comprehensive way to study complex and changing behaviors across various sciences. Many modern systems are too complicated to analyze directly or we do not have access to models, driving significant interest in learning methods. Koopman operators have emerged as a dominant approach because they allow the study of nonlinear dynamics using linear techniques by solving an infinite-dimensional spectral problem. However, current algorithms face challenges such as lack of convergence, hindering practical progress. This paper addresses a fundamental open question: \textit{When can we robustly learn the spectral properties of Koopman operators from trajectory data of dynamical systems, and when can we not?} Understanding these boundaries is crucial for analysis, applications, and designing algorithms. We establish a foundational approach that combines computational analysis and ergodic theory, revealing the first fundamental barriers -- universal for any algorithm -- associated with system geometry and complexity, regardless of data quality and quantity. For instance, we demonstrate well-behaved smooth dynamical systems on tori where non-trivial eigenfunctions of the Koopman operator cannot be determined by any sequence of (even randomized) algorithms, even with unlimited training data. Additionally, we identify when learning is possible and introduce optimal algorithms with verification that overcome issues in standard methods. These results pave the way for a sharp classification theory of data-driven dynamical systems based on how many limits are needed to solve a problem. These limits characterize all previous methods, presenting a unified view. Our framework systematically determines when and how Koopman spectral properties can be learned.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/eb7265ab4b5b6dce43f8b2a37e99d9fd03f2bef7" target='_blank'>
              Limits and Powers of Koopman Learning
              </a>
            </td>
          <td>
            Matthew J. Colbrook, Igor Mezi'c, Alexei Stepanenko
          </td>
          <td>2024-07-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>16</td>
        </tr>

        <tr id="This study presents the extension of the data-driven optimal prediction approach to the dynamical system with control. The optimal prediction is used to analyze dynamical systems in which the states consist of resolved and unresolved variables. The latter variables can not be measured explicitly. They may have smaller amplitudes and affect the resolved variables that can be measured. The optimal prediction approach recovers the averaged trajectories of the resolved variables by computing conditional expectations, while the distribution of the unresolved variables is assumed to be known. We consider such dynamical systems and introduce their additional control functions. To predict the targeted trajectories numerically, we develop a data-driven method based on the dynamic mode decomposition. The proposed approach takes the $\mathit{measured}$ trajectories of the resolved variables, constructs an approximate linear operator from the Mori-Zwanzig decomposition, and reconstructs the $\mathit{averaged}$ trajectories of the same variables. It is demonstrated that the method is much faster than the Monte Carlo simulations and it provides a reliable prediction. We experimentally confirm the efficacy of the proposed method for two Hamiltonian dynamical systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ff61c47f507c82d3e09807eb5ccbe742fb5c6272" target='_blank'>
              Data-driven optimal prediction with control
              </a>
            </td>
          <td>
            Aleksandr Katrutsa, Ivan V. Oseledets, Sergey Utyuzhnikov
          </td>
          <td>2024-06-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="The manipulation of deformable linear objects (DLOs) via model-based control requires an accurate and computationally efficient dynamics model. Yet, data-driven DLO dynamics models require large training data sets while their predictions often do not generalize, whereas physics-based models rely on good approximations of physical phenomena and often lack accuracy. To address these challenges, we propose a physics-informed neural ODE capable of predicting agile movements with significantly less data and hyper-parameter tuning. In particular, we model DLOs as serial chains of rigid bodies interconnected by passive elastic joints in which interaction forces are predicted by neural networks. The proposed model accurately predicts the motion of an robotically-actuated aluminium rod and an elastic foam cylinder after being trained on only thirty seconds of data. The project code and data are available at: \url{https://tinyurl.com/neuralprba}">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/815ff430d40660092c67ed599422c4c980a0db8d" target='_blank'>
              Learning deformable linear object dynamics from a single trajectory
              </a>
            </td>
          <td>
            Shamil Mamedov, A. R. Geist, Ruan Viljoen, Sebastian Trimpe, Jan Swevers
          </td>
          <td>2024-07-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="The dynamics of biological systems, from proteins to cells to organisms, is complex and stochastic. To decipher their physical laws, we need to bridge between experimental observations and theoretical modeling. Thanks to progress in microscopy and tracking, there is today an abundance of experimental trajectories reflecting these dynamical laws. Inferring physical models from noisy and imperfect experimental data, however, is challenging. Because there are no inference methods that are robust and efficient, model reconstruction from experimental trajectories is a bottleneck to data-driven biophysics. In this Thesis, I present a set of tools developed to bridge this gap and permit robust and universal inference of stochastic dynamical models from experimental trajectories. These methods are rooted in an information-theoretical framework that quantifies how much can be inferred from trajectories that are short, partial and noisy. They permit the efficient inference of dynamical models for overdamped and underdamped Langevin systems, as well as the inference of entropy production rates. I finally present early applications of these techniques, as well as future research directions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/36d5a9b10d628b238c485c3e97f0ad456101dedb" target='_blank'>
              Learning dynamical models from stochastic trajectories
              </a>
            </td>
          <td>
            Pierre Ronceray
          </td>
          <td>2024-06-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The goal of this paper is to make a strong point for the usage of dynamical models when using reinforcement learning (RL) for feedback control of dynamical systems governed by partial differential equations (PDEs). To breach the gap between the immense promises we see in RL and the applicability in complex engineering systems, the main challenges are the massive requirements in terms of the training data, as well as the lack of performance guarantees. We present a solution for the first issue using a data-driven surrogate model in the form of a convolutional Long-Short Term Memory network with actuation. We demonstrate that learning an actuated model in parallel to training the RL agent significantly reduces the total amount of required data sampled from the real system. Furthermore, we show that iteratively updating the model is of major importance to avoid biases in the RL training. Detailed ablation studies reveal the most important ingredients of the modeling process. We use the chaotic Kuramoto-Sivashinsky equation do demonstrate our findings.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/73d91c3ba7ba5d34e084bcd3bd2c0c397052d50a" target='_blank'>
              Numerical Evidence for Sample Efficiency of Model-Based Over Model-Free Reinforcement Learning Control of Partial Differential Equations
              </a>
            </td>
          <td>
            Stefan Werner, Sebastian Peitz
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The precise simulation of turbulent flows is of immense importance in a variety of scientific and engineering fields, including climate science, freshwater science, and the development of energy-efficient manufacturing processes. Within the realm of turbulent flow simulation, direct numerical simulation (DNS) is widely considered to be the most reliable approach, but it is prohibitively expensive for long-term simulation at fine spatial scales. Given the pressing need for efficient simulation, there is an increasing interest in building machine learning models for turbulence, either by reconstructing DNS from alternative low-fidelity simulations or by predicting DNS based on the patterns learned from historical data. However, standard machine learning techniques remain limited in capturing complex spatio-temporal characteristics of turbulent flows, resulting in limited performance and generalizability. This paper presents a novel physics-enhanced neural operator (PENO) that incorporates physical knowledge of partial differential equations (PDEs) to accurately model flow dynamics. The model is further refined by a self-augmentation mechanism to reduce the accumulated error in long-term simulations. The proposed method is evaluated through its performance on two distinct sets of 3D turbulent flow data, showcasing the model's capability to reconstruct high-resolution DNS data, maintain the inherent physical properties of flow transport, and generate flow simulations across various resolutions. Additionally, experimental results on multiple 2D vorticity flow series, generated by different PDEs, highlight the transferability and generalizability of the proposed method. This confirms its applicability to a wide range of real-world scenarios in which extensive simulations are needed under diverse settings.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/331e1df792ab191080d19024b6bb8c4541f5fdeb" target='_blank'>
              Physics-enhanced Neural Operator for Simulating Turbulent Transport
              </a>
            </td>
          <td>
            Shengyu Chen, P. Givi, Can Zheng, Xiaowei Jia
          </td>
          <td>2024-05-31</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>31</td>
        </tr>

        <tr id="Parameter estimation is one of the central problems in computational modeling of biological systems. Typically, scientists must fully specify the mathematical structure of the model, often expressed as a system of ordinary differential equations, to estimate the parameters. This process poses significant challenges due to the necessity for a detailed understanding of the underlying biological mechanisms. In this paper, we present an approach for estimating model parameters and assessing their identifiability in situations where only partial knowledge of the system structure is available. The partially known model is extended into a system of Hybrid Neural Ordinary Differential Equations, which captures the unknown portions of the system using neural networks. Integrating neural networks into the model structure introduces two primary challenges for parameter estimation: the need to globally explore the search space while employing gradient-based optimization, and the assessment of parameter identifiability, which may be hindered by the expressive nature of neural networks. To overcome the first issue, we treat biological parameters as hyperparameters in the extended model, exploring the parameter search space during hyperparameter tuning. The second issue is then addressed by an a posteriori analysis of parameter identifiability, computed by introducing a variant of a well-established approach for mechanistic models. These two components are integrated into an end-to-end pipeline that is thoroughly described in the paper. We assess the effectiveness of the proposed workflow on test cases derived from three different benchmark models. These test cases have been designed to mimic real-world conditions, including the presence of noise in the training data and various levels of data availability for the system variables. Author summary Parameter estimation is a central challenge in modeling biological systems. Typically, scientists calibrate the parameters by aligning model predictions with measured data once the model structure is defined. Our paper introduces a workflow that leverages the integration between mechanistic modeling and machine learning to estimate model parameters when the model structure is not fully known. We focus mainly on analyzing the identifiability of the model parameters, which measures how confident we can be in the parameter estimates given the available experimental data and partial mechanistic understanding of the system. We assessed the effectiveness of our approach in various in silico scenarios. Our workflow represents a first step to adapting traditional methods used in fully mechanistic models to the scenario of hybrid modeling.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a064c473effb10441bd8fe1c6bde24ed0162e1e3" target='_blank'>
              Robust parameter estimation and identifiability analysis with Hybrid Neural Ordinary Differential Equations in Computational Biology
              </a>
            </td>
          <td>
            Stefano Giampiccolo, Federico Reali, Anna Fochesato, Giovanni Iacca, Luca Marchetti
          </td>
          <td>2024-06-12</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="The temporal analysis of products (TAP) technique produces extensive transient kinetic data sets, but it is challenging to translate the large quantity of raw data into physically interpretable kinetic models, largely due to the computational scaling of existing numerical methods for fitting TAP data. In this work, we utilize kinetics-informed neural networks (KINNs), which are artificial feedforward neural networks designed to solve ordinary differential equations constrained by micro-kinetic models, to model the TAP data. We demonstrate that, under the assumption that all concentrations are known in the thin catalyst zone, KINNs can simultaneously fit the transient data, retrieve the kinetic model parameters, and interpolate unseen pulse behavior for multi-pulse experiments. We further demonstrate that, by modifying the loss function, KINNs maintain these capabilities even when precise thin-zone information is unavailable, as would be the case with real experimental TAP data. We also compare the approach to existing optimization techniques, which reveals improved noise tolerance and performance in extracting kinetic parameters. The KINNs approach offers an efficient alternative for TAP analysis and can assist in interpreting transient kinetics in complex systems over long timescales.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e1f3493d7eb9b985ff3ea227fb05f7db3343654b" target='_blank'>
              Fitting micro-kinetic models to transient kinetics of temporal analysis of product reactors using kinetics-informed neural networks
              </a>
            </td>
          <td>
            Dingqi Nai, G. S. Gusmão, Zachary Kilwein, Fani Boukouvala, A. Medford
          </td>
          <td>2024-06-20</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>40</td>
        </tr>

        <tr id="Approximation of solutions to partial differential equations (PDE) is an important problem in computational science and engineering. Using neural networks as an ansatz for the solution has proven a challenge in terms of training time and approximation accuracy. In this contribution, we discuss how sampling the hidden weights and biases of the ansatz network from data-agnostic and data-dependent probability distributions allows us to progress on both challenges. In most examples, the random sampling schemes outperform iterative, gradient-based optimization of physics-informed neural networks regarding training time and accuracy by several orders of magnitude. For time-dependent PDE, we construct neural basis functions only in the spatial domain and then solve the associated ordinary differential equation with classical methods from scientific computing over a long time horizon. This alleviates one of the greatest challenges for neural PDE solvers because it does not require us to parameterize the solution in time. For second-order elliptic PDE in Barron spaces, we prove the existence of sampled networks with $L^2$ convergence to the solution. We demonstrate our approach on several time-dependent and static PDEs. We also illustrate how sampled networks can effectively solve inverse problems in this setting. Benefits compared to common numerical schemes include spectral convergence and mesh-free construction of basis functions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6ea3ed2a0840d388a270a6cf6722fb68fd8a79ee" target='_blank'>
              Solving partial differential equations with sampled neural networks
              </a>
            </td>
          <td>
            Chinmay Datar, Taniya Kapoor, Abhishek Chandra, Qing Sun, Iryna Burak, Erik Lien Bolager, Anna Veselovska, Massimo Fornasier, Felix Dietrich
          </td>
          <td>2024-05-31</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Bifurcations mark qualitative changes of long-term behavior in dynamical systems and can often signal sudden ("hard") transitions or catastrophic events (divergences). Accurately locating them is critical not just for deeper understanding of observed dynamic behavior, but also for designing efficient interventions. When the dynamical system at hand is complex, possibly noisy, and expensive to sample, standard (e.g. continuation based) numerical methods may become impractical. We propose an active learning framework, where Bayesian Optimization is leveraged to discover saddle-node or Hopf bifurcations, from a judiciously chosen small number of vector field observations. Such an approach becomes especially attractive in systems whose state x parameter space exploration is resource-limited. It also naturally provides a framework for uncertainty quantification (aleatoric and epistemic), useful in systems with inherent stochasticity.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8580056dd0caf69a81d8730639e0828479823e8a" target='_blank'>
              Active search for Bifurcations
              </a>
            </td>
          <td>
            Y. M. Psarellis, T. Sapsis, I. G. Kevrekidis
          </td>
          <td>2024-06-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>37</td>
        </tr>

        <tr id="We study interacting particle systems driven by noise, modeling phenomena such as opinion dynamics. We are interested in systems that exhibit phase transitions i.e. non-uniqueness of stationary states for the corresponding McKean-Vlasov PDE, in the mean field limit. We develop an efficient numerical scheme for identifying all steady states (both stable and unstable) of the mean field McKean-Vlasov PDE, based on a spectral Galerkin approximation combined with a deflated Newton's method to handle the multiplicity of solutions. Having found all possible equilibra, we formulate an optimal control strategy for steering the dynamics towards a chosen unstable steady state. The control is computed using iterated open-loop solvers in a receding horizon fashion. We demonstrate the effectiveness of the proposed steady state computation and stabilization methodology on several examples, including the noisy Hegselmann-Krause model for opinion dynamics and the Haken-Kelso-Bunz model from biophysics. The numerical experiments validate the ability of the approach to capture the rich self-organization landscape of these systems and to stabilize unstable configurations of interest. The proposed computational framework opens up new possibilities for understanding and controlling the collective behavior of noise-driven interacting particle systems, with potential applications in various fields such as social dynamics, biological synchronization, and collective behavior in physical and social systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8cb185f3e81fd7f2446362e4cda24e70bab5a5c9" target='_blank'>
              Computation and Control of Unstable Steady States for Mean Field Multiagent Systems
              </a>
            </td>
          <td>
            Sara Bicego, D. Kalise, G. Pavliotis
          </td>
          <td>2024-06-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>32</td>
        </tr>

        <tr id="Physics informed neural networks have been gaining popularity due to their unique ability to incorporate physics laws into data-driven models, ensuring that the predictions are not only consistent with empirical data but also align with domain-specific knowledge in the form of physics equations. The integration of physics principles enables the method to require less data while maintaining the robustness of deep learning in modeling complex dynamical systems. However, current PINN frameworks are not sufficiently mature for real-world ODE systems, especially those with extreme multi-scale behavior such as mosquito population dynamical modelling. In this research, we propose a PINN framework with several improvements for forward and inverse problems for ODE systems with a case study application in modelling the dynamics of mosquito populations. The framework tackles the gradient imbalance and stiff problems posed by mosquito ordinary differential equations. The method offers a simple but effective way to resolve the time causality issue in PINNs by gradually expanding the training time domain until it covers entire domain of interest. As part of a robust evaluation, we conduct experiments using simulated data to evaluate the effectiveness of the approach. Preliminary results indicate that physics-informed machine learning holds significant potential for advancing the study of ecological systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bf1c97b75409ff1ee6e5c4298dd05295c9b772df" target='_blank'>
              Adapting Physics-Informed Neural Networks To Optimize ODEs in Mosquito Population Dynamics
              </a>
            </td>
          <td>
            D. V. Cuong, Branislava Lali'c, Mina Petri'c, Binh Nguyen, M. Roantree
          </td>
          <td>2024-06-07</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="We propose CoNSAL (Combining Neural networks and Symbolic regression for Analytical Lyapunov function) to construct analytical Lyapunov functions for nonlinear dynamic systems. This framework contains a neural Lyapunov function and a symbolic regression component, where symbolic regression is applied to distill the neural network to precise analytical forms. Our approach utilizes symbolic regression not only as a tool for translation but also as a means to uncover counterexamples. This procedure terminates when no counterexamples are found in the analytical formulation. Compared with previous results, CoNSAL directly produces an analytical form of the Lyapunov function with improved interpretability in both the learning process and the final results. We apply CoNSAL to 2-D inverted pendulum, path following, Van Der Pol Oscillator, 3-D trig dynamics, 4-D rotating wheel pendulum, 6-D 3-bus power system, and demonstrate that our algorithm successfully finds their valid Lyapunov functions. Code examples are available at https://github.com/HaohanZou/CoNSAL.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6829a0516285c595b5e8d5fcbc9c4858827f5784" target='_blank'>
              Combining Neural Networks and Symbolic Regression for Analytical Lyapunov Function Discovery
              </a>
            </td>
          <td>
            Jie Feng, Haohan Zou, Yuanyuan Shi
          </td>
          <td>2024-06-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="We developed a novel reservoir characterization workflow that addresses reservoir history matching by coupling a physics-informed neural operator (PINO) forward model with a mixture of experts' approach, termed cluster classify regress (CCR). The inverse modelling is achieved via an adaptive Regularized Ensemble Kalman inversion (aREKI) method, ideal for rapid inverse uncertainty quantification during history matching. We parametrize unknown permeability and porosity fields for non-Gaussian posterior measures using a variational convolution autoencoder and a denoising diffusion implicit model (DDIM) exotic priors. The CCR works as a supervised model with the PINO surrogate to replicate nonlinear Peaceman well equations. The CCR's flexibility allows any independent machine-learning algorithm for each stage. The PINO reservoir surrogate's loss function is derived from supervised data loss and losses from the initial conditions and residual of the governing black oil PDE. The PINO-CCR surrogate outputs pressure, water, and gas saturations, along with oil, water, and gas production rates. The methodology was compared to a standard numerical black oil simulator for a waterflooding case on the Norne field, showing similar outputs. This PINO-CCR surrogate was then used in the aREKI history matching workflow, successfully recovering the unknown permeability, porosity and fault multiplier, with simulations up to 6000 times faster than conventional methods. Training the PINO-CCR surrogate on an NVIDIA H100 with 80G memory takes about 5 hours for 100 samples of the Norne field. This workflow is suitable for ensemble-based approaches, where posterior density sampling, given an expensive likelihood evaluation, is desirable for uncertainty quantification.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3674d06c524c713fc2c4d956ddcdbea4f5c3261c" target='_blank'>
              Reservoir History Matching of the Norne field with generative exotic priors and a coupled Mixture of Experts - Physics Informed Neural Operator Forward Model
              </a>
            </td>
          <td>
            C. Etienam, Juntao Yang, O. Ovcharenko, Issam Said
          </td>
          <td>2024-06-02</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Port-Hamiltonian systems (pHS) allow for a structure-preserving modeling of dynamical systems. Coupling pHS via linear relations between input and output defines an overall pHS, which is structure preserving. However, in multiphysics applications, some subsystems do not allow for a physical pHS description, as (a) this is not available or (b) too expensive. Here, data-driven approaches can be used to deliver a pHS for such subsystems, which can then be coupled to the other subsystems in a structure-preserving way. In this work, we derive a data-driven identification approach for port-Hamiltonian differential algebraic equation (DAE) systems. The approach uses input and state space data to estimate nonlinear effort functions of pH-DAEs. As underlying technique, we us (multi-task) Gaussian processes. This work thereby extends over the current state of the art, in which only port-Hamiltonian ordinary differential equation systems could be identified via Gaussian processes. We apply this approach successfully to two applications from network design and constrained multibody system dynamics, based on pH-DAE system of index one and three, respectively.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f006ed4bbd09834cab7ba0f2c3258b36e07050c2" target='_blank'>
              Data-driven identification of port-Hamiltonian DAE systems by Gaussian processes
              </a>
            </td>
          <td>
            Peter Zaspel, Michael Günther
          </td>
          <td>2024-06-26</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="In chemical engineering, process data are expensive to acquire, and complex phenomena are difficult to fully model. We explore the use of physics-informed neural networks (PINNs) for dynamic processes with incomplete mechanistic semi-explicit differential-algebraic equation systems and scarce process data. In particular, we focus on estimating states for which neither direct observational data nor constitutive equations are available. We propose an easy-to-apply heuristic to assess whether estimation of such states may be possible. As numerical examples, we consider a continuously stirred tank reactor and a liquid-liquid separator. We find that PINNs can infer unmeasured states with reasonable accuracy, and they generalize better in low-data scenarios than purely data-driven models. We thus show that PINNs are capable of modeling processes when relatively few experimental data and only partially known mechanistic descriptions are available, and conclude that they constitute a promising avenue that warrants further investigation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7e4e0161b8d6befa3c8a0687b96bbfc9b32e40f7" target='_blank'>
              Physics-Informed Neural Networks for Dynamic Process Operations with Limited Physical Knowledge and Data
              </a>
            </td>
          <td>
            M. Velioglu, Song Zhai, Sophia Rupprecht, Alexander Mitsos, Andreas Jupke, M. Dahmen
          </td>
          <td>2024-06-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>13</td>
        </tr>

        <tr id="A central aim in computational neuroscience is to relate the activity of large populations of neurons to an underlying dynamical system. Models of these neural dynamics should ideally be both interpretable and fit the observed data well. Low-rank recurrent neural networks (RNNs) exhibit such interpretability by having tractable dynamics. However, it is unclear how to best fit low-rank RNNs to data consisting of noisy observations of an underlying stochastic system. Here, we propose to fit stochastic low-rank RNNs with variational sequential Monte Carlo methods. We validate our method on several datasets consisting of both continuous and spiking neural data, where we obtain lower dimensional latent dynamics than current state of the art methods. Additionally, for low-rank models with piecewise linear nonlinearities, we show how to efficiently identify all fixed points in polynomial rather than exponential cost in the number of units, making analysis of the inferred dynamics tractable for large RNNs. Our method both elucidates the dynamical systems underlying experimental recordings and provides a generative model whose trajectories match observed trial-to-trial variability.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/579f56813a03517163b86fa89044dc78505bf2cb" target='_blank'>
              Inferring stochastic low-rank recurrent neural networks from neural data
              </a>
            </td>
          <td>
            Matthijs Pals, A. E. Saugtekin, Felix Pei, Manuel Gloeckler, J. H. Macke
          </td>
          <td>2024-06-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="The effective inclusion of a priori knowledge when embedding known data in physics‐based models of dynamical systems can ensure that the reconstructed model respects physical principles, while simultaneously improving the accuracy of the solution in the previously unseen regions of state space. This paper presents a physics‐constrained data‐driven discrepancy modeling method that variationally embeds known data in the modeling framework. The hierarchical structure of the method yields fine scale variational equations that facilitate the derivation of residuals which are comprised of the first‐principles theory and sensor‐based data from the dynamical system. The embedding of the sensor data via residual terms leads to discrepancy‐informed closure models that yield a method which is driven not only by boundary and initial conditions, but also by measurements that are taken at only a few observation points in the target system. Specifically, the data‐embedding term serves as residual‐based least‐squares loss function, thus retaining variational consistency. Another important relation arises from the interpretation of the stabilization tensor as a kernel function, thereby incorporating a priori knowledge of the problem and adding computational intelligence to the modeling framework. Numerical test cases show that when known data is taken into account, the data driven variational (DDV) method can correctly predict the system response in the presence of several types of discrepancies. Specifically, the damped solution and correct energy time histories are recovered by including known data in the undamped situation. Morlet wavelet analyses reveal that the surrogate problem with embedded data recovers the fundamental frequency band of the target system. The enhanced stability and accuracy of the DDV method is manifested via reconstructed displacement and velocity fields that yield time histories of strain and kinetic energies which match the target systems. The proposed DDV method also serves as a procedure for restoring eigenvalues and eigenvectors of a deficient dynamical system when known data is taken into account, as shown in the numerical test cases presented here.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/dda505dc42399a19a75eff263166e84931a95cf6" target='_blank'>
              Data‐driven variational method for discrepancy modeling: Dynamics with small‐strain nonlinear elasticity and viscoelasticity
              </a>
            </td>
          <td>
            Arif Masud, Shoaib A. Goraya
          </td>
          <td>2024-07-04</td>
          <td>International Journal for Numerical Methods in Engineering</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Spatiotemporal processes are a fundamental tool for modeling dynamics across various domains, from heat propagation in materials to oceanic and atmospheric flows. However, currently available neural network-based modeling approaches fall short when faced with data collected randomly over time and space, as is often the case with sensor networks in real-world applications like crowdsourced earthquake detection or pollution monitoring. In response, we developed a new spatiotemporal method that effectively handles such randomly sampled data. Our model integrates techniques from amortized variational inference, neural differential equations, neural point processes, and implicit neural representations to predict both the dynamics of the system and the probabilistic locations and timings of future observations. It outperforms existing methods on challenging spatiotemporal datasets by offering substantial improvements in predictive accuracy and computational efficiency, making it a useful tool for modeling and understanding complex dynamical systems observed under realistic, unconstrained conditions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3672c7dfec49ffe06ab53ce52945c37c38e785c8" target='_blank'>
              Modeling Randomly Observed Spatiotemporal Dynamical Systems
              </a>
            </td>
          <td>
            V. Iakovlev, Harri Lähdesmäki
          </td>
          <td>2024-06-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="In this paper, we consider the problem of data-driven modelling and model predictive control (MPC) of a single machine infinite bus system (SMIB). When a linear state-space model of the plant is not available, a pair of Loewner matrices is constructed from a set of measured input-output data and a set of prescribed poles. We prove that the Loewner matrices are the solutions of two Sylvester equations. We compute the unique linear model of an order equal to the dimension of the data sets, that interpolates the input-output data and that has all the poles prescribed at the selected locations. As an application we perform MPC on both the original system and its approximant. The simulation show that the linear data-driven model is a good approximation of the SMIB and achieves good closed-loop MPC performance.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/309d92021f59dd4c7a69a8db0b5ba3bbb08f59af" target='_blank'>
              Data-Driven Loewner Matrices-Based Modeling and Model Predictive Control of a Single Machine Infinite Bus Model
              </a>
            </td>
          <td>
            T. Ionescu, O. Iftime, Ion Necoara
          </td>
          <td>2024-06-11</td>
          <td>2024 32nd Mediterranean Conference on Control and Automation (MED)</td>
          <td>0</td>
          <td>11</td>
        </tr>

        <tr id="The continuously increasing amount of noisy data demands the development of accurate and efficient models for analysis, modeling, and control. In this article, we propose a novel data-driven moment matching method which employs Tikhonov regularization in the Reproducing Kernel Hilbert Spaces (RKHSs). Specifically, considering a realistic scenario in which the system's plant is unknown and only noisy measured data are available, we provide an estimation of the moment of the unknown plant by solving a regularized optimization problem on RKHS. For, we first demonstrate that the estimation of the moment can be improved via tuning the regularization term, and further, we show under which condition the effect of the transient improves the performance of the estimation. Then, we construct a parameterized model characterized by a kernel-based output mapping. Finally, the proposed data-driven approach is validated and discussed by means of a DC-to-DC Cuk converter driven by a Van der Pol oscillator.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/970212021b4134e841e09f425053018067ffcdbb" target='_blank'>
              Nonlinear Data-Driven Moment Matching in Reproducing Kernel Hilbert Spaces
              </a>
            </td>
          <td>
            Alessio Moreschini, Matteo Scandella, Thomas Parisini
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="In this paper, we present a data-driven model predictive control (DDMPC) framework specifically designed for constrained single-input single-output (SISO) nonlinear systems. Our approach involves customizing a set-theoretic receding horizon controller within a data-driven context. To achieve this, we translate model-based conditions into data series of available input and output signals. This translation process leverages recent advances in data-driven control theory, enabling the controller to operate effectively without relying on explicit system models. The proposed framework incorporates a robust methodology for managing system constraints, ensuring that the control actions remain within predefined bounds. By means of time sequences, the controller learns the underlying system dynamics and adapts to changes in real time, providing enhanced performance and reliability. The integration of set-theoretic methods allows for the systematic handling of uncertainties and disturbances, which are common when the trajectory of a nonlinear system is embedded inside a linear trajectory state tube. To validate the effectiveness of our DDMPC framework, we conduct extensive simulations on a nonlinear DC motor system. The results demonstrate significant improvements in control performance, highlighting the robustness and adaptability of our approach compared to traditional model-based MPC techniques.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/557a1699a30747c83bf5827911be2a7cb58cbe44" target='_blank'>
              A Data-Driven Approach to Set-Theoretic Model Predictive Control for Nonlinear Systems
              </a>
            </td>
          <td>
            Francesco Giannini, Domenico Famularo
          </td>
          <td>2024-06-23</td>
          <td>Information</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Classical model reduction techniques project the governing equations onto a linear subspace of the original state space. More recent data-driven techniques use neural networks to enable nonlinear projections. Whilst those often enable stronger compression, they may have redundant parameters and lead to suboptimal latent dimensionality. To overcome these, we propose a multistep algorithm that induces sparsity in the encoder-decoder networks for effective reduction in the number of parameters and additional compression of the latent space. This algorithm starts with sparsely initialized a network and training it using linearized Bregman iterations. These iterations have been very successful in computer vision and compressed sensing tasks, but have not yet been used for reduced-order modelling. After the training, we further compress the latent space dimensionality by using a form of proper orthogonal decomposition. Last, we use a bias propagation technique to change the induced sparsity into an effective reduction of parameters. We apply this algorithm to three representative PDE models: 1D diffusion, 1D advection, and 2D reaction-diffusion. Compared to conventional training methods like Adam, the proposed method achieves similar accuracy with 30% less parameters and a significantly smaller latent space.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6d0716bb98b1bad42ed563160283dce3e8413da6" target='_blank'>
              Sparsifying dimensionality reduction of PDE solution data with Bregman learning
              </a>
            </td>
          <td>
            T. J. Heeringa, Christoph Brune, Mengwu Guo
          </td>
          <td>2024-06-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="To improve the predictive capacity of system models in the input-output sense, this paper presents a framework for model updating via learning of modeling uncertainties in locally (and thus also in globally) Lipschitz nonlinear systems. First, we introduce a method to extend an existing known model with an uncertainty model so that stability of the extended model is guaranteed in the sense of set invariance and input-to-state stability. To achieve this, we provide two tractable semi-definite programs. These programs allow obtaining optimal uncertainty model parameters for both locally and globally Lipschitz nonlinear models, given uncertainty and state trajectories. Subsequently, in order to extract this data from the available input-output trajectories, we introduce a filter that incorporates an approximated internal model of the uncertainty and asymptotically estimates uncertainty and state realizations. This filter is also synthesized using semi-definite programs with guaranteed robustness with respect to uncertainty model mismatches, disturbances, and noise. Numerical simulations for a large data-set of a roll plane model of a vehicle illustrate the effectiveness and practicality of the proposed methodology in improving model accuracy, while guaranteeing stability.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e7ee6ed031b0068e5df250ad046941ba05393280" target='_blank'>
              Model Updating for Nonlinear Systems with Stability Guarantees
              </a>
            </td>
          <td>
            Farhad Ghanipoor, C. Murguia, Peyman Mohajerin Esfahani, N. Wouw
          </td>
          <td>2024-06-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>47</td>
        </tr>

        <tr id="
 The growing time-series data make it possible to glimpse the hidden dynamics in various fields. However, developing a computational toolbox with high interpretability to unveil the interaction dynamics from data remains a crucial challenge. Here, we propose a new computational approach called Automated Dynamical Model Inference based on Expression Trees (ADMIET), in which the machine learning algorithm, the numerical integration of ordinary differential equations and the interpretability from prior knowledge are embedded into the symbolic learning scheme to establish a general framework for revealing the hidden dynamics in time-series data. ADMIET takes full advantage of both machine learning algorithm and expression tree. Firstly, we translate the prior knowledge into constraints on the structure of expression tree, reducing the search space and enhancing the interpretability. Secondly, we utilize the proposed adaptive penalty function to ensure the convergence of gradient descent algorithm and the selection of the symbols. Compared to gene expression programming, ADMIET exhibits its remarkable capability in function fitting with higher accuracy and broader applicability. Moreover, ADMIET can better fit parameters in nonlinear forms compared to regression methods. Furthermore, we apply ADMIET to two typical biological systems and one real data with different prior knowledge to infer the dynamical equations. The results indicate that ADMIET can not only discover the interaction relationships but also provide accurate estimates of the parameters in the equations. These results demonstrate ADMIET's superiority in revealing interpretable dynamics from time-series biological data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9687aa0373c8e0262b0df16232ea9a08145ff46c" target='_blank'>
              Inferring dynamical models from time-series biological data using an interpretable machine learning method based on weighted expression trees
              </a>
            </td>
          <td>
            Yu Zhou, Xiufen Zou
          </td>
          <td>2024-07-09</td>
          <td>Inverse Problems</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9fd49cad114aa0d9be0df7a779ad44da18fbea25" target='_blank'>
              Stochastic modeling of stationary scalar Gaussian processes in continuous time from autocorrelation data
              </a>
            </td>
          <td>
            Martin Hanke
          </td>
          <td>2024-06-24</td>
          <td>Advances in Computational Mathematics</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Physics-informed deep learning has been developed as a novel paradigm for learning physical dynamics recently. While general physics-informed deep learning methods have shown early promise in learning fluid dynamics, they are difficult to generalize in arbitrary time instants in real-world scenario, where the fluid motion can be considered as a time-variant trajectory involved large-scale particles. Inspired by the advantage of diffusion model in learning the distribution of data, we first propose Pi-fusion, a physics-informed diffusion model for predicting the temporal evolution of velocity and pressure field in fluid dynamics. Physics-informed guidance sampling is proposed in the inference procedure of Pi-fusion to improve the accuracy and interpretability of learning fluid dynamics. Furthermore, we introduce a training strategy based on reciprocal learning to learn the quasiperiodical pattern of fluid motion and thus improve the generalizability of the model. The proposed approach are then evaluated on both synthetic and real-world dataset, by comparing it with state-of-the-art physics-informed deep learning methods. Experimental results show that the proposed approach significantly outperforms existing methods for predicting temporal evolution of velocity and pressure field, confirming its strong generalization by drawing probabilistic inference of forward process and physics-informed guidance sampling. The proposed Pi-fusion can also be generalized in learning other physical dynamics governed by partial differential equations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/30d533bf917f7e4f8a81a52e26c206fadbb3f08b" target='_blank'>
              Pi-fusion: Physics-informed diffusion model for learning fluid dynamics
              </a>
            </td>
          <td>
            Jing Qiu, Jiancheng Huang, Xiangdong Zhang, Zeng Lin, Minglei Pan, Zengding Liu, F. Miao
          </td>
          <td>2024-06-06</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>20</td>
        </tr>

        <tr id="Modern data-driven control applications call for flexible nonlinear models that are amenable to principled controller synthesis and realtime feedback. Many nonlinear dynamical systems of interest are control affine. We propose two novel classes of nonlinear feature representations which capture control affine structure while allowing for arbitrary complexity in the state dependence. Our methods make use of random features (RF) approximations, inheriting the expressiveness of kernel methods at a lower computational cost. We formalize the representational capabilities of our methods by showing their relationship to the Affine Dot Product (ADP) kernel proposed by Casta\~neda et al. (2021) and a novel Affine Dense (AD) kernel that we introduce. We further illustrate the utility by presenting a case study of data-driven optimization-based control using control certificate functions (CCF). Simulation experiments on a double pendulum empirically demonstrate the advantages of our methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/29cde075fe82ea752c015715f01f8a198477efc2" target='_blank'>
              Random features approximation for control-affine systems
              </a>
            </td>
          <td>
            Kimia Kazemian, Yahya Sattar, Sarah Dean
          </td>
          <td>2024-06-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Turbulent flows play an important role in many scientific and technological design problems. Both Sub-Grid Scale (SGS) models in Large Eddy Simulations (LES) and Reynolds Averaged Navier Stokes (RANS) based modeling will require turbulence models for computational research of turbulent flows in the future. Turbulence model-based simulations suffer from a multitude of causes of forecast uncertainty. For example, the simplifications and assumptions employed to make these turbulence models computationally tractable and economical lead to predictive uncertainty. For safety-critical engineering design applications, we need reliable estimates of this uncertainty. This article focuses on Uncertainty Quantification (UQ) for Computational Fluid Dynamics (CFD) simulations. We review recent advances in the estimate of many types of uncertainty components, including numerical, aleatoric, and epistemic. We go into further depth on the possible use of Machine Learning (ML) methods to quantify these uncertainties. Above all, we elaborate further on significant limitations in these techniques. These range from realizability constraints on the Eigenspace Perturbation Method (EPM) to the requirement for Monte Carlo (MC) approaches for mixed uncertainty. Based on this study, we pinpoint important problems that need to be addressed and offer focused solutions to move beyond these obstacles.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e49be3a444808330433024b5c6fc46215617ea50" target='_blank'>
              Physics Based&Machine Learning Methods For Uncertainty Estimation In Turbulence Modeling
              </a>
            </td>
          <td>
            Minghan Chu
          </td>
          <td>2024-07-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="We are motivated by a study that seeks to better understand the dynamic relationship between muscle activation and paw position during locomotion. For each gait cycle in this experiment, activation in the biceps and triceps is measured continuously and in parallel with paw position as a mouse trotted on a treadmill. We propose an innovative general regression method that draws from both ordinary differential equations and functional data analysis to model the relationship between these functional inputs and responses as a dynamical system that evolves over time. Specifically, our model addresses gaps in both literatures and borrows strength across curves estimating ODE parameters across all curves simultaneously rather than separately modeling each functional observation. Our approach compares favorably to related functional data methods in simulations and in cross-validated predictive accuracy of paw position in the gait data. In the analysis of the gait cycles, we find that paw speed and position are dynamically influenced by inputs from the biceps and triceps muscles, and that the effect of muscle activation persists beyond the activation itself.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ee556de9ef994107f443707a53199f2a501350f6" target='_blank'>
              Modeling trajectories using functional linear differential equations
              </a>
            </td>
          <td>
            Julia Wrobel, Britton A. Sauerbrei, Erik A. Kirk, Jian-Zhong Guo, A. Hantman, Jeff Goldsmith
          </td>
          <td>2024-06-27</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>24</td>
        </tr>

        <tr id="In this paper, we introduce a physics and geometry informed neural operator network with application to the forward simulation of acoustic scattering. The development of geometry informed deep learning models capable of learning a solution operator for different computational domains is a problem of general importance for a variety of engineering applications. To this end, we propose a physics-informed deep operator network (DeepONet) capable of predicting the scattered pressure field for arbitrarily shaped scatterers using a geometric parameterization approach based on non-uniform rational B-splines (NURBS). This approach also results in parsimonious representations of non-trivial scatterer geometries. In contrast to existing physics-based approaches that require model re-evaluation when changing the computational domains, our trained model is capable of learning solution operator that can approximate physically-consistent scattered pressure field in just a few seconds for arbitrary rigid scatterer shapes; it follows that the computational time for forward simulations can improve (i.e. be reduced) by orders of magnitude in comparison to the traditional forward solvers. In addition, this approach can evaluate the scattered pressure field without the need for labeled training data. After presenting the theoretical approach, a comprehensive numerical study is also provided to illustrate the remarkable ability of this approach to simulate the acoustic pressure fields resulting from arbitrary combinations of arbitrary scatterer geometries. These results highlight the unique generalization capability of the proposed operator learning approach.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4d81cab15f6d634b2bc10b126542b7bc23e38d6e" target='_blank'>
              Physics and geometry informed neural operator network with application to acoustic scattering
              </a>
            </td>
          <td>
            S. Nair, Timothy F. Walsh, Greg Pickrell, Fabio Semperlotti
          </td>
          <td>2024-06-02</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="This work introduces neural Green's operators (NGOs), a novel neural operator network architecture that learns the solution operator for a parametric family of linear partial differential equations (PDEs). Our construction of NGOs is derived directly from the Green's formulation of such a solution operator. Similar to deep operator networks (DeepONets) and variationally mimetic operator networks (VarMiONs), NGOs constitutes an expansion of the solution to the PDE in terms of basis functions, that is returned from a sub-network, contracted with coefficients, that are returned from another sub-network. However, in accordance with the Green's formulation, NGOs accept weighted averages of the input functions, rather than sampled values thereof, as is the case in DeepONets and VarMiONs. Application of NGOs to canonical linear parametric PDEs shows that, while they remain competitive with DeepONets, VarMiONs and Fourier neural operators when testing on data that lie within the training distribution, they robustly generalize when testing on finer-scale data generated outside of the training distribution. Furthermore, we show that the explicit representation of the Green's function that is returned by NGOs enables the construction of effective preconditioners for numerical solvers for PDEs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/727cbd2480b7c613896a418f1c6a620acc92dd6a" target='_blank'>
              Neural Green's Operators for Parametric Partial Differential Equations
              </a>
            </td>
          <td>
            Hugo Melchers, Joost Prins, Michael Abdelmalik
          </td>
          <td>2024-06-04</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>0</td>
        </tr>

        <tr id="Identification of an accurate and simple model of a complex underactuated crane dynamics for varying operational conditions is a crucial step towards designing and implementation of real-time monitoring and control systems to enhance crane safety and operational efficiency. This paper considers a non-parametric data-driven identification of an overhead crane dynamics using symbolic regression techniques to find compromise between model complexity and predicted output accuracy. A grammar-guided genetic programming (G3P) combined with l 0 sparse regression is applied with two different variants of grammar to automatically construct a nonlinear autoregressive exogenous (NARX) model of different forms, termed extended and polynomial models. The proposed method is compared with a linear parameter-varying ARX (LPV-ARX) model. Identification is performed on experimental data ob - tained from a laboratory-scale overhead crane. The identified models are compared in terms of prediction accuracy, model’s complexity measured using number of model terms, and execution time. The regularized G3P method outperformed the LPV-ARX model in terms of model predictive output accuracy. The G3P with the extended gram - mar resulted in more accurate crane velocity prediction models than the models with the polynomial grammar. The payload sway prediction model with the polynomial grammar was less complex in all measured metrics while there was no statistical significance in the accuracy when compared to the models with extended grammar.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a0fd7459dec2b37c265c59ee912f91d33416fd37" target='_blank'>
              Evolutionary and Sparse Regression Approach for Data-Driven Modelling of an Overhead Crane Dynamics
              </a>
            </td>
          <td>
            Tom Kusznir, Jarosław Smoczek, Bolesław Karwat
          </td>
          <td>2024-08-01</td>
          <td>Advances in Science and Technology Research Journal</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="This paper introduces Physics-Informed Deep Equilibrium Models (PIDEQs) for solving initial value problems (IVPs) of ordinary differential equations (ODEs). Leveraging recent advancements in deep equilibrium models (DEQs) and physics-informed neural networks (PINNs), PIDEQs combine the implicit output representation of DEQs with physics-informed training techniques. We validate PIDEQs using the Van der Pol oscillator as a benchmark problem, demonstrating their efficiency and effectiveness in solving IVPs. Our analysis includes key hyperparameter considerations for optimizing PIDEQ performance. By bridging deep learning and physics-based modeling, this work advances computational techniques for solving IVPs, with implications for scientific computing and engineering applications.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/912c9ca80f70ec85971d37a895120c51b031edba" target='_blank'>
              Solving Differential Equations using Physics-Informed Deep Equilibrium Models
              </a>
            </td>
          <td>
            Bruno Machado Pacheco, E. Camponogara
          </td>
          <td>2024-06-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>22</td>
        </tr>

        <tr id="Finding self-similarity is a key step for understanding the governing law behind complex physical phenomena. Traditional methods for identifying self-similarity often rely on specific models, which can introduce significant bias. In this paper, we present a novel neural network-based approach that discovers self-similarity directly from observed data, without presupposing any models. The presence of self-similar solutions in a physical problem signals that the governing law contains a function whose arguments are given by power-law monomials of physical parameters, which are characterized by power-law exponents. The basic idea is to enforce such particular forms structurally in a neural network in a parametrized way. We train the neural network model using the observed data, and when the training is successful, we can extract the power exponents that characterize scale-transformation symmetries of the physical problem. We demonstrate the effectiveness of our method with both synthetic and experimental data, validating its potential as a robust, model-independent tool for exploring self-similarity in complex systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6fbbfdc1dc6eff47d32838a1d93d426c015b87f5" target='_blank'>
              Data-driven discovery of self-similarity using neural networks
              </a>
            </td>
          <td>
            Ryota Watanabe, Takanori Ishii, Yuji Hirono, Hirokazu Maruoka
          </td>
          <td>2024-06-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Predicting the dynamics of turbulent fluid flows has long been a central goal of science and engineering. Yet, even with modern computing technology, accurate simulation of all but the simplest turbulent flow-fields remains impossible: the fields are too chaotic and multi-scaled to directly store them in memory and perform time-evolution. An alternative is to treat turbulence $\textit{probabilistically}$, viewing flow properties as random variables distributed according to joint probability density functions (PDFs). Turbulence PDFs are neither chaotic nor multi-scale, but are still challenging to simulate due to their high dimensionality. Here we show how to overcome the dimensionality problem by parameterising turbulence PDFs into an extremely compressed format known as a"tensor network"(TN). The TN paradigm enables simulations on single CPU cores that would otherwise be impractical even with supercomputers: for a $5+1$ dimensional PDF of a chemically reactive turbulent flow, we achieve reductions in memory and computational costs by factors of $\mathcal{O}(10^6)$ and $\mathcal{O}(10^3)$, respectively, compared to standard finite difference algorithms. A future path is opened towards something heretofore regarded as infeasible: directly simulating high-dimensional PDFs of both turbulent flows and other chaotic systems that are useful to describe probabilistically.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/241b90969989bdb43a42587945b6b357630bfd72" target='_blank'>
              Tensor networks enable the calculation of turbulence probability distributions
              </a>
            </td>
          <td>
            Nikita Gourianov, P. Givi, Dieter Jaksch, Stephen B. Pope
          </td>
          <td>2024-07-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>31</td>
        </tr>

        <tr id="This paper presents the open-source stochastic model predictive control framework GRAMPC-S for nonlinear uncertain systems with chance constraints. It provides several uncertainty propagation methods to predict stochastic moments of the system state and can consider unknown parts of the system dynamics using Gaussian process regression. These methods are used to reformulate a stochastic MPC formulation as a deterministic one that is solved with GRAMPC. The performance of the presented framework is evaluated using examples from a wide range of technical areas. The experimental evaluation shows that GRAMPC-S can be used in practice for the control of nonlinear uncertain systems with sampling times in the millisecond range.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7c62a7baf784d003dda62b0480d24a61f0d5beb4" target='_blank'>
              A software framework for stochastic model predictive control of nonlinear continuous-time systems (GRAMPC-S)
              </a>
            </td>
          <td>
            D. Landgraf, Andreas Volz, Knut Graichen
          </td>
          <td>2024-07-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Modeling dynamical systems is a fundamental task in scientific and engineering fields, often accomplished by applying theory-based models with mathematical equations. Yet, in cases where these equations cannot be established or parameterized properly, theory-based models are not applicable. Instead, a viable alternative is to learn the system dynamics directly from data, for example with deep learning models. However, traditional deep learning models often produce physically inconsistent results and struggle to generalize to unseen data, especially when training data is limited. One solution to this shortcoming is knowledge-guided deep learning, leveraging prior knowledge about the expected behavior of a dynamical system. In this work, we identify and formalize permissible system states, a novel type of prior knowledge that is often available for systems in the context of temporal dynamics modeling. This prior knowledge describes dynamic states that the system is allowed to take during its operation. We propose a knowledge-guided multi-state constraint to encode this type of prior knowledge through a loss function, making it applicable to any deep learning model. This approach allows to create an accurate data-driven model with minimal effort and data requirements. We validate the effectiveness of our method by applying it to model the temporal behavior of a gas turbine in response to an input control signal. Our results indicate that the proposed method reduces the prediction error by up to 40%. In addition to reducing the dependency on extensive training data, our method mitigates training randomness and enhances the consistency of predictions with the expected behavior.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3ba124a5ffc81be0320f4553459c69561edd30f5" target='_blank'>
              Knowledge-Guided Learning of Temporal Dynamics and its Application to Gas Turbines
              </a>
            </td>
          <td>
            Pawel Bielski, Aleksandr Eismont, Jakob Bach, Florian Leiser, D. Kottonau, Klemens Böhm
          </td>
          <td>2024-05-31</td>
          <td>Proceedings of the 15th ACM International Conference on Future and Sustainable Energy Systems</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="A prevalent class of challenges in modern physics are inverse problems, where physical quantities must be extracted from experimental measurements. End-to-end machine learning approaches to inverse problems typically require constructing sophisticated estimators to achieve the desired accuracy, largely because they need to learn the complex underlying physical model. Here, we discuss an alternative paradigm: by making the physical model auto-differentiable we can construct a neural surrogate to represent the unknown physical quantity sought, while avoiding having to relearn the known physics entirely. We dub this process surrogate training embedded in physics (STEP) and illustrate that it generalizes well and is robust against overfitting and significant noise in the data. We demonstrate how STEP can be applied to perform dynamic kernel deconvolution to analyse resonant inelastic X-ray scattering spectra and show that surprisingly simple estimator architectures suffice to extract the relevant physical information.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d1d8fa049394aca47842288ebf6292789f931920" target='_blank'>
              STEP: extraction of underlying physics with robust machine learning
              </a>
            </td>
          <td>
            Karim K. Alaa El-Din, Alessandro Forte, Muhammad Firmansyah Kasim, Francesco Miniati, Sam M. Vinko
          </td>
          <td>2024-06-01</td>
          <td>Royal Society Open Science</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Next-generation reservoir computing is a machine-learning approach that has been recently proposed as an effective method for predicting the dynamics of chaotic systems. So far, this approach has been applied mainly under the assumption that all components of the state vector of dynamical systems are observable. Here we study the effectiveness of this method when only a scalar time series is available for observation. As illustrations, we use the time series of Rössler and Lorenz systems, as well as the chaotic time series generated by an electronic circuit. We found that prediction is only effective if the feature vector of a nonlinear autoregression algorithm contains monomials of a sufficiently high degree. Moreover, the prediction can be improved by replacing monomials with Chebyshev polynomials. Next-generation models, built on the basis of partial observations, are suitable not only for short-term forecasting, but are also capable of reproducing the long-term climate of chaotic systems. We demonstrate the reconstruction of the bifurcation diagram of the Rössler system and the return maps of the Lorenz and electronic circuit systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e2c4bbc2a4bf82fcaa60db77a7af0de4b84c526a" target='_blank'>
              Application of next-generation reservoir computing for predicting chaotic systems from partial observations.
              </a>
            </td>
          <td>
            Irmantas Ratas, Kestutis Pyragas
          </td>
          <td>2024-06-01</td>
          <td>Physical review. E</td>
          <td>0</td>
          <td>30</td>
        </tr>

        <tr id="We provide an algorithm for the simultaneous system identification and model predictive control of nonlinear systems. The algorithm has finite-time near-optimality guarantees and asymptotically converges to the optimal (non-causal) controller. Particularly, the algorithm enjoys sublinear dynamic regret, defined herein as the suboptimality against an optimal clairvoyant controller that knows how the unknown disturbances and system dynamics will adapt to its actions. The algorithm is self-supervised and applies to control-affine systems with unknown dynamics and disturbances that can be expressed in reproducing kernel Hilbert spaces. Such spaces can model external disturbances and modeling errors that can even be adaptive to the system's state and control input. For example, they can model wind and wave disturbances to aerial and marine vehicles, or inaccurate model parameters such as inertia of mechanical systems. The algorithm first generates random Fourier features that are used to approximate the unknown dynamics or disturbances. Then, it employs model predictive control based on the current learned model of the unknown dynamics (or disturbances). The model of the unknown dynamics is updated online using least squares based on the data collected while controlling the system. We validate our algorithm in both hardware experiments and physics-based simulations. The simulations include (i) a cart-pole aiming to maintain the pole upright despite inaccurate model parameters, and (ii) a quadrotor aiming to track reference trajectories despite unmodeled aerodynamic drag effects. The hardware experiments include a quadrotor aiming to track a circular trajectory despite unmodeled aerodynamic drag effects, ground effects, and wind disturbances.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f6fdbd86334d255c0b4f1f232d3ee77ab3286d0f" target='_blank'>
              Simultaneous System Identification and Model Predictive Control with No Dynamic Regret
              </a>
            </td>
          <td>
            Hongyu Zhou, Vasileios Tzoumas
          </td>
          <td>2024-07-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>19</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/233d8ac0f20cf948548fc9238018c681a00d4cec" target='_blank'>
              Structure-preserving formulations for data-driven analysis of coupled multi-physics systems
              </a>
            </td>
          <td>
            Alba Muixí, David González, Francisco Chinesta, Elías Cueto
          </td>
          <td>2024-06-07</td>
          <td>Computational Mechanics</td>
          <td>0</td>
          <td>13</td>
        </tr>

        <tr id="The Koopman operator theory is a powerful tool for the linear analysis and control of nonlinear systems that lifts the nonlinear states into a higher dimensional linear space known as the Koopman space. The linear Koopman space provides an attractive approach for designing linear control strategies for nonlinear systems. However, a significant challenge arises because the Koopman states cannot be directly related to the actual states of the system. This discrepancy can complicate the design of cost functions and constraints for a model predictive controller. In this work, we introduce a novel Koopman representation combined with a training scheme that resolves this issue by defining auxiliary states that are injective and monotonic to the original states. We evaluate the effectiveness of the proposed scheme through numerical experiments.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c8db596cd32649e058785f5df77360f7b2b12672" target='_blank'>
              A Novel Koopman Representation for Efficient Linear Model Predictive Control of Nonlinear Systems
              </a>
            </td>
          <td>
            Omar Sayed, Sergio Lucia
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="The contributions of this technical note are twofold. Firstly, we formulate an optimization problem to obtain a linear representation of a nonlinear vector field based on a system's trajectory. We also prove that its cost function is strictly convex, given the trajectory is persistently exciting. Under certain observability conditions, we provide results that guarantee the Hurwitz stability of the global minimizer. Secondly, we present a novel algorithm based on point-wise geometric flows to estimate the boundary of the region of attraction. We show that the algorithm converges to the exact boundary of the region of attraction under certain assumptions on the system dynamics. Finally, we validate the results using simulations on various nonlinear autonomous systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4f60368ae370b28f9ac8a52aafa0723b5154ed62" target='_blank'>
              Analog Data-Driven Theory and Estimation of the Region of Attraction Using Sampled-Data
              </a>
            </td>
          <td>
            Karthik Shenoy, Arvind Ragghav, V. Chellaboina
          </td>
          <td>2024-07-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>30</td>
        </tr>

        <tr id="This paper aims to construct a representation to approximate the behavior of linear time-invariant systems from a large data set whose input contains unmeasured uncertainty and output is subject to measurement noise. Using big data combined with the statistical properties of the input uncertainty and measurement noise, the covariance of the input uncertainty and the output can be approximated. This enables the construction of an approximate covariance of the trajectories in the data set, through which a representation for the approximation of system behavior is obtained. The behavior of this representation is shown to converge in probability to the true behavior. An illustrative example is provided to show that the proposed representation is able to predict the system trajectory to a satisfactory accuracy. The result of this paper provides a potential basis for the development of data-based trajectory estimation and predictive control algorithm when the system input uncertainty is unmeasured.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/963fe53a6065bfdb118e3128347e8c5bfc500a1d" target='_blank'>
              Approximating the System Behavior with Input Uncertainty Using Big Data
              </a>
            </td>
          <td>
            Yitao Yan, Jie Bao, Biao Huang
          </td>
          <td>2024-06-18</td>
          <td>2024 IEEE 18th International Conference on Control & Automation (ICCA)</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="We demonstrate the effectiveness of simple observer-based linear feedback policies for"pixels-to-torques"control of robotic systems using only a robot-facing camera. Specifically, we show that the matrices of an image-based Luenberger observer (linear state estimator) for a"student"output-feedback policy can be learned from demonstration data provided by a"teacher"state-feedback policy via simple linear-least-squares regression. The resulting linear output-feedback controller maps directly from high-dimensional raw images to torques while being amenable to the rich set of analytical tools from linear systems theory, allowing us to enforce closed-loop stability constraints in the learning problem. We also investigate a nonlinear extension of the method via the Koopman embedding. Finally, we demonstrate the surprising effectiveness of linear pixels-to-torques policies on a cartpole system, both in simulation and on real-world hardware. The policy successfully executes both stabilizing and swing-up trajectory tracking tasks using only camera feedback while subject to model mismatch, process and sensor noise, perturbations, and occlusions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b599f6105b0ceda38eff1d2e2e40f3a1dd1c88ee" target='_blank'>
              From Pixels to Torques with Linear Feedback
              </a>
            </td>
          <td>
            Jeonghoon Lee, Sam Schoedel, Aditya Bhardwaj, Zachary Manchester
          </td>
          <td>2024-06-26</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Neural operators extend data-driven models to map between infinite-dimensional functional spaces. While these operators perform effectively in either the time or frequency domain, their performance may be limited when applied to non-stationary spatial or temporal signals whose frequency characteristics change with time. Here, we introduce Complex Neural Operator (CoNO) that parameterizes the integral kernel using Fractional Fourier Transform (FrFT), better representing non-stationary signals in a complex-valued domain. Theoretically, we prove the universal approximation capability of CoNO. We perform an extensive empirical evaluation of CoNO on seven challenging partial differential equations (PDEs), including regular grids, structured meshes, and point clouds. Empirically, CoNO consistently attains state-of-the-art performance, showcasing an average relative gain of 10.9%. Further, CoNO exhibits superior performance, outperforming all other models in additional tasks such as zero-shot super-resolution and robustness to noise. CoNO also exhibits the ability to learn from small amounts of data -- giving the same performance as the next best model with just 60% of the training data. Altogether, CoNO presents a robust and superior model for modeling continuous dynamical systems, providing a fillip to scientific machine learning.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/95ae0fd0ecd3160ef6c0f799a22f398702eca929" target='_blank'>
              CoNO: Complex Neural Operator for Continous Dynamical Physical Systems
              </a>
            </td>
          <td>
            Karn Tiwari, N. M. A. Krishnan, P. PrathoshA
          </td>
          <td>2024-06-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Living organisms exhibit remarkable adaptations across all scales, from molecules to ecosystems. We believe that many of these adaptations correspond to optimal solutions driven by evolution, training, and underlying physical and chemical laws and constraints. While some argue against such optimality principles due to their potential ambiguity, we propose generalized inverse optimal control to infer them directly from data. This novel approach incorporates multi-criteria optimality, nestedness of objective functions on different scales, the presence of active constraints, the possibility of switches of optimality principles during the observed time horizon, maximization of robustness, and minimization of time as important special cases, as well as uncertainties involved with the mathematical modeling of biological systems. This data-driven approach ensures that optimality principles are not merely theoretical constructs but are firmly rooted in experimental observations. Furthermore, the inferred principles can be used in forward optimal control to predict and manipulate biological systems, with possible applications in bio-medicine, biotechnology, and agriculture. As discussed and illustrated, the well-posed problem formulation and the inference are challenging and require a substantial interdisciplinary effort in the development of theory and robust numerical methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8e4280fd4998f275db90da926b44eac2001bb2e0" target='_blank'>
              Generalized Inverse Optimal Control and its Application in Biology
              </a>
            </td>
          <td>
            J. Banga, Sebastian Sager
          </td>
          <td>2024-05-31</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>54</td>
        </tr>

        <tr id="The advancement of scientific machine learning (ML) techniques has led to the development of methods for approximating solutions to nonlinear partial differential equations (PDE) with increased efficiency and accuracy. Automatic differentiation has played a pivotal role in this progress, enabling the creation of physics-informed neural networks (PINN) that integrate relevant physics into machine learning models. PINN have shown promise in approximating the solutions to the Navier–Stokes equations, overcoming the limitations of traditional numerical discretization methods. However, challenges such as local minima and long training times persist, motivating the exploration of domain decomposition techniques to improve it. Previous domain decomposition models have introduced spatial and temporal domain decompositions but have yet to fully address issues of smoothness and regularity of global solutions. In this study, we present a novel domain decomposition approach for PINN, termed domain-discretized PINN (DD-PINN), which incorporates complementary loss functions, subdomain-specific transformer networks (TRF), and independent optimization within each subdomain. By enforcing continuity and differentiability through interface constraints and leveraging the Sobolev (H 1) norm of the mean squared error (MSE), rather than the Euclidean norm (L 2), DD-PINN enhances solution regularity and accuracy. The inclusion of TRF in each subdomain facilitates feature extraction and improves convergence rates, as demonstrated through simulations of threetest problems: steady-state flow in a two-dimensional lid-driven cavity, the time-dependent cylinder wake, and the viscous Burgers equation. Numerical comparisons highlight the effectiveness of DD-PINN in preserving global solution regularity and accurately approximating complex phenomena, marking a significant advancement over previous domain decomposition methods within the PINN framework.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ea15c09f70a4fe243856a69a988cd4b37e7e4a11" target='_blank'>
              A novel discretized physics-informed neural network model applied to the Navier–Stokes equations
              </a>
            </td>
          <td>
            Amirhossein Khademi, Steven Dufour
          </td>
          <td>2024-06-07</td>
          <td>Physica Scripta</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Matrix evolution equations occur in many applications, such as dynamical Lyapunov/Sylvester systems or Riccati equations in optimization and stochastic control, machine learning or data assimilation. In many cases, their tightest stability condition is coming from a linear term. Exponential time differencing (ETD) is known to produce highly stable numerical schemes by treating the linear term in an exact fashion. In particular, for stiff problems, ETD methods are a method of choice. We propose an extension of the class of ETD algorithms to matrix-valued dynamical equations. This allows us to produce highly efficient and stable integration schemes. We show their efficiency and applicability for a variety of real-world problems, from geophysical applications to dynamical problems in machine learning.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f314941ad68915d7af43429006a76cffcf6ab2db" target='_blank'>
              Exponential time differencing for matrix-valued dynamical systems
              </a>
            </td>
          <td>
            Nayef Shkeir, Tobias Schäfer, T. Grafke
          </td>
          <td>2024-06-19</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>14</td>
        </tr>

        <tr id="There is a growing interest in methods for detecting and interpreting changes in experimental time evolution data. Based on measured time series, the quantitative characterization of dynamical phase transitions at bifurcation points of the underlying chaotic systems is a notoriously difficult task. Building on prior theoretical studies that focus on the discontinuities at $q=1$ in the order-$q$ R\'enyi-entropy of the trajectory space, we measure the derivative of the spectrum. We derive within the general context of Markov processes a computationally efficient closed-form expression for this measure. We investigate its properties through well-known dynamical systems exploring its scope and limitations. The proposed mathematical instrument can serve as a predictor of dynamical phase transitions in time series.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/68dbc71449fe5142fd6c84de4af2b46f1f3412b9" target='_blank'>
              Measuring dynamical phase transitions in time series
              </a>
            </td>
          <td>
            Bulcs'u S'andor, Andr'as Rusu, K'aroly D'enes, M'aria Ercsey-Ravasz, Zs.I. L'az'ar
          </td>
          <td>2024-07-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="We present a new strategy for filtering high-dimensional multiscale systems characterized by high-order non-Gaussian statistics using observations from leading-order moments. A closed stochastic-statistical modeling framework suitable for systematic theoretical analysis and efficient numerical simulations is designed. Optimal filtering solutions are derived based on the explicit coupling structures of stochastic and statistical equations subject to linear operators, which satisfy an infinite-dimensional Kalman-Bucy filter with conditional Gaussian dynamics. To facilitate practical implementation, we develop a finite-dimensional stochastic filter model that approximates the optimal filter solution. We prove that this approximating filter effectively captures key non-Gaussian features, demonstrating consistent statistics with the optimal filter first in its analysis step update, then at the long-time limit guaranteeing stable convergence to the optimal filter. Finally, we build a practical ensemble filter algorithm based on the approximating filtering model, which enables accurate recovery of the true model statistics. The proposed modeling and filtering strategies are applicable to a wide range challenging problems in science and engineering, particularly for statistical prediction and uncertainty quantification of multiscale turbulent states.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c13177983b0f8c570ef00623d67a9361984a8d2d" target='_blank'>
              Coupled Stochastic-Statistical Equations for Filtering Multiscale Turbulent Systems
              </a>
            </td>
          <td>
            Di Qi, Jian-Guo Liu
          </td>
          <td>2024-07-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="In many state-of-the-art control approaches for power systems with storage units, an explicit model of the storage dynamics is required. With growing numbers of storage units, identifying these dynamics can be cumbersome. This paper employs recent data-driven control approaches that do not require an explicit identification step. Instead, they use measured input/output data in control formulations. In detail, we propose an economic data-driven model predictive control (MPC) scheme to operate a small power system with input-nonlinear battery dynamics. First, a linear data-driven MPC approach that uses a slack variable to account for plant-model-mismatch is proposed. In a second step, an input-nonlinear data-driven MPC scheme is deduced. Comparisons with a reference indicate that the linear data-driven MPC approximates the nonlinear plant in an acceptable manner. Even better results, however, can be obtained with the input-nonlinear data-driven MPC scheme which provides increased prediction accuracy.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9e5bf8d50ab982d90d57c28ea067fb4197f8d902" target='_blank'>
              Data-driven model predictive control of battery storage units
              </a>
            </td>
          <td>
            Johannes B. Lipka, Christian A. Hans
          </td>
          <td>2024-07-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Scientific Machine Learning is a new class of approaches that integrate physical knowledge and mechanistic models with data-driven techniques for uncovering governing equations of complex processes. Among the available approaches, Universal Differential Equations (UDEs) are used to combine prior knowledge in the form of mechanistic formulations with universal function approximators, like neural networks. Integral to the efficacy of UDEs is the joint estimation of parameters within mechanistic formulations and the universal function approximators using empirical data. The robustness and applicability of resultant models, however, hinge upon the rigorous quantification of uncertainties associated with these parameters, as well as the predictive capabilities of the overall model or its constituent components. With this work, we provide a formalisation of uncertainty quantification (UQ) for UDEs and investigate important frequentist and Bayesian methods. By analysing three synthetic examples of varying complexity, we evaluate the validity and efficiency of ensembles, variational inference and Markov chain Monte Carlo sampling as epistemic UQ methods for UDEs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/320dbbdecad0c6895c5ce6a4b03811b5cb0b85c8" target='_blank'>
              Assessment of Uncertainty Quantification in Universal Differential Equations
              </a>
            </td>
          <td>
            Nina Schmid, David Fernandes del Pozo, Willem Waegeman, Jan Hasenauer
          </td>
          <td>2024-06-13</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Localized vibrations, arising from nonlinearities or symmetry breaking, pose a challenge in engineering, as the resulting high-amplitude vibrations may result in component failure due to fatigue. During operation, the emergence of localization is difficult to predict, partly because of changing parameters over the life cycle of a system. This work proposes a novel, network-based approach to predicting an imminent localized vibration. Synthetic measurement data is used to generate a functional network, which captures the dynamic interplay of the machine parts, complementary to their geometric coupling. Analysis of these functional networks reveals an impending localized vibration and its location. The method is demonstrated using a model system for a bladed disk, a ring composed of coupled nonlinear Duffing oscillators. Results indicate that the proposed method is robust against small parameter uncertainties, added measurement noise, and the length of the measurement data samples. The source code for this work is available.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/afd5a5cef7da7db6985f9d39e5bc1778cb55539f" target='_blank'>
              Exploring localization in nonlinear oscillator systems through network-based predictions
              </a>
            </td>
          <td>
            Charlotte Geier, Norbert Hoffmann . Hamburg University of Technology, I. -. London
          </td>
          <td>2024-07-07</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>30</td>
        </tr>

        <tr id="We present a domain decomposition strategy for developing structure-preserving finite element discretizations from data when exact governing equations are unknown. On subdomains, trainable Whitney form elements are used to identify structure-preserving models from data, providing a Dirichlet-to-Neumann map which may be used to globally construct a mortar method. The reduced-order local elements may be trained offline to reproduce high-fidelity Dirichlet data in cases where first principles model derivation is either intractable, unknown, or computationally prohibitive. In such cases, particular care must be taken to preserve structure on both local and mortar levels without knowledge of the governing equations, as well as to ensure well-posedness and stability of the resulting monolithic data-driven system. This strategy provides a flexible means of both scaling to large systems and treating complex geometries, and is particularly attractive for multiscale problems with complex microstructure geometry. While consistency is traditionally obtained in finite element methods via quasi-optimality results and the Bramble-Hilbert lemma as the local element diameter $h\rightarrow0$, our analysis establishes notions of accuracy and stability for finite h with accuracy coming from matching data. Numerical experiments and analysis establish properties for $H(\operatorname{div})$ problems in small data limits ($\mathcal{O}(1)$ reference solutions).">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5e40b79cf0d6051174cb4015baf4f92afc84afb1" target='_blank'>
              A Structure-Preserving Domain Decomposition Method for Data-Driven Modeling
              </a>
            </td>
          <td>
            Shuai Jiang, Jonas A. Actor, Scott A. Roberts, Nathaniel Trask
          </td>
          <td>2024-06-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="This paper proposes a generalized algorithmic approach for learning linear model representations for nonlinear systems within the Koopman framework. We focus on schemes that rely on learning the nonlinear transformation functions using deep neural networks. Beyond achieving dynamical accuracy, our primary objective is to develop models capable of simulating nonlinear systems across multiple time steps in the linear space. An algorithm that is based on recursive least squares is proposed to address the optimization complexities inherent in learning such models. In addition, we leverage the learned linear representation to design a linear quadratic regulator to control the original nonlinear system. The effectiveness of the proposed algorithm is demonstrated in two numerical examples.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1dc9bf823159462d30a9a2199b18f6959ef1ccd3" target='_blank'>
              Recursive Least Squares-Based Identification for Multi-Step Koopman Operators
              </a>
            </td>
          <td>
            Omar Sayed, Sergio Lucia
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>1</td>
          <td>1</td>
        </tr>

        <tr id="This paper examines the alignment of inductive biases in machine learning (ML) with structural models of economic dynamics. Unlike dynamical systems found in physical and life sciences, economics models are often specified by differential equations with a mixture of easy-to-enforce initial conditions and hard-to-enforce infinite horizon boundary conditions (e.g. transversality and no-ponzi-scheme conditions). Traditional methods for enforcing these constraints are computationally expensive and unstable. We investigate algorithms where those infinite horizon constraints are ignored, simply training unregularized kernel machines and neural networks to obey the differential equations. Despite the inherent underspecification of this approach, our findings reveal that the inductive biases of these ML models innately enforce the infinite-horizon conditions necessary for the well-posedness. We theoretically demonstrate that (approximate or exact) min-norm ML solutions to interpolation problems are sufficient conditions for these infinite-horizon boundary conditions in a wide class of problems. We then provide empirical evidence that deep learning and ridgeless kernel methods are not only theoretically sound with respect to economic assumptions, but may even dominate classic algorithms in low to medium dimensions. More importantly, these results give confidence that, despite solving seemingly ill-posed problems, there are reasons to trust the plethora of black-box ML algorithms used by economists to solve previously intractable, high-dimensional dynamical systems -- paving the way for future work on estimation of inverse problems with embedded optimal control problems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ea77e3ea1cbcdc65fdeab71d987d86833d4f8a9f" target='_blank'>
              How Inductive Bias in Machine Learning Aligns with Optimality in Economic Dynamics
              </a>
            </td>
          <td>
            Mahdi Ebrahimi Kahou, James Yu, Jesse Perla, Geoff Pleiss
          </td>
          <td>2024-06-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="A machine-learning strategy for investigating the stability of fluid flow problems is proposed herein. The computational procedure is demonstrably robust and does not require parameter tuning. The essential feature of the strategy is that the computational solution of the Navier--Stokes equations is a reliable proxy for laboratory experiments investigating sensitivity to flow parameters. The applicability of our bifurcation detection strategy is demonstrated by an investigation of two classical examples of flow instability associated with thermal convection. The codes used to generate the numerical results are available online.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ada3b0ba98c9f07f4ec32419fa6e2cd617f9cbce" target='_blank'>
              Machine learning for hydrodynamic stability
              </a>
            </td>
          <td>
            David J. Silvester
          </td>
          <td>2024-07-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Predicting the behavior of AI-driven agents is particularly challenging without a preexisting model. In our paper, we address this by treating AI agents as nonlinear dynamical systems and adopting a probabilistic perspective to predict their statistical behavior using the Perron-Frobenius (PF) operator. We formulate the approximation of the PF operator as an entropy minimization problem, which can be solved by leveraging the Markovian property of the operator and decomposing its spectrum. Our data-driven methodology simultaneously approximates the PF operator to perform prediction of the evolution of the agents and also predicts the terminal probability density of AI agents, such as robotic systems and generative models. We demonstrate the effectiveness of our prediction model through extensive experiments on practical systems driven by AI algorithms.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1a2486e3ffd171f8e90604ce1900f9467023bd1d" target='_blank'>
              Predicting AI Agent Behavior through Approximation of the Perron-Frobenius Operator
              </a>
            </td>
          <td>
            Shiqi Zhang, D. Gadginmath, Fabio Pasqualetti
          </td>
          <td>2024-06-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Single-cell time series data frequently display considerable variability across a cell population. The current gold standard for inferring parameter distributions across cell populations is the Global Two Stage (GTS) approach for nonlinear mixed-effects (NLME) models. However, this method is computationally intensive, as it makes repeated use of non-convex optimization that in turn requires numerical integration of the underlying system. Here, we propose the Gradient Matching GTS (GMGTS) method as an efficient alternative to GTS. Gradient matching offers an integration-free approach to parameter estimation that is particularly powerful for dynamical systems that are linear in the unknown parameters, such as biochemical networks modeled by mass action kinetics. Here, we harness the power of gradient matching by integrating it into the GTS framework. To this end, we significantly expand the capabilities of gradient matching via uncertainty propagation calculations and the development of an iterative estimation scheme for partially observed systems. Through comparisons of GMGTS with GTS in different inference setups, we demonstrate that our method provides a significant computational advantage, thereby facilitating the use of complex NLME models in systems biology applications.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4dced58f5c5737541e67c9ad6ec12731d8224877" target='_blank'>
              Gradient matching accelerates mixed-effects inference for biochemical networks
              </a>
            </td>
          <td>
            Yulan B van Oppen, Andreas Milias-Argeitis
          </td>
          <td>2024-06-12</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>15</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c78e8674f4b4b137f15f996d2bc27957f1fe2af7" target='_blank'>
              Optimal Reconstruction of Vector Fields from Data for Prediction and Uncertainty Quantification
              </a>
            </td>
          <td>
            Sean P. McGowan, William S. P. Robertson, Chantelle Blachut, Sanjeeva Balasuriya
          </td>
          <td>2024-06-13</td>
          <td>J. Nonlinear Sci.</td>
          <td>0</td>
          <td>18</td>
        </tr>

        <tr id="The control and modeling of bionic robot dynamics have increasingly adopted model-free control strategies using machine learning methods. Given the non-linear elastic nature of bionic robotic systems, learning-based methods provide reliable alternatives by utilizing numerical data to establish a direct mapping from actuation inputs to robot trajectories without complex kinematics models. However, for developers, the method of identifying an appropriate learning model for their specific bionic robots and further constructing the transfer function has not been thoroughly discussed. Thus, this research trains four types of models, including ensemble learning models, regularization-based models, kernel-based models, and neural network models, suitable for multi-input multi-output (MIMO) data and non-linear transfer function identification, in order to evaluate their (1) accuracy, (2) computation complexity, and (3) performance of capturing biological movements. This research encompasses data collection methods for control inputs and action outputs, selection of machine learning models, comparative analysis of training results, and transfer function identifications. The main objective is to provide a comprehensive evaluation strategy and framework for the application of model-free control.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/433edf81dbd7f0bda53efef26b89259a7da7dc7e" target='_blank'>
              Comparative Evaluation of Learning Models for Bionic Robots: Non-Linear Transfer Function Identifications
              </a>
            </td>
          <td>
            Po-Yu Hsieh, June-Hao Hou
          </td>
          <td>2024-07-02</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="In dynamical systems reconstruction (DSR) we seek to infer from time series measurements a generative model of the underlying dynamical process. This is a prime objective in any scientific discipline, where we are particularly interested in parsimonious models with a low parameter load. A common strategy here is parameter pruning, removing all parameters with small weights. However, here we find this strategy does not work for DSR, where even low magnitude parameters can contribute considerably to the system dynamics. On the other hand, it is well known that many natural systems which generate complex dynamics, like the brain or ecological networks, have a sparse topology with comparatively few links. Inspired by this, we show that geometric pruning, where in contrast to magnitude-based pruning weights with a low contribution to an attractor's geometrical structure are removed, indeed manages to reduce parameter load substantially without significantly hampering DSR quality. We further find that the networks resulting from geometric pruning have a specific type of topology, and that this topology, and not the magnitude of weights, is what is most crucial to performance. We provide an algorithm that automatically generates such topologies which can be used as priors for generative modeling of dynamical systems by RNNs, and compare it to other well studied topologies like small-world or scale-free networks.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f7262300a7dc61b5b9020753dc9d2bbd63a06cc2" target='_blank'>
              Optimal Recurrent Network Topologies for Dynamical Systems Reconstruction
              </a>
            </td>
          <td>
            Christoph Jurgen Hemmer, Manuel Brenner, Florian Hess, Daniel Durstewitz
          </td>
          <td>2024-06-07</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="This paper addresses the need for deep learning models to integrate well-defined constraints into their outputs, driven by their application in surrogate models, learning with limited data and partial information, and scenarios requiring flexible model behavior to incorporate non-data sample information. We introduce Bayesian Entropy Neural Networks (BENN), a framework grounded in Maximum Entropy (MaxEnt) principles, designed to impose constraints on Bayesian Neural Network (BNN) predictions. BENN is capable of constraining not only the predicted values but also their derivatives and variances, ensuring a more robust and reliable model output. To achieve simultaneous uncertainty quantification and constraint satisfaction, we employ the method of multipliers approach. This allows for the concurrent estimation of neural network parameters and the Lagrangian multipliers associated with the constraints. Our experiments, spanning diverse applications such as beam deflection modeling and microstructure generation, demonstrate the effectiveness of BENN. The results highlight significant improvements over traditional BNNs and showcase competitive performance relative to contemporary constrained deep learning methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4d74383a8ad720e106440e126defbad7231d316d" target='_blank'>
              Bayesian Entropy Neural Networks for Physics-Aware Prediction
              </a>
            </td>
          <td>
            R. Rathnakumar, Jiayu Huang, Hao Yan, Yongming Liu
          </td>
          <td>2024-07-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/aa3f44ccd771db0db020f6c18e73d2e428030047" target='_blank'>
              Learning unbounded-domain spatiotemporal differential equations using adaptive spectral methods
              </a>
            </td>
          <td>
            Mingtao Xia, Xiangting Li, Qijing Shen, Tom Chou
          </td>
          <td>2024-06-03</td>
          <td>Journal of Applied Mathematics and Computing</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id="Many dynamical systems are subjected to stochastic influences, such as random excitations, noise, and unmodeled behavior. Tracking the system's state and parameters based on a physical model is a common task for which filtering algorithms, such as Kalman filters and their non-linear extensions, are typically used. However, many of these filters use assumptions on the transition probabilities or the covariance model, which can lead to inaccuracies in non-linear systems. We will show the application of a stochastic coupling filter that can approximate arbitrary transition densities under non-Gaussian noise. The filter is based on transport maps, which couple the approximation densities to a user-chosen reference density, allowing for straightforward sampling and evaluation of probabilities.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/674a1134430bb9d26de4b9e60e39258373cc6b87" target='_blank'>
              Transport Map Coupling Filter for State-Parameter Estimation
              </a>
            </td>
          <td>
            J. Grashorn, M. Broggi, Ludovic Chamoin, Michael Beer
          </td>
          <td>2024-07-02</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>21</td>
        </tr>

        <tr id="This work introduces a new approach for accelerating the numerical analysis of time-domain partial differential equations (PDEs) governing complex physical systems. The methodology is based on a combination of a classical reduced-order modeling (ROM) framework and recently-introduced Graph Neural Networks (GNNs), where the latter is trained on highly heterogeneous databases of varying numerical discretization sizes. The proposed techniques are shown to be particularly suitable for non-parametric geometries, ultimately enabling the treatment of a diverse range of geometries and topologies. Performance studies are presented in an application context related to the design of aircraft seats and their corresponding mechanical responses to shocks, where the main motivation is to reduce the computational burden and enable the rapid design iteration for such problems that entail non-parametric geometries. The methods proposed here are straightforwardly applicable to other scientific or engineering problems requiring a large number of finite element-based numerical simulations, with the potential to significantly enhance efficiency while maintaining reasonable accuracy.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/19eca8092723dbf1132774137ba348d7ca909850" target='_blank'>
              A hybrid numerical methodology coupling Reduced Order Modeling and Graph Neural Networks for non-parametric geometries: applications to structural dynamics problems
              </a>
            </td>
          <td>
            Victor Matray, Faisal Amlani, Fr'ed'eric Feyel, David N'eron
          </td>
          <td>2024-06-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Modeling real-world problems with partial differential equations (PDEs) is a prominent topic in scientific machine learning. Classic solvers for this task continue to play a central role, e.g. to generate training data for deep learning analogues. Any such numerical solution is subject to multiple sources of uncertainty, both from limited computational resources and limited data (including unknown parameters). Gaussian process analogues to classic PDE simulation methods have recently emerged as a framework to construct fully probabilistic estimates of all these types of uncertainty. So far, much of this work focused on theoretical foundations, and as such is not particularly data efficient or scalable. Here we propose a framework combining a discretization scheme based on the popular Finite Volume Method with complementary numerical linear algebra techniques. Practical experiments, including a spatiotemporal tsunami simulation, demonstrate substantially improved scaling behavior of this approach over previous collocation-based techniques.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f405569ff0b7887d7f887ed428142bf13a634400" target='_blank'>
              Scaling up Probabilistic PDE Simulators with Structured Volumetric Information
              </a>
            </td>
          <td>
            Tim Weiland, Marvin Pförtner, Philipp Hennig
          </td>
          <td>2024-06-07</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="A dynamical system may be defined by a simple transition law - such as a map or a vector field. Most learning techniques primarily try to recreate the dynamic evolution law. This is a major shortcoming, as most dynamic properties of interest are asymptotic properties such as an attractor or invariant measure. One of the major theoretical challenges for numerical methods is that approximating the dynamical law may not be sufficient to approximate these asymptotic properties. This article presents a method of representing a discrete-time deterministic dynamical system as a Markov process. The procedure is completely data-driven. The technique is proved to be convergent -- the stationary density of the Markov process has a support that converges to the targeted invariant set. Thus invariant sets of arbitrary dynamical systems, even with complicated non-smooth topology, can be approximated by this technique. Under further assumptions of stochastic stability of the targeted system, the technique is also shown to provide a convergent statistical approximation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f7a9c8ed7750a7d4d14152ec7fe7c869a1655699" target='_blank'>
              Reconstructing dynamical systems as zero-noise limits
              </a>
            </td>
          <td>
            Suddhasattwa Das
          </td>
          <td>2024-07-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Mathematical models are indispensable to the system biology toolkit for studying the structure and behavior of intracellular signaling networks. A common approach to modeling is to develop a system of equations that encode the known biology using approximations and simplifying assumptions. As a result, the same signaling pathway can be represented by multiple models, each with its set of underlying assumptions, which opens up challenges for model selection and decreases certainty in model predictions. Here, we use Bayesian multimodel inference to develop a framework to increase certainty in systems biology models. Using models of the extracellular regulated kinase (ERK) pathway, we first show that multimodel inference increases predictive certainty and yields predictors that are robust to changes in the set of available models. We then show that predictions made with multi-model inference are robust to data uncertainties introduced by decreasing the measurement duration and reducing the sample size. Finally, we use multimodel inference to identify a new model to explain experimentally measured sub-cellular location-specific ERK activity dynamics. In summary, our framework highlights multimodel inference as a disciplined approach to increasing the certainty of intracellular signaling activity predictions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/492e6724b6c05e22b755836f73b25e0ce04843d4" target='_blank'>
              Increasing certainty in systems biology models using Bayesian multimodel inference
              </a>
            </td>
          <td>
            Nathaniel Linden-Santangeli, Jin Zhang, Boris Kramer, P. Rangamani
          </td>
          <td>2024-06-17</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Machine learning (ML) techniques, especially neural networks (NNs), have shown promise in learning subgrid-scale parameterizations for climate models. However, a major problem with data-driven parameterizations, particularly those learned with supervised algorithms, is model instability. Current remedies are often ad-hoc and lack a theoretical foundation. Here, we combine ML theory and climate physics to address a source of instability in NN-based parameterization. We demonstrate the importance of learning spatially $\textit{non-local}$ dynamics using a 1D model of the quasi-biennial oscillation (QBO) with gravity wave (GW) parameterization as a testbed. While common offline metrics fail to identify shortcomings in learning non-local dynamics, we show that the concept of receptive field (RF) can identify instability a-priori. We find that NN-based parameterizations that seem to accurately predict GW forcings from wind profiles ($\mathbf{R^2 \approx 0.99}$) cause unstable simulations when RF is too small to capture the non-local dynamics, while NNs of the same size but large-enough RF are stable. We examine three broad classes of architectures, namely convolutional NNs, Fourier neural operators, and fully-connected NNs; the latter two have inherently large RFs. We also demonstrate that learning non-local dynamics is crucial for the stability and accuracy of a data-driven spatiotemporal emulator of the zonal wind field. Given the ubiquity of non-local dynamics in the climate system, we expect the use of effective RF, which can be computed for any NN architecture, to be important for many applications. This work highlights the necessity of integrating ML theory with physics to design and analyze data-driven algorithms for weather and climate modeling.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bd11d93aa02d18fe1868d0af83c62f1e536ac6fb" target='_blank'>
              On the importance of learning non-local dynamics for stable data-driven climate modeling: A 1D gravity wave-QBO testbed
              </a>
            </td>
          <td>
            H. Pahlavan, P. Hassanzadeh, M. J. Alexander
          </td>
          <td>2024-07-07</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>24</td>
        </tr>

        <tr id="Echo state network (ESN) implements an alternative paradigm called reservoir computing to train recurrent neural networks (RNNs), where internal weights are randomly generated and kept fixed, and only readout weights need to be trained, which greatly reduces the training complexity of RNNs. ESN not only facilitates the practical implementation of RNNs but also shows superior performance over fully trained RNNs across a range of applications. However, the conventional ESN suffers from the drawbacks of stringent conditions for weight convergence and slow convergence speed. This paper proposes a memory regressor extended learning method to update the readout weights of ESNs. By constructing and incorporating a generalized prediction error based on regressor extension and filtering, the capacity of ESN to utilize historical data can be greatly improved. In the discrete-time domain, it is proven that exponential convergence of readout weights is achieved under a condition termed interval excitation that is strictly weaker than the classical condition of persistent excitation. Simulation results on modeling a 10th-order nonlinear autoregressive moving-average (NARMA) system have revealed that the proposed approach accelerates weight convergence speed almost ten times higher compared to the conventional ESN.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4e0fa7b7dfe357970b3e72acb8d86266f028d299" target='_blank'>
              Memory Regressor Extended Echo State Networks for Nonlinear Dynamics Modeling
              </a>
            </td>
          <td>
            Kai Hu, Qian Wang, Tian Shi, Kohei Nakajima, Yongping Pan
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="This work aims to improve generalization and interpretability of dynamical systems by recovering the underlying lower-dimensional latent states and their time evolutions. Previous work on disentangled representation learning within the realm of dynamical systems focused on the latent states, possibly with linear transition approximations. As such, they cannot identify nonlinear transition dynamics, and hence fail to reliably predict complex future behavior. Inspired by the advances in nonlinear ICA, we propose a state-space modeling framework in which we can identify not just the latent states but also the unknown transition function that maps the past states to the present. We introduce a practical algorithm based on variational auto-encoders and empirically demonstrate in realistic synthetic settings that we can (i) recover latent state dynamics with high accuracy, (ii) correspondingly achieve high future prediction accuracy, and (iii) adapt fast to new environments.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b91569481a5aad3715608ea42c4bee05aa9187d5" target='_blank'>
              Identifying latent state transition in non-linear dynamical systems
              </a>
            </td>
          <td>
            cCauglar Hizli, cCaugatay Yildiz, Matthias Bethge, ST John, Pekka Marttinen
          </td>
          <td>2024-06-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="This work proposes a data‐driven state observation algorithm for nonlinear dynamical systems, when the true state trajectory is not measurable and hence the states information needs to be reconstructed from input and output measurements. Such a reduction is formed by kernel canonical correlation analysis (KCCA), which (i) implicitly maps the available input–output data into a higher‐dimensional feature space, namely the reproducing kernel Hilbert space (RKHS); (ii) finds a projection of the past input–output data and a projection of the future input–output data with maximal correlation; and (iii) identifies the projected inputs and outputs, namely the canonical variates, as the observed states. We adopt a least squares support vector machine (LS‐SVM) formulation for KCCA, which imposes regularization on the vectors that specify the projections and is amenable to convex optimization. We prove theoretically that, based on the statistical consistency of KCCA, the observed states determined by the proposed state observer has a guaranteed correlativity with the actual states (when properly transformed). Furthermore, such observed states, when supplemented with the information of succeeding inputs, can be used to predict the succeeding outputs with guaranteed upper bound on the prediction error. Case studies are performed on two numerical examples and an exothermic continuously stirred tank reactor (CSTR).">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/afc53bd0e86a21cb48431210cc83dc9943ac1742" target='_blank'>
              Data‐driven nonlinear state observation for controlled systems: A kernel method and its analysis
              </a>
            </td>
          <td>
            Moritz Woelk, Wentao Tang
          </td>
          <td>2024-07-08</td>
          <td>The Canadian Journal of Chemical Engineering</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="The Realization Independent Iterative Rational Krylov Algorithm (TF-IRKA) is a frequency-based data-driven reduced order modeling (DDROM) method that constructs $\mathcal H_2$ optimal DDROMs. However, as the $\mathcal H_2$ optimal approximation theory dictates, TF-IRKA requires repeated sampling of frequency data, that is, values of the system transfer function and its derivative, outside the unit circle. This repeated evaluation of frequency data requires repeated full model computations and may not be feasible. The data-informativity framework for moment matching provides a method for obtaining such frequency data from a single time-domain simulation. However, this framework usually requires solving linear systems with prohibitively ill-conditioned matrices, especially when recovering frequency data from off the unit circle as required for optimality. In this paper, building upon our previous work with the data informativity framework for moment matching, we provide a formula for the nonzero extreme eigenvalues of a symmetric rank-$1$ perturbation to an orthogonal projection, which then leads to an optimal scaling of the aforementioned linear systems. We also establish connections between the underlying dynamical system and conditioning of these linear systems. This analysis then leads to our algorithmic development, time-domain IRKA, which allows us to implement a time-domain variant of TF-IRKA, constructing $\mathcal H_2$ optimal DDROMs from a single time-domain simulation without requiring repeated frequency data evaluations. The numerical examples illustrate the effectiveness of the proposed algorithm.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f90d4456bd8e538b620928a9ce87f5d39d48c1b7" target='_blank'>
              Time-Domain Iterative Rational Krylov Method
              </a>
            </td>
          <td>
            Michael S. Ackermann, S. Gugercin
          </td>
          <td>2024-07-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>38</td>
        </tr>

        <tr id="The Koopman operator framework is a promising direction of analysis and synthesis of systems with nonlinear dynamics based on (linear) Koopman operators. In this paper, we address the resolvent of a Koopman operator for a nonlinear autonomous discrete-time system, which we call the Koopman resolvent, and its identification problem. First, we show that for the nonlinear system with a scalar-valued output, the $z$- transform of the output is represented by the action of Koop-man resolvent. Second, we describe an identification method of the Koopman resolvent directly from time-series data of the output, in which we estimate parameters of the resolvent as well as poles and residues of the z-transform of the output. By combining the so-called frequency-domain Prony method with the Vandermonde-Cauchy form in the Dynamic Mode Decomposition (DMD), we propose the method which we call the frequency-domain DMD, in which all the unknowns can be estimated in the frequency domain.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/df691892a89d4f0c1e7b43d373b04818f75bcc0b" target='_blank'>
              Koopman Resolvents of Nonlinear Discrete-Time Systems: Formulation and Identification
              </a>
            </td>
          <td>
            Yoshihiko Susuki, A. Mauroy, Z. Drmač
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>20</td>
        </tr>

        <tr id="Within the context of machine learning-based closure mappings for RANS turbulence modelling, physical realizability is often enforced using ad-hoc postprocessing of the predicted anisotropy tensor. In this study, we address the realizability issue via a new physics-based loss function that penalizes non-realizable results during training, thereby embedding a preference for realizable predictions into the model. Additionally, we propose a new framework for data-driven turbulence modelling which retains the stability and conditioning of optimal eddy viscosity-based approaches while embedding equivariance. Several modifications to the tensor basis neural network to enhance training and testing stability are proposed. We demonstrate the conditioning, stability, and generalization of the new framework and model architecture on three flows: flow over a flat plate, flow over periodic hills, and flow through a square duct. The realizability-informed loss function is demonstrated to significantly increase the number of realizable predictions made by the model when generalizing to a new flow configuration. Altogether, the proposed framework enables the training of stable and equivariant anisotropy mappings, with more physically realizable predictions on new data. We make our code available for use and modification by others.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d49d700d5797f8d7145ca83fa89f5c1491a5d703" target='_blank'>
              Realizability-Informed Machine Learning for Turbulence Anisotropy Mappings
              </a>
            </td>
          <td>
            R. McConkey, Eugene Yee, F. Lien
          </td>
          <td>2024-06-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>36</td>
        </tr>

        <tr id="Cyclostationary linear inverse models (CS-LIMs), generalized versions of the classical (stationary) LIM, are advanced data-driven techniques for extracting the first-order time-dependent dynamics and random forcing relevant information from complex non-linear stochastic processes. Though CS-LIMs lead to a breakthrough in climate sciences, their mathematical background and properties are worth further exploration. This study focuses on the mathematical perspective of CS-LIMs and introduces two variants: e-CS-LIM and l-CS-LIM. The former refines the original CS-LIM using the interval-wise linear Markov approximation, while the latter serves as an analytic inverse model for the linear periodic stochastic systems. Although relying on approximation, e-CS-LIM converges to l-CS-LIM under specific conditions and shows noise-robust performance. Numerical experiments demonstrate that each CS-LIM reveals the temporal structure of the system. The e-CS-LIM optimizes the original model for better dynamics performance, while l-CS-LIM excels in diffusion estimation due to reduced approximation reliance. Moreover, CS-LIMs are applied to real-world ENSO data, yielding a consistent result aligning with observations and current ENSO understanding.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7f20f17be02b5ed8df3e9de809737832dc15d7e7" target='_blank'>
              On the Cyclostationary Linear Inverse Models: A Mathematical Insight and Implication
              </a>
            </td>
          <td>
            Justin Lien, Yan-Ning Kuo, Hiroyasu Ando
          </td>
          <td>2024-07-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Nonlinear optimization (NOPT) is a meaningful tool for solving complex tasks in fields like engineering, economics, and operations research, among others. However, NOPT has problems when it comes to dealing with data variability and noisy input measurements that lead to incorrect solutions. Furthermore, nonlinear constraints may result in outcomes that are either infeasible or suboptimal, such as nonconvex optimization. This paper introduces a novel regularized physics-informed neural network (RPINN) framework as a new NOPT tool for both supervised and unsupervised data-driven scenarios. Our RPINN is threefold: By using custom activation functions and regularization penalties in an artificial neural network (ANN), RPINN can handle data variability and noisy inputs. Furthermore, it employs physics principles to construct the network architecture, computing the optimization variables based on network weights and learned features. In addition, it uses automatic differentiation training to make the system scalable and cut down on computation time through batch-based back-propagation. The test results for both supervised and unsupervised NOPT tasks show that our RPINN can provide solutions that are competitive compared to state-of-the-art solvers. In turn, the robustness of RPINN against noisy input measurements makes it particularly valuable in environments with fluctuating information. Specifically, we test a uniform mixture model and a gas-powered system as NOPT scenarios. Overall, with RPINN, its ANN-based foundation offers significant flexibility and scalability.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/516f48e222fdad35b92113ecdbf8a459d37c95aa" target='_blank'>
              A Regularized Physics-Informed Neural Network to Support Data-Driven Nonlinear Constrained Optimization
              </a>
            </td>
          <td>
            Diego Armando Perez-Rosero, A. Álvarez-Meza, C. Castellanos-Dominguez
          </td>
          <td>2024-07-18</td>
          <td>Computers</td>
          <td>0</td>
          <td>15</td>
        </tr>

        <tr id="Reachability analysis is a popular method to give safety guarantees for stochastic cyber-physical systems (SCPSs) that takes in a symbolic description of the system dynamics and uses set-propagation methods to compute an overapproximation of the set of reachable states over a bounded time horizon. In this paper, we investigate the problem of performing reachability analysis for an SCPS that does not have a symbolic description of the dynamics, but instead is described using a digital twin model that can be simulated to generate system trajectories. An important challenge is that the simulator implicitly models a probability distribution over the set of trajectories of the SCPS; however, it is typical to have a sim2real gap, i.e., the actual distribution of the trajectories in a deployment setting may be shifted from the distribution assumed by the simulator. We thus propose a statistical reachability analysis technique that, given a user-provided threshold $1-\epsilon$, provides a set that guarantees that any reachable state during deployment lies in this set with probability not smaller than this threshold. Our method is based on three main steps: (1) learning a deterministic surrogate model from sampled trajectories, (2) conducting reachability analysis over the surrogate model, and (3) employing {\em robust conformal inference} using an additional set of sampled trajectories to quantify the surrogate model's distribution shift with respect to the deployed SCPS. To counter conservatism in reachable sets, we propose a novel method to train surrogate models that minimizes a quantile loss term (instead of the usual mean squared loss), and a new method that provides tighter guarantees using conformal inference using a normalized surrogate error. We demonstrate the effectiveness of our technique on various case studies.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/93907ec40f0d01dbc1a340eca1edf00aee68ef8b" target='_blank'>
              Statistical Reachability Analysis of Stochastic Cyber-Physical Systems under Distribution Shift
              </a>
            </td>
          <td>
            Navid Hashemi, Lars Lindemann, Jyotirmoy V. Deshmukh
          </td>
          <td>2024-07-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>26</td>
        </tr>

        <tr id="Type 1 diabetes is one of the main issues in current medical research. If not properly managed, it can lead to serious long-term complications such as blindness, stroke, coma and, ultimately, death. In recent years, research endeavors have focused on the development of a fully automated system for glucose control through automated insulin injections, known as Artificial Pancreas, which, however, is not yet robust enough for practical use. Currently, the UVA/Padova simulator provides the most accurate model for effectively representing the insulin-glucose dynamics of individual diabetic patients. As it is highly complex, consisting of 18 strongly nonlinear and time-varying equations, the objective of this work is to linearize it and reduce its dimensionality exploiting Dynamic Mode Decomposition with Control. This allows for the synthesis of a controller based on Linear Model Predictive Control to be applied to the original model. This is justified by the need to integrate the control algorithm into portable devices with limited computational capabilities. The proposed dimensionality reduction method is validated through in-vitro simulations showing that an accurate representation of the system dynamics is effectively preserved, while conveniently reducing required computational power.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4a2d5d47a3af830b93a57059fd7ce53ec9a2770c" target='_blank'>
              Dynamic Mode Decomposition for Individualized Model Predictive Control with Application to Type 1 Diabetes
              </a>
            </td>
          <td>
            Valentina Becchetti, Mohab M. H. Atanasious, Danilo Menegatti, Federico Baldisseri, Alessandro Giuseppi
          </td>
          <td>2024-06-11</td>
          <td>2024 32nd Mediterranean Conference on Control and Automation (MED)</td>
          <td>0</td>
          <td>15</td>
        </tr>

        <tr id="Complex phenomena can be better understood when broken down into a limited number of simpler"components". Linear statistical methods such as the principal component analysis and its variants are widely used across various fields of applied science to identify and rank these components based on the variance they represent in the data. These methods can be seen as factorizations of the matrix collecting all the data, which are assumed to be a collection of time series sampled from fixed points in space. However, when data sampling locations vary over time, as with mobile monitoring stations in meteorology and oceanography or with particle tracking velocimetry in experimental fluid dynamics, advanced interpolation techniques are required to project the data onto a fixed grid before carrying out the factorization. This interpolation is often expensive and inaccurate. This work proposes a method to decompose scattered data without interpolating. The approach is based on physics-constrained radial basis function regression to compute inner products in space and time. The method provides an analytical and mesh-independent decomposition in space and time, demonstrating higher accuracy than the traditional approach. Our results show that it is possible to distill the most relevant"components"even for measurements whose natural output is a distribution of data scattered in space and time, maintaining high accuracy and mesh independence.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/86c7267e0b2467d8246052b53c6b8f70898b757e" target='_blank'>
              A meshless method to compute the proper orthogonal decomposition and its variants from scattered data
              </a>
            </td>
          <td>
            Iacopo Tirelli, M. A. Mendez, A. Ianiro, S. Discetti
          </td>
          <td>2024-07-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>24</td>
        </tr>

        <tr id="The task of sampling from a probability density can be approached as transporting a tractable density function to the target, known as dynamical measure transport. In this work, we tackle it through a principled unified framework using deterministic or stochastic evolutions described by partial differential equations (PDEs). This framework incorporates prior trajectory-based sampling methods, such as diffusion models or Schr\"odinger bridges, without relying on the concept of time-reversals. Moreover, it allows us to propose novel numerical methods for solving the transport task and thus sampling from complicated targets without the need for the normalization constant or data samples. We employ physics-informed neural networks (PINNs) to approximate the respective PDE solutions, implying both conceptional and computational advantages. In particular, PINNs allow for simulation- and discretization-free optimization and can be trained very efficiently, leading to significantly better mode coverage in the sampling task compared to alternative methods. Moreover, they can readily be fine-tuned with Gauss-Newton methods to achieve high accuracy in sampling.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/be6b71f84d3c641029effa69aa23e0c32eb9de03" target='_blank'>
              Dynamical Measure Transport and Neural PDE Solvers for Sampling
              </a>
            </td>
          <td>
            Jingtong Sun, Julius Berner, Lorenz Richter, Marius Zeinhofer, Johannes Muller, K. Azizzadenesheli, A. Anandkumar
          </td>
          <td>2024-07-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>31</td>
        </tr>

        <tr id="The advent of machine learning has led to innovative approaches in dealing with clinical data. Among these, Neural Ordinary Differential Equations (Neural ODEs), hybrid models merging mechanistic with deep learning models have shown promise in accurately modeling continuous dynamical systems. Although initial applications of Neural ODEs in the field of model-informed drug development and clinical pharmacology are becoming evident, applying these models to actual clinical trial datasets-characterized by sparse and irregularly timed measurements-poses several challenges. Traditional models often have limitations with sparse data, highlighting the urgent need to address this issue, potentially through the use of assumptions. This review examines the fundamentals of Neural ODEs, their ability to handle sparse and irregular data, and their applications in model-informed drug development.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d55a1a4acc93d905399f2126e7beb524fd64ec38" target='_blank'>
              Bridging pharmacology and neural networks: A deep dive into neural ordinary differential equations.
              </a>
            </td>
          <td>
            Idris Bachali Losada, N. Terranova
          </td>
          <td>2024-07-11</td>
          <td>CPT: pharmacometrics & systems pharmacology</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="In the context of traditional reduced order modeling methods (ROMs), time and parameter extrapolation tasks remain a formidable challenge. To this end, we propose a hybrid projection/data-driven framework that leverages two subspaces to improve the prediction accuracy of traditional ROMs. We first obtain inaccurate mode coefficients from traditional ROMs in the reduced order subspace. Then, in the prior dimensionality reduced subspace, we correct the inaccurate mode coefficients and restore the discarded mode coefficients through neural network. Finally, we approximate the solutions with these mode coefficients in the prior dimensionality reduced subspace. To reduce the computational cost during the offline training stage, we propose a training data sampling strategy based on dynamic mode decomposition (DMD). The effectiveness of the proposed method is investigated with the parameterized Navier–Stokes equations in stream-vorticity formulation. In addition, two additional time extrapolation methods based on DMD are also proposed and compared.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/09b007cd20e11f8bc8ad01998bb169399cd7e181" target='_blank'>
              A new hybrid reduced order modeling for parametrized Navier–Stokes equations in stream-vorticity formulation
              </a>
            </td>
          <td>
            Tao Zhang, Hui Xu, Lei Guo, Xinlong Feng
          </td>
          <td>2024-06-01</td>
          <td>Physics of Fluids</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="The research topic is: data-driven Bayesian state estimation with compressed measurement (BSCM) of model-free process, say for a (causal) tracking application. The dimension of the temporal measurement vector is lower than the dimension of the temporal state vector to be estimated. Hence the state estimation problem is an underdetermined inverse problem. The state-space-model (SSM) of the underlying dynamical process is assumed to be unknown and hence, we use the terminology 'model-free process'. In absence of the SSM, we can not employ traditional model-driven methods like Kalman Filter (KF) and Particle Filter (PF) and instead require data-driven methods. We first experimentally show that two existing unsupervised learning-based data-driven methods fail to address the BSCM problem for model-free process; they are data-driven nonlinear state estimation (DANSE) method and deep Markov model (DMM) method. The unsupervised learning uses unlabelled data comprised of only noisy measurements. While DANSE provides a good predictive performance to model the temporal measurement data as time-series, its unsupervised learning lacks a regularization for state estimation. We then investigate use of a semi-supervised learning approach, and develop a semi-supervised learning-based DANSE method, referred to as SemiDANSE. In the semi-supervised learning, we use a limited amount of labelled data along-with a large amount of unlabelled data, and that helps to bring the desired regularization for BSCM problem in the absence of SSM. The labelled data means pairwise measurement-and-state data. Using three chaotic dynamical systems (or processes) with nonlinear SSMs as benchmark, we show that the data-driven SemiDANSE provides competitive performance for BSCM against three SSM-informed methods - a hybrid method called KalmanNet, and two traditional model-driven methods called extended KF and unscented KF.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f2671168e70fb8ea79bbef366bd1d59fc9ae9415" target='_blank'>
              Data-driven Bayesian State Estimation with Compressed Measurement of Model-free Process using Semi-supervised Learning
              </a>
            </td>
          <td>
            Anubhab Ghosh, Y. Eldar, Saikat Chatterjee
          </td>
          <td>2024-07-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>26</td>
        </tr>

        <tr id="Physics-Informed Neural Networks (PINNs) have emerged as a robust framework for solving Partial Differential Equations (PDEs) by approximating their solutions via neural networks and imposing physics-based constraints on the loss function. Traditionally, Multilayer Perceptrons (MLPs) are the neural network of choice, and significant progress has been made in optimizing their training. Recently, Kolmogorov-Arnold Networks (KANs) were introduced as a viable alternative, with the potential of offering better interpretability and efficiency while requiring fewer parameters. In this paper, we present a fast JAX-based implementation of grid-dependent Physics-Informed Kolmogorov-Arnold Networks (PIKANs) for solving PDEs. We propose an adaptive training scheme for PIKANs, incorporating known MLP-based PINN techniques, introducing an adaptive state transition scheme to avoid loss function peaks between grid updates, and proposing a methodology for designing PIKANs with alternative basis functions. Through comparative experiments we demonstrate that these adaptive features significantly enhance training efficiency and solution accuracy. Our results illustrate the effectiveness of PIKANs in improving performance for PDE solutions, highlighting their potential as a superior alternative in scientific and engineering applications.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c1aaa25c69658448f0abd4e2430cf6925f39fdd5" target='_blank'>
              Adaptive Training of Grid-Dependent Physics-Informed Kolmogorov-Arnold Networks
              </a>
            </td>
          <td>
            Spyros Rigas, M. Papachristou, Theofilos Papadopoulos, Fotios Anagnostopoulos, Georgios Alexandridis
          </td>
          <td>2024-07-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="We introduce data to predictive control, D2PC, a framework to facilitate the design of robust and predictive controllers from data. The proposed framework is designed for discrete-time stochastic linear systems with output measurements and provides a principled design of a predictive controller based on data. The framework starts with a parameter identification method based on the Expectation-Maximization algorithm, which incorporates pre-defined structural constraints. Additionally, we provide an asymptotically correct method to quantify uncertainty in parameter estimates. Next, we develop a strategy to synthesize robust dynamic output-feedback controllers tailored to the derived uncertainty characterization. Finally, we introduce a predictive control scheme that guarantees recursive feasibility and satisfaction of chance constraints. This framework marks a significant advancement in integrating data into robust and predictive control schemes. We demonstrate the efficacy of D2PC through a numerical example involving a $10$-dimensional spring-mass-damper system.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2ea52a361e1eddc6fae9770357307a43f124b006" target='_blank'>
              From Data to Predictive Control: A Framework for Stochastic Linear Systems with Output Measurements
              </a>
            </td>
          <td>
            Haldun Balim, Andrea Carron, M. Zeilinger, Johannes Kohler
          </td>
          <td>2024-07-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>35</td>
        </tr>

        <tr id="We consider the problem of optimizing initial conditions and timing in dynamical systems governed by unknown ordinary differential equations (ODEs), where evaluating different initial conditions is costly and there are constraints on observation times. To identify the optimal conditions within several trials, we introduce a few-shot Bayesian Optimization (BO) framework based on the system's prior information. At the core of our approach is the System-Aware Neural ODE Processes (SANODEP), an extension of Neural ODE Processes (NODEP) designed to meta-learn ODE systems from multiple trajectories using a novel context embedding block. Additionally, we propose a multi-scenario loss function specifically for optimization purposes. Our two-stage BO framework effectively incorporates search space constraints, enabling efficient optimization of both initial conditions and observation timings. We conduct extensive experiments showcasing SANODEP's potential for few-shot BO. We also explore SANODEP's adaptability to varying levels of prior information, highlighting the trade-off between prior flexibility and model fitting accuracy.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/fcc3aee3d63369b46495f52c938226e7f6a37977" target='_blank'>
              System-Aware Neural ODE Processes for Few-Shot Bayesian Optimization
              </a>
            </td>
          <td>
            Jixiang Qing, Becky D Langdon, Robert M. Lee, B. Shafei, Mark van der Wilk, Calvin Tsay, Ruth Misener
          </td>
          <td>2024-06-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>22</td>
        </tr>

        <tr id="We study the model reduction by moment matching problem for linear systems in a data-driven framework. We show that reduced-order models can be directly computed from data without knowledge of the structure of the signal generator or of its internal state. The reduced-order models thus obtained match the moments of the unknown underlying system asymptotically. Our construction provides a simple way to enforce additional constraints in the reduced-order model. We demonstrate the applicability of the results using data from a high-dimensional model of a building.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/83399652779edc533b785a20de6431d8d0060e66" target='_blank'>
              Data-Driven Model Reduction by Moment Matching for Linear Systems Driven by an Unknown Implicit Signal Generator
              </a>
            </td>
          <td>
            Debraj Bhattacharjee, Alessandro Astolfi
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="AI for partial differential equations (PDEs) has garnered significant attention, particularly with the emergence of Physics-informed neural networks (PINNs). The recent advent of Kolmogorov-Arnold Network (KAN) indicates that there is potential to revisit and enhance the previously MLP-based PINNs. Compared to MLPs, KANs offer interpretability and require fewer parameters. PDEs can be described in various forms, such as strong form, energy form, and inverse form. While mathematically equivalent, these forms are not computationally equivalent, making the exploration of different PDE formulations significant in computational physics. Thus, we propose different PDE forms based on KAN instead of MLP, termed Kolmogorov-Arnold-Informed Neural Network (KINN). We systematically compare MLP and KAN in various numerical examples of PDEs, including multi-scale, singularity, stress concentration, nonlinear hyperelasticity, heterogeneous, and complex geometry problems. Our results demonstrate that KINN significantly outperforms MLP in terms of accuracy and convergence speed for numerous PDEs in computational solid mechanics, except for the complex geometry problem. This highlights KINN's potential for more efficient and accurate PDE solutions in AI for PDEs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1aa27d5cd7dc99860324bb6f0eacb96de0d9e57b" target='_blank'>
              Kolmogorov Arnold Informed neural network: A physics-informed deep learning framework for solving PDEs based on Kolmogorov Arnold Networks
              </a>
            </td>
          <td>
            Yizheng Wang, Jia Sun, Jinshuai Bai, C. Anitescu, M. Eshaghi, X. Zhuang, T. Rabczuk, Yinghua Liu
          </td>
          <td>2024-06-16</td>
          <td>ArXiv</td>
          <td>7</td>
          <td>69</td>
        </tr>

        <tr id="Generally, discretization of partial differential equations (PDEs) creates a sequence of linear systems $A_k x_k = b_k, k = 0, 1, 2, ..., N$ with well-known and structured sparsity patterns. Preconditioners are often necessary to achieve fast convergence When solving these linear systems using iterative solvers. We can use preconditioner updates for closely related systems instead of computing a preconditioner for each system from scratch. One such preconditioner update is the sparse approximate map (SAM), which is based on the sparse approximate inverse preconditioner using a least squares approximation. A SAM then acts as a map from one matrix in the sequence to another nearby one for which we have an effective preconditioner. To efficiently compute an effective SAM update (i.e., one that facilitates fast convergence of the iterative solver), we seek to compute an optimal sparsity pattern. In this paper, we examine several sparsity patterns for computing the SAM update to characterize optimal or near-optimal sparsity patterns for linear systems arising from discretized PDEs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/59d72a8c8b408e0eac4977fbc8730eb55a568d80" target='_blank'>
              Optimization of Approximate Maps for Linear Systems Arising in Discretized PDEs
              </a>
            </td>
          <td>
            Rishad Islam, Arielle Carr, Colin Jacobs
          </td>
          <td>2024-06-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Using equilibrium fluctuations to understand the response of a physical system to an externally imposed perturbation is the basis for linear response theory, which is widely used to interpret experiments and shed light on microscopic dynamics. For nonequilibrium systems, perturbations cannot be interpreted simply by monitoring fluctuations in a conjugate observable -- additional dynamical information is needed. The theory of linear response around nonequilibrium steady states relies on path ensemble averaging, which makes this theory inapplicable to perturbations that affect the diffusion constant or temperature in a stochastic system. Here, we show that a separate, ``effective'' physical process can be used to describe the perturbed dynamics and that this dynamics in turn allows us to accurately calculate the response to a change in the diffusion. Interestingly, the effective dynamics contains an additional drift that is proportional to the ``score'' of the instantaneous probability density of the system -- this object has also been studied extensively in recent years in the context of denoising diffusion models in the machine learning literature. Exploiting recently developed algorithms for learning the score, we show that we can carry out nonequilibrium response calculations on systems for which the exact score cannot be obtained.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f45af9914ab526c24b8c0bd202775dddc280a5c4" target='_blank'>
              Computing Nonequilibrium Responses with Score-shifted Stochastic Differential Equations
              </a>
            </td>
          <td>
            J'er'emie Klinger, Grant M. Rotskoff
          </td>
          <td>2024-06-20</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>24</td>
        </tr>

        <tr id="We apply two data assimilation (DA) methods, a smoother and a filter, and a model-free machine learning (ML) shallow network to forecast two weakly turbulent systems. We analyse the effect of the spatial sparsity of observations on accuracy of the predictions obtained from these data-driven methods. Based on the results, we divide the spatial sparsity levels in three zones. First is the good-predictions zone in which both DA and ML methods work. We find that in the good-predictions zone the observations remain dense enough to accurately capture the fractal manifold of the system's dynamics, which is measured using the correlation dimension. The accuracy of the DA methods in this zone remains almost as good as for full-resolution observations. Second is the reasonable-predictions zone in which the DA methods still work but at reduced prediction accuracy. Third is the bad-predictions zone in which even the DA methods fail. We find that the sparsity level up to which the DA methods work is almost the same up to which chaos synchronisation of these systems can be achieved. The main implications of these results are that they (i) firmly establish the spatial resolution up to which the data-driven methods can be utilised, (ii) provide measures to determine if adding more sensors will improve the predictions, and (iii) quantify the advantage (in terms of the required measurement resolution) of using the governing equations within data-driven methods. We also discuss the applicability of these results to fully developed turbulence.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f37955fcf738b892c9cedb2952e279d466fad9b8" target='_blank'>
              Predictability of weakly turbulent systems from spatially sparse observations using data assimilation and machine learning
              </a>
            </td>
          <td>
            Vikrant Gupta, Yuanqing Chen, Minping Wan
          </td>
          <td>2024-07-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Time-fractional differential equations offer a robust framework for capturing intricate phenomena characterized by memory effects, particularly in fields like biotransport and rheology. However, solving inverse problems involving fractional derivatives presents notable challenges, including issues related to stability and uniqueness. While Physics-Informed Neural Networks (PINNs) have emerged as effective tools for solving inverse problems, most existing PINN frameworks primarily focus on integer-ordered derivatives. In this study, we extend the application of PINNs to address inverse problems involving time-fractional derivatives, specifically targeting two problems: 1) anomalous diffusion and 2) fractional viscoelastic constitutive equation. Leveraging both numerically generated datasets and experimental data, we calibrate the concentration-dependent generalized diffusion coefficient and parameters for the fractional Maxwell model. We devise a tailored residual loss function that scales with the standard deviation of observed data. We rigorously test our framework's efficacy in handling anomalous diffusion. Even after introducing 25% Gaussian noise to the concentration dataset, our framework demonstrates remarkable robustness. Notably, the relative error in predicting the generalized diffusion coefficient and the order of the fractional derivative is less than 10% for all cases, underscoring the resilience and accuracy of our approach. In another test case, we predict relaxation moduli for three pig tissue samples, consistently achieving relative errors below 10%. Furthermore, our framework exhibits promise in modeling anomalous diffusion and non-linear fractional viscoelasticity.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/031362230099634ba2b74997a05c18cfaa22860e" target='_blank'>
              Physics-Informed Neural Network based inverse framework for time-fractional differential equations for rheology
              </a>
            </td>
          <td>
            Sukirt Thakur, H. Mitra, A. Ardekani
          </td>
          <td>2024-06-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Transition path theory (TPT) offers a powerful formalism for extracting the rate and mechanism of rare dynamical transitions between metastable states. Most applications of TPT either focus on systems with modestly sized state spaces or use collective variables to try to tame the curse of dimensionality. Increasingly, expressive function approximators like neural networks and tensor networks have shown promise in computing the central object of TPT, the committor function, even in very high dimensional systems. That progress prompts our consideration of how one could use such a high dimensional function to extract mechanistic insight. Here, we present and illustrate a straightforward but powerful way to track how individual dynamical coordinates evolve during a reactive event. The strategy, which involves marginalizing the reactive ensemble, naturally captures the evolution of the dynamical coordinate's distribution, not just its mean reactive behavior.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7865e0e14652cd5e6197f84e71fe9d692fb99d9c" target='_blank'>
              From high-dimensional committors to reactive insights
              </a>
            </td>
          <td>
            Nils E. Strand, Schuyler B. Nicholson, Hadrien Vroylandt, Todd R. Gingrich
          </td>
          <td>2024-06-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="We investigate learning the eigenfunctions of evolution operators for time-reversal invariant stochastic processes, a prime example being the Langevin equation used in molecular dynamics. Many physical or chemical processes described by this equation involve transitions between metastable states separated by high potential barriers that can hardly be crossed during a simulation. To overcome this bottleneck, data are collected via biased simulations that explore the state space more rapidly. We propose a framework for learning from biased simulations rooted in the infinitesimal generator of the process and the associated resolvent operator. We contrast our approach to more common ones based on the transfer operator, showing that it can provably learn the spectral properties of the unbiased system from biased data. In experiments, we highlight the advantages of our method over transfer operator approaches and recent developments based on generator learning, demonstrating its effectiveness in estimating eigenfunctions and eigenvalues. Importantly, we show that even with datasets containing only a few relevant transitions due to sub-optimal biasing, our approach recovers relevant information about the transition mechanism.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/33ff38eef166593508576694dab15cbdbd79cb82" target='_blank'>
              From Biased to Unbiased Dynamics: An Infinitesimal Generator Approach
              </a>
            </td>
          <td>
            Timothée Devergne, Vladimir Kostic, Michele Parrinello, Massimiliano Pontil
          </td>
          <td>2024-06-13</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Recently, machine learning potentials (MLP) largely enhances the reliability of molecular dynamics, but its accuracy is limited by the underlying $\textit{ab initio}$ methods. A viable approach to overcome this limitation is to refine the potential by learning from experimental data, which now can be done efficiently using modern automatic differentiation technique. However, potential refinement is mostly performed using thermodynamic properties, leaving the most accessible and informative dynamical data (like spectroscopy) unexploited. In this work, through a comprehensive application of adjoint and gradient truncation methods, we show that both memory and gradient explosion issues can be circumvented in many situations, so the dynamical property differentiation is well-behaved. Consequently, both transport coefficients and spectroscopic data can be used to improve the density functional theory based MLP towards higher accuracy. Essentially, this work contributes to the solution of the inverse problem of spectroscopy by extracting microscopic interactions from vibrational spectroscopic data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b907da66c5c83725b4a28f0615aa0dec6d876592" target='_blank'>
              Refining Potential Energy Surface through Dynamical Properties via Differentiable Molecular Simulation
              </a>
            </td>
          <td>
            Bin Han, Kuang Yu
          </td>
          <td>2024-06-26</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Turbulent diffusion causes particles placed in proximity to separate. We investigate the required swimming efforts to maintain a particle close to its passively advected counterpart. We explore optimally balancing these efforts with the intended goal by developing and comparing a novel Physics-Informed Reinforcement Learning (PIRL) strategy with prescribed control (PC) and standard physics-agnostic Reinforcement Learning strategies. Our PIRL scheme, coined the Actor-Physicist, is an adaptation of the Actor-Critic algorithm in which the Neural Network parameterized Critic is replaced with an analytically derived physical heuristic function (the physicist). This strategy is then compared with an analytically computed optimal PC policy derived from a stochastic optimal control formulation and standard physics-agnostic Actor-Critic type algorithms.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/48afca8d5a93e95e02d050121877781421eff9ad" target='_blank'>
              Physics-Informed Critic in an Actor-Critic Reinforcement Learning for Swimming in Turbulence
              </a>
            </td>
          <td>
            Christopher Koh, Laurent Pagnier, Michael Chertkov
          </td>
          <td>2024-06-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="The practical implementation of Model Predictive Control (MPC) often presents challenges that remain unaddressed in theoretical formulations. Among these challenges, the tuning of the receding horizon cost becomes particularly intricate in the context of data-driven learning-based MPC, where models exhibit partial uncertainty. This paper introduces SelfMPC, a pioneering approach within a Gaussian process learning framework, illustrating that a tracking MPC cost can be formulated as the maximum likelihood estimation of the reference output. This formulation provides automatic cost shaping and effective regularization, eliminating the need for manual tuning efforts. Moreover, the proposed formulation provides a natural way to employ information from empirical experiments into the definition of the MPC optimization problem for unknown systems. Empirical validation against conventional weighting matrix selection methods confirms the effectiveness of the proposed approach.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c8c1ab1e1df61c9f0ff1b2b30de0895627bf4240" target='_blank'>
              Automated Data-Driven Tuning of Learning-Based Model Predictive Control (SelfMPC): A Maximum-Likelihood Approach
              </a>
            </td>
          <td>
            Guitao Yang, Matteo Scandella, Simone Formentin, Thomas Parisini
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="Neural simulators for modeling complex dynamical systems have been extensively studied for various real-world applications, such as weather forecasting, ocean current prediction, and computational fluid dynamics simulation. Although they have demonstrated powerful fitting and predicting, most existing models are only built to learn single-system dynamics. Several advanced researches have considered learning dynamics across environments, which can exploit the potential commonalities among the dynamics across environments and adapt to new environments. However, these methods still are prone to scarcity problems where per-environment data is sparse or limited. Therefore, we propose a novel CoNDP (Context-Informed Neural ODE Processes) to achieve learning system dynamics from sparse observations across environments. It can fully use contextual information of each environment to better capture the intrinsic commonalities across environments and distinguishable differences among environments while modeling uncertainty of system evolution, producing more accurate predictions. Intensive experiments are conducted on five complex dynamical systems in various fields. Results show that the proposed CoNDP can achieve optimal results compared with common neural simulators and state-of-the-art cross-environmental models.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/40337006a651c2110229b8ae928a5d5fe9a01da1" target='_blank'>
              Stochastic Neural Simulator for Generalizing Dynamical Systems across Environments
              </a>
            </td>
          <td>
            Liu Jiaqi, Jiaxu Cui, Jiayi Yang, Bo Yang
          </td>
          <td>2024-08-01</td>
          <td>Proceedings of the Thirty-ThirdInternational Joint Conference on Artificial Intelligence</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="High-precision control for nonlinear systems is impeded by the low-fidelity dynamical model and external disturbance. Especially, the intricate coupling between internal uncertainty and external disturbance is usually difficult to be modeled explicitly. Here we show an effective and convergent algorithm enabling accurate estimation of the coupled disturbance via combining control and learning philosophies. Specifically, by resorting to Chebyshev series expansion, the coupled disturbance is firstly decomposed into an unknown parameter matrix and two known structures depending on system state and external disturbance respectively. A Regularized Least Squares (RLS) algorithm is subsequently formalized to learn the parameter matrix by using historical time-series data. Finally, a higher-order disturbance observer (HODO) is developed to achieve a high-precision estimation of the coupled disturbance by utilizing the learned portion. The efficiency of the proposed algorithm is evaluated through extensive simulations. We believe this work can offer a new option to merge learning schemes into the control framework for addressing existing intractable control problems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2c2b582f6ad335402a40cb9dffeaea1baf4781dd" target='_blank'>
              Disturbance Observer for Estimating Coupled Disturbances
              </a>
            </td>
          <td>
            Jindou Jia, Yuhang Liu, Kexin Guo, Xiang Yu, Lihua Xie, Lei Guo
          </td>
          <td>2024-07-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>16</td>
        </tr>

        <tr id="We study the problem of estimating the states of a linear system based on measured data. We investigate the problem in both deterministic and stochastic settings. In the deterministic case, we develop data-driven conditions under which we can reconstruct state trajectories uniquely. Also, we discuss the case in which we have some missing data in the given input/output measurements. In the stochastic case, we develop a Kalman filter-like algorithm to recursively estimate both states and outputs. Finally, we consider a multi-input multi-output system to elucidate the developed results.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/344c27f38393d70906627a195cc65ea2636e5a14" target='_blank'>
              Data-Driven State Estimation for Linear Systems
              </a>
            </td>
          <td>
            Vikas Kumar Mishra, S. Hiremath, N. Bajçinca
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>15</td>
        </tr>

        <tr id="Macroscopic features of dynamical systems such as almost-invariant sets and coherent sets provide crucial high-level information on how the dynamics organises phase space. We introduce a method to identify time-parameterised families of almost-invariant sets in time-dependent dynamical systems, as well as the families' emergence and disappearance. In contrast to coherent sets, which may freely move about in phase space over time, our technique focuses on families of metastable sets that are quasi-stationary in space. Our straightforward approach extends successful transfer operator methods for almost-invariant sets to time-dependent dynamics and utilises the Ulam scheme for the generator of the transfer operator on a time-expanded domain. The new methodology is illustrated with an idealised fluid flow and with atmospheric velocity data. We identify atmospheric blocking events in the 2003 European heatwave and compare our technique to existing geophysical methods of blocking diagnosis.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/85cdef684e76e594fd24e0e2863fe622d0a8314d" target='_blank'>
              Identifying the onset and decay of quasi-stationary families of almost-invariant sets with an application to atmospheric blocking events
              </a>
            </td>
          <td>
            Aleksandar Badza, Gary Froyland School of Mathematics, Statistics Unsw Sydney Nsw Australia
          </td>
          <td>2024-07-09</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Filtering-the task of estimating the conditional distribution of states of a dynamical system given partial, noisy, observations-is important in many areas of science and engineering, including weather and climate prediction. However, the filtering distribution is generally intractable to obtain for high-dimensional, nonlinear systems. Filters used in practice, such as the ensemble Kalman filter (EnKF), are biased for nonlinear systems and have numerous tuning parameters. Here, we present a framework for learning a parameterized analysis map-the map that takes a forecast distribution and observations to the filtering distribution-using variational inference. We show that this methodology can be used to learn gain matrices for filtering linear and nonlinear dynamical systems, as well as inflation and localization parameters for an EnKF. Future work will apply this framework to learn new filtering algorithms.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0caedb45ee3429ec36e56edd056c7ae412f7b6b8" target='_blank'>
              Learning Optimal Filters Using Variational Inference
              </a>
            </td>
          <td>
            Enoch Luk, Eviatar Bach, Ricardo Baptista, Andrew Stuart
          </td>
          <td>2024-06-26</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id="One of the core concepts in science, and something that happens intuitively in every-day dynamic systems modeling, is the combination of models or methods. Especially in dynamical systems modeling, often two or more structures are combined to obtain a more powerful or efficient architecture regarding a specific application (area). Further, even physical simulations are combined with machine learning architectures, to increase prediction accuracy or optimize the computational performance. In this work, we shortly discuss, which types of models are usually combined and propose a model interface that is capable of expressing a width variety of mixed algebraic, discrete and differential equation based models. Further, we examine different established, as well as new ways of combining these models from a system theoretical point of view and highlight two challenges - algebraic loops and local event affect functions in discontinuous models - that require a special approach. Finally, we propose a new wildcard topology, that is capable of describing the generic connection between two combined models in an easy to interpret fashion that can be learned as part of a gradient based optimization procedure. The contributions of this paper are highlighted at a proof of concept: Different connection topologies between two models are learned, interpreted and compared applying the proposed methodology and software implementation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/fe81ab9d1a688154b1e40c6ca68ccf95c122d0c7" target='_blank'>
              Learnable & Interpretable Model Combination in Dynamic Systems Modeling
              </a>
            </td>
          <td>
            Tobias Thummerer, Lars Mikelsons
          </td>
          <td>2024-06-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>11</td>
        </tr>

        <tr id="A data-driven approach to calculating tight-binding models for discrete coupled-mode systems is presented. Specifically, spectral and topological data is used to build an appropriate discrete model that accurately replicates these properties. This work is motivated by topological insulator systems that are often described by tight-binding models. The problem is formulated as the minimization of an appropriate residual (objective) function. Given bulk spectral data and a topological index (e.g. winding number), an appropriate discrete model is obtained to arbitrary precision. A nonlinear least squares method is used to determine the coefficients. The effectiveness of the scheme is highlighted against a Schr\"odinger equation with a periodic potential that can be described by the Su-Schrieffer-Heeger model.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b260d38c46caaea8a67dc40a10c56986fd078985" target='_blank'>
              Data-driven approximations of topological insulator systems
              </a>
            </td>
          <td>
            Justin T. Cole, Michael J. Nameika
          </td>
          <td>2024-07-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Although neural operator networks theoretically approximate any operator mapping, the limited generalization capability prevents them from learning correct physical dynamics when potential data biases exist, particularly in the practical PDE solving scenario where the available data amount is restricted or the resolution is extremely low. To address this issue, we propose and formulate the Physical Trajectory Residual Learning (DeltaPhi), which learns to predict the physical residuals between the pending solved trajectory and a known similar auxiliary trajectory. First, we transform the direct operator mapping between input-output function fields in original training data to residual operator mapping between input function pairs and output function residuals. Next, we learn the surrogate model for the residual operator mapping based on existing neural operator networks. Additionally, we design helpful customized auxiliary inputs for efficient optimization. Through extensive experiments, we conclude that, compared to direct learning, physical residual learning is preferred for PDE solving.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/75ea87f76067c9b62442cad18c16c45c61d35489" target='_blank'>
              DeltaPhi: Learning Physical Trajectory Residual for PDE Solving
              </a>
            </td>
          <td>
            Xihang Yue, Linchao Zhu, Yi Yang
          </td>
          <td>2024-06-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>41</td>
        </tr>

        <tr id="
Fusing known physics into data-driven learners allows modelling practitioners to combine the expressive power of traditional machine learning with known mechanistic laws, where the objective is to enhance predictive performance, interpretability, and model generalisation. A core consideration that must be made when implementing a physics-informed learning architecture is how relevant knowledge will be embedded into the model structure, which, generally, is informed by the type of physics that is available. Frequently this knowledge may not be complete, with only a partial understanding of the governing physics available. 

In this work, possible paths for deriving Gaussian process kernels that are representative of partial knowledge will be considered. How the type of knowledge that is possessed influences the derivation will be explored, particularly when there is the potential for some aspect of misspecified physics. An example of deriving partially structured kernels will be investigated for modelling the decoupled response of a GARTEUR laboratory aircraft structure, where the derived kernels are used to decompose the dynamics of the aircraft into modal contributions. 

">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/da9bbf07470b8cc6d6606c4b51a040b8e45ce3d6" target='_blank'>
              Gaussian process kernels for partial physical insight
              </a>
            </td>
          <td>
            Matthew R. Jones, D. J. Pitchforth, E. J. Cross
          </td>
          <td>2024-07-01</td>
          <td>e-Journal of Nondestructive Testing</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="In recent decades, the utilization of machine learning (ML) and artificial intelligence (AI) approaches have been explored for process modelling applications. However, different types of ML models may have contrasting advantages and disadvantages, which become critical during the optimal selection of a specific data‐driven model for a particular application as well as estimation of parameters during model training. This paper compares and contrasts two different types of data‐driven modelling approaches, namely the series/parallel all‐nonlinear static‐dynamic neural network models and models from a Bayesian ML approach. Both types of AI modelling approaches considered in this work have shown to significantly outperform several state‐of‐the‐art steady‐state and dynamic data‐driven modelling techniques for various performance measures, specifically, model sparsity, predictive capabilities, and computational expense. The performances of the proposed model structures and algorithms have been evaluated for two nonlinear dynamic chemical engineering systems—a plug‐flow reactor for vapour phase cracking of acetone for production of acetic anhydride and a pilot‐plant for post‐combustion CO2 capture using monoethanolamine as the solvent. For the validation data from the CO2 capture pilot plant, root mean squared error (RMSE) for flue gas outlet temperature, flowrate and CO2 concentration is 0.05%, 1.07%, and 5.0%, respectively, for the all‐nonlinear static‐dynamic neural networks and 0.1%, 1.75%, and 14.14%, respectively, for the Bayesian ML models. For the plug flow reactor data, the Bayesian ML models yield superior RMSE compared to the all‐nonlinear static‐dynamic neural networks when the measurement data are corrupted with Gaussian, auto‐correlated, or cross‐correlated noise.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/056ceb214531414b85db491a54767e185fb5c38a" target='_blank'>
              All‐nonlinear static‐dynamic neural networks versus Bayesian machine learning for data‐driven modelling of chemical processes
              </a>
            </td>
          <td>
            Angan Mukherjee, Samuel Adeyemo, D. Bhattacharyya
          </td>
          <td>2024-06-24</td>
          <td>The Canadian Journal of Chemical Engineering</td>
          <td>0</td>
          <td>29</td>
        </tr>

        <tr id="The paper presents a framework for online learning of the Koopman operator using streaming data. Many complex systems for which data-driven modeling and control are sought provide streaming sensor data, the abundance of which can present computational challenges but cannot be ignored. Streaming data can intermittently sample dynamically different regimes or rare events which could be critical to model and control. Using ideas from subspace identification, we present a method where the Grassmannian distance between the subspace of an extended observability matrix and the streaming segment of data is used to assess the `novelty' of the data. If this distance is above a threshold, it is added to an archive and the Koopman operator is updated if not it is discarded. Therefore, our method identifies data from segments of trajectories of a dynamical system that are from different dynamical regimes, prioritizes minimizing the amount of data needed in updating the Koopman model and furthermore reduces the number of basis functions by learning them adaptively. Therefore, by dynamically adjusting the amount of data used and learning basis functions, our method optimizes the model's accuracy and the system order.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a7ee04d648defa5ecd02e1e1b2368c710c5df6c2" target='_blank'>
              Online learning of Koopman operator using streaming data from different dynamical regimes
              </a>
            </td>
          <td>
            Kartik Loya, Phanindra Tallapragada
          </td>
          <td>2024-07-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>16</td>
        </tr>

        <tr id="Neural networks are lately more and more often being used in the context of data-driven control, as an approximate model of the true system dynamics. Model Predictive Control (MPC) adopts this practise leading to neural MPC strategies. This raises a question of whether the trained neural network has converged and generalized in a way that the learned model encapsulates an accurate approximation of the true dynamic model of the system, thus making it a reliable choice for model-based control, especially for disturbed and uncertain systems. To tackle that, we propose Dropout MPC, a novel sampling-based ensemble neural MPC algorithm that employs the Monte-Carlo dropout technique on the learned system model. The closed loop is based on an ensemble of predictive controllers, that are used simultaneously at each time-step for trajectory optimization. Each member of the ensemble influences the control input, based on a weighted voting scheme, thus by employing different realizations of the learned system dynamics, neural control becomes more reliable by design. An additional strength of the method is that it offers by design a way to estimate future uncertainty, leading to cautious control. While the method aims in general at uncertain systems with complex dynamics, where models derived from first principles are hard to infer, to showcase the application we utilize data gathered in the laboratory from a real mobile manipulator and employ the proposed algorithm for the navigation of the robot in simulation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ffb5110c1249088154b163fffe6b0fa9097287fd" target='_blank'>
              Dropout MPC: An Ensemble Neural MPC Approach for Systems with Learned Dynamics
              </a>
            </td>
          <td>
            Spyridon Syntakas, K. Vlachos
          </td>
          <td>2024-06-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Learning dynamical systems from sparse observations is critical in numerous fields, including biology, finance, and physics. Even if tackling such problems is standard in general information fusion, it remains challenging for contemporary machine learning models, such as diffusion models. We introduce a method that integrates conditional particle filtering with ancestral sampling and diffusion models, enabling the generation of realistic trajectories that align with observed data. Our approach uses a smoother based on iterating a conditional particle filter with ancestral sampling to first generate plausible trajectories matching observed marginals, and learns the corresponding diffusion model. This approach provides both a generative method for high-quality, smoothed trajectories under complex constraints, and an efficient approximation of the particle smoothing distribution for classical tracking problems. We demonstrate the approach in time-series generation and interpolation tasks, including vehicle tracking and single-cell RNA sequencing data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/259c6de89cac71f6f0a9faf860c8cdb8339a4240" target='_blank'>
              Learning to Approximate Particle Smoothing Trajectories via Diffusion Generative Models
              </a>
            </td>
          <td>
            Ella Tamir, Arno Solin
          </td>
          <td>2024-06-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Sampling-based kinodynamic motion planners (SKMPs) are powerful in finding collision-free trajectories for high-dimensional systems under differential constraints. Time-informed set (TIS) can provide the heuristic search domain to accelerate their convergence to the time-optimal solution. However, existing TIS approximation methods suffer from the curse of dimensionality, computational burden, and limited system applicable scope, e.g., linear and polynomial nonlinear systems. To overcome these problems, we propose a method by leveraging deep learning technology, Koopman operator theory, and random set theory. Specifically, we propose a Deep Invertible Koopman operator with control U model named DIKU to predict states forward and backward over a long horizon by modifying the auxiliary network with an invertible neural network. A sampling-based approach, ASKU, performing reachability analysis for the DIKU is developed to approximate the TIS of nonlinear control systems online. Furthermore, we design an online time-informed SKMP using a direct sampling technique to draw uniform random samples in the TIS. Simulation experiment results demonstrate that our method outperforms other existing works, approximating TIS in near real-time and achieving superior planning performance in several time-optimal kinodynamic motion planning problems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/47eec5e6ac343847f3ccf8a58bf04f8fa124b137" target='_blank'>
              Online Time-Informed Kinodynamic Motion Planning of Nonlinear Systems
              </a>
            </td>
          <td>
            Fei Meng, Jianbang Liu, Hao-bin Shi, Han Ma, Hongliang Ren, Max Q.-H. Meng
          </td>
          <td>2024-07-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>13</td>
        </tr>

        <tr id="We introduce a method that combines neural operators, physics-informed machine learning, and standard numerical methods for solving PDEs. The proposed approach extends each of the aforementioned methods and unifies them within a single framework. We can parametrically solve partial differential equations in a data-free manner and provide accurate sensitivities, meaning the derivatives of the solution space with respect to the design space. These capabilities enable gradient-based optimization without the typical sensitivity analysis costs, unlike adjoint methods that scale directly with the number of response functions. Our Finite Operator Learning (FOL) approach uses an uncomplicated feed-forward neural network model to directly map the discrete design space (i.e. parametric input space) to the discrete solution space (i.e. finite number of sensor points in the arbitrary shape domain) ensuring compliance with physical laws by designing them into loss functions. The discretized governing equations, as well as the design and solution spaces, can be derived from any well-established numerical techniques. In this work, we employ the Finite Element Method (FEM) to approximate fields and their spatial derivatives. Subsequently, we conduct Sobolev training to minimize a multi-objective loss function, which includes the discretized weak form of the energy functional, boundary conditions violations, and the stationarity of the residuals with respect to the design variables. Our study focuses on the steady-state heat equation within heterogeneous materials that exhibits significant phase contrast and possibly temperature-dependent conductivity. The network's tangent matrix is directly used for gradient-based optimization to improve the microstructure's heat transfer characteristics. ...">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6248ca7a394e7da69cd6d0cb638b974e5ed8f57e" target='_blank'>
              Finite Operator Learning: Bridging Neural Operators and Numerical Methods for Efficient Parametric Solution and Optimization of PDEs
              </a>
            </td>
          <td>
            Shahed Rezaei, Reza Najian Asl, Kianoosh Taghikhani, Ahmad Moeineddin, Michael Kaliske, Markus Apel
          </td>
          <td>2024-07-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>18</td>
        </tr>

        <tr id="Stochastic dynamics on sparse graphs and disordered systems often lead to complex behaviors characterized by heterogeneity in time and spatial scales, slow relaxation, localization, and aging phenomena. The mathematical tools and approximation techniques required to analyze these complex systems are still under development, posing significant technical challenges and resulting in a reliance on numerical simulations. We introduce a novel computational framework for investigating the dynamics of sparse disordered systems with continuous degrees of freedom. Starting with a graphical model representation of the dynamic partition function for a system of linearly-coupled stochastic differential equations, we use dynamic cavity equations on locally tree-like factor graphs to approximate the stochastic measure. Here, cavity marginals are identified with local functionals of single-site trajectories. Our primary approximation involves a second-order truncation of a small-coupling expansion, leading to a Gaussian form for the cavity marginals. For linear dynamics with additive noise, this method yields a closed set of causal integro-differential equations for cavity versions of one-time and two-time averages. These equations provide an exact dynamical description within the local tree-like approximation, retrieving classical results for the spectral density of sparse random matrices. Global constraints, non-linear forces, and state-dependent noise terms can be addressed using a self-consistent perturbative closure technique. The resulting equations resemble those of dynamical mean-field theory in the mode-coupling approximation used for fully-connected models. However, due to their cavity formulation, the present method can also be applied to ensembles of sparse random graphs and employed as a message-passing algorithm on specific graph instances.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1409599021b5a3a43a70ea04c2d775f534dd885c" target='_blank'>
              Gaussian approximation of dynamic cavity equations for linearly-coupled stochastic dynamics
              </a>
            </td>
          <td>
            Mattia Tarabolo, Luca Dall'Asta
          </td>
          <td>2024-06-20</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="High computational cost and storage/memory requirements of fluid dynamics simulations constrain their usefulness as a predictive tool. Reduced-order models (ROMs) provide a viable solution to this challenge by extracting the key underlying dynamics of a complex system directly from data. We investigate the efficacy and robustness of an extended dynamic mode decomposition (xDMD) algorithm in constructing ROMs of three-dimensional cardiovascular computations. Focusing on the ROMs' accuracy in representation and interpolation, we relate these metrics to the truncation rank of singular value decomposition, which underpins xDMD and other approaches to ROM construction. Our key innovation is to relate the truncation rank to the singular values of the original flow problem. This result establishes a priori guidelines for the xDMD deployment and its likely success as a means of data compression and reconstruction of the system's dynamics from dominant spatiotemporal structures present in the data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6855e540db04b94302cbd9cade410091d7cdd63a" target='_blank'>
              Extended dynamic mode decomposition for model reduction in fluid dynamics simulations
              </a>
            </td>
          <td>
            G. Libero, Alessia Chiofalo, V. Ciriello, D. Tartakovsky
          </td>
          <td>2024-06-01</td>
          <td>Physics of Fluids</td>
          <td>0</td>
          <td>47</td>
        </tr>

        <tr id="Dynamic systems described by differential equations often involve feedback among system components. When there are time delays for components to sense and respond to feedback, delay differential equation (DDE) models are commonly used. This paper considers the problem of inferring unknown system parameters, including the time delays, from noisy and sparse experimental data observed from the system. We propose an extension of manifold-constrained Gaussian processes to conduct parameter inference for DDEs, whereas the time delay parameters have posed a challenge for existing methods that bypass numerical solvers. Our method uses a Bayesian framework to impose a Gaussian process model over the system trajectory, conditioned on the manifold constraint that satisfies the DDEs. For efficient computation, a linear interpolation scheme is developed to approximate the values of the time-delayed system outputs, along with corresponding theoretical error bounds on the approximated derivatives. Two simulation examples, based on Hutchinson's equation and the lac operon system, together with a real-world application using Ontario COVID-19 data, are used to illustrate the efficacy of our method.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/59505531dc6e56a864c5a883b0860d09309620d3" target='_blank'>
              Inference for Delay Differential Equations Using Manifold-Constrained Gaussian Processes
              </a>
            </td>
          <td>
            Yuxuan Zhao, Samuel W. K. Wong
          </td>
          <td>2024-06-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Dynamical systems with polynomials on the right-hand side can model a wide range of physical processes. A subset of such dynamical systems that can model chemical reactions under mass-action kinetics are called chemical systems. A central problem in synthetic biology is to map general polynomial dynamical systems into dynamically similar chemical ones. In this paper, we present a novel map, called the quasi-chemical map, that can systematically solve this problem. The quasi-chemical map introduces suitable state-dependent perturbations into any given polynomial dynamical system which then becomes chemical under suitably large translation of variables. We prove that this map preserves robust dynamical features, such as generic equilibria and limit cycles, as well as temporal properties, such as periods of oscillations. Furthermore, the resulting chemical systems are of only at most one degree higher than the original dynamical systems. We demonstrate the quasi-chemical map by designing relatively simple chemical systems with exotic dynamics and pre-defined bifurcation structures.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2b50161626557df2f0f3c71836f1c0babdaf9403" target='_blank'>
              Mapping dynamical systems into chemical reactions
              </a>
            </td>
          <td>
            Tomislav Plesa
          </td>
          <td>2024-06-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Permutation Entropy and statistiCal Complexity Analysis for astRophysics (PECCARY) is a computationally inexpensive, statistical method by which any time-series can be characterized as predominately regular, complex, or stochastic. Elements of the PECCARY method have been used in a variety of physical, biological, economic, and mathematical scenarios, but have not yet gained traction in the astrophysical community. This study introduces the PECCARY technique with the specific aims to motivate its use in and optimize it for the analysis of astrophysical orbital systems. PECCARY works by decomposing a time-dependent measure, such as the x-coordinate or orbital angular momentum time-series, into ordinal patterns. Due to its unique approach and statistical nature, PECCARY is well-suited for detecting preferred and forbidden patterns (a signature of chaos), even when the chaotic behavior is short-lived or when working with a relatively short duration time-series or small sets of time-series data. A variety of examples are used to demonstrate the capabilities of PECCARY. These include mathematical examples (sine waves, varieties of noise, sums of sine waves, well-known chaotic functions), a double pendulum system, and astrophysical tracer particle simulations with potentials of varying intricacies. Since the adopted timescale used to diagnose a given time-series can affect the outcome, a method is presented to identify an ideal sampling scheme, constrained by the overall duration and the natural timescale of the system. The accompanying PECCARY Python package and its usage are discussed.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/25ce7d8d451515fc444a52821aa2ac11a8fd5f54" target='_blank'>
              PECCARY: A novel approach for characterizing orbital complexity, stochasticity, and regularity
              </a>
            </td>
          <td>
            S'oley 'O. Hyman, Kathryne J. Daniel, David A. Schaffner
          </td>
          <td>2024-07-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Machine learning has been proposed as an alternative to theoretical modeling when dealing with complex problems in biological physics. However, in this perspective, we argue that a more successful approach is a proper combination of these two methodologies. We discuss how ideas coming from physical modeling neuronal processing led to early formulations of computational neural networks, e.g., Hopfield networks. We then show how modern learning approaches like Potts models, Boltzmann machines, and the transformer architecture are related to each other, specifically, through a shared energy representation. We summarize recent efforts to establish these connections and provide examples on how each of these formulations integrating physical modeling and machine learning have been successful in tackling recent problems in biomolecular structure, dynamics, function, evolution, and design. Instances include protein structure prediction; improvement in computational complexity and accuracy of molecular dynamics simulations; better inference of the effects of mutations in proteins leading to improved evolutionary modeling and finally how machine learning is revolutionizing protein engineering and design. Going beyond naturally existing protein sequences, a connection to protein design is discussed where synthetic sequences are able to fold to naturally occurring motifs driven by a model rooted in physical principles. We show that this model is “learnable” and propose its future use in the generation of unique sequences that can fold into a target structure.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/857c85e6a44f8c49c7d41155c041eb3e9361ca60" target='_blank'>
              Machine learning in biological physics: From biomolecular prediction to design
              </a>
            </td>
          <td>
            Jonathan Martin, Marcos Lequerica Mateos, J. Onuchic, Ivan Coluzza, F. Morcos
          </td>
          <td>2024-06-24</td>
          <td>Proceedings of the National Academy of Sciences of the United States of America</td>
          <td>1</td>
          <td>95</td>
        </tr>

        <tr id="We introduce an innovative approach for solving high-dimensional Fokker-Planck-L\'evy (FPL) equations in modeling non-Brownian processes across disciplines such as physics, finance, and ecology. We utilize a fractional score function and Physical-informed neural networks (PINN) to lift the curse of dimensionality (CoD) and alleviate numerical overflow from exponentially decaying solutions with dimensions. The introduction of a fractional score function allows us to transform the FPL equation into a second-order partial differential equation without fractional Laplacian and thus can be readily solved with standard physics-informed neural networks (PINNs). We propose two methods to obtain a fractional score function: fractional score matching (FSM) and score-fPINN for fitting the fractional score function. While FSM is more cost-effective, it relies on known conditional distributions. On the other hand, score-fPINN is independent of specific stochastic differential equations (SDEs) but requires evaluating the PINN model's derivatives, which may be more costly. We conduct our experiments on various SDEs and demonstrate numerical stability and effectiveness of our method in dealing with high-dimensional problems, marking a significant advancement in addressing the CoD in FPL equations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8627a1dd31e82891b19eb525d8d99ebc327fe094" target='_blank'>
              Score-fPINN: Fractional Score-Based Physics-Informed Neural Networks for High-Dimensional Fokker-Planck-Levy Equations
              </a>
            </td>
          <td>
            Zheyuan Hu, Zhongqiang Zhang, G. Karniadakis, Kenji Kawaguchi
          </td>
          <td>2024-06-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>127</td>
        </tr>

        <tr id="We introduce mochi_class, an extension of the Einstein-Boltzmann solver hi_class, designed to unlock the full phenomenological potential of Horndeski gravity. This extension allows for general input functions of time without the need for hard-coded parametrisations or covariant Lagrangians. By replacing the traditional $\alpha$-parametrisation with a set of stable basis functions, mochi_class ensures that the resulting effective theories are inherently free from gradient and ghost instabilities. Additionally, mochi_class features a quasi-static approximation implemented at the level of modified metric potentials, enhancing prediction accuracy, especially for models transitioning between a super- and sub-Compton regime. mochi_class can robustly handle a wide range of models without fine-tuning, and introduces a new approximation scheme that activates modifications to the standard cosmology deep in the matter-dominated era. Furthermore, it incorporates viability conditions on the equation of motion for the scalar field fluctuations, aiding in the identification of numerical instabilities. Through comprehensive validation against other Einstein-Boltzmann solvers, mochi_class demonstrates excellent performance and accuracy, broadening the scope of hi_class by facilitating the study of specific modified gravity models and enabling exploration of previously inaccessible regions of the Horndeski landscape. The code is publicly available at https://github.com/mcataneo/mochi_class_public">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/45c44ba92da169b2eb987805f3b6ad66528aeee4" target='_blank'>
              mochi_class: Modelling Optimisation to Compute Horndeski In class
              </a>
            </td>
          <td>
            Matteo Cataneo, Emilio Bellini
          </td>
          <td>2024-07-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Modeling dynamical systems, e.g. in climate and engineering sciences, often necessitates solving partial differential equations. Neural operators are deep neural networks designed to learn nontrivial solution operators of such differential equations from data. As for all statistical models, the predictions of these models are imperfect and exhibit errors. Such errors are particularly difficult to spot in the complex nonlinear behaviour of dynamical systems. We introduce a new framework for approximate Bayesian uncertainty quantification in neural operators using function-valued Gaussian processes. Our approach can be interpreted as a probabilistic analogue of the concept of currying from functional programming and provides a practical yet theoretically sound way to apply the linearized Laplace approximation to neural operators. In a case study on Fourier neural operators, we show that, even for a discretized input, our method yields a Gaussian closure--a structured Gaussian process posterior capturing the uncertainty in the output function of the neural operator, which can be evaluated at an arbitrary set of points. The method adds minimal prediction overhead, can be applied post-hoc without retraining the neural operator, and scales to large models and datasets. We showcase the efficacy of our approach through applications to different types of partial differential equations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2fb48eb416a7b362eb444cb5d9c111a6939db5fe" target='_blank'>
              Linearization Turns Neural Operators into Function-Valued Gaussian Processes
              </a>
            </td>
          <td>
            Emilia Magnani, Marvin Pförtner, Tobias Weber, Philipp Hennig
          </td>
          <td>2024-06-07</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="We construct a new representation of entropy solutions to nonlinear scalar conservation laws with a smooth convex flux function in a single spatial dimension. The representation is a generalization of the method of characteristics and posseses a compositional form. While it is a nonlinear representation, the embedded dynamics of the solution in the time variable is linear. This representation is then discretized as a manifold of implicit neural representations where the feedforward neural network architecture has a low rank structure. Finally, we show that the low rank neural representation with a fixed number of layers and a small number of coefficients can approximate any entropy solution regardless of the complexity of the shock topology, while retaining the linearity of the embedded dynamics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/198bd235ebdfd54438bc1206669a2167466ea31d" target='_blank'>
              A Low Rank Neural Representation of Entropy Solutions
              </a>
            </td>
          <td>
            Donsub Rim, Gerrit Welper
          </td>
          <td>2024-06-09</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id="This two-part tutorial dives into the field of data-driven power flow linearization (DPFL), a domain gaining increased attention. DPFL stands out for its higher approximation accuracy, wide adaptability, and better ability to implicitly incorporate the latest system attributes. This renders DPFL a potentially superior option for managing the significant fluctuations from renewable energy sources, a step towards realizing a more sustainable energy future, by translating the higher model accuracy into increased economic efficiency and less energy losses. To conduct a deep and rigorous reexamination, this tutorial first classifies existing DPFL methods into DPFL training algorithms and supportive techniques. Their mathematical models, analytical solutions, capabilities, limitations, and generalizability are systematically examined, discussed, and summarized. In addition, this tutorial reviews existing DPFL experiments, examining the settings of test systems, the fidelity of datasets, and the comparison made among a limited number of DPFL methods. Further, this tutorial implements extensive numerical comparisons of all existing DPFL methods (40 methods in total) and four classic physics-driven approaches, focusing on their generalizability, applicability, accuracy, and computational efficiency. Through these simulationmethodss, this tutorial aims to reveal the actual performance of all the methods (including the performances exposed to data noise or outliers), guiding the selection of appropriate linearization methods. Furthermore, this tutorial discusses future directions based on the theoretical and numerical insights gained. As the first part, this paper reexamines DPFL theories, covering all the training algorithms and supportive techniques. Capabilities, limitations, and aspects of generalizability, which were previously unmentioned in the literature, have been identified.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1bdfa4f227320698ee10d100d4da18f732e22c80" target='_blank'>
              Data-driven Power Flow Linearization: Theory
              </a>
            </td>
          <td>
            Mengshuo Jia, Gabriela Hug, Ning Zhang, Zhaojian Wang, Yi Wang, Chongqing Kang
          </td>
          <td>2024-06-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>31</td>
        </tr>

        <tr id="Physics-informed neural networks (PINNs) have shown promising potential for solving partial differential equations (PDEs) using deep learning. 

However, PINNs face training difficulties for evolutionary PDEs, particularly for dynamical systems whose solutions exhibit multi-scale or turbulent behavior over time.

The reason is that PINNs may violate the temporal causality property since all the temporal features in the PINNs loss are trained simultaneously. 

This paper proposes to use implicit time differencing schemes to enforce temporal causality, and use transfer learning to sequentially update the PINNs in space as surrogates for PDE solutions in different time frames.

The evolving PINNs are better able to capture the varying complexities of the evolutionary equations, while only requiring minor updates between adjacent time frames.

Our method is theoretically proven to be convergent if the time step is small and each PINN in different time frames is well-trained.

In addition, we provide state-of-the-art (SOTA) numerical results for a variety of benchmarks for which existing PINNs formulations may fail or be inefficient.

We demonstrate that the proposed method improves the accuracy of PINNs approximation for evolutionary PDEs and improves efficiency by a factor of 4–40x.

The code is available at https://github.com/SiqiChen9/TL-DPINNs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2baf92352b6cdc0a229e693600511b572a32085f" target='_blank'>
              Causality-enhanced Discreted Physics-informed Neural Networks for Predicting Evolutionary Equations
              </a>
            </td>
          <td>
            Ye Li, Siqi Chen, Bin Shan, 
          </td>
          <td>2024-08-01</td>
          <td>Proceedings of the Thirty-ThirdInternational Joint Conference on Artificial Intelligence</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="A data-driven model, in conjunction with economic model predictive control, presents a promising approach to enhance the control of an industrial system with limited development cost. Neural network-based models inherently offer the capacity to identify a wide spectrum of dynamic systems, a pivotal aspect in ensuring a flexible control methodology. However, the training of such neural models requires datasets that are often unattainable in practical scenarios, given that available data is typically confined to the operational data of the system. The literature has shown that linear models are sometimes more relevant in these types of situations, even if they are less flexible. This contribution proposes a comparative study between black-box linear models and neural network-based models. The objective is to evaluate their relevance when used as part of economic predictive controllers in the context of building temperature regulation. The BOPTEST (Building Optimization Performance Tests) benchmark is used for this purpose. Emphasis is placed on different nonlinear model structures to better understand their influence on the results observed in the literature.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/aa9ec3d5a582c497587f6e727b29796fdecde5be" target='_blank'>
              Comparing Neural Network and Linear Models in Economic MPC: Insights from BOPTEST for Building Temperature Control
              </a>
            </td>
          <td>
            François Gauthier-Clerc, Hoel Le Capitaine, F. Claveau, P. Chevrel
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>20</td>
        </tr>

        <tr id="Reservoir computing has been shown to be a useful framework for predicting critical transitions of a dynamical system if the bifurcation parameter is also provided as an input. Its utility is significant because in real-world scenarios, the exact model equations are unknown. This Letter shows how the theory of dynamical system provides the underlying mechanism behind the prediction. Using numerical methods, by considering dynamical systems which show Hopf bifurcation, we demonstrate that the map produced by the reservoir after a successful training undergoes a Neimark-Sacker bifurcation such that the critical point of the map is in immediate proximity to that of the original dynamical system. In addition, we have compared and analyzed different structures in the phase space. Our findings provide insight into the functioning of machine learning algorithms for predicting critical transitions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3e38c7638dd9a0b907d25cf396095bd4a2d25e12" target='_blank'>
              Dynamical analysis of a parameter-aware reservoir computer
              </a>
            </td>
          <td>
            Dishant Sisodia, S. Jalan
          </td>
          <td>2024-07-20</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>26</td>
        </tr>

        <tr id="For many industrial processes, a digital twin is available, which is essentially a highly complex model whose parameters may not be properly tuned for the specific process. By relying on the availability of such a digital twin, this paper introduces a novel approach to data-driven control, where the digital twin is used to generate samples and suitable controllers for various perturbed versions of its parameters. A supervised learning algorithm is then employed to estimate a direct mapping from the data to the best controller to use. This map consists of a model reduction step, followed by a neural network architecture whose output provides the parameters of the controller. The data-to-controller map is pre-computed based on artificially generated data, but its execution once deployed is computationally very efficient, thus providing a simple and inexpensive way to tune and re-calibrate controllers directly from data. The benefits of this novel approach are illustrated via numerical simulations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6916b9be2764f075e341e143b9e58edc122152ad" target='_blank'>
              From Data to Control: A Two-Stage Simulation-Based Approach
              </a>
            </td>
          <td>
            Federico Dettù, Braghadeesh Lakshminarayanan, Simone Formentin, Cristian R. Rojas
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="We provide two methods for computation of continuum backstepping kernels that arise in control of continua (ensembles) of linear hyperbolic PDEs and which can approximate backstepping kernels arising in control of a large-scale, PDE system counterpart (with computational complexity that does not grow with the number of state components of the large-scale system). In the first method, we identify a class of systems for which the solution to the continuum (and hence, also an approximate solution to the respective large-scale) kernel equations can be constructed in closed form. In the second method, we provide explicit formulae for the solution to the continuum kernels PDEs, employing a (triple) power series representation of the continuum kernel and establishing its convergence properties. In this case, we also provide means for reducing computational complexity by properly truncating the power series (in the powers of the ensemble variable). We also present numerical examples to illustrate computational efficiency/accuracy of the approaches, as well as to validate the stabilization properties of the approximate control kernels, constructed based on the continuum.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/06dc550f2b40b1aada690bea9441924c53597c22" target='_blank'>
              On Computation of Approximate Solutions to Large-Scale Backstepping Kernel Equations via Continuum Approximation
              </a>
            </td>
          <td>
            Jukka-Pekka Humaloja, N. Bekiaris-Liberis
          </td>
          <td>2024-06-19</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>31</td>
        </tr>

        <tr id="
 Turbulence closure modeling using machine learning is at an early crossroads. The extraordinary success of machine learning (ML) in a variety of challenging fields had given rise to an expectation of similar transformative advances in the area of turbulence closure modeling. However, by most accounts, the current rate of progress toward accurate and predictive ML-RANS (Reynolds Averaged Navier-Stokes) closure models has been very slow. Upon retrospection, the absence of rapid transformative progress can be attributed to two factors: the underestimation of the intricacies of turbulence modeling and the overestimation of ML’s ability to capture all features without employing targeted strategies. To pave the way for more meaningful ML closures tailored to address the nuances of turbulence, this article seeks to review the foundational flow physics to assess the challenges in the context of data-driven approaches. Revisiting analogies with statistical mechanics and stochastic systems, the key physical complexities and mathematical limitations are explicated. It is noted that the current ML approaches do not systematically address the inherent limitations of a statistical approach or the inadequacies of the mathematical forms of closure expressions. The study underscores the drawbacks of supervised learning-based closures and stresses the importance of a more discerning ML modeling framework. As ML methods evolve (which is happening at a rapid pace) and our understanding of the turbulence phenomenon improves, the inferences expressed here should be suitably modified.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d5cf3709be3b3ab9de17733558b062f9c6b30ac8" target='_blank'>
              Turbulence Closure Modeling with Machine Learning: A Foundational Physics Perspective
              </a>
            </td>
          <td>
            S. Girimaji
          </td>
          <td>2024-07-23</td>
          <td>New Journal of Physics</td>
          <td>0</td>
          <td>42</td>
        </tr>

        <tr id="This paper presents a new approach to the nonlinear model predictive control (NMPC) of an underactuated overhead crane system developed using a data-driven prediction model obtained utilizing the regularized genetic programming-based symbolic regression method. Grammar-guided genetic programming combined with regularized least squares was applied to identify a nonlinear autoregressive model with an exogenous input (NARX) prediction model of the crane dynamics from input–output data. The resulting prediction model was implemented in the NMPC scheme, using a particle swarm optimization (PSO) algorithm as a solver to find an optimal sequence of the control actions satisfying multi-objective performance requirements and input constraints. The feasibility and performance of the controller were experimentally verified using a laboratory crane actuated by AC motors and compared with a discrete-time feedback controller developed using the pole placement technique. A series of experiments proved the effectiveness of the controller in terms of robustness against operating condition variation and external disturbances.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/623f596a28fa6216be9b739b2d8b53b83ad90a45" target='_blank'>
              Nonlinear Model Predictive Control with Evolutionary Data-Driven Prediction Model and Particle Swarm Optimization Optimizer for an Overhead Crane
              </a>
            </td>
          <td>
            Tom Kusznir, Jarosław Smoczek
          </td>
          <td>2024-06-12</td>
          <td>Applied Sciences</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Markov state modeling has gained popularity in various scientific fields due to its ability to reduce complex time series data into transitions between a few states. Yet, current frameworks are limited by assuming a single Markov chain describes the data, and they suffer an inability to discern heterogeneities. As a solution, this paper proposes a variational expectation-maximization algorithm that identifies a mixture of Markov chains in a time-series data set. The method is agnostic to the definition of the Markov states, whether data-driven (e.g. by spectral clustering) or based on domain knowledge. Variational EM efficiently and organically identifies the number of Markov chains and dynamics of each chain without expensive model comparisons or posterior sampling. The approach is supported by a theoretical analysis and numerical experiments, including simulated and observational data sets based on ${\tt Last.fm}$ music listening, ultramarathon running, and gene expression. The results show the new algorithm is competitive with contemporary mixture modeling approaches and powerful in identifying meaningful heterogeneities in time series data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/93236af9998c08b712c5c7b73c86658e1735ae9e" target='_blank'>
              Dynamical mixture modeling with fast, automatic determination of Markov chains
              </a>
            </td>
          <td>
            Christopher E Miles, Robert J. Webber
          </td>
          <td>2024-06-07</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="We introduce and analyze generalised polynomial chaos (gPC), considering both intrusive and non-intrusive approaches, as an uncertainty quantification method in studies of probabilistic robustness. The considered gPC methods are complementary to Monte Carlo (MC) methods and are shown to be fast and scalable, allowing for comprehensive and efficient exploration of parameter spaces. These properties enable robustness analysis of a wider set of models, compared to computationally expensive MC methods, while retaining desired levels of accuracy. We discuss the application of gPC methods to systems in biology and neuroscience, notably subject to multiple parametric uncertainties, and we examine a well-known model of neural dynamics as a case study.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/abb89db7124ec1925a107b3eb959ec0287242359" target='_blank'>
              Efficient gPC-based quantification of probabilistic robustness for systems in neuroscience
              </a>
            </td>
          <td>
            Uros Sutulovic, Daniele Proverbio, Rami Katz, Giulia Giordano
          </td>
          <td>2024-06-19</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Gaussian Processes (GPs) and Linear Dynamical Systems (LDSs) are essential time series and dynamic system modeling tools. GPs can handle complex, nonlinear dynamics but are computationally demanding, while LDSs offer efficient computation but lack the expressive power of GPs. To combine their benefits, we introduce a universal method that allows an LDS to mirror stationary temporal GPs. This state-space representation, known as the Markovian Gaussian Process (Markovian GP), leverages the flexibility of kernel functions while maintaining efficient linear computation. Unlike existing GP-LDS conversion methods, which require separability for most multi-output kernels, our approach works universally for single- and multi-output stationary temporal kernels. We evaluate our method by computing covariance, performing regression tasks, and applying it to a neuroscience application, demonstrating that our method provides an accurate state-space representation for stationary temporal GPs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f45b6ab8336d143d48c626e23d36a99a22707758" target='_blank'>
              Markovian Gaussian Process: A Universal State-Space Representation for Stationary Temporal Gaussian Process
              </a>
            </td>
          <td>
            Weihan Li, Yule Wang, Chengrui Li, Anqi Wu
          </td>
          <td>2024-06-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="In this work, we present a novel methodology for performing the supervised classification of time-ordered noisy data; we call this methodology Entropic Sparse Probabilistic Approximation with Markov regularization (eSPA-Markov). It is an extension of entropic learning methodologies, allowing the simultaneous learning of segmentation patterns, entropy-optimal feature space discretizations, and Bayesian classification rules. We prove the conditions for the existence and uniqueness of the learning problem solution and propose a one-shot numerical learning algorithm that—in the leading order—scales linearly in dimension. We show how this technique can be used for the computationally scalable identification of persistent (metastable) regime affiliations and regime switches from high-dimensional non-stationary and noisy time series, i.e., when the size of the data statistics is small compared to their dimensionality and when the noise variance is larger than the variance in the signal. We demonstrate its performance on a set of toy learning problems, comparing eSPA-Markov to state-of-the-art techniques, including deep learning and random forests. We show how this technique can be used for the analysis of noisy time series from DNA and RNA Nanopore sequencing.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/eadfee466307a1a3b8e63299cb3e600477c1f902" target='_blank'>
              On Entropic Learning from Noisy Time Series in the Small Data Regime
              </a>
            </td>
          <td>
            Davide Bassetti, Lukáš Pospíšil, I. Horenko
          </td>
          <td>2024-06-28</td>
          <td>Entropy</td>
          <td>0</td>
          <td>26</td>
        </tr>

        <tr id="Intratumour phenotypic heterogeneity is nowadays understood to play a critical role in disease progression and treatment failure. Accordingly, there has been increasing interest in the development of mathematical models capable of capturing its role in cancer cell adaptation. This can be systematically achieved by means of models comprising phenotype-structured nonlocal partial differential equations, tracking the evolution of the phenotypic density distribution of the cell population, which may be compared to gene and protein expression distributions obtained experimentally. Nevertheless, given the high analytical and computational cost of solving these models, much is to be gained from reducing them to systems of ordinary differential equations for the moments of the distribution. We propose a generalised method of model-reduction, relying on the use of a moment generating function, Taylor series expansion and truncation closure, to reduce a nonlocal reaction-advection-diffusion equation, with general phenotypic drift and proliferation rate functions, to a system of moment equations up to arbitrary order. Our method extends previous results in the literature, which we address via two examples, by removing any \textit{a priori} assumption on the shape of the distribution, and provides a flexible framework for mathematical modellers to account for the role of phenotypic heterogeneity in cancer adaptive dynamics, in a simpler mathematical framework.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4d951ebfbeb9789f55de6ae13ba4fa4d0ddb0abc" target='_blank'>
              Reducing phenotype-structured PDE models of cancer evolution to systems of ODEs: a generalised moment dynamics approach
              </a>
            </td>
          <td>
            Chiara Villa, P. K. Maini, Alexander P Browning, A. Jenner, Sara Hamis, Tyler Cassidy
          </td>
          <td>2024-06-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>26</td>
        </tr>

        <tr id="Physical learning is an emerging paradigm in science and engineering whereby (meta)materials acquire desired macroscopic behaviors by exposure to examples. So far, it has been applied to static properties such as elastic moduli and self-assembled structures encoded in minima of an energy landscape. Here, we extend this paradigm to dynamic functionalities, such as motion and shape change, that are instead encoded in limit cycles or pathways of a dynamical system. We identify the two ingredients needed to learn time-dependent behaviors irrespective of experimental platforms: (i) learning rules with time delays and (ii) exposure to examples that break time-reversal symmetry during training. After providing a hands-on demonstration of these requirements using programmable LEGO toys, we turn to realistic particle-based simulations where the training rules are not programmed on a computer. Instead, we elucidate how they emerge from physico-chemical processes involving the causal propagation of fields, like in recent experiments on moving oil droplets with chemotactic signalling. Our trainable particles can self-assemble into structures that move or change shape on demand, either by retrieving the dynamic behavior previously seen during training, or by learning on the fly. This rich phenomenology is captured by a modified Hopfield spin model amenable to analytical treatment. The principles illustrated here provide a step towards von Neumann's dream of engineering synthetic living systems that adapt to the environment.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/65200d8b0fc58bbbf5835e07be38dc47b087a743" target='_blank'>
              Learning dynamical behaviors in physical systems
              </a>
            </td>
          <td>
            R. Mandal, Rosalind Huang, Michel Fruchart, P. Moerman, Suriyanarayanan Vaikuntanathan, Arvind Murugan, Vincenzo Vitelli
          </td>
          <td>2024-06-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>25</td>
        </tr>

        <tr id="Model predictive control (MPC) is a powerful control method for handling complex nonlinear systems that are subject to constraints. However, the real-time application of this approach can be severely limited by the need to solve constrained nonlinear optimization problems at each sampling time. To this end, this work introduces a novel learning-based iterative solver that provides highly accurate predictions, optimality certification, and fast evaluation of the MPC solution at each sampling time. To learn this iterative solver, we propose an unsupervised training algorithm that builds on the Karush-Kuhn-Tucker optimality conditions, modified by a Fischer-Burmeister formulation, and eliminates the need for prior sampling of exact optimizer solutions. By exploiting efficient vector-Jacobian and Jacobian-vector products via automatic differentiation, the proposed training algorithm can be efficiently executed. We demonstrate the potential of the proposed learning-based iterative solver on the example of nonlinear model predictive control of a nonlinear double integrator. We show its advantages when compared to exact optimizer solutions and with an imitation learning-based approach that directly obtains a data-based approximation of the MPC control law.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/04655a12d07dee491135aaae2f055b737e275291" target='_blank'>
              Learning Iterative Solvers for Accurate and Fast Nonlinear Model Predictive Control via Unsupervised Training
              </a>
            </td>
          <td>
            Lukas Lüken, Sergio Lucia
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Motivated by important applications to the analysis of complex noise-induced phenomena, we consider a problem of the constructive description of randomly forced equilibria for nonlinear systems with multiplicative noise. Using the apparatus of the first approximation systems, we construct an approximation of mean square deviations that explicitly takes into account the presence of multiplicative noises, depending on the current system state. A spectral criterion of existence and exponential stability of the stationary second moments for the solution of the first approximation system is presented. For mean square deviation, we derive an expansion in powers of the small parameter of noise intensity. Based on this theory, we derive a new, more accurate approximation of mean square deviations in a general nonlinear system with multiplicative noises. This approximation is compared with the widely used approximation based on the stochastic sensitivity technique. The general mathematical results are illustrated with examples of the model of climate dynamics and the van der Pol oscillator with hard excitement.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f8b4c1e986ba88d48cf2674010a03c5713b44f90" target='_blank'>
              Approximations in Mean Square Analysis of Stochastically Forced Equilibria for Nonlinear Dynamical Systems
              </a>
            </td>
          <td>
            I. Bashkirtseva
          </td>
          <td>2024-07-13</td>
          <td>Mathematics</td>
          <td>0</td>
          <td>26</td>
        </tr>

        <tr id="Abstract Motivation In recent years, applying computational modeling to systems biology has caused a substantial surge in both discovery and practical applications and a significant shift in our understanding of the complexity inherent in biological systems. Results In this perspective article, we briefly overview computational modeling in biology, highlighting recent advancements such as multi-scale modeling due to the omics revolution, single-cell technology, and integration of artificial intelligence and machine learning approaches. We also discuss the primary challenges faced: integration, standardization, model complexity, scalability, and interdisciplinary collaboration. Lastly, we highlight the contribution made by the Computational Modeling of Biological Systems (SysMod) Community of Special Interest (COSI) associated with the International Society of Computational Biology (ISCB) in driving progress within this rapidly evolving field through community engagement (via both in person and virtual meetings, social media interactions), webinars, and conferences. Availability and implementation Additional information about SysMod is available at https://sysmod.info.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1b174dea12ab92a7f7139cb9122517aefde98aa6" target='_blank'>
              Perspectives on computational modeling of biological systems and the significance of the SysMod community
              </a>
            </td>
          <td>
            B. L. Puniya, Meghna Verma, Chiara Damiani, Shaimaa Bakr, Andreas Dräger
          </td>
          <td>2024-06-26</td>
          <td>Bioinformatics Advances</td>
          <td>0</td>
          <td>11</td>
        </tr>

        <tr id="This article focuses on solving a finite-horizon nonlinear optimal control problem by using the Pontryagin's maximum principle. In practical applications, linearization is a common approach for solving nonlinear dynamical systems. However, it is not universally applicable due to various reasons, such as instability and low accuracy. In contrast to linearization, the inherent challenge in directly solving the above nonlinear optimal control problem lies in addressing the highly coupled nonlinear forward and backward differential equations. In order to address this problem, an equivalent relationship is established between these equations and a new optimization problem. By exploiting the inherent relationship between supervised learning and an optimization problem from the view of a dynamical system, a deep neural network framework is constructed for describing the new optimization problem. Furthermore, a numerical algorithm for optimal control, which is very powerful for a large variety of nonlinear dynamical systems, is implemented by training a deep residual network. Finally, the effectiveness of the algorithm is demonstrated by solving a trajectory tracking control problem for automatic guided vehicle. The obtained results reveal that the proposed control scheme can achieve high-precision tracking.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/590a182981bd44368ad369640ae4005fa1d66650" target='_blank'>
              Nonlinear Optimal Control Based on FBDEs and its Application to AGV.
              </a>
            </td>
          <td>
            Chuanzhi Lv, Hongdan Li, Huanshui Zhang, Minyue Fu
          </td>
          <td>2024-07-19</td>
          <td>IEEE transactions on cybernetics</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/65f70fe6d698072acfae68cb9be3a90281df6d72" target='_blank'>
              Application of physics encoded neural networks to improve predictability of properties of complex multi-scale systems
              </a>
            </td>
          <td>
            M. Meinders, Jack Yang, Erik van der Linden
          </td>
          <td>2024-07-01</td>
          <td>Scientific Reports</td>
          <td>0</td>
          <td>29</td>
        </tr>

        <tr id="In this article, a distributed neural network modeling framework including a novel neural hybrid system model is proposed for enhancing the scalability of neural network models in modeling dynamical systems. First, high-dimensional training data samples will be mapped to a low-dimensional feature space through the principal component analysis (PCA) featuring process. Following that, the feature space is bisected into multiple partitions based on the variation of the Shannon entropy under the maximum entropy (ME) bisecting process. The behavior of subsystems in the prespecified state space partitions will then be approximated using a group of shallow neural networks (SNNs) known as extreme learning machines (ELMs), and then it can further simplify the model by merging the redundant lattices based on their training error performance. The proposed modeling framework can handle high-dimensional dynamical system modeling problems with the advantages of reducing model complexity and improving model performance in training and verification. To demonstrate the effectiveness of the proposed modeling framework, examples of modeling the LASA dataset and an industrial robot are presented.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7a2a2b97f2bbf0735400cc24119a8d6645252543" target='_blank'>
              A Distributed Neural Hybrid System Learning Framework in Modeling Complex Dynamical Systems.
              </a>
            </td>
          <td>
            Yejiang Yang, Tao Wang, Weiming Xiang
          </td>
          <td>2024-06-28</td>
          <td>IEEE transactions on neural networks and learning systems</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Parametric data-driven modeling is relevant for many applications in which the model depends on parameters that can potentially vary in both space and time. In this paper, we present a method to obtain a global parametric model based on snapshots of the parameter space. The parameter snapshots are interpolated using the classical univariate Loewner framework and the global bivariate transfer function is extracted using a linear fractional transformation (LFT). Rank bounds for the minimal order of the global realization are also derived. The results are supported by various numerical examples.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6f9ad2c0eef766d60843158a7cce5734f7a4512d" target='_blank'>
              Snapshot-driven Rational Interpolation of Parametric Systems
              </a>
            </td>
          <td>
            Art J. R. Pelling, Karim Cherifi, I. V. Gosea, E. Sarradj
          </td>
          <td>2024-06-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>25</td>
        </tr>

        <tr id="Data driven system identification is the technique for learning models from input/output data. To increase the robustness of the model estimation, prior knowledge can be incorporated, the so-called gray-box identification. In finite impulse response (FIR) models, prior knowledge of the process under investigation can be introduced by regularization. In the regularization term basic impulse response characteristics such as smoothness and exponentially decaying behavior can be incorporated. For estimation of time-delay systems, the novel impulse response and time-delay preserving (IRDP) regularization matrix is proposed. In this contribution this method is extended to the estimation of multiple input single output (MISO) processes and is compared to other state-of-the-art approaches. A linear process with four inputs and different input dynamics and time-delays is investigated. The focus of the evaluation is placed on model quality, time-delay estimation, and computation time. The simulation results point out the superiority of the novel regularization approach in comparison to state-of-the-art methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a8735d69bbb91950534f1fe2742f48352fd17202" target='_blank'>
              Handling of Time Delays in MISO Processes with Regularized Finite Impulse Response Models
              </a>
            </td>
          <td>
            Christopher Illg, Tarek Kösters, Oliver Nelles
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Networks in machine learning offer examples of complex high-dimensional dynamical systems inspired by and reminiscent of biological systems. Here, we study the learning dynamics of generalized Hopfield networks, which permit visualization of internal memories. These networks have been shown to proceed through a “feature-to-prototype” transition, as the strength of network nonlinearity is increased, wherein the learned, or terminal, states of internal memories transition from mixed to pure states. Focusing on the prototype learning dynamics of the internal memories, we observe stereotypical dynamics of memories wherein similar subgroups of memories sequentially split at well-defined saddles. The splitting order is interpretable and reproducible from one simulation to the other. The dynamics prior to splits are robust to variations in many features of the system. To develop a more rigorous understanding of these global dynamics, we study smaller subsystems that exhibit similar properties to the full system. Within these smaller systems, we combine analytical calculations with numerical simulations to study the dynamics of the feature-to-prototype transition, and the emergence of saddle points in the learning landscape. We exhibit regimes where saddles appear and disappear through saddle-node bifurcations, qualitatively changing the distribution of learned memories as the strength of the nonlinearity is varied—allowing us to systematically investigate the mechanisms that underlie the emergence of the learning dynamics. Several features of the learning dynamics are reminiscent of the Waddington's caricature of cellular differentiation, and we attempt to make this analogy more precise. Memories can thus differentiate in a predictive and controlled way, revealing bridges between experimental biology, dynamical systems theory, and machine learning.




 Published by the American Physical Society
 2024


">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/acfb0996b8a2dd52af629b0fc803ccf66a9f85a9" target='_blank'>
              Waddington landscape for prototype learning in generalized Hopfield networks
              </a>
            </td>
          <td>
            Nacer Eddine Boukacem, Allen Leary, Robin Thériault, Felix Gottlieb, Madhav Mani, Paul François
          </td>
          <td>2024-07-23</td>
          <td>Physical Review Research</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Physics-informed neural networks (PINNs) have recently emerged as a promising way to compute the solutions of partial differential equations (PDEs) using deep neural networks. However, despite their significant success in various fields, it remains unclear in many aspects how to effectively train PINNs if the solutions of PDEs exhibit stiff behaviors or high frequencies. In this paper, we propose a new method for training PINNs using variable-scaling techniques. This method is simple and it can be applied to a wide range of problems including PDEs with rapidly-varying solutions. Throughout various numerical experiments, we will demonstrate the effectiveness of the proposed method for these problems and confirm that it can significantly improve the training efficiency and performance of PINNs. Furthermore, based on the analysis of the neural tangent kernel (NTK), we will provide theoretical evidence for this phenomenon and show that our methods can indeed improve the performance of PINNs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9124ec1fca5f99e93eb695497f13fd9c818c0fa1" target='_blank'>
              VS-PINN: A Fast and efficient training of physics-informed neural networks using variable-scaling methods for solving PDEs with stiff behavior
              </a>
            </td>
          <td>
            Seungchan Ko, Sang Hyeon Park
          </td>
          <td>2024-06-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="This work addresses stochastic optimal control problems where the unknown state evolves in continuous time while partial, noisy, and possibly controllable measurements are only available in discrete time. We develop a framework for controlling such systems, focusing on the measure-valued process of the system's state and the control actions that depend on noisy and incomplete data. Our approach uses a stochastic optimal control framework with a probability measure-valued state, which accommodates noisy measurements and integrates them into control decisions through a Bayesian update mechanism. We characterize the control optimality in terms of a sequence of interlaced Hamilton Jacobi Bellman (HJB) equations coupled with controlled impulse steps at the measurement times. For the case of Gaussian-controlled processes, we derive an equivalent HJB equation whose state variable is finite-dimensional, namely the state's mean and covariance. We demonstrate the effectiveness of our methods through numerical examples. These include control under perfect observations, control under no observations, and control under noisy observations. Our numerical results highlight significant differences in the control strategies and their performance, emphasizing the challenges and computational demands of dealing with uncertainty in state observation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e6ba24031ebf3376cb6db64dd547b84c989cf92e" target='_blank'>
              Continuous time Stochastic optimal control under discrete time partial observations
              </a>
            </td>
          <td>
            Christian Bayer, Boualem Djehiche, Eliza Rezvanova, Raúl Tempone
          </td>
          <td>2024-07-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>24</td>
        </tr>

        <tr id="We present the hidden-layer concatenated physics informed neural network (HLConcPINN) method, which combines hidden-layer concatenated feed-forward neural networks, a modified block time marching strategy, and a physics informed approach for approximating partial differential equations (PDEs). We analyze the convergence properties and establish the error bounds of this method for two types of PDEs: parabolic (exemplified by the heat and Burgers' equations) and hyperbolic (exemplified by the wave and nonlinear Klein-Gordon equations). We show that its approximation error of the solution can be effectively controlled by the training loss for dynamic simulations with long time horizons. The HLConcPINN method in principle allows an arbitrary number of hidden layers not smaller than two and any of the commonly-used smooth activation functions for the hidden layers beyond the first two, with theoretical guarantees. This generalizes several recent neural-network techniques, which have theoretical guarantees but are confined to two hidden layers in the network architecture and the $\tanh$ activation function. Our theoretical analyses subsequently inform the formulation of appropriate training loss functions for these PDEs, leading to physics informed neural network (PINN) type computational algorithms that differ from the standard PINN formulation. Ample numerical experiments are presented based on the proposed algorithm to validate the effectiveness of this method and confirm aspects of the theoretical analyses.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/756e42c72cc211bde08b9880438d676e69260474" target='_blank'>
              Error Analysis and Numerical Algorithm for PDE Approximation with Hidden-Layer Concatenated Physics Informed Neural Networks
              </a>
            </td>
          <td>
            Yianxia Qian, Yongchao Zhang, Suchuan Dong
          </td>
          <td>2024-06-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Nonlinearity and dimensionality have always been computationally challenging problems when it comes to the online implementation of optimization-based control approaches, especially in the presence of disturbances. In this paper, we show how to alleviate the problem via a variable reformulation derived from differential flatness for a quadcopter vehicle. More specifically, we present a robust model predictive control design, to track a predefined trajectory of a quadcopter in the presence of disturbances. The synthesis procedure starts with a coordinate change mediated by the model's flatness property. In this new representation, the dynamics become linear in closed-loop at the price of more convoluted constraint expressions, which are usually disregarded in the literature or simple approximations are proposed. Subsequently, with a proper parameterization to portray the feasible domain, the trajectory tracking problem is transformed into the stabilization of a constrained linear time-invariant system under disturbances, which is then handled by a robust model predictive controller. Simulations and experimental results are presented to analyze and validate the proposed scheme.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e2f8aa7582a93f39d79be08c42d5a1fe77bda997" target='_blank'>
              Tube MPC via flatness for multicopter trajectory tracking
              </a>
            </td>
          <td>
            H. Do, I. Prodan
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="Real-world non-autonomous systems are open, out-of-equilibrium systems that evolve in and are driven by temporally varying environments. Such systems can show multiple timescale and transient dynamics together with transitions to very different and, at times, even disastrous dynamical regimes. Since such critical transitions disrupt the systems' intended or desired functionality, it is crucial to understand the underlying mechanisms, to identify precursors of such transitions, and to reliably detect them in time series of suitable system observables to enable forecasts. This review critically assesses the various steps of investigation involved in time-series-analysis-based detection of critical transitions in real-world non-autonomous systems: from the data recording to evaluating the reliability of offline and online detections. It will highlight pros and cons to stimulate further developments, which would be necessary to advance understanding and forecasting nonlinear behavior such as critical transitions in complex systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0b774b7e6f09a7e0224e2806d7eeec8722233491" target='_blank'>
              Time-series-analysis-based detection of critical transitions in real-world non-autonomous systems.
              </a>
            </td>
          <td>
            Klaus Lehnertz
          </td>
          <td>2024-06-07</td>
          <td>Chaos</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="In the wild, we often encounter collections of sequential data such as electrocardiograms, motion capture, genomes, and natural language, and sequences may be multichannel or symbolic with nonlinear dynamics. We introduce a new method to learn low-dimensional representations of nonlinear time series without supervision and can have provable recovery guarantees. The learned representation can be used for downstream machine-learning tasks such as clustering and classification. The method is based on the assumption that the observed sequences arise from a common domain, but each sequence obeys its own autoregressive models that are related to each other through low-rank regularization. We cast the problem as a computationally efficient convex matrix parameter recovery problem using monotone Variational Inequality and encode the common domain assumption via low-rank constraint across the learned representations, which can learn the geometry for the entire domain as well as faithful representations for the dynamics of each individual sequence using the domain information in totality. We show the competitive performance of our method on real-world time-series data with the baselines and demonstrate its effectiveness for symbolic text modeling and RNA sequence clustering.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/374d6dcbbd6b7bc58c4e0fdbbfe9c1648975a899" target='_blank'>
              Nonlinear time-series embedding by monotone variational inequality
              </a>
            </td>
          <td>
            Jonathan Y. Zhou, Yao Xie
          </td>
          <td>2024-06-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Reservoir computing, a machine learning framework used for modeling the brain, can predict temporal data with little observations and minimal computational resources. However, it is difficult to accurately reproduce the long-term target time series because the reservoir system becomes unstable. This predictive capability is required for a wide variety of time-series processing, including predictions of motor timing and chaotic dynamical systems. This study proposes oscillation-driven reservoir computing (ODRC) with feedback, where oscillatory signals are fed into a reservoir network to stabilize the network activity and induce complex reservoir dynamics. The ODRC can reproduce long-term target time series more accurately than conventional reservoir computing methods in a motor timing and chaotic time-series prediction tasks. Furthermore, it generates a time series similar to the target in the unexperienced period, that is, it can learn the abstract generative rules from limited observations. Given these significant improvements made by the simple and computationally inexpensive implementation, the ODRC would serve as a practical model of various time series data. Moreover, we will discuss biological implications of the ODRC, considering it as a model of neural oscillations and their cerebellar processors.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/be6e6176cecfe11f59814a81dd7ff34c2eada2b4" target='_blank'>
              Oscillations enhance time-series prediction in reservoir computing with feedback
              </a>
            </td>
          <td>
            Yuji Kawai, Takashi Morita, Jihoon Park, Minoru Asada
          </td>
          <td>2024-06-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Flow estimation problems are ubiquitous in scientific imaging. Often, the underlying flows are subject to physical constraints that can be exploited in the flow estimation; for example, incompressible (divergence-free) flows are expected for many fluid experiments, while irrotational (curl-free) flows arise in the analysis of optical distortions and wavefront sensing. In this work, we propose a Physics- Inspired Neural Network (PINN) named HDNet, which performs a Helmholtz decomposition of an arbitrary flow field, i.e., it decomposes the input flow into a divergence-only and a curl-only component. HDNet can be trained exclusively on synthetic data generated by reverse Helmholtz decomposition, which we call Helmholtz synthesis. As a PINN, HDNet is fully differentiable and can easily be integrated into arbitrary flow estimation problems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3cf74daf478f8997bca401680db82727a5ce0ee6" target='_blank'>
              HDNet: Physics-Inspired Neural Network for Flow Estimation based on Helmholtz Decomposition
              </a>
            </td>
          <td>
            Miao Qi, R. Idoughi, Wolfgang Heidrich
          </td>
          <td>2024-06-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="Temporal data modelling techniques with neural networks are useful in many domain applications, including time-series forecasting and control engineering. This paper aims at developing a recurrent version of stochastic configuration networks (RSCNs) for problem solving, where we have no underlying assumption on the dynamic orders of the input variables. Given a collection of historical data, we first build an initial RSCN model in the light of a supervisory mechanism, followed by an online update of the output weights by using a projection algorithm. Some theoretical results are established, including the echo state property, the universal approximation property of RSCNs for both the offline and online learnings, and the convergence of the output weights. The proposed RSCN model is remarkably distinguished from the well-known echo state networks (ESNs) in terms of the way of assigning the input random weight matrix and a special structure of the random feedback matrix. A comprehensive comparison study among the long short-term memory (LSTM) network, the original ESN, and several state-of-the-art ESN methods such as the simple cycle reservoir (SCR), the polynomial ESN (PESN), the leaky-integrator ESN (LIESN) and RSCN is carried out. Numerical results clearly indicate that the proposed RSCN performs favourably over all of the datasets.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/46e3c55f0b0e77192fb6cc422ecf599a47334d73" target='_blank'>
              Recurrent Stochastic Configuration Networks for Temporal Data Analytics
              </a>
            </td>
          <td>
            Dianhui Wang, Gang Dang
          </td>
          <td>2024-06-21</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>1</td>
        </tr>

        <tr id="This letter presents a high-dimensional analysis of the training dynamics for a single-layer nonlinear contrastive learning model. The empirical distribution of the model weights converges to a deterministic measure governed by a McKean-Vlasov nonlinear partial differential equation (PDE). Under L2 regularization, this PDE reduces to a closed set of low-dimensional ordinary differential equations (ODEs), reflecting the evolution of the model performance during the training process. We analyze the fixed point locations and their stability of the ODEs unveiling several interesting findings. First, only the hidden variable's second moment affects feature learnability at the state with uninformative initialization. Second, higher moments influence the probability of feature selection by controlling the attraction region, rather than affecting local stability. Finally, independent noises added in the data argumentation degrade performance but negatively correlated noise can reduces the variance of gradient estimation yielding better performance. Despite of the simplicity of the analyzed model, it exhibits a rich phenomena of training dynamics, paving a way to understand more complex mechanism behind practical large models.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6a791eb3679c0d2b194a35ba38ca2fe814772263" target='_blank'>
              Training Dynamics of Nonlinear Contrastive Learning Model in the High Dimensional Limit
              </a>
            </td>
          <td>
            Lineghuan Meng, Chuang Wang
          </td>
          <td>2024-06-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="A fast solution of supersonic flow is one of the crucial challenges in engineering applications of supersonic flight. This article introduces a deep learning framework, the supersonic physics-constrained network (SPC), for the rapid solution of unsteady supersonic flow problems. SPC integrates deep convolutional neural networks with physics-constrained methods based on the Euler equation to derive a new loss function that can accurately calculate the flow fields by considering the spatial and temporal characteristics of the flow fields at the previous moment. Compared to purely data-driven methods, SPC significantly reduces the dependency on training data volume by incorporating physical constraints. Additionally, the training process of SPC is more stable than that of data-driven methods. Taking the classic supersonic forward step flow as an example, SPC can accurately calculate strong discontinuities in the flow fields, while reducing the data volume by approximately 60%. In the generalization test experiment for forward step flow and compression ramp flow, SPC also demonstrates good predictive accuracy and generalization capability under different geometric configurations and inflow conditions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4c8d498ff31e4aaa78b1f27f392473204f410d9c" target='_blank'>
              A physics-constrained and data-driven method for modeling supersonic flow
              </a>
            </td>
          <td>
            Tong Zhao, Jian An, Yuming Xu, Guoqiang He, Fei Qin
          </td>
          <td>2024-06-01</td>
          <td>Physics of Fluids</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="In this paper, we present a convergence analysis of the Group Projected Subspace Pursuit (GPSP) algorithm proposed by He et al. [HKL+23] (Group Projected subspace pursuit for IDENTification of variable coefficient differential equations (GP-IDENT), Journal of Computational Physics, 494, 112526) and extend its application to general tasks of block sparse signal recovery. We prove that when the sampling matrix satisfies the Block Restricted Isometry Property (BRIP) with a sufficiently small Block Restricted Isometry Constant (BRIC), GPSP exactly recovers the true block sparse signals. When the observations are noisy, this convergence property of GPSP remains valid if the magnitude of true signal is sufficiently large. GPSP selects the features by subspace projection criterion (SPC) for candidate inclusion and response magnitude criterion (RMC) for candidate exclusion. We compare these criteria with counterparts of other state-of-the-art greedy algorithms. Our theoretical analysis and numerical ablation studies reveal that SPC is critical to the superior performances of GPSP, and that RMC can enhance the robustness of feature identification when observations contain noises. We test and compare GPSP with other methods in diverse settings, including heterogeneous random block matrices, inexact observations, face recognition, and PDE identification. We find that GPSP outperforms the other algorithms in most cases for various levels of block sparsity and block sizes, justifying its effectiveness for general applications.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/19e538c3f236f6fd5cbc7f615c8771d2336e3fc9" target='_blank'>
              Group Projected Subspace Pursuit for Block Sparse Signal Reconstruction: Convergence Analysis and Applications
              </a>
            </td>
          <td>
            Roy Y. He, Haixia Liu, Hao L'iu
          </td>
          <td>2024-06-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Neural networks are popular data-driven modeling tools that come with high data collection costs. This paper proposes a residual-based multipeaks adaptive sampling (RMAS) algorithm, which can reduce the demand for a large number of samples in the identification of stochastic dynamical systems. Compared to classical residual-based sampling algorithms, the RMAS algorithm achieves higher system identification accuracy without relying on any hyperparameters. Subsequently, combining the RMAS algorithm and neural network, a few-shot identification (FSI) method for stochastic dynamical systems is proposed, which is applied to the identification of a vegetation biomass change model and the Rayleigh-Van der Pol impact vibration model. We show that the RMAS algorithm modifies residual-based sampling algorithms and, in particular, reduces the system identification error by 76% with the same sample sizes. Moreover, the surrogate model accurately predicts the first escape probability density function and the P bifurcation behavior in the systems, with the error of less than 1.59×10-2. Finally, the robustness of the FSI method is validated.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/295396f31e547b6c81f17b2bb53b2116ac400a8e" target='_blank'>
              A few-shot identification method for stochastic dynamical systems based on residual multipeaks adaptive sampling.
              </a>
            </td>
          <td>
            Xiao-Kai An, Lin Du, Feng Jiang, Yu-jia Zhang, Zi-Chen Deng, Jürgen Kurths
          </td>
          <td>2024-07-01</td>
          <td>Chaos</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Solving partial differential equations (PDEs) and their inverse problems using Physics-informed neural networks (PINNs) is a rapidly growing approach in the physics and machine learning community. Although several architectures exist for PINNs that work remarkably in practice, our theoretical understanding of their performances is somewhat limited. In this work, we study the behavior of a Bayesian PINN estimator of the solution of a PDE from $n$ independent noisy measurement of the solution. We focus on a class of equations that are linear in their parameters (with unknown coefficients $\theta_\star$). We show that when the partial differential equation admits a classical solution (say $u_\star$), differentiable to order $\beta$, the mean square error of the Bayesian posterior mean is at least of order $n^{-2\beta/(2\beta + d)}$. Furthermore, we establish a convergence rate of the linear coefficients of $\theta_\star$ depending on the order of the underlying differential operator. Last but not least, our theoretical results are validated through extensive simulations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d332b278e945ecc01ec826948d1f3554cba5312b" target='_blank'>
              On the estimation rate of Bayesian PINN for inverse problems
              </a>
            </td>
          <td>
            Yi Sun, Debarghya Mukherjee, Yves Atchadé
          </td>
          <td>2024-06-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Advances in experimental techniques allow the collection of high-space-and-time resolution data that track individual motile entities over time. This poses the question of how to use these data to efficiently and effectively calibrate motion models. However, typical mathematical models often overlook the inherent aspects of data collection, such as the discreteness and the experimental noise of the measured locations. In this paper, we focus on velocity-jump models suitable to describe single-agent motion in one spatial dimension, characterised by successive Markovian transitions between a finite network of $n$ states, each with a specified velocity and a fixed rate of switching to every other state. Since the problem of finding the exact distributions of discrete-time noisy data is generally intractable, we derive a series of approximations for the data distributions and compare them to in-silico data generated by the models using four example network structures. These comparisons suggest that the approximations are accurate given sufficiently infrequent state switching, or equivalently, a sufficiently high data collection frequency. Moreover, for infrequent switching, the PDFs comparisons highlight the importance of accounting for the correlation between subsequent measured locations, due to the likely permanence in the state visited in the previous measurement. The approximate distributions computed can be used for fast parameter inference and model selection between a range of velocity-jump models using single-agent tracking data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8f4862ab7ce4151b9c0569c8c9b73d89ab08ca0e" target='_blank'>
              Approximate solutions of a general stochastic velocity-jump process subject to discrete-time noisy observations
              </a>
            </td>
          <td>
            Arianna Ceccarelli, Alexander P. Browning, Ruth E. Baker
          </td>
          <td>2024-06-28</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The integration of particle or Kalman filters with machine learning tools like support vector machines, Gaussian processes, or neural networks has seen extensive exploration in the context of prognostic and health management, particularly in model-based applications. This paper focuses on the Multi-Layer Perceptron Particle Filter (MLP-PF), a data-driven approach that harnesses the non-linearity of MLP to describe degradation trajectories without relying on a physical model. The Bayesian nature of the particle filter is utilized to update MLP parameters, providing flexibility to the method and accommodating unexpected changes in the degradation behavior. To showcase the versatility of MLP-PF, this work demonstrates its seamless integration into diverse use cases, such as lithium-ion battery analysis, virtual health monitoring for turbofans, and the assessment of fatigue crack growth. We illustrate how it effortlessly accommodates various contexts through slight parameter modifications. Adjustment includes variation in the number of neurons or layers in the MLP, threshold adjustments, initial training refinements and the adaptation of the process noise. Addressing different degradation processes across these applications, MLP-PF proves its adaptability and utility in various contexts. These findings highlight the method’s versatility in adapting to diverse use cases and its potential as a robust prognostic tool across various industries. MLP-PF offers a practical and efficient means of estimating remaining useful life and predicting degradation in complex systems, with implications for advancing prognostic tools in diverse applications.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/eb6fdd4461741278755a0c986fba0e2f5cd89de3" target='_blank'>
              Data-Driven Prognostics with Multi-Layer Perceptron Particle Filter: a Cross-Industry Exploration
              </a>
            </td>
          <td>
            Francesco Canceliere, Sylvain Girard, Jean-Marc Bourinet
          </td>
          <td>2024-06-27</td>
          <td>PHM Society European Conference</td>
          <td>0</td>
          <td>15</td>
        </tr>

        <tr id="In functional data analysis, replicate observations of a smooth functional process and its derivatives offer a unique opportunity to flexibly estimate continuous-time ordinary differential equation models. Ramsay (1996) first proposed to estimate a linear ordinary differential equation from functional data in a technique called Principal Differential Analysis, by formulating a functional regression in which the highest-order derivative of a function is modelled as a time-varying linear combination of its lower-order derivatives. Principal Differential Analysis was introduced as a technique for data reduction and representation, using solutions of the estimated differential equation as a basis to represent the functional data. In this work, we re-formulate PDA as a generative statistical model in which functional observations arise as solutions of a deterministic ODE that is forced by a smooth random error process. This viewpoint defines a flexible class of functional models based on differential equations and leads to an improved understanding and characterisation of the sources of variability in Principal Differential Analysis. It does, however, result in parameter estimates that can be heavily biased under the standard estimation approach of PDA. Therefore, we introduce an iterative bias-reduction algorithm that can be applied to improve parameter estimates. We also examine the utility of our approach when the form of the deterministic part of the differential equation is unknown and possibly non-linear, where Principal Differential Analysis is treated as an approximate model based on time-varying linearisation. We demonstrate our approach on simulated data from linear and non-linear differential equations and on real data from human movement biomechanics. Supplementary R code for this manuscript is available at \url{https://github.com/edwardgunning/UnderstandingOfPDAManuscript}.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8d0be3d0b8344a99cb8ce9f30ed01a1653af4baa" target='_blank'>
              An Understanding of Principal Differential Analysis
              </a>
            </td>
          <td>
            Edward Gunning, Giles Hooker
          </td>
          <td>2024-06-26</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Inverse problems describe the process of estimating the causal factors from a set of measurements or data. Mapping of often incomplete or degraded data to parameters is ill-posed, thus data-driven iterative solutions are required, for example when reconstructing clean images from poor signals. Diffusion models have shown promise as potent generative tools for solving inverse problems due to their superior reconstruction quality and their compatibility with iterative solvers. However, most existing approaches are limited to linear inverse problems represented as Stochastic Differential Equations (SDEs). This simplification falls short of addressing the challenging nature of real-world problems, leading to amplified cumulative errors and biases. We provide an explanation for this gap through the lens of measure-preserving dynamics of Random Dynamical Systems (RDS) with which we analyse Temporal Distribution Discrepancy and thus introduce a theoretical framework based on RDS for SDE diffusion models. We uncover several strategies that inherently enhance the stability and generalizability of diffusion models for inverse problems and introduce a novel score-based diffusion framework, the \textbf{D}ynamics-aware S\textbf{D}E \textbf{D}iffusion \textbf{G}enerative \textbf{M}odel (D$^3$GM). The \textit{Measure-preserving property} can return the degraded measurement to the original state despite complex degradation with the RDS concept of \textit{stability}. Our extensive experimental results corroborate the effectiveness of D$^3$GM across multiple benchmarks including a prominent application for inverse problems, magnetic resonance imaging. Code and data will be publicly available.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bf17cd0dcbb94d9ebc02ca488860c685bf255511" target='_blank'>
              Stability and Generalizability in SDE Diffusion Models with Measure-Preserving Dynamics
              </a>
            </td>
          <td>
            Weitong Zhang, Chengqi Zang, Liu Li, Sarah Cechnicka, Ouyang Cheng, Bernhard Kainz
          </td>
          <td>2024-06-19</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Coarse-grained models describe the macroscopic mean response of a process at large scales, which derives from stochastic processes at small scales. Common examples include accounting for velocity fluctuations in a turbulent fluid flow model and cloud evolution in climate models. Most existing techniques for constructing coarse-grained models feature ill-defined parameters whose values are arbitrarily chosen (e.g., a window size), are narrow in their applicability (e.g., only applicable to time series or spatial data), or cannot readily incorporate physics information. Here, we introduce the concept of physics-guided Gaussian process regression as a machine-learning-based coarse-graining technique that is broadly applicable and amenable to input from known physics-based relationships. Using a pair of case studies derived from molecular dynamics simulations, we demonstrate the attractive properties and superior performance of physics-guided Gaussian processes for coarse-graining relative to prevalent benchmarks. The key advantage of Gaussian-process-based coarse-graining is its ability to seamlessly integrate data-driven and physics-based information.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/cc16c4b91b82b3dc25087cb4b3937ffe3ae22c4c" target='_blank'>
              Constructing coarse-grained models with physics-guided Gaussian process regression
              </a>
            </td>
          <td>
            Yating Fang, Qian Qian Zhao, R. Sills, A. Ezzat
          </td>
          <td>2024-06-01</td>
          <td>APL Machine Learning</td>
          <td>0</td>
          <td>19</td>
        </tr>

        <tr id="Machine Learning (ML) is extensively used for predicting transfer times for general purpose Wide Area Networks (WANs) or public Internet applications, but for Research and Education Networks (RENs) two major gaps exist in literature. First, RENs i.e. networks carrying large data flows have received limited attention by the networking community. RENs behave differently compared to the general purpose Internet applications and other network types. Hence, ML models from other network types cannot be used interchangeably for large data transfers. Second, the ML models are used as blackboxes to train on measured network values and then used to predict transfer times or other runtime network parameters. In this paper, we present a dynamical systems model of the large data transfers typical of RENs in the form of a system of Ordinary Differential Equations (ODEs) inspired by the Lotka-Volterra competition model. We present a transfer time prediction component called Dynamic Transfer Time Predictor (DTTP) which solves the ODEs and predicts the future transfer times. Second we formulate a loss function based on Lyapunov function called Lyapunov Drift Correction (LDC) that self-corrects the transfer time prediction errors dynamically.To design and develop our model, we studied real-world datasets consisting of over 100 million transfer records collected from platforms such as Open Science Grid (OSG), Large Hadron Collider Optical Private Network (LHCOPN), Worldwide LHC Grid (WLCG), as well as the RENs of Internet2 and ESNet. We integrate our model into well-known neural network models and regressors and present evaluation results.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4cf5d71336cf90025f7d641a600628cc1d15b0d7" target='_blank'>
              Improving Transfer Time Prediction of ML Models via Auto-correcting Dynamical Systems Modeling
              </a>
            </td>
          <td>
            Venkat Sai Suman Lamba Karanam, B. Ramamurthy
          </td>
          <td>2024-06-24</td>
          <td>2024 IEEE 10th International Conference on Network Softwarization (NetSoft)</td>
          <td>0</td>
          <td>38</td>
        </tr>

        <tr id="We construct and compare three operator learning architectures, DeepONet, Fourier Neural Operator, and Wavelet Neural Operator, in order to learn the operator mapping a time-dependent applied current to the transmembrane potential of the Hodgkin- Huxley ionic model. The underlying non-linearity of the Hodgkin-Huxley dynamical system, the stiffness of its solutions, and the threshold dynamics depending on the intensity of the applied current, are some of the challenges to address when exploiting artificial neural networks to learn this class of complex operators. By properly designing these operator learning techniques, we demonstrate their ability to effectively address these challenges, achieving a relative L2 error as low as 1.4% in learning the solutions of the Hodgkin-Huxley ionic model.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/01df798da7a622d54d2e08c91dffe063fefb7403" target='_blank'>
              Learning the Hodgkin-Huxley Model with Operator Learning Techniques
              </a>
            </td>
          <td>
            Edoardo Centofanti, Massimiliano Ghiotto, L. Pavarino
          </td>
          <td>2024-06-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>20</td>
        </tr>

        <tr id="Energy based models (EBMs) are appealing for their generality and simplicity in data likelihood modeling, but have conventionally been difficult to train due to the unstable and time-consuming implicit MCMC sampling during contrastive divergence training. In this paper, we present a novel energy-based generative framework, Variational Potential Flow (VAPO), that entirely dispenses with implicit MCMC sampling and does not rely on complementary latent models or cooperative training. The VAPO framework aims to learn a potential energy function whose gradient (flow) guides the prior samples, so that their density evolution closely follows an approximate data likelihood homotopy. An energy loss function is then formulated to minimize the Kullback-Leibler divergence between density evolution of the flow-driven prior and the data likelihood homotopy. Images can be generated after training the potential energy, by initializing the samples from Gaussian prior and solving the ODE governing the potential flow on a fixed time interval using generic ODE solvers. Experiment results show that the proposed VAPO framework is capable of generating realistic images on various image datasets. In particular, our proposed framework achieves competitive FID scores for unconditional image generation on the CIFAR-10 and CelebA datasets.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6bc60701775b0cc308c3beaf6e494e8920626217" target='_blank'>
              Variational Potential Flow: A Novel Probabilistic Framework for Energy-Based Generative Modelling
              </a>
            </td>
          <td>
            J. Loo, Michelle Adeline, Arghya Pal, Vishnu Monn Baskaran, Chee-Ming Ting, Raphaël C.-W. Phan
          </td>
          <td>2024-07-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="With the growing interest and applications in machine learning and data science, finding an efficient method to sparse analysis the high-dimensional data and optimizing a dimension reduction model to extract lower dimensional features has becoming more and more important. Orthogonal constraints (Stiefel manifold) is a commonly met constraint in these applications, and the sparsity is usually enforced through the element-wise L1 norm. Many applications can be found on optimization over Stiefel manifold within the area of physics and machine learning. In this paper, we propose a novel idea by tackling the Stiefel manifold through an nonlinear eigen-approach by first using ADMM to split the problem into smooth optimization over manifold and convex non-smooth optimization, and then transforming the former into the form of nonlinear eigenvalue problem with eigenvector dependency (NEPv) which is solved by self-consistent field (SCF) iteration, and the latter can be found to have an closed-form solution through proximal gradient. Compared with existing methods, our proposed algorithm takes the advantage of specific structure of the objective function, and has efficient convergence results under mild assumptions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/86b67d398cb778c49186f1ac648ccc81bad37baa" target='_blank'>
              Nonlinear Eigen-approach ADMM for Sparse Optimization on Stiefel Manifold
              </a>
            </td>
          <td>
            Jiawei Wang, Rencang Li, Richard Yi Da Xu
          </td>
          <td>2024-06-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Transformer-based models have demonstrated exceptional performance across diverse domains, becoming the state-of-the-art solution for addressing sequential machine learning problems. Even though we have a general understanding of the fundamental components in the transformer architecture, little is known about how they operate or what are their expected dynamics. Recently, there has been an increasing interest in exploring the relationship between attention mechanisms and Hopfield networks, promising to shed light on the statistical physics of transformer networks. However, to date, the dynamical regimes of transformer-like models have not been studied in depth. In this paper, we address this gap by using methods for the study of asymmetric Hopfield networks in nonequilibrium regimes --namely path integral methods over generating functionals, yielding dynamics governed by concurrent mean-field variables. Assuming 1-bit tokens and weights, we derive analytical approximations for the behavior of large self-attention neural networks coupled to a softmax output, which become exact in the large limit size. Our findings reveal nontrivial dynamical phenomena, including nonequilibrium phase transitions associated with chaotic bifurcations, even for very simple configurations with a few encoded features and a very short context window. Finally, we discuss the potential of our analytic approach to improve our understanding of the inner workings of transformer models, potentially reducing computational training costs and enhancing model interpretability.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c2a1c230935b9a3eeb376741764f658296dcdd3b" target='_blank'>
              Dynamical Mean-Field Theory of Self-Attention Neural Networks
              </a>
            </td>
          <td>
            Ángel Poc-López, Miguel Aguilera
          </td>
          <td>2024-06-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Optimal control of multiple heating, ventilation, and air-conditioning units in an open-plan space demands fast and accurate thermodynamic modeling. While computational fluid dynamics is precise, it is computationally impractical for real-time control. Lumped thermal models divide the room into cells and explicitly model inter-cell air-mixing. However, solving the coupled differential equations is still computationally challenging. Data-driven methods like long-short term memory may handle non-linear thermal dynamics but face limitations in observability, adherence to physical constraints, and generalization. Physics-informed neural networks (PINN) impose physical constraints even while learning from data. However, PINNs still lack the scalability required for effective control in large open-plan offices, primarily due to air-mixing interactions Our approach, PhyGICS, combines graph neural networks with physics-informed learning (PI-GNN) to overcome these challenges. Specifically, we model the thermodynamic interactions as edges between nodes that represent cells. Further, the modeling approach allows explicit modeling of wall and window surface temperatures that are commonly ignored. PhyGICS, utilizing PI-GNN as a state-estimator, employs a receding-horizon approach for optimal HVAC control. We adapt PI-GNNs for building HVAC control by incorporating a time-resetting strategy to handle time-dependent ambient conditions and therefore set-points. Evaluations in a simulated environment with real-world data show PhyGICS outperforms a regular PINN model and other baseline control strategies on: 1) thermal model accuracy; 2) computation time; 3) energy consumption; and 4) user comfort.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/77b9dc12e24efd410665c6606c578c428451e250" target='_blank'>
              PhyGICS – A Physics-informed Graph Neural Network-based Intelligent HVAC Controller for Open-plan Spaces
              </a>
            </td>
          <td>
            S. Nagarathinam, Arunchandar Vasan
          </td>
          <td>2024-05-31</td>
          <td>Proceedings of the 15th ACM International Conference on Future and Sustainable Energy Systems</td>
          <td>0</td>
          <td>15</td>
        </tr>

        <tr id="The optimization of process systems within the field of Chemical Engineering often confronts uncertainties that can exert significant influences on the performance and dependability of the obtained solutions. This research endeavors to investigate the application of Bayesian optimization in the realm of constrained mixed integer nonlinear problems. A comparative analysis was conducted, exploring different surrogate models, and evaluating diverse kernel functions and acquisition functions. Furthermore, a sampling strategy was devised to assess the enhancement achieved by the acquisition function. The findings of this article reveal the superior performance of sparse Gaussian processes in conjunction with computationally inexpensive acquisition functions, thereby highlighting their suitability for addressing mixed integer nonlinear programming problems characterized by noisy functions and stochastic behavior. Consequently, this article presents a computationally efficient approach to effectively tackle the challenges associated with data‐driven mixed integer nonlinear programming problems within the domain of Process System Engineering.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c7451794a9973ec908c182dd426f6c81b49a2139" target='_blank'>
              A Bayesian optimization approach for data‐driven mixed‐integer nonlinear programming problems
              </a>
            </td>
          <td>
            Javier Morlet-Espinosa, A. Flores‐Tlacuahuac
          </td>
          <td>2024-06-04</td>
          <td>AIChE Journal</td>
          <td>0</td>
          <td>29</td>
        </tr>

        <tr id="In this paper, we study efficient approximate sampling for probability distributions known up to normalization constants. We specifically focus on a problem class arising in Bayesian inference for large-scale inverse problems in science and engineering applications. The computational challenges we address with the proposed methodology are: (i) the need for repeated evaluations of expensive forward models; (ii) the potential existence of multiple modes; and (iii) the fact that gradient of, or adjoint solver for, the forward model might not be feasible. While existing Bayesian inference methods meet some of these challenges individually, we propose a framework that tackles all three systematically. Our approach builds upon the Fisher-Rao gradient flow in probability space, yielding a dynamical system for probability densities that converges towards the target distribution at a uniform exponential rate. This rapid convergence is advantageous for the computational burden outlined in (i). We apply Gaussian mixture approximations with operator splitting techniques to simulate the flow numerically; the resulting approximation can capture multiple modes thus addressing (ii). Furthermore, we employ the Kalman methodology to facilitate a derivative-free update of these Gaussian components and their respective weights, addressing the issue in (iii). The proposed methodology results in an efficient derivative-free sampler flexible enough to handle multi-modal distributions: Gaussian Mixture Kalman Inversion (GMKI). The effectiveness of GMKI is demonstrated both theoretically and numerically in several experiments with multimodal target distributions, including proof-of-concept and two-dimensional examples, as well as a large-scale application: recovering the Navier-Stokes initial condition from solution data at positive times.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0d77575c529cb455ba8ac5289fe0e14615a7c4f1" target='_blank'>
              Efficient, Multimodal, and Derivative-Free Bayesian Inference With Fisher-Rao Gradient Flows
              </a>
            </td>
          <td>
            Yifan Chen, Daniel Zhengyu Huang, Jiaoyang Huang, Sebastian Reich, Andrew M. Stuart
          </td>
          <td>2024-06-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id="In this work, we propose a set of physics-informed geometric operators (GOs) to enrich the geometric data provided for training surrogate/discriminative models, dimension reduction, and generative models, typically employed for performance prediction, dimension reduction, and creating data-driven parameterisations, respectively. However, as both the input and output streams of these models consist of low-level shape representations, they often fail to capture shape characteristics essential for performance analyses. Therefore, the proposed GOs exploit the differential and integral properties of shapes--accessed through Fourier descriptors, curvature integrals, geometric moments, and their invariants--to infuse high-level intrinsic geometric information and physics into the feature vector used for training, even when employing simple model architectures or low-level parametric descriptions. We showed that for surrogate modelling, along with the inclusion of the notion of physics, GOs enact regularisation to reduce over-fitting and enhance generalisation to new, unseen designs. Furthermore, through extensive experimentation, we demonstrate that for dimension reduction and generative models, incorporating the proposed GOs enriches the training data with compact global and local geometric features. This significantly enhances the quality of the resulting latent space, thereby facilitating the generation of valid and diverse designs. Lastly, we also show that GOs can enable learning parametric sensitivities to a great extent. Consequently, these enhancements accelerate the convergence rate of shape optimisers towards optimal solutions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e89b2b8bdad2c98d764f8c828e40b1065ff7464d" target='_blank'>
              Physics-Informed Geometric Operators to Support Surrogate, Dimension Reduction and Generative Models for Engineering Design
              </a>
            </td>
          <td>
            Shahroz Khan, Zahid Masood, Muhammad Usama, Konstantinos V. Kostas, P. Kaklis, Wei Chen
          </td>
          <td>2024-07-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>21</td>
        </tr>

        <tr id="We discuss an approach to mathematically modelling systems made of objects that are coupled together, using generative models of the dependence relationships between states (or trajectories) of the things comprising such systems. This broad class includes open or non-equilibrium systems and is especially relevant to self-organising systems. The ensuing variational free energy principle (FEP) has certain advantages over using random dynamical systems explicitly, notably, by being more tractable and offering a parsimonious explanation of why the joint system evolves in the way that it does, based on the properties of the coupling between system components. Using the FEP allows us to model the dynamics of an object as if it were a process of variational inference, because variational free energy (or surprisal) is a Lyapunov function for its dynamics. In short, we argue that using generative models to represent and track relations among subsystems leads us to a particular statistical theory of interacting systems. Conversely, this theory enables us to construct nested models that respect the known relations among subsystems. We point out that the fact that a physical object conforms to the FEP does not necessarily imply that this object performs inference in the literal sense; rather, it is a useful explanatory fiction which replaces the 'explicit' dynamics of the object with an 'implicit' flow on free energy gradients - a fiction that may or may not be entertained by the object itself.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7d9000095cab2d2187f9dc3eb5aeba6fe5752a46" target='_blank'>
              An approach to non-equilibrium statistical physics using variational Bayesian inference
              </a>
            </td>
          <td>
            M. Ramstead, D. A. R. Sakthivadivel, K. Friston
          </td>
          <td>2024-06-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>23</td>
        </tr>

        <tr id="In this work, we discuss the use of a recently introduced machine learning (ML) technique known as Fourier neural operators (FNO) as an efficient alternative to the traditional solution of the time-dependent Schrödinger equation (TDSE). FNOs are ML models which are employed in the approximated solution of partial differential equations. For a wavepacket propagating in an anharmonic potential and for a tunneling system, we show that the FNO approach can accurately and faithfully model wavepacket propagation via the density. Additionally, we demonstrate that FNOs can be a suitable replacement for traditional TDSE solvers in cases where the results of the quantum dynamical simulation are required repeatedly such as in the case of parameter optimization problems (e.g., control). The speed-up from the FNO method allows for its combination with the Markov-chain Monte Carlo approach in applications that involve solving inverse problems such as optimal and coherent laser control of the outcome of dynamical processes.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e9adc38ac192d36f40f2d38abb968ebc1c04c08b" target='_blank'>
              Accelerating wavepacket propagation with machine learning.
              </a>
            </td>
          <td>
            Kanishka Singh, Ka Hei Lee, Daniel Peláez, A. Bande
          </td>
          <td>2024-06-21</td>
          <td>Journal of computational chemistry</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="The unfolding of detector effects in experimental data is critical for enabling precision measurements in high-energy physics. However, traditional unfolding methods face challenges in scalability, flexibility, and dependence on simulations. We introduce a novel unfolding approach using conditional Denoising Diffusion Probabilistic Models (cDDPM). Our method utilizes the cDDPM for a non-iterative, flexible posterior sampling approach, which exhibits a strong inductive bias that allows it to generalize to unseen physics processes without explicitly assuming the underlying distribution. We test our approach by training a single cDDPM to perform multidimensional particle-wise unfolding for a variety of physics processes, including those not seen during training. Our results highlight the potential of this method as a step towards a"universal"unfolding tool that reduces dependence on truth-level assumptions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e1f5deb4a4d6beedb5bdd63c8435ba7aea302410" target='_blank'>
              Towards Universal Unfolding of Detector Effects in High-Energy Physics using Denoising Diffusion Probabilistic Models
              </a>
            </td>
          <td>
            Camila Pazos, Shuchin Aeron, P. Beauchemin, Vincent Croft, Martin Klassen, Taritree Wongjirad
          </td>
          <td>2024-06-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>41</td>
        </tr>

        <tr id="Time-varying optimization problems are central to many engineering applications, where performance metrics and system constraints evolve dynamically with time. A number of algorithms have been proposed in recent years to solve such problems; a common feature of all these methods is that they implicitly require precise knowledge of the temporal variability of the solutions in order to exactly track the optimizers. In this paper, we seek to lift these stringent assumptions. Our main result is a fundamental characterization, showing that an algorithm can track an optimal trajectory if and only if it contains a model of the temporal variability of the problem. We refer to this concept to as the internal model principle of time-varying optimization. By recasting the optimization objective as a nonlinear regulation problem and using tools from center manifold theory, we provide necessary and sufficient conditions both for an optimization algorithm to achieve exact asymptotic tracking and for such an algorithm to exist. We illustrate the applicability of the approach numerically on both synthetic problems as well as practical problems in transportation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8aee1c4d1d9bfe7e68a03ee2eb770d81f18d112d" target='_blank'>
              The Internal Model Principle of Time-Varying Optimization
              </a>
            </td>
          <td>
            G. Bianchin, Bryan Van Scoy
          </td>
          <td>2024-07-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>11</td>
        </tr>

        <tr id="Inverse stochastic resonance (ISR) is a phenomenon where noise reduces rather than increases the firing rate of a neuron, sometimes leading to complete quiescence. ISR was first experimentally verified with cerebellar Purkinje neurons. These experiments showed that ISR enables optimal information transfer between the input and output spike train of neurons. Subsequent studies demonstrated the efficiency of information processing and transfer in neural networks with small-world topology. We conducted a numerical investigation into the impact of adaptivity on ISR in a small-world network of noisy FitzHugh-Nagumo (FHN) neurons, operating in a bistable regime with a stable fixed point and a limit cycle -- a prerequisite for ISR. Our results show that the degree of ISR is highly dependent on the FHN model's timescale separation parameter $\epsilon$. The network structure undergoes dynamic adaptation via mechanisms of either spike-time-dependent plasticity (STDP) with potentiation-/depression-domination parameter $P$, or homeostatic structural plasticity (HSP) with rewiring frequency $F$. We demonstrate that both STDP and HSP amplify ISR when $\epsilon$ lies within the bistability region of FHN neurons. Specifically, at larger values of $\epsilon$ within the bistability regime, higher rewiring frequencies $F$ enhance ISR at intermediate (weak) synaptic noise intensities, while values of $P$ consistent with depression-domination (potentiation-domination) enhance (deteriorate) ISR. Moreover, although STDP and HSP parameters may jointly enhance ISR, $P$ has a greater impact on ISR compared to $F$. Our findings inform future ISR enhancement strategies in noisy artificial neural circuits, aiming to optimize information transfer between input and output spike trains in neuromorphic systems, and prompt venues for experiments in neural networks.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d7c658287ef239a4055ba2bf2436639fd02518af" target='_blank'>
              Inverse stochastic resonance in adaptive small-world neural networks
              </a>
            </td>
          <td>
            Marius E. Yamakou, Jinjie Zhu, Erik A. Martens
          </td>
          <td>2024-07-03</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>9</td>
        </tr>

        <tr id="In multilayer complex networks, the uncertainty in node states leads to intricate behaviors. It is, therefore, of great importance to be able to estimate the states of target nodes in these systems, both for theoretical advancements and practical applications. This paper introduces a state observer-based approach for the state estimation of such networks, focusing specifically on a class of complex dynamic networks with nodes that correspond one-to-one. Initially, a chaotic system is employed to model the dynamics of each node and highlight the essential state components for analysis and derivation. A network state observer is then constructed using a unique diagonal matrix, which underpins the driver and response-layer networks. By integrating control theory and stability function analysis, the effectiveness of the observer in achieving synchronization between complex dynamic networks and target systems is confirmed. Additionally, the efficacy and precision of the proposed method are validated through simulation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/cd898ee780466c2c104b7862223e1dabdc80de43" target='_blank'>
              Dynamical Analysis and Synchronization of Complex Network Dynamic Systems under Continuous-Time
              </a>
            </td>
          <td>
            Rui Yang, Huaigu Tian, Zhen Wang, Wei Wang, Yang Zhang
          </td>
          <td>2024-06-04</td>
          <td>Symmetry</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Modeling microbial metabolic dynamics is important for the rational optimization of both biosynthetic systems and industrial processes to facilitate green and efficient biomanufacturing. Classical approaches utilize explicit equation systems to represent metabolic networks, enabling the quantification of pathway fluxes to identify metabolic bottlenecks. However, these white-box models, despite their diverse applications, have limitations in simulating metabolic dynamics and are intrinsically inaccurate for industrial strains that lack information on network structures and kinetic parameters. On the other hand, black-box models do not rely on prior mechanistic knowledge of strains but are built upon observed time-series trajectories of biosynthetic systems in action. In practice, these observations are typically irregular, with discontinuously observed time points across multiple independent batches, each time point potentially containing missing measurements. Learning from such irregular data remains challenging for existing approaches. To address this issue, we present the Bidirectional Time-Series State Transfer Network (BTSTN) for modeling metabolic dynamics directly from irregular observations. Using evaluation data sets derived from both ideal dynamic systems and a real-world fermentation process, we demonstrate that BTSTN accurately reconstructs dynamic behaviors and predicts future trajectories. This approach exhibits enhanced robustness against missing measurements and noise, as compared to the state-of-the-art methods.IMPORTANCEIndustrial biosynthetic systems often involve strains with unclear genetic backgrounds, posing challenges in modeling their distinct metabolic dynamics. In such scenarios, white-box models, which commonly rely on inferred networks, are thereby of limited applicability and accuracy. In contrast, black-box models, such as statistical models and neural networks, are directly fitted or learned from observed time-series trajectories of biosynthetic systems in action. These methods typically assume regular observations without missing time points or measurements. If the observations are irregular, a pre-processing step becomes necessary to obtain a fully filled data set for subsequent model training, which, at the same time, inevitably introduces errors into the resulting models. BTSTN is a novel approach that natively learns from irregular observations. This distinctive feature makes it a unique addition to the current arsenal of technologies modeling metabolic dynamics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/785a05393eb4183a5588329b88690a34dd79651f" target='_blank'>
              Learning metabolic dynamics from irregular observations by Bidirectional Time-Series State Transfer Network.
              </a>
            </td>
          <td>
            Shaohua Xu, Ting Xu, Yuping Yang, Xin Chen
          </td>
          <td>2024-07-26</td>
          <td>mSystems</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Many important phenomena in chemistry and biology are realized via dynamical features such as multi-stability, oscillations, and chaos. Construction of novel chemical systems with such finely-tuned dynamics is a challenging problem central to the growing field of synthetic biology. In this paper, we address this problem by putting forward a molecular version of a recurrent artificial neural network, which we call a recurrent neural chemical reaction network (RNCRN). We prove that the RNCRN, with sufficiently many auxiliary chemical species and suitable fast reactions, can be systematically trained to achieve any dynamics. This approximation ability is shown to hold independent of the initial conditions for the auxiliary species, making the RNCRN more experimentally feasible. To demonstrate the results, we present a number of relatively simple RNCRNs trained to display a variety of biologically-important dynamical features.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f5a91dd6388e9a3802dccb6e3ec719b06acd65c1" target='_blank'>
              Recurrent neural chemical reaction networks that approximate arbitrary dynamics
              </a>
            </td>
          <td>
            Alexander Dack, Benjamin Qureshi, T. Ouldridge, Tomislav Plesa
          </td>
          <td>2024-06-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>32</td>
        </tr>

        <tr id="Areas of computational mechanics such as uncertainty quantification and optimization usually involve repeated evaluation of numerical models that represent the behavior of engineering systems. In the case of complex nonlinear systems however, these models tend to be expensive to evaluate, making surrogate models quite valuable. Artificial neural networks approximate systems very well by taking advantage of the inherent information of its given training data. In this context, this paper investigates the improvement of the training process by including sensitivity information, which are partial derivatives w.r.t. inputs, as outlined by Sobolev training. In computational mechanics, sensitivities can be applied to neural networks by expanding the training loss function with additional loss terms, thereby improving training convergence resulting in lower generalisation error. This improvement is shown in two examples of linear and non-linear material behavior. More specifically, the Sobolev designed loss function is expanded with residual weights adjusting the effect of each loss on the training step. Residual weighting is the given scaling to the different training data, which in this case are response and sensitivities. These residual weights are optimized by an adaptive scheme, whereby varying objective functions are explored, with some showing improvements in accuracy and precision of the general training convergence.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bc84ce2dba59d576dd4d3f10a9b0f7b62826171a" target='_blank'>
              Sobolev neural network with residual weighting as a surrogate in linear and non-linear mechanics
              </a>
            </td>
          <td>
            A.O.M. Kilicsoy, J. Liedmann, M. Valdebenito, F. Barthold, M. Faes
          </td>
          <td>2024-07-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>23</td>
        </tr>

        <tr id="The brain needs to perform time-critical computations to ensure survival. A potential solution lies in the non-local, distributed computation at the whole-brain level made possible by criticality and amplified by the rare long-range connections found in the brain’s unique anatomical structure. This non-locality can be captured by the mathematical structure of Schrödinger’s wave equation, which is at the heart of the novel CHARM (Complex Harmonics decomposition) framework that performs the necessary dimensional manifold reduction able to extract non-locality in critical spacetime brain dynamics. Using a large neuroimaging dataset of over 1,000 people, CHARM captured the critical, non-local/long-range nature of brain dynamics and the underlying mechanisms were established using a precise whole-brain model. Equally, CHARM revealed the significantly different critical dynamics of wakefulness and sleep. Overall, CHARM is a promising theoretical framework for capturing the low-dimensionality of the complex network dynamics observed in neuroscience and provides evidence that networks of brain regions rather than individual brain regions are the key computational engines of critical brain dynamics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/79c92bde562ae0356acda295ead7128e8c11928b" target='_blank'>
              Complex harmonics reveal low-dimensional manifolds of critical brain dynamics
              </a>
            </td>
          <td>
            G. Deco, Y. Perl, M. Kringelbach
          </td>
          <td>2024-06-16</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>13</td>
        </tr>

        <tr id="Dynamic Positron Emission Tomography (dPET) imaging and Time-Activity Curve (TAC) analyses are essential for understanding and quantifying the biodistribution of radiopharmaceuticals over time and space. Traditional compartmental modeling, while foundational, commonly struggles to fully capture the complexities of biological systems, including non-linear dynamics and variability. This study introduces an innovative data-driven neural network-based framework, inspired by Reaction Diffusion systems, designed to address these limitations. Our approach, which adaptively fits TACs from dPET, enables the direct calibration of diffusion coefficients and reaction terms from observed data, offering significant improvements in predictive accuracy and robustness over traditional methods, especially in complex biological scenarios. By more accurately modeling the spatio-temporal dynamics of radiopharmaceuticals, our method advances modeling of pharmacokinetic and pharmacodynamic processes, enabling new possibilities in quantitative nuclear medicine.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/db7e97f4a77c199435d67bf7917712e6bcfb5bc2" target='_blank'>
              Beyond Conventional Parametric Modeling: Data-Driven Framework for Estimation and Prediction of Time Activity Curves in Dynamic PET Imaging
              </a>
            </td>
          <td>
            N. Zakariaei, Arman Rahmim, Eldad Haber
          </td>
          <td>2024-05-31</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Mechanistic models of dynamic, interacting cell populations have yielded many insights into the growth and resolution of immune responses. Historically these models have described the behavior of pre-defined cell types based on small numbers of phenotypic markers. The ubiquity of deep phenotyping therefore presents a new challenge; how do we confront tractable and interpretable mathematical models with high-dimensional data? To tackle this problem, we studied the development and persistence of lung-resident memory CD4 and CD8 T cells (TRM) in mice infected with influenza virus. We developed an approach in which dynamical model parameters and the population structure are inferred simultaneously. This method uses deep learning and stochastic variational inference and is trained on the single-cell flow-cytometry data directly, rather than on the kinetics of pre-identified clusters. We show that during the resolution phase of the immune response, memory CD4 and CD8 T cells within the lung are phenotypically diverse, with subsets exhibiting highly distinct and time-dependent dynamics. TRM heterogeneity is maintained long-term by ongoing differentiation of relatively persistent Bcl-2hi CD4 and CD8 TRM subsets which resolve into distinct functional populations. Our approach yields new insights into the dynamics of tissue-localized immune memory, and is a novel basis for interpreting time series of high-dimensional data, broadly applicable to diverse biological systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/de98a7caad311fa21b6e5ae069bafe928ed0e792" target='_blank'>
              A variational deep-learning approach to modeling memory T cell dynamics
              </a>
            </td>
          <td>
            C. V. van Dorp, Joshua I. Gray, Daniel H. Paik, Donna L. Farber, Andrew J. Yates
          </td>
          <td>2024-07-11</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="The primal approach to physics-informed learning is a residual minimization. We argue that residual is, at best, an indirect measure of the error of approximate solution and propose to train with error majorant instead. Since error majorant provides a direct upper bound on error, one can reliably estimate how close PiNN is to the exact solution and stop the optimization process when the desired accuracy is reached. We call loss function associated with error majorant $\textbf{Astral}$: neur$\textbf{A}$l a po$\textbf{ST}$erio$\textbf{RI}$ function$\textbf{A}$l Loss. To compare Astral and residual loss functions, we illustrate how error majorants can be derived for various PDEs and conduct experiments with diffusion equations (including anisotropic and in the L-shaped domain), convection-diffusion equation, temporal discretization of Maxwell's equation, and magnetostatics problem. The results indicate that Astral loss is competitive to the residual loss, typically leading to faster convergence and lower error (e.g., for Maxwell's equations, we observe an order of magnitude better relative error and training time). We also report that the error estimate obtained with Astral loss is usually tight enough to be informative, e.g., for a highly anisotropic equation, on average, Astral overestimates error by a factor of $1.5$, and for convection-diffusion by a factor of $1.7$.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b32fe6ecb82e3bd52fd301e700773cb8b6e06af2" target='_blank'>
              Astral: training physics-informed neural networks with error majorants
              </a>
            </td>
          <td>
            V. Fanaskov, Tianchi Yu, Alexander Rudikov, I. Oseledets
          </td>
          <td>2024-06-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Stochastic Analytic Continuation (SAC) of Quantum Monte Carlo (QMC) imaginary-time correlation function data is a valuable tool in connecting many-body models to experiments. Recent developments of the SAC method have allowed for spectral functions with sharp features, e.g. narrow peaks and divergent edges, to be resolved with unprecedented fidelity. Often times, it is not known what exact sharp features are present a priori, and, due to the ill-posed nature of the analytic continuation problem, multiple spectral representations may be acceptable. In this work, we borrow from the machine learning and statistics literature and implement a cross validation technique to provide an unbiased method to identify the most likely spectrum. We show examples using imaginary-time data generated by QMC simulations and synthetic data generated from artificial spectra. Our procedure, which can be considered a form of"model selection,"can be applied to a variety of numerical analytic continuation methods, beyond just SAC.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5883e9c8f116a9429fe69552dbcff3deba372cb1" target='_blank'>
              Cross Validation in Stochastic Analytic Continuation
              </a>
            </td>
          <td>
            Gabe Schumm, Sibin Yang, Anders Sandvik
          </td>
          <td>2024-06-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Stochastic differential equation (SDE) models are the foundation for pricing and hedging financial derivatives. The drift and volatility functions in SDE models are typically chosen to be algebraic functions with a small number (less than 5) parameters which can be calibrated to market data. A more flexible approach is to use neural networks to model the drift and volatility functions, which provides more degrees-of-freedom to match observed market data. Training of models requires optimizing over an SDE, which is computationally challenging. For European options, we develop a fast stochastic gradient descent (SGD) algorithm for training the neural network-SDE model. Our SGD algorithm uses two independent SDE paths to obtain an unbiased estimate of the direction of steepest descent. For American options, we optimize over the corresponding Kolmogorov partial differential equation (PDE). The neural network appears as coefficient functions in the PDE. Models are trained on large datasets (many contracts), requiring either large simulations (many Monte Carlo samples for the stock price paths) or large numbers of PDEs (a PDE must be solved for each contract). Numerical results are presented for real market data including S&P 500 index options, S&P 100 index options, and single-stock American options. The neural-network-based SDE models are compared against the Black-Scholes model, the Dupire's local volatility model, and the Heston model. Models are evaluated in terms of how accurate they are at pricing out-of-sample financial derivatives, which is a core task in derivative pricing at financial institutions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a8f6b1c99e8ae54bfdda8277b9e7880d34a1f49e" target='_blank'>
              Machine Learning Methods for Pricing Financial Derivatives
              </a>
            </td>
          <td>
            Lei Fan, Justin A. Sirignano
          </td>
          <td>2024-06-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>16</td>
        </tr>

        <tr id="The dynamics of supercooled liquids slow down and become increasingly heterogeneous as they are cooled. Recently, local structural variables identified using machine learning, such as"softness", have emerged as predictors of local dynamics. Here we construct a model using softness to describe the structural origins of dynamical heterogeneity in supercooled liquids. In our model, the probability of particles to rearrange is determined by their softness, and each rearrangement induces changes in the softness of nearby particles, describing facilitation. We show how to ensure that these changes respect the underlying time-reversal symmetry of the liquid's dynamics. The model reproduces the salient features of dynamical heterogeneity, and demonstrates how long-ranged dynamical correlations can emerge at long time scales from a relatively short softness correlation length.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d32819cfd5ee45a8ac43a269f5f4b86638fff470" target='_blank'>
              The dynamics of machine-learned"softness"in supercooled liquids describe dynamical heterogeneity
              </a>
            </td>
          <td>
            S. Ridout, Andrea J. Liu
          </td>
          <td>2024-06-09</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="We propose a meta-learning method for modeling Hamiltonian dynamics from a limited number of data. Although Hamiltonian neural networks have been successfully used for modeling dynamics that obey the energy conservation law, they require many data to achieve high performance. The proposed method meta-learns our neural network-based model using datasets in various dynamical systems, such that our model can predict vector fields of unseen systems. In our model, a system representation is inferred from given small data using an encoder network. Then, the system-specific vector field is predicted by modeling the Hamiltonian using a Gaussian process (GP) with neural network-based mean and kernel functions that depend on the inferred system representation. This GP-based Hamiltonian allows us to analytically obtain predictions that are adapted to small data while imposing the constraint of the conservation law. The neural networks are shared across systems, which enables us to learn knowledge from multiple systems, and use it for unseen systems. In our experiments, we demonstrate that the proposed method outperforms existing methods for predicting dynamics from a small number of observations in target systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/37ac3a5b751bd136ecb4369b5f0c68f06bf4a91f" target='_blank'>
              Symplectic Neural Gaussian Processes for Meta-learning Hamiltonian Dynamics
              </a>
            </td>
          <td>
            Tomoharu Iwata, Yusuke Tanaka
          </td>
          <td>2024-08-01</td>
          <td>Proceedings of the Thirty-ThirdInternational Joint Conference on Artificial Intelligence</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Building on the theoretical insights of Part I, this paper, as the second part of the tutorial, dives deeper into data-driven power flow linearization (DPFL), focusing on comprehensive numerical testing. The necessity of these simulations stems from the theoretical analysis's inherent limitations, particularly the challenge of identifying the differences in real-world performance among DPFL methods with overlapping theoretical capabilities and/or limitations. The absence of a comprehensive numerical comparison of DPFL approaches in the literature also motivates this paper, especially given the fact that over 95% of existing DPFL studies have not provided any open-source codes. To bridge the gap, this paper first reviews existing DPFL experiments, examining the adopted test scenarios, load fluctuation settings, data sources, considerations for data noise/outliers, and the comparison made so far. Subsequently, this paper evaluates a total of 44 methods, containing over 30 existing DPFL approaches, some innovative DPFL techniques, and several classic physics-driven power flow linearization methods for benchmarking. The evaluation spans various dimensions, including generalizability, applicability, accuracy, and computational efficiency, using various different test cases scaling from 9-bus to 1354-bus systems. The numerical analysis identifies and examines significant trends and consistent findings across all methods under various test cases. It also offers theoretical insights into phenomena like under-performance, failure, excessive computation times, etc. Overall, this paper identifies the differences in the performances of the wide range of DPFL methods, reveals gaps not evident from theoretical discussions, assists in method selection for real-world applications, and provides thorough discussions on open questions within DPFL research, indicating ten potential future directions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0f47d0913cfb09769bbb1f75b23b0e2b9ebd2c2c" target='_blank'>
              Data-driven Power Flow Linearization: Simulation
              </a>
            </td>
          <td>
            Mengshuo Jia, Gabriela Hug, Ning Zhang, Zhaojian Wang, Yi Wang, Chongqing Kang
          </td>
          <td>2024-06-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>31</td>
        </tr>

        <tr id="Verification of uncertain, complex dynamical systems is crucial in the modern day world. An increasingly common method to verify complex logic specifications for dynamical systems involves symbolic abstractions: simpler, finite-state models whose behaviour mimics the one of the systems of interest. By sampling trajectories of the concrete, unknown system and via robust analysis, we build a data-driven abstraction, related to the underlying model through a probabilistic behavioural inclusion relation. As the distribution from which the trajectories are drawn is unknown, we adopt two distinct distribution-free theories, namely scenario optimization and conformal prediction. We compare and discuss the differences between the two approaches in terms of the type of guarantees that they are able to provide. Furthermore, via experimental benchmarks we outline the efficiency of the two methods with respect to the number of samples available and the tightness of the guarantees.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a4bc6fac276ef549b5a06e10e0b424eaf5ed1fd7" target='_blank'>
              Scenario Approach and Conformal Prediction for Verification of Unknown Systems via Data-Driven Abstractions
              </a>
            </td>
          <td>
            Rudi Coppola, Andrea Peruffo, Lars Lindemann, Manuel Mazo
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id="Controlling the evolution of complex physical systems is a fundamental task across science and engineering. Classical techniques suffer from limited applicability or huge computational costs. On the other hand, recent deep learning and reinforcement learning-based approaches often struggle to optimize long-term control sequences under the constraints of system dynamics. In this work, we introduce Diffusion Physical systems Control (DiffPhyCon), a new class of method to address the physical systems control problem. DiffPhyCon excels by simultaneously minimizing both the learned generative energy function and the predefined control objectives across the entire trajectory and control sequence. Thus, it can explore globally and identify near-optimal control sequences. Moreover, we enhance DiffPhyCon with prior reweighting, enabling the discovery of control sequences that significantly deviate from the training distribution. We test our method in 1D Burgers' equation and 2D jellyfish movement control in a fluid environment. Our method outperforms widely applied classical approaches and state-of-the-art deep learning and reinforcement learning methods. Notably, DiffPhyCon unveils an intriguing fast-close-slow-open pattern observed in the jellyfish, aligning with established findings in the field of fluid dynamics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2ed151b432bd4c9d4bafa7399dadc48d42ebe3d6" target='_blank'>
              A Generative Approach to Control Complex Physical Systems
              </a>
            </td>
          <td>
            Long Wei, Peiyan Hu, Ruiqi Feng, Haodong Feng, Yixuan Du, Tao Zhang, Rui Wang, Yue Wang, Zhi-Ming Ma, Tailin Wu
          </td>
          <td>2024-07-09</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="We present a dimension-incremental method for function approximation in bounded orthonormal product bases to learn the solutions of various differential equations. Therefore, we deconstruct the source function of the differential equation into parameters like Fourier or Spline coefficients and treat the solution of the differential equation as a high-dimensional function w.r.t. the spatial variables, these parameters and also further possible parameters from the differential equation itself. Finally, we learn this function in the sense of sparse approximation in a suitable function space by detecting coefficients of the basis expansion with largest absolute value. Investigating the corresponding indices of the basis coefficients yields further insights on the structure of the solution as well as its dependency on the parameters and their interactions and allows for a reasonable generalization to even higher dimensions and therefore better resolutions of the deconstructed source function.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0de000a0bd01b131094e72a67c83522ecef7bd9b" target='_blank'>
              Operator learning based on sparse high-dimensional approximation
              </a>
            </td>
          <td>
            Daniel Potts, Fabian Taubert
          </td>
          <td>2024-06-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="We explore the dynamics of a swarmalator population comprising second-order harmonics in phase interaction. A key observation in our study is the emergence of the active asynchronous state in swarmalators with second-order harmonics, mirroring findings in the one-dimensional analog of the model, accompanied by the formation of clustered states. Particularly, we observe a transition from the static asynchronous state to the active phase wave state via the active asynchronous state. We have successfully delineated and quantified the stability boundary of the active asynchronous state through a completely data-driven method. This was achieved by utilizing the enhanced image processing capabilities of convolutional neural networks, specifically, the U-Net architecture. Complementing this data-driven analysis, our study also incorporates an analytical stability of the clustered states, providing a multifaceted perspective on the system's behavior. Our investigation not only sheds light on the nuanced behavior of swarmalators under second-order harmonics, but also demonstrates the efficacy of convolutional neural networks in analyzing complex dynamical systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/beae0a544893393f36be3f405efaf41f1b437748" target='_blank'>
              Data-driven exploration of swarmalators with second-order harmonics.
              </a>
            </td>
          <td>
            R. Senthamizhan, R. Gopal, V. K. Chandrasekar
          </td>
          <td>2024-06-01</td>
          <td>Physical review. E</td>
          <td>0</td>
          <td>23</td>
        </tr>

        <tr id="Encoding frequency stability constraints in the operation problem is challenging due to its complex dynamics. Recently, data-driven approaches have been proposed to learn the stability criteria offline with the trained model embedded as a constraint of online optimization. However, random sampling of stationary operation points is less efficient in generating balanced stable and unstable samples. Meanwhile, the performance of such a model is strongly dependent on the quality of the training dataset. Observing this research gap, we propose a gradient-based data generation method via forward-mode automatic differentiation. In this method, the original dynamic system is augmented with new states that represent the dynamic of sensitivities of the original states, which can be solved by invoking any ODE solver for a single time. To compensate for the contradiction between the gradient of various frequency stability criteria, gradient surgery is proposed by projecting the gradient on the normal plane of the other. In the end, we demonstrate the superior performance of the proposed sampling algorithm, compared with the unrolling differentiation and finite difference. All codes are available at https://github.com/xuwkk/frequency_sample_ad.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c2a8a10d25fc8962321b615ea83477e1fb4d6310" target='_blank'>
              Efficient Sampling for Data-Driven Frequency Stability Constraint via Forward-Mode Automatic Differentiation
              </a>
            </td>
          <td>
            Wangkun Xu, Qian Chen, Pudong Ge, Zhongda Chu, Fei Teng
          </td>
          <td>2024-07-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Multi-factor screenings are commonly used in diverse applications in medicine and bioengineering, including optimizing combination drug treatments and microbiome engineering. Despite the advances in high-throughput technologies, large-scale experiments typically remain prohibitively expensive. Here we introduce a machine learning platform, structure-augmented regression (SAR), that exploits the intrinsic structure of each biological system to learn a high-accuracy model with minimal data requirement. Under different environmental perturbations, each biological system exhibits a unique, structured phenotypic response. This structure can be learned based on limited data and once learned, can constrain subsequent quantitative predictions. We demonstrate that SAR requires significantly fewer data comparing to other existing machine-learning methods to achieve a high prediction accuracy, first on simulated data, then on experimental data of various systems and input dimensions. We then show how a learned structure can guide effective design of new experiments. Our approach has implications for predictive control of biological systems and an integration of machine learning prediction and experimental design.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c960a00bc91e7ef861762c26cbaf5fb088878ab0" target='_blank'>
              Data-driven learning of structure augments quantitative prediction of biological responses
              </a>
            </td>
          <td>
            Yuanchi Ha, Helena R. Ma, Feilun Wu, Andrea Weiss, Katherine Duncker, Helen Xu, Jia Lu, Max Golovsky, Daniel Reker, Lingchong You
          </td>
          <td>2024-06-01</td>
          <td>PLOS Computational Biology</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Algorithms for solving Quadratic Programs (QPs) are indispensable in the research of Model Predictive Control (MPC) of linear dynamical systems. In a recent paper, Raghunathan [1] proposed a novel Homogeneous Quadratic Program (HQP) formulation that can determine optimality and infeasibility of QPs under assumptions that are readily satisfied for MPC. In this paper, we develop a structure exploiting factorization for the linear systems that occur when solving the QPs arising in MPC using the HQP formulation. We have developed a C++ framework (QOACH-MPC) that abstracts the structure exploiting factorization from the algorithm implementation, and makes it convenient for implementing and testing algorithms for MPC. Currently, QOACH-MPC implements an Interior Point Method (IPM) and Semismooth Newton Method (SNM) for solving the HQP, where the step computation exploits the structure in MPC. We demonstrate how our framework can be leveraged to produce a mixed algorithmic strategy for solving the closed-loop MPC problem.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/eb3e8fc98a53a40f781d8796e5560a4b65f78522" target='_blank'>
              Structural Exploitation for the Homogeneous Reformulation of Model Predictive Control Problems
              </a>
            </td>
          <td>
            Jonas Hall, A. Raghunathan
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>29</td>
        </tr>

        <tr id="This paper considers the extraction of sparse solutions using the L1 minimization surrogate for two approximations of the nonlinear relation between parameters and features; in the first, nonline-arity is discarded altogether and in the second a quadratic relation is assumed. The associated algorithms are the well-known Basis Pursuit (BP) and the more recently introduced Quadratic Basis Pursuit (QBP). It is contended that measuring success by comparing the extracted solutions with the underlying truth is unnecessary, as all that’s needed from the extractor is to identify a sufficiently small parameter set to render the problem determined. Specifically, with p as the number of features, one is interest in the likelihood that the algorithm leads to Ωp ∩ Θ = Θ, where Θ = true set and Ωp = set of the largest p non-zero entries in the solution. When operating in this manner the disruption that nonlinearity brings into the BP solution derives only from the nonlinearity induced rotation of the right-hand side away from the span of the column partition of the Jacobian for the non-zero entries. From this perspective one expects performance to deteriorate only weakly with the extent of damage and this result is numerically con-firmed. It is found that although QBP has the quadratic premise as an advantage over BP, the perfor-mance in simulations, due to the difficulty in obtaining optimal values for the free parameters (and the fact that damage extent prediction was not relevant) proved somewhat poorer than BP.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4ed0a002166134ac823c8746c6347447cd8cb406" target='_blank'>
              Quadratic Basis Pursuit in Model Updating of Underconstrained Problems
              </a>
            </td>
          <td>
            Dionisio Bernal, M. D. Ulriksen
          </td>
          <td>2024-06-01</td>
          <td>Journal of Physics: Conference Series</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="Laplace approximations are popular techniques for endowing deep networks with epistemic uncertainty estimates as they can be applied without altering the predictions of the neural network, and they scale to large models and datasets. While the choice of prior strongly affects the resulting posterior distribution, computational tractability and lack of interpretability of weight space typically limit the Laplace approximation to isotropic Gaussian priors, which are known to cause pathological behavior as depth increases. As a remedy, we directly place a prior on function space. More precisely, since Lebesgue densities do not exist on infinite-dimensional function spaces, we have to recast training as finding the so-called weak mode of the posterior measure under a Gaussian process (GP) prior restricted to the space of functions representable by the neural network. Through the GP prior, one can express structured and interpretable inductive biases, such as regularity or periodicity, directly in function space, while still exploiting the implicit inductive biases that allow deep networks to generalize. After model linearization, the training objective induces a negative log-posterior density to which we apply a Laplace approximation, leveraging highly scalable methods from matrix-free linear algebra. Our method provides improved results where prior knowledge is abundant, e.g., in many scientific inference tasks. At the same time, it stays competitive for black-box regression and classification tasks where neural networks typically excel.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c1a0555187db175d6e1fb7be3e3ea84e032a4d7c" target='_blank'>
              FSP-Laplace: Function-Space Priors for the Laplace Approximation in Bayesian Deep Learning
              </a>
            </td>
          <td>
            Tristan Cinquin, Marvin Pfortner, Vincent Fortuin, Philipp Hennig, Robert Bamler
          </td>
          <td>2024-07-18</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>14</td>
        </tr>

        <tr id="Optimal transport has been an essential tool for reconstructing dynamics from complex data. With the increasingly available multifaceted data, a system can often be characterized across multiple spaces. Therefore, it is crucial to maintain coherence in the dynamics across these diverse spaces. To address this challenge, we introduce Synchronized Optimal Transport (SyncOT), a novel approach to jointly model dynamics that represent the same system through multiple spaces. With given correspondence between the spaces, SyncOT minimizes the aggregated cost of the dynamics induced across all considered spaces. The problem is discretized into a finite-dimensional convex problem using a staggered grid. Primal-dual algorithm-based approaches are then developed to solve the discretized problem. Various numerical experiments demonstrate the capabilities and properties of SyncOT and validate the effectiveness of the proposed algorithms.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bafa108eb9b78b8523cef21c7af52ee299aa0fd1" target='_blank'>
              Synchronized Optimal Transport for Joint Modeling of Dynamics Across Multiple Spaces
              </a>
            </td>
          <td>
            Zixuan Cang, Yanxiang Zhao
          </td>
          <td>2024-06-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="Symmetries play a pivotal role in our understanding of the properties of quantum many-body systems. While there are theorems and a well-established toolbox for systems in thermal equilibrium, much less is known about the role of symmetries and their connection to dynamics out of equilibrium. This arises due to the direct link between a system's thermal state and its Hamiltonian, which is generally not the case for nonequilibrium dynamics. Here we present a pathway to identify the effective symmetries and to extract them from data in nonequilibrium quantum many-body systems. Our approach is based on exact relations between correlation functions involving different numbers of spatial points, which can be viewed as nonequilibrium versions of (equal-time) Ward identities encoding the symmetries of the system. We derive symmetry witnesses, which are particularly suitable for the analysis of measured or simulated data at different snapshots in time. To demonstrate the potential of the approach, we apply our method to numerical and experimental data for a spinor Bose gas. We investigate the important question of a dynamical restoration of an explicitly broken symmetry of the Hamiltonian by the initial state. Remarkably, it is found that effective symmetry restoration can occur long before the system equilibrates. We also use the approach to define and identify spontaneous symmetry breaking far from equilibrium, which is of great relevance for applications to nonequilibrium phase transitions. Our work opens new avenues for the classification and analysis of quantum as well as classical many-body dynamics in a large variety of systems, ranging from ultracold quantum gases to cosmology.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8a8950d1ce041653ba3716007a86405364e34167" target='_blank'>
              Extracting the symmetries of nonequilibrium quantum many-body systems
              </a>
            </td>
          <td>
            A. Mikheev, Viktoria Noel, Ido Siovitz, H. Strobel, M. Oberthaler, Jurgen Berges
          </td>
          <td>2024-07-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>48</td>
        </tr>

        <tr id="Large matrices arise in many machine learning and data analysis applications, including as representations of datasets, graphs, model weights, and first and second-order derivatives. Randomized Numerical Linear Algebra (RandNLA) is an area which uses randomness to develop improved algorithms for ubiquitous matrix problems. The area has reached a certain level of maturity; but recent hardware trends, efforts to incorporate RandNLA algorithms into core numerical libraries, and advances in machine learning, statistics, and random matrix theory, have lead to new theoretical and practical challenges. This article provides a self-contained overview of RandNLA, in light of these developments.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/87ba4c0a0658c3c635c4a84120e5a3c8cd322fdd" target='_blank'>
              Recent and Upcoming Developments in Randomized Numerical Linear Algebra for Machine Learning
              </a>
            </td>
          <td>
            Michal Derezi'nski, Michael W. Mahoney
          </td>
          <td>2024-06-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="In this study, we introduce a unified neural network architecture, the Deep Equilibrium Density Functional Theory Hamiltonian (DEQH) model, which incorporates Deep Equilibrium Models (DEQs) for predicting Density Functional Theory (DFT) Hamiltonians. The DEQH model inherently captures the self-consistency nature of Hamiltonian, a critical aspect often overlooked by traditional machine learning approaches for Hamiltonian prediction. By employing DEQ within our model architecture, we circumvent the need for DFT calculations during the training phase to introduce the Hamiltonian's self-consistency, thus addressing computational bottlenecks associated with large or complex systems. We propose a versatile framework that combines DEQ with off-the-shelf machine learning models for predicting Hamiltonians. When benchmarked on the MD17 and QH9 datasets, DEQHNet, an instantiation of the DEQH framework, has demonstrated a significant improvement in prediction accuracy. Beyond a predictor, the DEQH model is a Hamiltonian solver, in the sense that it uses the fixed-point solving capability of the deep equilibrium model to iteratively solve for the Hamiltonian. Ablation studies of DEQHNet further elucidate the network's effectiveness, offering insights into the potential of DEQ-integrated networks for Hamiltonian learning.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/47c5a47f16e2328f610a37c4f443092abf6a63ef" target='_blank'>
              Infusing Self-Consistency into Density Functional Theory Hamiltonian Prediction via Deep Equilibrium Models
              </a>
            </td>
          <td>
            Zun Wang, Chang Liu, Nianlong Zou, He Zhang, Xinran Wei, Lin Huang, Lijun Wu, Bin Shao
          </td>
          <td>2024-06-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="In addition to their importance in statistical thermodynamics, probabilistic entropy measurements are crucial for understanding and analyzing complex systems, with diverse applications in time series and one-dimensional profiles. However, extending these methods to two- and three-dimensional data still requires further development. In this study, we present a new method for classifying spatiotemporal processes based on entropy measurements. To test and validate the method, we selected five classes of similar processes related to the evolution of random patterns: (i) white noise; (ii) red noise; (iii) weak turbulence from reaction to diffusion; (iv) hydrodynamic fully developed turbulence; and (v) plasma turbulence from MHD. Considering seven possible ways to measure entropy from a matrix, we present the method as a parameter space composed of the two best separating measures of the five selected classes. The results highlight better combined performance of Shannon permutation entropy (SHp) and a new approach based on Tsallis Spectral Permutation Entropy (Sqs). Notably, our observations reveal the segregation of reaction terms in this SHp×Sqs space, a result that identifies specific sectors for each class of dynamic process, and it can be used to train machine learning models for the automatic classification of complex spatiotemporal patterns.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4fae43044a526bebea8671c99e56cb68c4982b26" target='_blank'>
              Characterizing Complex Spatiotemporal Patterns from Entropy Measures
              </a>
            </td>
          <td>
            Luan O. Barauna, Rubens Andreas Sautter, R. Rosa, E. Rempel, Alejandro C. Frery
          </td>
          <td>2024-06-01</td>
          <td>Entropy</td>
          <td>0</td>
          <td>20</td>
        </tr>

        <tr id="We present an expansion of a many-body correlation function in a sum of pseudomodes - exponents with complex frequencies that encompass both decay and oscillations. We demonstrate that, typically, it is enough to take a few first terms of this infinite sum to obtain an excellent approximation to the correlation function at any time, with the large time behavior being determined solely by the first pseudomode. The pseudomode expansion emerges in the framework of the Heisenberg version of the recursion method. This method essentially solves Heisenberg equations in a Lanczos tridiagonal basis constructed in the Krylov space of a given observable. To obtain pseudomodes, we first add artificial dissipation satisfying the dissipative generalization of the universal operator growth hypothesis, and then take the limit of the vanishing dissipation strength. Fast convergence of the pseudomode expansion is facilitated by the localization in the Krylov space, which is generic in the presence of dissipation and can survive the limit of the vanishing dissipation strength. As an illustration, we apply the pseudomode expansion to calculate infinite-temperature autocorrelation functions in the quantum Ising and $XX$ spin-$1/2$ models on the square lattice.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8c0e1c45eedb9a16b0066dded4a252c6974da710" target='_blank'>
              Pseudomode expansion of many-body correlation functions
              </a>
            </td>
          <td>
            Alexander Teretenkov, F. Uskov, Oleg Lychkovskiy
          </td>
          <td>2024-07-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="In this paper, we introduce a data-driven framework for synthesis of provably-correct controllers for general nonlinear switched systems under complex specifications. The focus is on systems with unknown disturbances whose effects on the dynamics of the system is nonlinear. The specifications are assumed to be given as linear temporal logic over finite traces (LTLf) formulas. Starting from observations of either the disturbance or the state of the system, we first learn an ambiguity set that contains the unknown distribution of the disturbances with a user-defined confidence. Next, we construct a robust Markov decision process (RMDP) as a finite abstraction of the system. By composing the RMDP with the automaton obtained from the LTLf formula and performing optimal robust value iteration on the composed RMDP, we synthesize a strategy that yields a high probability that the uncertain system satisfies the specifications. Our empirical evaluations on systems with a wide variety of disturbances show that the strategies synthesized with our approach lead to high satisfaction probabilities and validate the theoretical guarantees.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f06b9a0330864b690724e969231d4d73b5f9727e" target='_blank'>
              Data-driven strategy synthesis for stochastic systems with unknown nonlinear disturbances
              </a>
            </td>
          <td>
            Ibon Gracia, Dimitris Boskos, Luca Laurenti, Morteza Lahijanian
          </td>
          <td>2024-06-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="The nonlinear filtering problem has enduringly been an active research topic in both academia and industry due to its ever-growing theoretical importance and practical significance. The main objective of nonlinear filtering is to infer the states of a nonlinear dynamical system of interest based on the available noisy measurements. In recent years, the advance of network communication technology has not only popularized the networked systems with apparent advantages in terms of installation, cost and maintenance, but also brought about a series of challenges to the design of nonlinear filtering algorithms, among which the communication constraint has been recognized as a dominating concern. In this context, a great number of investigations have been launched towards the networked nonlinear filtering problem with communication constraints, and many sample-based nonlinear filters have been developed to deal with the highly nonlinear and/or non-Gaussian scenarios. The aim of this paper is to provide a timely survey about the recent advances on the sample-based networked nonlinear filtering problem from the perspective of communication constraints. More specifically, we first review three important families of sample-based filtering methods known as the unscented Kalman filter, particle filter, and maximum correntropy filter. Then, the latest developments are surveyed with stress on the topics regarding incomplete/imperfect information, limited resources and cyber security. Finally, several challenges and open problems are highlighted to shed some lights on the possible trends of future research in this realm.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7b2ab547863c1e18aa730f1ca9040c34f915e81b" target='_blank'>
              Nonlinear Filtering With Sample-Based Approximation Under Constrained Communication: Progress, Insights and Trends
              </a>
            </td>
          <td>
            Weihao Song, Zidong Wang, Zhongkui Li, Jianan Wang, Qing‐Long Han
          </td>
          <td>2024-07-01</td>
          <td>IEEE/CAA Journal of Automatica Sinica</td>
          <td>0</td>
          <td>27</td>
        </tr>

        <tr id="This paper introduces a new multi-model predictive control (MMPC) method for quadrotor attitude control with performance nearly on par with nonlinear model predictive control (NMPC) and computational efficiency similar to linear model predictive control (LMPC). Conventional NMPC, while effective, is computationally intensive, especially for attitude control that needs a high refresh rate. Conversely, LMPC offers computational advantages but suffers from poor performance and local stability. Our approach relies on multiple linear models of attitude dynamics, each accompanied by a linear model predictive controller, dynamically switching between them given flight conditions. We leverage gap metric analysis to minimize the number of models required to accurately predict the vehicle behavior in various conditions and incorporate a soft switching mechanism to ensure system stability during controller transitions. Our results show that with just 15 models, the vehicle attitude can be accurately controlled across various set points. Comparative evaluations with existing controllers such as incremental nonlinear dynamic inversion, sliding mode control, LMPC, and NMPC reveal that our approach closely matches the effectiveness of NMPC, outperforming other methods, with a running time comparable to LMPC.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/738c2748d64a1ccd587588fc7fe94184fbe052b6" target='_blank'>
              Multi-Model Predictive Attitude Control of Quadrotors
              </a>
            </td>
          <td>
            Mohammadreza Izadi, Zeinab Shayan, R. Faieghi
          </td>
          <td>2024-06-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Developing and optimizing models for complex systems poses challenges due to the inherent complexity introduced by multiple types of input information and sources of uncertainty. In this study, we utilize Bayesian formalism to analytically examine the propagation of probability in the modeling process and propose quantitative assessments for it. Upon which, we develop a method for optimizing models for complex systems by (i) minimizing model uncertainty; (ii) maximizing model consistency; and (iii) minimizing model complexity, following the Bayesian Occam’s razor rationale. We showcase the benefits of this method by optimizing the modeling of the dynamic system of glucose-stimulated insulin secretion in pancreatic β-cells, leading to an optimized model that demonstrates better alignment with experimental observations compared to the non-optimized one. We anticipate that this method will facilitate the construction of accurate, precise, and sufficiently simple models for diverse complex systems. It is implemented in our open-source software Integrative Modeling Platform (IMP), ensuring its broad applicability.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2852aa1c64c573614d3968195a3e4de98331119b" target='_blank'>
              Bayesian Occam’s Razor to Optimize Models for Complex Systems
              </a>
            </td>
          <td>
            Chenxi Wang, Jihui Zhao, Jingjing Zheng, Barak Raveh, Xuming He, Liping Sun
          </td>
          <td>2024-06-02</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id="Studying the temporal evolution of complex systems requires tools able to detect the presence and quantify the strength of predictable dynamics within their output signals. Information theory aids in such a description, particularly through information storage (IS), which reflects the regularity of system dynamics by measuring the information shared between the present and the past system states. While the conventional IS computation provides an overall measure of predictable information, transient behaviors of predictability occurring during system transitions can be assessed by time-resolved measures such as the local information storage (L-IS), assuming stationarity, and the time-varying information storage (TV-IS), without stationarity assumptions. In this work, through a comparative analysis in simulated and real contexts, we aim to demonstrate how these methods complement each other and reveal dynamic changes of the system behavior associated to state transitions. In simulations, we show that the TV-IS can effectively track sudden changes of the information stored in the system, which is reflected in its average value computed over specific time intervals; on the other hand, the surprise originated by the emergence of a change in the predictability of the system is reflected in the variance of the L-IS computed within specific time intervals. In neurophysiological applications, the distinct phenomena of respiratory activity in sleep apnea and brain activity during somatosensory stimulation both reveal a significant decrease of IS evoked by state transitions, highlighting how such transitions can inject new information in physiological systems, affecting significantly their internal dynamics. Overall, TV-IS and L-IS appear to provide different and complementary information about the behavior of the systems under investigation, thereby offering valuable tools for the study of complex physiological systems where both stationary and non-stationary conditions may be present.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7c3b648f9e9d48cea5dda06ced2a7fa4a474d58a" target='_blank'>
              Exploring transient neurophysiological states through local and time-varying measures of Information Dynamics
              </a>
            </td>
          <td>
            Y. Antonacci, C. Barà, G. De Felice, A. Sferlazza, R. Pernice, L. Faes
          </td>
          <td>2024-06-24</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>20</td>
        </tr>

        <tr id="In this article we study if a Deep Learning technique can be used to obtain an approximated value of the Lyapunov exponents of a dynamical system. Moreover, we want to know if Machine Learning techniques are able, once trained, to provide the complete Lyapunov exponents spectrum with just single-variable time series. We train a Convolutional Neural Network and we use the resulting network to approximate the complete spectrum using the time series of just one variable from the studied systems (Lorenz system and coupled Lorenz system). The results are quite stunning as all the values are well approximated with only partial data. This strategy permits to speed up the complete analysis of the systems and also to study the hyperchaotic dynamics in the coupled Lorenz system.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/09290aec6c4160820790c56611a3f3eca51095dc" target='_blank'>
              Full Lyapunov Exponents spectrum with Deep Learning from single-variable time series
              </a>
            </td>
          <td>
            C. Mayora-Cebollero, A. Mayora-Cebollero, 'Alvaro Lozano, Roberto Barrio
          </td>
          <td>2024-06-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Trajectory inference seeks to recover the temporal dynamics of a population from snapshots of its (uncoupled) temporal marginals, i.e. where observed particles are not tracked over time. Lavenant et al. arXiv:2102.09204 addressed this challenging problem under a stochastic differential equation (SDE) model with a gradient-driven drift in the observed space, introducing a minimum entropy estimator relative to the Wiener measure. Chizat et al. arXiv:2205.07146 then provided a practical grid-free mean-field Langevin (MFL) algorithm using Schr\"odinger bridges. Motivated by the overwhelming success of observable state space models in the traditional paired trajectory inference problem (e.g. target tracking), we extend the above framework to a class of latent SDEs in the form of observable state space models. In this setting, we use partial observations to infer trajectories in the latent space under a specified dynamics model (e.g. the constant velocity/acceleration models from target tracking). We introduce PO-MFL to solve this latent trajectory inference problem and provide theoretical guarantees by extending the results of arXiv:2102.09204 to the partially observed setting. We leverage the MFL framework of arXiv:2205.07146, yielding an algorithm based on entropic OT between dynamics-adjusted adjacent time marginals. Experiments validate the robustness of our method and the exponential convergence of the MFL dynamics, and demonstrate significant outperformance over the latent-free method of arXiv:2205.07146 in key scenarios.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/00a1683e0adbd5e56aa4f83d49091c5542d29179" target='_blank'>
              Partially Observed Trajectory Inference using Optimal Transport and a Dynamics Prior
              </a>
            </td>
          <td>
            Anming Gu, Edward Chien, K. Greenewald
          </td>
          <td>2024-06-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>20</td>
        </tr>

        <tr id="
 Reservoir computing is an efficient artificial neural network for model-free prediction and analysis of dynamical systems time series. As a data-based method, the capacity of reservoir computing is stongly affected by the time sampling interval of training data. In this paper, taking Lorenz system as an example, we explore the influence of this sampling interval on the performance of reservoir computing in predicting chaotic sequences. When the sampling interval increases, the prediction capacity of reservoir computing is first enhanced then weakened, presenting a bell-shaped curve. By slightly revising the calculation method of the output matrix, the prediction performance of reservoir computing with small sampling interval can be improved. Furthermore, reservoir computing can learn and reproduce the state of chaotic system with a large time interval, which is almost five times larger than that of the classic fourth-order Runge-Kutta method. Our results show the capacity of reservoir computing in the applications where the time sampling intervals are constrained and laid the foundation for building a fast algorithm with larger time iteration steps.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2299dd61e3d42dbb604ec45370f99d03bbd6e6f9" target='_blank'>
              Large sampling intervals for learning and predicting chaotic systems with reservoir computing
              </a>
            </td>
          <td>
            Qingyan Xie, Zixiang Yan, Hui Zhao, Jian Gao, Jinghua Xiao
          </td>
          <td>2024-06-28</td>
          <td>Journal of Physics A: Mathematical and Theoretical</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Overparameterized stochastic differential equation (SDE) models have achieved remarkable success in various complex environments, such as PDE-constrained optimization, stochastic control and reinforcement learning, financial engineering, and neural SDEs. These models often feature system evolution coefficients that are parameterized by a high-dimensional vector $\theta \in \mathbb{R}^n$, aiming to optimize expectations of the SDE, such as a value function, through stochastic gradient ascent. Consequently, designing efficient gradient estimators for which the computational complexity scales well with $n$ is of significant interest. This paper introduces a novel unbiased stochastic gradient estimator--the generator gradient estimator--for which the computation time remains stable in $n$. In addition to establishing the validity of our methodology for general SDEs with jumps, we also perform numerical experiments that test our estimator in linear-quadratic control problems parameterized by high-dimensional neural networks. The results show a significant improvement in efficiency compared to the widely used pathwise differentiation method: Our estimator achieves near-constant computation times, increasingly outperforms its counterpart as $n$ increases, and does so without compromising estimation variance. These empirical findings highlight the potential of our proposed methodology for optimizing SDEs in contemporary applications.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6fc1545e20fb78c9271560d34a3512c20ad26286" target='_blank'>
              An Efficient High-dimensional Gradient Estimator for Stochastic Differential Equations
              </a>
            </td>
          <td>
            Shengbo Wang, Jose Blanchet, Peter Glynn
          </td>
          <td>2024-07-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Stochastic systems are used to model a variety of phenomena in which noise plays an essential role. In these models, one potential goal is to determine if noise can induce transitions between states, and if so, to calculate the most probable escape path from an attractor. In the small noise limit, the Freidlin-Wentzell theory of large deviations provides a variational framework to calculate these paths. This work focuses on using large deviation theory to calculate such paths for stochastic gradient systems with non-gradient perturbations. While for gradient systems the most probable escape paths consist of time-reversed heteroclinic orbits, for general systems it can be a challenging calculation. By applying Melnikov theory to the resulting Euler-Lagrange equations recast in Hamiltonian form, we determine a condition for when the optimal escape path is the heteroclinic orbit for the perturbed system. We provide a numerical example to illustrate how the computed most probable escape path compares with the theoretical result.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/330a794bfa885f5551f29fba1960f92ebc6ccf55" target='_blank'>
              Most probable escape paths in perturbed gradient systems
              </a>
            </td>
          <td>
            Katherine Slyman, Mackenzie Simper, John A Gemmer, Bjorn Sandstede
          </td>
          <td>2024-07-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

    </tbody>
    <tfoot>
      <tr>
          <th>Abstract</th>
          <th>Title</th>
          <th>Authors</th>
          <th>Publication Date</th>
          <th>Journal/Conference</th>
          <th>Citation count</th>
          <th>Highest h-index</th>
      </tr>
    </tfoot>
    </table>
    </p>
  </div>

</body>

<script>

  function create_author_list(author_list) {
    let td_author_element = document.getElementById();
    for (let i = 0; i < author_list.length; i++) {
          // tdElements[i].innerHTML = greet(tdElements[i].innerHTML);
          alert (author_list[i]);
      }
  }

  var trace1 = {
    x: ['2024'],
    y: [25],
    name: 'Num of citations',
    yaxis: 'y1',
    type: 'scatter'
  };

  var data = [trace1];

  var layout = {
    yaxis: {
      title: 'Num of citations',
      }
  };
  Plotly.newPlot('myDiv1', data, layout);
</script>
<script>
var dataTableOptions = {
        initComplete: function () {
        this.api()
            .columns()
            .every(function () {
                let column = this;

                // Create select element
                let select = document.createElement('select');
                select.add(new Option(''));
                column.footer().replaceChildren(select);

                // Apply listener for user change in value
                select.addEventListener('change', function () {
                    column
                        .search(select.value, {exact: true})
                        .draw();
                });

                // keep the width of the select element same as the column
                select.style.width = '100%';

                // Add list of options
                column
                    .data()
                    .unique()
                    .sort()
                    .each(function (d, j) {
                        select.add(new Option(d));
                    });
            });
    },
    scrollX: true,
    scrollCollapse: true,
    paging: true,
    fixedColumns: true,
    columnDefs: [
        {"className": "dt-center", "targets": "_all"},
        // set width for both columns 0 and 1 as 25%
        { width: '7%', targets: 0 },
        { width: '30%', targets: 1 },
        { width: '25%', targets: 2 },
        { width: '15%', targets: 4 }

      ],
    pageLength: 10,
    layout: {
        topStart: {
            buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
        }
    }
  }
  new DataTable('#table1', dataTableOptions);
  new DataTable('#table2', dataTableOptions);

  var table1 = $('#table1').DataTable();
  $('#table1 tbody').on('click', 'td:first-child', function () {
    var tr = $(this).closest('tr');
    var row = table1.row( tr );

    var rowId = tr.attr('id');
    // alert(rowId);

    if (row.child.isShown()) {
      // This row is already open - close it.
      row.child.hide();
      tr.removeClass('shown');
      tr.find('td:first-child').html('<i class="material-icons">visibility_off</i>');
    } else {
      // Open row.
      // row.child('foo').show();
      tr.find('td:first-child').html('<i class="material-icons">visibility</i>');
      var content = '<div class="child-row-content"><strong>Abstract:</strong> ' + rowId + '</div>';
      row.child(content).show();
      tr.addClass('shown');
    }
  });
  var table2 = $('#table2').DataTable();
  $('#table2 tbody').on('click', 'td:first-child', function () {
    var tr = $(this).closest('tr');
    var row = table2.row( tr );

    var rowId = tr.attr('id');
    // alert(rowId);

    if (row.child.isShown()) {
      // This row is already open - close it.
      row.child.hide();
      tr.removeClass('shown');
      tr.find('td:first-child').html('<i class="material-icons">visibility_off</i>');
    } else {
      // Open row.
      // row.child('foo').show();
      var content = '<div class="child-row-content"><strong>Abstract:</strong> ' + rowId + '</div>';
      row.child(content).show();
      tr.addClass('shown');
      tr.find('td:first-child').html('<i class="material-icons">visibility</i>');
    }
  });
</script>
<style>
  .child-row-content {
    text-align: justify;
    text-justify: inter-word;
    word-wrap: break-word; /* Ensure long words are broken */
    white-space: normal; /* Ensure text wraps to the next line */
    max-width: 100%; /* Ensure content does not exceed the table width */
    padding: 10px; /* Optional: add some padding for better readability */
    /* font size */
    font-size: small;
  }
</style>
</html>







  
  




  



                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.top", "navigation.tabs"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    

      <script src="../assets/javascripts/bundle.c8d2eff1.min.js"></script>
      
    
<script>
  // Execute intro.js when a button with id 'intro' is clicked
  function startIntro(){
      introJs().setOptions({
          tooltipClass: 'customTooltip'
      }).start();
  }
</script>
<script>
  

  // new DataTable('#table1', {
  //   order: [[5, 'desc']],
  //   "columnDefs": [
  //       {"className": "dt-center", "targets": "_all"},
  //       { width: '30%', targets: 0 }
  //     ],
  //   pageLength: 10,
  //   layout: {
  //       topStart: {
  //           buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
  //       }
  //   }
  // });

  // new DataTable('#table2', {
  //   order: [[3, 'desc']],
  //   "columnDefs": [
  //       {"className": "dt-center", "targets": "_all"},
  //       { width: '30%', targets: 0 }
  //     ],
  //   pageLength: 10,
  //   layout: {
  //       topStart: {
  //           buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
  //       }
  //   }
  // });
  new DataTable('#table3', {
    initComplete: function () {
        this.api()
            .columns()
            .every(function () {
                let column = this;
 
                // Create select element
                let select = document.createElement('select');
                select.add(new Option(''));
                column.footer().replaceChildren(select);
 
                // Apply listener for user change in value
                select.addEventListener('change', function () {
                    column
                        .search(select.value, {exact: true})
                        .draw();
                });

                // keep the width of the select element same as the column
                select.style.width = '100%';
 
                // Add list of options
                column
                    .data()
                    .unique()
                    .sort()
                    .each(function (d, j) {
                        select.add(new Option(d));
                    });
            });
    },
    // order: [[3, 'desc']],
    "columnDefs": [
        {"className": "dt-center", "targets": "_all"},
        { width: '30%', targets: 0 }
      ],
    pageLength: 10,
    layout: {
        topStart: {
            buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
        }
    }
  });
  new DataTable('#table4', {
    initComplete: function () {
        this.api()
            .columns()
            .every(function () {
                let column = this;
 
                // Create select element
                let select = document.createElement('select');
                select.add(new Option(''));
                column.footer().replaceChildren(select);
 
                // Apply listener for user change in value
                select.addEventListener('change', function () {
                    column
                        .search(select.value, {exact: true})
                        .draw();
                });

                // keep the width of the select element same as the column
                select.style.width = '100%';
 
                // Add list of options
                column
                    .data()
                    .unique()
                    .sort()
                    .each(function (d, j) {
                        select.add(new Option(d));
                    });
            });
    },
    // order: [[3, 'desc']],
    "columnDefs": [
        {"className": "dt-center", "targets": "_all"},
        { width: '30%', targets: 0 }
      ],
    pageLength: 10,
    layout: {
        topStart: {
            buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
        }
    }
  });
</script>


  </body>
</html>