<!DOCTYPE html>

<html lang="en">


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../Time-series%20forecasting/">
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.12">
    
    
<title>Literature Survey (VPE)</title>

    
      <link rel="stylesheet" href="../assets/stylesheets/main.7e359304.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
  <!-- Add scripts that need to run before here -->
  <!-- Add jquery script -->
  <script src="https://code.jquery.com/jquery-3.7.1.js"></script>
  <!-- Add data table libraries -->
  <script src="https://cdn.datatables.net/2.0.1/js/dataTables.js"></script>
  <link rel="stylesheet" href="https://cdn.datatables.net/2.0.1/css/dataTables.dataTables.css">
  <!-- Load plotly.js into the DOM -->
	<script src='https://cdn.plot.ly/plotly-2.29.1.min.js'></script>
  <link rel="stylesheet" href="https://cdn.datatables.net/buttons/3.0.1/css/buttons.dataTables.css">
  <!-- fixedColumns -->
  <script src="https://cdn.datatables.net/fixedcolumns/5.0.0/js/dataTables.fixedColumns.js"></script>
  <script src="https://cdn.datatables.net/fixedcolumns/5.0.0/js/fixedColumns.dataTables.js"></script>
  <link rel="stylesheet" href="https://cdn.datatables.net/fixedcolumns/5.0.0/css/fixedColumns.dataTables.css">
  <!-- Already specified in mkdocs.yml -->
  <!-- <link rel="stylesheet" href="../docs/custom.css"> -->
  <script src="https://cdn.datatables.net/buttons/3.0.1/js/dataTables.buttons.js"></script>
  <script src="https://cdn.datatables.net/buttons/3.0.1/js/buttons.dataTables.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.1/jszip.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdfmake/0.2.7/pdfmake.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdfmake/0.2.7/vfs_fonts.js"></script>
  <script src="https://cdn.datatables.net/buttons/3.0.1/js/buttons.html5.min.js"></script>
  <script src="https://cdn.datatables.net/buttons/3.0.1/js/buttons.print.min.js"></script>
  <!-- Google fonts -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
  <!-- Intro.js -->
  <script src="https://cdn.jsdelivr.net/npm/intro.js@7.2.0/intro.min.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/intro.js@7.2.0/minified/introjs.min.css">


  <!-- 
      
     -->
  <!-- Add scripts that need to run afterwards here -->

    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../custom.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="black">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Literature Survey (VPE)" class="md-header__button md-logo" aria-label="Literature Survey (VPE)" data-md-component="logo">
      
  <img src="../assets/VPE.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Literature Survey (VPE)
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Symbolic regression
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="black"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="white" data-md-color-accent="black"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/VirtualPatientEngine/literatureSurvey" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    VPE/LiteratureSurvey
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href=".." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../Time-series%20forecasting/" class="md-tabs__link">
        
  
    
  
  Time-series forecasting

      </a>
    </li>
  

      
        
  
  
    
  
  
    <li class="md-tabs__item md-tabs__item--active">
      <a href="./" class="md-tabs__link">
        
  
    
  
  Symbolic regression

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
                
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" hidden>
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Literature Survey (VPE)" class="md-nav__button md-logo" aria-label="Literature Survey (VPE)" data-md-component="logo">
      
  <img src="../assets/VPE.png" alt="logo">

    </a>
    Literature Survey (VPE)
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/VirtualPatientEngine/literatureSurvey" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    VPE/LiteratureSurvey
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Time-series%20forecasting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Time-series forecasting
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Symbolic regression
  </span>
  

      </a>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
                
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>Symbolic regression</h1>

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
</head>

<body>
  <p>
  <i class="footer">This page was last updated on 2024-08-23 15:31:45 UTC</i>
  </p>

  <div class="note info" onclick="startIntro()">
    <p>
      <button type="button" class="buttons">
        <div style="display: flex; align-items: center;">
        Click here for a quick intro of the page! <i class="material-icons">help</i>
        </div>
      </button>
    </p>
  </div>

  <!--
  <div data-intro='Table of contents'>
    <p>
    <h3>Table of Contents</h3>
      <a href="#plot1">1. Citations over time on Symbolic regression</a><br>
      <a href="#manually_curated_articles">2. Manually curated articles on Symbolic regression</a><br>
      <a href="#recommended_articles">3. Recommended articles on Symbolic regression</a><br>
    <p>
  </div>

  <div data-intro='Plot displaying number of citations over time 
                  on the given topic based on recommended articles'>
    <p>
    <h3 id="plot1">1. Citations over time on Symbolic regression</h3>
      <div id='myDiv1'>
      </div>
    </p>
  </div>
  -->

  <div data-intro='Manually curated articles on the given topic'>
    <p>
    <h3 id="manually_curated_articles">Manually curated articles on <i>Symbolic regression</i></h3>
    <table id="table1" class="display" style="width:100%">
    <thead>
      <tr>
          <th data-intro='Click to view the abstract (if available)'>Abstract</th>
          <th>Title</th>
          <th>Authors</th>
          <th>Publication Date</th>
          <th>Journal/ Conference</th>
          <th>Citation count</th>
          <th data-intro='Highest h-index among the authors'>Highest h-index</th>
          <th data-intro='Recommended articles extracted by considering
                          only the given article'>
              View recommendations
              </th>
      </tr>
    </thead>
    <tbody>

        <tr id="Significance Understanding dynamic constraints and balances in nature has facilitated rapid development of knowledge and enabled technology, including aircraft, combustion engines, satellites, and electrical power. This work develops a novel framework to discover governing equations underlying a dynamical system simply from data measurements, leveraging advances in sparsity techniques and machine learning. The resulting models are parsimonious, balancing model complexity with descriptive ability while avoiding overfitting. There are many critical data-driven problems, such as understanding cognition from neural recordings, inferring climate patterns, determining stability of financial markets, predicting and suppressing the spread of disease, and controlling turbulence for greener transportation and energy. With abundant data and elusive laws, data-driven discovery of dynamics will continue to play an important role in these efforts. Extracting governing equations from data is a central challenge in many diverse areas of science and engineering. Data are abundant whereas models often remain elusive, as in climate science, neuroscience, ecology, finance, and epidemiology, to name only a few examples. In this work, we combine sparsity-promoting techniques and machine learning with nonlinear dynamical systems to discover governing equations from noisy measurement data. The only assumption about the structure of the model is that there are only a few important terms that govern the dynamics, so that the equations are sparse in the space of possible functions; this assumption holds for many physical systems in an appropriate basis. In particular, we use sparse regression to determine the fewest terms in the dynamic governing equations required to accurately represent the data. This results in parsimonious models that balance accuracy with model complexity to avoid overfitting. We demonstrate the algorithm on a wide range of problems, from simple canonical systems, including linear and nonlinear oscillators and the chaotic Lorenz system, to the fluid vortex shedding behind an obstacle. The fluid example illustrates the ability of this method to discover the underlying dynamics of a system that took experts in the community nearly 30 years to resolve. We also show that this method generalizes to parameterized systems and systems that are time-varying or have external forcing.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5d150cec2775f9bc863760448f14104cc8f42368" target='_blank'>
                Discovering governing equations from data by sparse identification of nonlinear dynamical systems
                </a>
              </td>
          <td>
            S. Brunton, J. Proctor, J. Kutz
          </td>
          <td>2015-09-11</td>
          <td>Proceedings of the National Academy of Sciences, Proceedings of the National Academy of Sciences of the United States of America</td>
          <td>3196</td>
          <td>65</td>

            <td><a href='../recommendations/5d150cec2775f9bc863760448f14104cc8f42368' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/60d0d998fa038182b3b69a57adb9b2f82d40589c" target='_blank'>
                Robust learning from noisy, incomplete, high-dimensional experimental data via physically constrained symbolic regression
                </a>
              </td>
          <td>
            Patrick A. K. Reinbold, Logan Kageorge, M. Schatz, R. Grigoriev
          </td>
          <td>2021-02-24</td>
          <td>Nature Communications</td>
          <td>86</td>
          <td>23</td>

            <td><a href='../recommendations/60d0d998fa038182b3b69a57adb9b2f82d40589c' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Significance Governing equations are essential to the study of physical systems, providing models that can generalize to predict previously unseen behaviors. There are many systems of interest across disciplines where large quantities of data have been collected, but the underlying governing equations remain unknown. This work introduces an approach to discover governing models from data. The proposed method addresses a key limitation of prior approaches by simultaneously discovering coordinates that admit a parsimonious dynamical model. Developing parsimonious and interpretable governing models has the potential to transform our understanding of complex systems, including in neuroscience, biology, and climate science. The discovery of governing equations from scientific data has the potential to transform data-rich fields that lack well-characterized quantitative descriptions. Advances in sparse regression are currently enabling the tractable identification of both the structure and parameters of a nonlinear dynamical system from data. The resulting models have the fewest terms necessary to describe the dynamics, balancing model complexity with descriptive ability, and thus promoting interpretability and generalizability. This provides an algorithmic approach to Occam’s razor for model discovery. However, this approach fundamentally relies on an effective coordinate system in which the dynamics have a simple representation. In this work, we design a custom deep autoencoder network to discover a coordinate transformation into a reduced space where the dynamics may be sparsely represented. Thus, we simultaneously learn the governing equations and the associated coordinate system. We demonstrate this approach on several example high-dimensional systems with low-dimensional behavior. The resulting modeling framework combines the strengths of deep neural networks for flexible representation and sparse identification of nonlinear dynamics (SINDy) for parsimonious models. This method places the discovery of coordinates and models on an equal footing.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3c9961153493370500020c81527b3548c96f81e0" target='_blank'>
                Data-driven discovery of coordinates and governing equations
                </a>
              </td>
          <td>
            Kathleen P. Champion, Bethany Lusch, J. Kutz, S. Brunton
          </td>
          <td>2019-03-29</td>
          <td>Proceedings of the National Academy of Sciences of the United States of America</td>
          <td>607</td>
          <td>65</td>

            <td><a href='../recommendations/3c9961153493370500020c81527b3548c96f81e0' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3df50e9b73cc2937dfd651f4c3344bc99b7ed3f2" target='_blank'>
                Chaos as an intermittently forced linear system
                </a>
              </td>
          <td>
            S. Brunton, Bingni W. Brunton, J. Proctor, E. Kaiser, J. Kutz
          </td>
          <td>2016-08-18</td>
          <td>Nature Communications</td>
          <td>448</td>
          <td>65</td>

            <td><a href='../recommendations/3df50e9b73cc2937dfd651f4c3344bc99b7ed3f2' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Data-driven discovery of dynamics via machine learning is pushing the frontiers of modelling and control efforts, providing a tremendous opportunity to extend the reach of model predictive control (MPC). However, many leading methods in machine learning, such as neural networks (NN), require large volumes of training data, may not be interpretable, do not easily include known constraints and symmetries, and may not generalize beyond the attractor where models are trained. These factors limit their use for the online identification of a model in the low-data limit, for example following an abrupt change to the system dynamics. In this work, we extend the recent sparse identification of nonlinear dynamics (SINDY) modelling procedure to include the effects of actuation and demonstrate the ability of these models to enhance the performance of MPC, based on limited, noisy data. SINDY models are parsimonious, identifying the fewest terms in the model needed to explain the data, making them interpretable and generalizable. We show that the resulting SINDY-MPC framework has higher performance, requires significantly less data, and is more computationally efficient and robust to noise than NN models, making it viable for online training and execution in response to rapid system changes. SINDY-MPC also shows improved performance over linear data-driven models, although linear models may provide a stopgap until enough data is available for SINDY. SINDY-MPC is demonstrated on a variety of dynamical systems with different challenges, including the chaotic Lorenz system, a simple model for flight control of an F8 aircraft, and an HIV model incorporating drug treatment.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b2eb064f432557c59ce99834d7dc7817e4687271" target='_blank'>
                Sparse identification of nonlinear dynamics for model predictive control in the low-data limit
                </a>
              </td>
          <td>
            E. Kaiser, J. Kutz, S. Brunton
          </td>
          <td>2017-11-15</td>
          <td>Proceedings of the Royal Society A, Proceedings. Mathematical, Physical, and Engineering Sciences</td>
          <td>429</td>
          <td>65</td>

            <td><a href='../recommendations/b2eb064f432557c59ce99834d7dc7817e4687271' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Inferring the structure and dynamics of network models is critical to understanding the functionality and control of complex systems, such as metabolic and regulatory biological networks. The increasing quality and quantity of experimental data enable statistical approaches based on information theory for model selection and goodness-of-fit metrics. We propose an alternative data-driven method to infer networked nonlinear dynamical systems by using sparsity-promoting optimization to select a subset of nonlinear interactions representing dynamics on a network. In contrast to standard model selection methods-based upon information content for a finite number of heuristic models (order 10 or less), our model selection procedure discovers a parsimonious model from a combinatorially large set of models, without an exhaustive search. Our particular innovation is appropriate for many biological networks, where the governing dynamical systems have rational function nonlinearities with cross terms, thus requiring an implicit formulation and the equations to be identified in the null-space of a library of mixed nonlinearities, including the state and derivative terms. This method, implicit-SINDy, succeeds in inferring three canonical biological models: 1) Michaelis-Menten enzyme kinetics; 2) the regulatory network for competence in bacteria; and 3) the metabolic network for yeast glycolysis.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/06a0ba437d41a7c82c08a9636a4438c1b5031378" target='_blank'>
                Inferring Biological Networks by Sparse Identification of Nonlinear Dynamics
                </a>
              </td>
          <td>
            N. Mangan, S. Brunton, J. Proctor, J. Kutz
          </td>
          <td>2016-05-26</td>
          <td>IEEE Transactions on Molecular, Biological and Multi-Scale Communications, IEEE Transactions on Molecular Biological and Multi-Scale Communications</td>
          <td>319</td>
          <td>65</td>

            <td><a href='../recommendations/06a0ba437d41a7c82c08a9636a4438c1b5031378' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Accurately modelling the nonlinear dynamics of a system from measurement data is a challenging yet vital topic. The sparse identification of nonlinear dynamics (SINDy) algorithm is one approach to discover dynamical systems models from data. Although extensions have been developed to identify implicit dynamics, or dynamics described by rational functions, these extensions are extremely sensitive to noise. In this work, we develop SINDy-PI (parallel, implicit), a robust variant of the SINDy algorithm to identify implicit dynamics and rational nonlinearities. The SINDy-PI framework includes multiple optimization algorithms and a principled approach to model selection. We demonstrate the ability of this algorithm to learn implicit ordinary and partial differential equations and conservation laws from limited and noisy data. In particular, we show that the proposed approach is several orders of magnitude more noise robust than previous approaches, and may be used to identify a class of ODE and PDE dynamics that were previously unattainable with SINDy, including for the double pendulum dynamics and simplified model for the Belousov–Zhabotinsky (BZ) reaction.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4971f9abd024e40fbbdff2e9492745b68a6bca01" target='_blank'>
                SINDy-PI: a robust algorithm for parallel implicit sparse identification of nonlinear dynamics
                </a>
              </td>
          <td>
            Kadierdan Kaheman, J. Kutz, S. Brunton
          </td>
          <td>2020-04-05</td>
          <td>Proceedings of the Royal Society A, Proceedings. Mathematical, Physical, and Engineering Sciences</td>
          <td>195</td>
          <td>65</td>

            <td><a href='../recommendations/4971f9abd024e40fbbdff2e9492745b68a6bca01' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="A key task in the field of modeling and analyzing nonlinear dynamical systems is the recovery of unknown governing equations from measurement data only. There is a wide range of application areas for this important instance of system identification, ranging from industrial engineering and acoustic signal processing to stock market models. In order to find appropriate representations of underlying dynamical systems, various data-driven methods have been proposed by different communities. However, if the given data sets are high-dimensional, then these methods typically suffer from the curse of dimensionality. To significantly reduce the computational costs and storage consumption, we propose the method multidimensional approximation of nonlinear dynamical systems (MANDy) which combines data-driven methods with tensor network decompositions. The efficiency of the introduced approach will be illustrated with the aid of several high-dimensional nonlinear dynamical systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2b2aa13d4959073f61ad70555bc8c7da7d116196" target='_blank'>
                Multidimensional Approximation of Nonlinear Dynamical Systems
                </a>
              </td>
          <td>
            Patrick Gelß, Stefan Klus, J. Eisert, Christof Schutte
          </td>
          <td>2018-09-07</td>
          <td>Journal of Computational and Nonlinear Dynamics</td>
          <td>61</td>
          <td>76</td>

            <td><a href='../recommendations/2b2aa13d4959073f61ad70555bc8c7da7d116196' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="First principles modeling of physical systems has led to significant technological advances across all branches of science. For nonlinear systems, however, small modeling errors can lead to significant deviations from the true, measured behavior. Even in mechanical systems, where the equations are assumed to be well-known, there are often model discrepancies corresponding to nonlinear friction, wind resistance, etc. Discovering models for these discrepancies remains an open challenge for many complex systems. In this work, we use the sparse identification of nonlinear dynamics (SINDy) algorithm to discover a model for the discrepancy between a simplified model and measurement data. In particular, we assume that the model mismatch can be sparsely represented in a library of candidate model terms. We demonstrate the efficacy of our approach on several examples including experimental data from a double pendulum on a cart. We further design and implement a feed-forward controller in simulations, showing improvement with a discrepancy model.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/73dd9c49f205280991826b2ea4b50344203916b4" target='_blank'>
                Learning Discrepancy Models From Experimental Data
                </a>
              </td>
          <td>
            Kadierdan Kaheman, E. Kaiser, B. Strom, J. Kutz, S. Brunton
          </td>
          <td>2019-09-18</td>
          <td>ArXiv, arXiv.org</td>
          <td>32</td>
          <td>65</td>

            <td><a href='../recommendations/73dd9c49f205280991826b2ea4b50344203916b4' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Machine learning (ML) and artificial intelligence (AI) algorithms are now being used to automate the discovery of physics principles and governing equations from measurement data alone. However, positing a universal physical law from data is challenging without simultaneously proposing an accompanying discrepancy model to account for the inevitable mismatch between theory and measurements. By revisiting the classic problem of modeling falling objects of different size and mass, we highlight a number of nuanced issues that must be addressed by modern data-driven methods for automated physics discovery. Specifically, we show that measurement noise and complex secondary physical mechanisms, like unsteady fluid drag forces, can obscure the underlying law of gravitation, leading to an erroneous model. We use the sparse identification of non-linear dynamics (SINDy) method to identify governing equations for real-world measurement data and simulated trajectories. Incorporating into SINDy the assumption that each falling object is governed by a similar physical law is shown to improve the robustness of the learned models, but discrepancies between the predictions and observations persist due to subtleties in drag dynamics. This work highlights the fact that the naive application of ML/AI will generally be insufficient to infer universal physical laws without further modification.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/35e2571c17246577e0bc1b9de57a314c3b60e220" target='_blank'>
                Discovery of Physics From Data: Universal Laws and Discrepancies
                </a>
              </td>
          <td>
            Brian M. de Silva, D. Higdon, S. Brunton, J. Kutz
          </td>
          <td>2019-06-19</td>
          <td>Frontiers in Artificial Intelligence</td>
          <td>67</td>
          <td>65</td>

            <td><a href='../recommendations/35e2571c17246577e0bc1b9de57a314c3b60e220' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Researchers propose sparse regression for identifying governing partial differential equations for spatiotemporal systems. We propose a sparse regression method capable of discovering the governing partial differential equation(s) of a given system by time series measurements in the spatial domain. The regression framework relies on sparsity-promoting techniques to select the nonlinear and partial derivative terms of the governing equations that most accurately represent the data, bypassing a combinatorially large search through all possible candidate models. The method balances model complexity and regression accuracy by selecting a parsimonious model via Pareto analysis. Time series measurements can be made in an Eulerian framework, where the sensors are fixed spatially, or in a Lagrangian framework, where the sensors move with the dynamics. The method is computationally efficient, robust, and demonstrated to work on a variety of canonical problems spanning a number of scientific domains including Navier-Stokes, the quantum harmonic oscillator, and the diffusion equation. Moreover, the method is capable of disambiguating between potentially nonunique dynamical terms by using multiple time series taken with different initial data. Thus, for a traveling wave, the method can distinguish between a linear wave equation and the Korteweg–de Vries equation, for instance. The method provides a promising new technique for discovering governing equations and physical laws in parameterized spatiotemporal systems, where first-principles derivations are intractable.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0acd117521ef5aafb09fed02ab415523b330b058" target='_blank'>
                Data-driven discovery of partial differential equations
                </a>
              </td>
          <td>
            S. Rudy, S. Brunton, J. Proctor, J. Kutz
          </td>
          <td>2016-09-21</td>
          <td>Science Advances</td>
          <td>1173</td>
          <td>65</td>

            <td><a href='../recommendations/0acd117521ef5aafb09fed02ab415523b330b058' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Sparse model identification enables the discovery of nonlinear dynamical systems purely from data; however, this approach is sensitive to noise, especially in the low-data limit. In this work, we leverage the statistical approach of bootstrap aggregating (bagging) to robustify the sparse identification of the nonlinear dynamics (SINDy) algorithm. First, an ensemble of SINDy models is identified from subsets of limited and noisy data. The aggregate model statistics are then used to produce inclusion probabilities of the candidate functions, which enables uncertainty quantification and probabilistic forecasts. We apply this ensemble-SINDy (E-SINDy) algorithm to several synthetic and real-world datasets and demonstrate substantial improvements to the accuracy and robustness of model discovery from extremely noisy and limited data. For example, E-SINDy uncovers partial differential equations models from data with more than twice as much measurement noise as has been previously reported. Similarly, E-SINDy learns the Lotka Volterra dynamics from remarkably limited data of yearly lynx and hare pelts collected from 1900 to 1920. E-SINDy is computationally efficient, with similar scaling as standard SINDy. Finally, we show that ensemble statistics from E-SINDy can be exploited for active learning and improved model predictive control.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/883547fdbd88552328a6615ec620f96e39c57018" target='_blank'>
                Ensemble-SINDy: Robust sparse model discovery in the low-data, high-noise limit, with active learning and control
                </a>
              </td>
          <td>
            Urban Fasel, J. Kutz, Bingni W. Brunton, S. Brunton
          </td>
          <td>2021-11-22</td>
          <td>Proceedings of the Royal Society A, Proceedings. Mathematical, Physical, and Engineering Sciences</td>
          <td>159</td>
          <td>65</td>

            <td><a href='../recommendations/883547fdbd88552328a6615ec620f96e39c57018' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e6f0a85009481dcfd93aaa43ed3f980e5033b0d8" target='_blank'>
                Learning sparse nonlinear dynamics via mixed-integer optimization
                </a>
              </td>
          <td>
            D. Bertsimas, Wes Gurnee
          </td>
          <td>2022-06-01</td>
          <td>Nonlinear Dynamics</td>
          <td>28</td>
          <td>91</td>

            <td><a href='../recommendations/e6f0a85009481dcfd93aaa43ed3f980e5033b0d8' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Regularized regression problems are ubiquitous in statistical modeling, signal processing, and machine learning. Sparse regression, in particular, has been instrumental in scientific model discovery, including compressed sensing applications, variable selection, and high-dimensional analysis. We propose a broad framework for sparse relaxed regularized regression, called SR3. The key idea is to solve a relaxation of the regularized problem, which has three advantages over the state-of-the-art: 1) solutions of the relaxed problem are superior with respect to errors, false positives, and conditioning; 2) relaxation allows extremely fast algorithms for both convex and nonconvex formulations; and 3) the methods apply to composite regularizers, essential for total variation (TV) as well as sparsity-promoting formulations using tight frames. We demonstrate the advantages of SR3 (computational efficiency, higher accuracy, faster convergence rates, and greater flexibility) across a range of regularized regression problems with synthetic and real data, including applications in compressed sensing, LASSO, matrix completion, TV regularization, and group sparsity. Following standards of reproducible research, we also provide a companion MATLAB package that implements these examples.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c0fc3882a9976f6a9cdc3a724bce184b786503da" target='_blank'>
                A Unified Framework for Sparse Relaxed Regularized Regression: SR3
                </a>
              </td>
          <td>
            P. Zheng, T. Askham, S. Brunton, J. Kutz, A. Aravkin
          </td>
          <td>2018-07-14</td>
          <td>IEEE Access</td>
          <td>115</td>
          <td>65</td>

            <td><a href='../recommendations/c0fc3882a9976f6a9cdc3a724bce184b786503da' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

    </tbody>
    <tfoot>
      <tr>
          <th>Abstract</th>
          <th>Title</th>
          <th>Authors</th>
          <th>Publication Date</th>
          <th>Journal/ Conference</th>
          <th>Citation count</th>
          <th>Highest h-index</th>
          <th>View recommendations</th>
      </tr>
    </tfoot>
    </table>
    </p>
  </div>

  <div data-intro='Recommended articles extracted by contrasting
                  articles that are relevant against not relevant for Symbolic regression'>
    <p>
    <h3 id="recommended_articles">Recommended articles on <i>Symbolic regression</i></h3>
    <table id="table2" class="display" style="width:100%">
    <thead>
      <tr>
          <th>Abstract</th>
          <th>Title</th>
          <th>Authors</th>
          <th>Publication Date</th>
          <th>Journal/Conference</th>
          <th>Citation count</th>
          <th>Highest h-index</th>
      </tr>
    </thead>
    <tbody>

        <tr id="Over the past few years, equation discovery has gained popularity in different fields of science and engineering. However, existing equation discovery algorithms rely on the availability of noisy measurements of the state variables (i.e., displacement {and velocity}). This is a major bottleneck in structural dynamics, where we often only have access to acceleration measurements. To that end, this paper introduces a novel equation discovery algorithm for discovering governing equations of dynamical systems from acceleration-only measurements. The proposed algorithm employs a library-based approach for equation discovery. To enable equation discovery from acceleration-only measurements, we propose a novel Approximate Bayesian Computation (ABC) model that prioritizes parsimonious models. The efficacy of the proposed algorithm is illustrated using {four} structural dynamics examples that include both linear and nonlinear dynamical systems. The case studies presented illustrate the possible application of the proposed approach for equation discovery of dynamical systems from acceleration-only measurements.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f046e6be05e115bc55624ef726d92d6d06303346" target='_blank'>
              Discovering governing equation in structural dynamics from acceleration-only measurements
              </a>
            </td>
          <td>
            Calvin Alvares, Souvik Chakraborty
          </td>
          <td>2024-07-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="This work presents a data-driven method for learning low-dimensional time-dependent physics-based surrogate models whose predictions are endowed with uncertainty estimates. We use the operator inference approach to model reduction that poses the problem of learning low-dimensional model terms as a regression of state space data and corresponding time derivatives by minimizing the residual of reduced system equations. Standard operator inference models perform well with accurate training data that are dense in time, but producing stable and accurate models when the state data are noisy and/or sparse in time remains a challenge. Another challenge is the lack of uncertainty estimation for the predictions from the operator inference models. Our approach addresses these challenges by incorporating Gaussian process surrogates into the operator inference framework to (1) probabilistically describe uncertainties in the state predictions and (2) procure analytical time derivative estimates with quantified uncertainties. The formulation leads to a generalized least-squares regression and, ultimately, reduced-order models that are described probabilistically with a closed-form expression for the posterior distribution of the operators. The resulting probabilistic surrogate model propagates uncertainties from the observed state data to reduced-order predictions. We demonstrate the method is effective for constructing low-dimensional models of two nonlinear partial differential equations representing a compressible flow and a nonlinear diffusion-reaction process, as well as for estimating the parameters of a low-dimensional system of nonlinear ordinary differential equations representing compartmental models in epidemiology.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6c14dacd4e17965fe6d0db5f5cefb7cb8547dbb3" target='_blank'>
              Bayesian learning with Gaussian processes for low-dimensional representations of time-dependent nonlinear systems
              </a>
            </td>
          <td>
            Shane A. McQuarrie, Anirban Chaudhuri, Karen Willcox, Mengwu Guo
          </td>
          <td>2024-08-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Enhancing the sparsity of data-driven reduced-order models (ROMs) has gained increasing attention in recent years. In this work, we analyze an efficient approach to identifying skillful ROMs with a sparse structure using an information-theoretic indicator called causation entropy. The causation entropy quantifies in a statistical way the additional contribution of each term to the underlying dynamics beyond the information already captured by all the other terms in the ansatz. By doing so, the causation entropy assesses the importance of each term to the dynamics before a parameter estimation procedure is performed. Thus, the approach can be utilized to eliminate terms with little dynamic impact, leading to a parsimonious structure that retains the essential physics. To circumvent the difficulty of estimating high-dimensional probability density functions (PDFs) involved in the causation entropy computation, we leverage Gaussian approximations for such PDFs, which are demonstrated to be sufficient even in the presence of highly non-Gaussian dynamics. The effectiveness of the approach is illustrated by the Kuramoto-Sivashinsky equation by building sparse causation-based ROMs for various purposes, such as recovering long-term statistics and inferring unobserved dynamics via data assimilation with partial observations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/51343d94516402e35ba4c9c52a62e0d4dd4986ba" target='_blank'>
              Minimum Reduced-Order Models via Causal Inference
              </a>
            </td>
          <td>
            Nan Chen, Honghu Liu
          </td>
          <td>2024-06-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="This paper focuses on the application of experimental data-based system identification of unknown systems utilising sparse identification of nonlinear dynamics (SINDy). SINDy is used to detect the system dynamics in the three well-known nonlinear systems. Analyzed are SINDy’s abilities to accurately represent transient/steady-state behaviour, noise effect, and model structure. A sparse set of basis functions can effectively capture the dynamics of a system, according to the data-driven approach known as SINDy. The coefficients of these basis functions are determined via methods of sparse regression, and the final model is made up of a number of sparse ordinary differential equations. The findings demonstrate that SINDy, with sufficient time-series data, can capture both transient and steady-state phenomena. According to the analysis of the noise effect, SINDy’s performance declines as the system’s noise level rises. The feature library must contain the appropriate model structure in order for SINDy to function effectively. SINDy has the potential to extract unknown system dynamics from experimental data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/315b7c145c5a86b92e656ad174cede9f67bf3f34" target='_blank'>
              Data-driven system identification of unknown systems utilising sparse identification of nonlinear dynamics (SINDy)
              </a>
            </td>
          <td>
            P. Pandey, H. Haddad Khodaparast, M. Friswell, T. Chatterjee, N. Jamia, T. Deighan
          </td>
          <td>2024-06-01</td>
          <td>Journal of Physics: Conference Series</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="The Sparse Identification of Nonlinear Dynamics (SINDy) framework is a robust method for identifying governing equations, successfully applied to ordinary, partial, and stochastic differential equations. In this work we extend SINDy to identify delay differential equations by using an augmented library that includes delayed samples and Bayesian optimization. To identify a possibly unknown delay we minimize the reconstruction error over a set of candidates. The resulting methodology improves the overall performance by remarkably reducing the number of calls to SINDy with respect to a brute force approach. We also address a multivariate setting to identify multiple unknown delays and (non-multiplicative) parameters. Several numerical tests on delay differential equations with different long-term behavior, number of variables, delays, and parameters support the use of Bayesian optimization highlighting both the efficacy of the proposed methodology and its computational advantages. As a consequence, the class of discoverable models is significantly expanded.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/827638609aa7a84d10096156bc7ead43d8060c5a" target='_blank'>
              Data-driven Discovery of Delay Differential Equations with Discrete Delays
              </a>
            </td>
          <td>
            Alessandro Pecile, N. Demo, M. Tezzele, G. Rozza, Dimitri Breda
          </td>
          <td>2024-07-29</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>49</td>
        </tr>

        <tr id="We present a computational technique for modeling the evolution of dynamical systems in a reduced basis, with a focus on the challenging problem of modeling partially-observed partial differential equations (PDEs) on high-dimensional non-uniform grids. We address limitations of previous work on data-driven flow map learning in the sense that we focus on noisy and limited data to move toward data collection scenarios in real-world applications. Leveraging recent work on modeling PDEs in modal and nodal spaces, we present a neural network structure that is suitable for PDE modeling with noisy and limited data available only on a subset of the state variables or computational domain. In particular, spatial grid-point measurements are reduced using a learned linear transformation, after which the dynamics are learned in this reduced basis before being transformed back out to the nodal space. This approach yields a drastically reduced parameterization of the neural network compared with previous flow map models for nodal space learning. This primarily allows for smaller training data sets, but also enables reduced training times.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/33821b7c0acd5258ca0c60a09ffdc55439ac7ac2" target='_blank'>
              Principal Component Flow Map Learning of PDEs from Incomplete, Limited, and Noisy Data
              </a>
            </td>
          <td>
            Victor Churchill
          </td>
          <td>2024-07-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Model parsimony is an important \emph{cognitive bias} in data-driven modelling that aids interpretability and helps to prevent over-fitting. Sparse identification of nonlinear dynamics (SINDy) methods are able to learn sparse representations of complex dynamics directly from data, given a basis of library functions. In this work, a novel Bayesian treatment of dictionary learning system identification, as an alternative to SINDy, is envisaged. The proposed method -- Bayesian identification of nonlinear dynamics (BINDy) -- is distinct from previous approaches in that it targets the full joint posterior distribution over both the terms in the library and their parameterisation in the model. This formulation confers the advantage that an arbitrary prior may be placed over the model structure to produce models that are sparse in the model space rather than in parameter space. Because this posterior is defined over parameter vectors that can change in dimension, the inference cannot be performed by standard techniques. Instead, a Gibbs sampler based on reversible-jump Markov-chain Monte-Carlo is proposed. BINDy is shown to compare favourably to ensemble SINDy in three benchmark case-studies. In particular, it is seen that the proposed method is better able to assign high probability to correct model terms.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/04666a9e47b5508a0c0f966265fe51da2b2c634a" target='_blank'>
              BINDy -- Bayesian identification of nonlinear dynamics with reversible-jump Markov-chain Monte-Carlo
              </a>
            </td>
          <td>
            M.D. Champneys, T. J. Rogers
          </td>
          <td>2024-08-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="The quasipotential function allows for comprehension and prediction of the escape mechanisms from metastable states in nonlinear dynamical systems. This function acts as a natural extension of the potential function for non-gradient systems and it unveils important properties such as the maximum likelihood transition paths, transition rates and expected exit times of the system. Here, we leverage on machine learning via the combination of two data-driven techniques, namely a neural network and a sparse regression algorithm, to obtain symbolic expressions of quasipotential functions. The key idea is first to determine an orthogonal decomposition of the vector field that governs the underlying dynamics using neural networks, then to interpret symbolically the downhill and circulatory components of the decomposition. These functions are regressed simultaneously with the addition of mathematical constraints. We show that our approach discovers a parsimonious quasipotential equation for an archetypal model with a known exact quasipotential and for the dynamics of a nanomechanical resonator. The analytical forms deliver direct access to the stability of the metastable states and predict rare events with significant computational advantages. Our data-driven approach is of interest for a wide range of applications in which to assess the fluctuating dynamics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/174f3a662f5a30364246d8cf0f34af33eac8ccfd" target='_blank'>
              Sparse identification of quasipotentials via a combined data-driven method
              </a>
            </td>
          <td>
            Bo Lin, P. Belardinelli
          </td>
          <td>2024-07-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="Kolmogorov-Arnold networks (KANs) as an alternative to multi-layer perceptrons (MLPs) are a recent development demonstrating strong potential for data-driven modeling. This work applies KANs as the backbone of a neural ordinary differential equation (ODE) framework, generalizing their use to the time-dependent and temporal grid-sensitive cases often seen in dynamical systems and scientific machine learning applications. The proposed KAN-ODEs retain the flexible dynamical system modeling framework of Neural ODEs while leveraging the many benefits of KANs compared to MLPs, including higher accuracy and faster neural scaling, stronger interpretability and generalizability, and lower parameter counts. First, we quantitatively demonstrated these improvements in a comprehensive study of the classical Lotka-Volterra predator-prey model. We then showcased the KAN-ODE framework's ability to learn symbolic source terms and complete solution profiles in higher-complexity and data-lean scenarios including wave propagation and shock formation, the complex Schr\"odinger equation, and the Allen-Cahn phase separation equation. The successful training of KAN-ODEs, and their improved performance compared to traditional Neural ODEs, implies significant potential in leveraging this novel network architecture in myriad scientific machine learning applications for discovering hidden physics and predicting dynamic evolution.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/efeeddb4162e3eefbe1d974d6ce7cd1d32498a6b" target='_blank'>
              KAN-ODEs: Kolmogorov-Arnold Network Ordinary Differential Equations for Learning Dynamical Systems and Hidden Physics
              </a>
            </td>
          <td>
            Benjamin C. Koenig, Suyong Kim, Sili Deng
          </td>
          <td>2024-07-05</td>
          <td>ArXiv</td>
          <td>3</td>
          <td>22</td>
        </tr>

        <tr id="This paper presents a sequence of two approaches for the data-driven control-oriented modeling of networked systems, i.e., the systems that involve many interacting dynamical components. First, a novel deep learning approach named the weak Latent Dynamics Model (wLDM) is developed for learning generic nonlinear dynamics with control. Leveraging the weak form, the wLDM enables more numerically stable and computationally efficient training as well as more accurate prediction, when compared to conventional methods such as neural ordinary differential equations. Building upon the wLDM framework, we propose the weak Graph Koopman Bilinear Form (wGKBF) model, which integrates geometric deep learning and Koopman theory to learn latent space dynamics for networked systems, especially for the challenging cases having multiple timescales. The effectiveness of the wLDM framework and wGKBF model are demonstrated on three example systems of increasing complexity - a controlled double pendulum, the stiff Brusselator dynamics, and an electrified aircraft energy system. These numerical examples show that the wLDM and wGKBF achieve superior predictive accuracy and training efficiency as compared to baseline models. Parametric studies provide insights into the effects of hyperparameters in the weak form. The proposed framework shows the capability to efficiently capture control-dependent dynamics in these systems, including stiff dynamics and multi-physics interactions, offering a promising direction for learning control-oriented models of complex networked systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c2168dc84b931e82498692c0f9277bed180e91df" target='_blank'>
              Learning Networked Dynamical System Models with Weak Form and Graph Neural Networks
              </a>
            </td>
          <td>
            Yin Yu, Daning Huang, Seho Park, H. Pangborn
          </td>
          <td>2024-07-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>11</td>
        </tr>

        <tr id="The parametric greedy latent space dynamics identification (gLaSDI) framework has demonstrated promising potential for accurate and efficient modeling of high-dimensional nonlinear physical systems. However, it remains challenging to handle noisy data. To enhance robustness against noise, we incorporate the weak-form estimation of nonlinear dynamics (WENDy) into gLaSDI. In the proposed weak-form gLaSDI (WgLaSDI) framework, an autoencoder and WENDy are trained simultaneously to discover intrinsic nonlinear latent-space dynamics of high-dimensional data. Compared to the standard sparse identification of nonlinear dynamics (SINDy) employed in gLaSDI, WENDy enables variance reduction and robust latent space discovery, therefore leading to more accurate and efficient reduced-order modeling. Furthermore, the greedy physics-informed active learning in WgLaSDI enables adaptive sampling of optimal training data on the fly for enhanced modeling accuracy. The effectiveness of the proposed framework is demonstrated by modeling various nonlinear dynamical problems, including viscous and inviscid Burgers' equations, time-dependent radial advection, and the Vlasov equation for plasma physics. With data that contains 5-10% Gaussian white noise, WgLaSDI outperforms gLaSDI by orders of magnitude, achieving 1-7% relative errors. Compared with the high-fidelity models, WgLaSDI achieves 121 to 1,779x speed-up.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/15fe2e82d4161103b69fe83f184552b9e9774633" target='_blank'>
              Physics-informed active learning with simultaneous weak-form latent space dynamics identification
              </a>
            </td>
          <td>
            Xiaolong He, April Tran, David M. Bortz, Youngsoo Choi
          </td>
          <td>2024-06-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Dynamic Mode Decomposition (DMD) and its variants, such as extended DMD (EDMD), are broadly used to fit simple linear models to dynamical systems known from observable data. As DMD methods work well in several situations but perform poorly in others, a clarification of the assumptions under which DMD is applicable is desirable. Upon closer inspection, existing interpretations of DMD methods based on the Koopman operator are not quite satisfactory: they justify DMD under assumptions that hold only with probability zero for generic observables. Here, we give a justification for DMD as a local, leading-order reduced model for the dominant system dynamics under conditions that hold with probability one for generic observables and non-degenerate observational data. We achieve this for autonomous and for periodically forced systems of finite or infinite dimensions by constructing linearizing transformations for their dominant dynamics within attracting slow spectral submanifolds (SSMs). Our arguments also lead to a new algorithm, data-driven linearization (DDL), which is a higher-order, systematic linearization of the observable dynamics within slow SSMs. We show by examples how DDL outperforms DMD and EDMD on numerical and experimental data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ce624ece7e2f2933c1731bee6e5b03bf7a57c90b" target='_blank'>
              Data-Driven Linearization of Dynamical Systems
              </a>
            </td>
          <td>
            George Haller, B. Kasz'as
          </td>
          <td>2024-07-11</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>1</td>
        </tr>

        <tr id="Machine learning techniques have recently been of great interest for solving differential equations. Training these models is classically a data-fitting task, but knowledge of the expression of the differential equation can be used to supplement the training objective, leading to the development of physics-informed scientific machine learning. In this article, we focus on one class of models called nonlinear vector autoregression (NVAR) to solve ordinary differential equations (ODEs). Motivated by connections to numerical integration and physics-informed neural networks, we explicitly derive the physics-informed NVAR (piNVAR) which enforces the right-hand side of the underlying differential equation regardless of NVAR construction. Because NVAR and piNVAR completely share their learned parameters, we propose an augmented procedure to jointly train the two models. Then, using both data-driven and ODE-driven metrics, we evaluate the ability of the piNVAR model to predict solutions to various ODE systems, such as the undamped spring, a Lotka-Volterra predator-prey nonlinear model, and the chaotic Lorenz system.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/59096640a40ed6b70acbbfdaca5a505cd1330bb4" target='_blank'>
              Physics-informed nonlinear vector autoregressive models for the prediction of dynamical systems
              </a>
            </td>
          <td>
            James H. Adler, Samuel Hocking, Xiaozhe Hu, Shafiqul Islam
          </td>
          <td>2024-07-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="We propose a novel learning framework for Koopman operator of nonlinear dynamical systems that is informed by the governing equation and guarantees long-time stability and robustness to noise. In contrast to existing frameworks where either ad-hoc observables or blackbox neural networks are used to construct observables in the extended dynamic mode decomposition (EDMD), our observables are informed by governing equations via Polyflow. To improve the noise robustness and guarantee long-term stability, we designed a stable parameterization of the Koopman operator together with a progressive learning strategy for roll-out recurrent loss. To further improve model performance in the phase space, a simple iterative strategy of data augmentation was developed. Numerical experiments of prediction and control of classic nonlinear systems with ablation study showed the effectiveness of the proposed techniques over several state-of-the-art practices.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/33d038a0e7775662768898c432284e433922c891" target='_blank'>
              Learning Noise-Robust Stable Koopman Operator for Control with Physics-Informed Observables
              </a>
            </td>
          <td>
            Shahriar Akbar Sakib, Shaowu Pan
          </td>
          <td>2024-08-13</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Stochastic collocation (SC) is a well‐known non‐intrusive method of constructing surrogate models for uncertainty quantification. In dynamical systems, SC is especially suited for full‐field uncertainty propagation that characterizes the distributions of the high‐dimensional solution fields of a model with stochastic input parameters. However, due to the highly nonlinear nature of the parameter‐to‐solution map in even the simplest dynamical systems, the constructed SC surrogates are often inaccurate. This work presents an alternative approach, where we apply the SC approximation over the dynamics of the model, rather than the solution. By combining the data‐driven sparse identification of nonlinear dynamics framework with SC, we construct dynamics surrogates and integrate them through time to construct the surrogate solutions. We demonstrate that the SC‐over‐dynamics framework leads to smaller errors, both in terms of the approximated system trajectories as well as the model state distributions, when compared against full‐field SC applied to the solutions directly. We present numerical evidence of this improvement using three test problems: a chaotic ordinary differential equation, and two partial differential equations from solid mechanics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/dc0b58e254bb512300814c52b4a101046377d6e4" target='_blank'>
              Accurate data‐driven surrogates of dynamical systems for forward propagation of uncertainty
              </a>
            </td>
          <td>
            Saibal De, Reese E. Jones, H. Kolla
          </td>
          <td>2024-08-03</td>
          <td>International Journal for Numerical Methods in Engineering</td>
          <td>0</td>
          <td>30</td>
        </tr>

        <tr id="Data-driven discovery of partial differential equations (PDEs) has emerged as a promising approach for deriving governing physics when domain knowledge about observed data is limited. Despite recent progress, the identification of governing equations and their parametric dependencies using conventional information criteria remains challenging in noisy situations, as the criteria tend to select overly complex PDEs. In this paper, we introduce an extension of the uncertainty-penalized Bayesian information criterion (UBIC), which is adapted to solve parametric PDE discovery problems efficiently without requiring computationally expensive PDE simulations. This extended UBIC uses quantified PDE uncertainty over different temporal or spatial points to prevent overfitting in model selection. The UBIC is computed with data transformation based on power spectral densities to discover the governing parametric PDE that truly captures qualitative features in frequency space with a few significant terms and their parametric dependencies (i.e., the varying PDE coefficients), evaluated with confidence intervals. Numerical experiments on canonical PDEs demonstrate that our extended UBIC can identify the true number of terms and their varying coefficients accurately, even in the presence of noise. The code is available at \url{https://github.com/Pongpisit-Thanasutives/parametric-discovery}.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d605721a21ed5e6e69cc14a1ab3eb9a559099ea9" target='_blank'>
              Adaptation of uncertainty-penalized Bayesian information criterion for parametric partial differential equation discovery
              </a>
            </td>
          <td>
            Pongpisit Thanasutives, Ken-ichi Fukui
          </td>
          <td>2024-08-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Structural dynamics models with nonlinear stiffness appear, for example, when analyzing systems with nonlinear material behavior or undergoing large deformations. For complex systems, these models become too large for real-time applications or multi-query workflows. Hence, model reduction is needed. However, the mathematical operators of these models are often not available since, as is common in industry practice, the models are constructed using commercial simulation software. In this work, we propose an operator inference-based approach aimed at inferring, from data generated by the simulation model, reduced-order models (ROMs) of structural dynamics systems with stiffness terms represented by polynomials of arbitrary degree. To ensure physically meaningful models, we impose constraints on the inference such that the model is guaranteed to exhibit stability properties. Convexity of the optimization problem associated with the inference is maintained by applying a sum-of-squares relaxation to the polynomial term. To further reduce the size of the ROM and improve numerical conditioning of the inference, we also propose a novel clustering-based sparsification of the polynomial term. We validate the proposed method on several numerical examples, including a representative 3D Finite Element Model (FEM) of a steel piston rod.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/12474e97123f0f45095cbb219da196a32731873d" target='_blank'>
              Stable Sparse Operator Inference for Nonlinear Structural Dynamics
              </a>
            </td>
          <td>
            P. D. Boef, Diana Manvelyan, Jos Maubach, W. Schilders, N. Wouw
          </td>
          <td>2024-07-31</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>47</td>
        </tr>

        <tr id="While linear systems are well-understood, no explicit solution exists for general nonlinear systems. Thus, it is desirable to make the understanding of linear system available in the nonlinear setting. This motivates the search for linearization techniques which are able to represent the nonlinear system by an equivalent, linear system. While much progress has been made extending various linearization techniques to larger domains and more delicate attractor geometries, the limitations of such techniques for truly nonlinear dynamics, such as dynamics with coexisting attractors, have been pointed out recently. In this work, we show that genuinely nonlinear dynamics can be globally linearized. To this end, we investigate systems with a continuous spectrum, a limit cycle, and coexisting solutions and explicitly construct linear systems mimicking these nonlinear behaviors as close as possible. We approximate the transformations between linear and nonlinear system with deep neural networks. The obtained linearizations are finite dimensional exceeding the phase space dimension of the underlying linear system by one at most.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2196ed95f5d349e07c7af94fd99240eec34dfdb2" target='_blank'>
              Learning Global Linear Representations of Truly Nonlinear Dynamics
              </a>
            </td>
          <td>
            Thomas Breunung, F. Kogelbauer
          </td>
          <td>2024-08-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Physics-Informed Neural Networks (PINNs) have revolutionized solving differential equations by integrating physical laws into neural network training. This paper explores PINNs for open-loop optimal control problems (OCPs) with incomplete information, such as unknown initial conditions and sparse boundary data. We derive optimality conditions from the Lagrangian multipliers and use a neural network to predict the state, adjoint, and control variables. In contrast with previous methods, our approach integrates these elements into a single neural network and addresses scenarios with consistently limited data. Specifically, we address the study of partially unknown equations identifying underlying parameters online by searching for the optimal solution. Numerical examples show the effectiveness of the proposed method even in scenarios characterized by a considerable lack of information.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1de965a4fc10f47113e0b8b25e5ae6627f2c9cbb" target='_blank'>
              A PINN approach for the online identification and control of unknown PDEs
              </a>
            </td>
          <td>
            Alessandro Alla, Giulia Bertaglia, Elisa Calzola
          </td>
          <td>2024-08-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/cabb9ef9934cc450e8873d693c8dd8dfc73087ab" target='_blank'>
              MBD-NODE: Physics-informed data-driven modeling and simulation of constrained multibody systems
              </a>
            </td>
          <td>
            Jingquan Wang, Shu Wang, H. Unjhawala, Jinlong Wu, D. Negrut
          </td>
          <td>2024-07-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>29</td>
        </tr>

        <tr id="The identification of a mathematical dynamics model is a crucial step in the designing process of a controller. However, it is often very difficult to identify the system's governing equations, especially in complex environments that combine physical laws of different disciplines. In this paper, we present a new approach that allows identifying an ordinary differential equation by means of a physics-informed machine learning algorithm. Our method introduces a special neural network that allows exploiting prior human knowledge to a certain degree and extends it autonomously, so that the resulting differential equations describe the system as accurately as possible. We validate the method on a Duffing oscillator with simulation data and, additionally, on a cascaded tank example with real-world data. Subsequently, we use the developed algorithm in a model-based reinforcement learning framework by alternately identifying and controlling a system to a target state. We test the performance by swinging-up an inverted pendulum on a cart.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9fb84f2c4de6cf8d43f1207b6c58095273d711f1" target='_blank'>
              Identifying Ordinary Differential Equations for Data-efficient Model-based Reinforcement Learning
              </a>
            </td>
          <td>
            Tobias Nagel, Marco F. Huber
          </td>
          <td>2024-06-28</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="We present a pragmatic approach to the sparse identification of nonlinear dynamics for systems with discrete delays. It relies on approximating the underlying delay model with a system of ordinary differential equations via pseudospectral collocation. To minimize the reconstruction error, the new strategy avoids optimizing all possible multiple unknown delays, identifying only the maximum one. The computational burden is thus greatly reduced, improving the performance of recent implementations that work directly on the delay system.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/af6a7301b4680a556da5635cdd6aedbb64f047b0" target='_blank'>
              Sparse identification of time delay systems via pseudospectral collocation
              </a>
            </td>
          <td>
            Enrico Bozzo, Dimitri Breda, Muhammad Tanveer
          </td>
          <td>2024-08-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0d487b041502645ead57bcc0782fa0256ccec2fc" target='_blank'>
              Development of data-driven modeling method for nonlinear coupling components
              </a>
            </td>
          <td>
            Taesan Ryu, Seunghun Baek
          </td>
          <td>2024-06-27</td>
          <td>Scientific Reports</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Conventional physics-based modeling techniques involve high effort, e.g., time and expert knowledge, while data-driven methods often lack interpretability, structure, and sometimes reliability. To mitigate this, we present a data-driven system identification framework that derives models in the port-Hamiltonian (pH) formulation. This formulation is suitable for multi-physical systems while guaranteeing the useful system theoretical properties of passivity and stability. Our framework combines linear and nonlinear reduction with structured, physics-motivated system identification. In this process, high-dimensional state data obtained from possibly nonlinear systems serves as input for an autoencoder, which then performs two tasks: (i) nonlinearly transforming and (ii) reducing this data onto a low-dimensional latent space. In this space, a linear pH system, that satisfies the pH properties per construction, is parameterized by the weights of a neural network. The mathematical requirements are met by defining the pH matrices through Cholesky factorizations. The neural networks that define the coordinate transformation and the pH system are identified in a joint optimization process to match the dynamics observed in the data while defining a linear pH system in the latent space. The learned, low-dimensional pH system can describe even nonlinear systems and is rapidly computable due to its small size. The method is exemplified by a parametric mass-spring-damper and a nonlinear pendulum example, as well as the high-dimensional model of a disc brake with linear thermoelastic behavior.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8c88f9ec4b5bd522ac8e312f90d2801489785951" target='_blank'>
              Data-driven identification of latent port-Hamiltonian systems
              </a>
            </td>
          <td>
            J. Rettberg, Jonas Kneifl, Julius Herb, Patrick Buchfink, J. Fehr, B. Haasdonk
          </td>
          <td>2024-08-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>32</td>
        </tr>

        <tr id="Closure models are widely used in simulating complex multiscale dynamical systems such as turbulence and the earth system, for which direct numerical simulation that resolves all scales is often too expensive. For those systems without a clear scale separation, deterministic and local closure models often lack enough generalization capability, which limits their performance in many real-world applications. In this work, we propose a data-driven modeling framework for constructing stochastic and non-local closure models via conditional diffusion model and neural operator. Specifically, the Fourier neural operator is incorporated into a score-based diffusion model, which serves as a data-driven stochastic closure model for complex dynamical systems governed by partial differential equations (PDEs). We also demonstrate how accelerated sampling methods can improve the efficiency of the data-driven stochastic closure model. The results show that the proposed methodology provides a systematic approach via generative machine learning techniques to construct data-driven stochastic closure models for multiscale dynamical systems with continuous spatiotemporal fields.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5b117384f237e71d202a61374a42d92e97b0c697" target='_blank'>
              Data-Driven Stochastic Closure Modeling via Conditional Diffusion Model and Neural Operator
              </a>
            </td>
          <td>
            Xinghao Dong, Chuanqi Chen, Jin-Long Wu
          </td>
          <td>2024-08-06</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>2</td>
        </tr>

        <tr id="An exponential growth in computing power, which has brought more sophisticated and higher resolution simulations of the climate system, and an exponential increase in observations since the first weather satellite was put in orbit, are revolutionizing climate science. Big data and associated algorithms, coalesced under the field of Machine Learning (ML), offer the opportunity to study the physics of the climate system in ways, and with an amount of detail, infeasible few years ago. The inference provided by ML has allowed to ask causal questions and improve prediction skills beyond classical barriers. Furthermore, when paired with modeling experiments or robust research in model parameterizations, ML is accelerating computations, increasing accuracy and allowing for generating very large ensembles at a fraction of the cost. In light of the urgency imposed by climate change and the rapidly growing role of ML, we review its broader accomplishments in climate physics. Decades long standing problems in observational data reconstruction, representation of sub-grid scale phenomena and climate (and weather) prediction are being tackled with new and justified optimism. Ultimately, this review aims at providing a perspective on the benefits and major challenges of exploiting ML in studying complex systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a92dc27ba04348cdf71682bfa77081d8a478b78f" target='_blank'>
              Machine Learning for the Physics of Climate
              </a>
            </td>
          <td>
            Annalisa Bracco, Julien Brajard, Henk Dijkstra, P. Hassanzadeh, Christian Lessig, C. Monteleoni
          </td>
          <td>2024-08-19</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>24</td>
        </tr>

        <tr id="The identification of self-similarity is an indispensable tool for understanding and modelling physical phenomena. Unfortunately, this is not always possible to perform formally in highly complex problems. We propose a methodology to extract the similarity variables of a self-similar physical process directly from data, without prior knowledge of the governing equations or boundary conditions, based on an optimization problem and symbolic regression. We analyze the accuracy and robustness of our method in four problems which have been influential in fluid mechanics research: a laminar boundary layer, Burger's equation, a turbulent wake, and a collapsing cavity. Our analysis considers datasets acquired via both numerical and wind-tunnel experiments.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b4e59a9e878c505fc222908a8279de60c32a29db" target='_blank'>
              Extracting self-similarity from data
              </a>
            </td>
          <td>
            Nikos Bempedelis, Luca Magri, Konstantinos Steiros
          </td>
          <td>2024-07-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Understanding how the collective activity of neural populations relates to computation and ultimately behavior is a key goal in neuroscience. To this end, statistical methods which describe high-dimensional neural time series in terms of low-dimensional latent dynamics have played a fundamental role in characterizing neural systems. Yet, what constitutes a successful method involves two opposing criteria: (1) methods should be expressive enough to capture complex nonlinear dynamics, and (2) they should maintain a notion of interpretability often only warranted by simpler linear models. In this paper, we develop an approach that balances these two objectives: the Gaussian Process Switching Linear Dynamical System (gpSLDS). Our method builds on previous work modeling the latent state evolution via a stochastic differential equation whose nonlinear dynamics are described by a Gaussian process (GP-SDEs). We propose a novel kernel function which enforces smoothly interpolated locally linear dynamics, and therefore expresses flexible -- yet interpretable -- dynamics akin to those of recurrent switching linear dynamical systems (rSLDS). Our approach resolves key limitations of the rSLDS such as artifactual oscillations in dynamics near discrete state boundaries, while also providing posterior uncertainty estimates of the dynamics. To fit our models, we leverage a modified learning objective which improves the estimation accuracy of kernel hyperparameters compared to previous GP-SDE fitting approaches. We apply our method to synthetic data and data recorded in two neuroscience experiments and demonstrate favorable performance in comparison to the rSLDS.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b38dffa6030cac42cce7564c8fe38875646c5f4f" target='_blank'>
              Modeling Latent Neural Dynamics with Gaussian Process Switching Linear Dynamical Systems
              </a>
            </td>
          <td>
            Amber Hu, D. Zoltowski, Aditya Nair, David Anderson, Lea Duncker, Scott W. Linderman
          </td>
          <td>2024-07-19</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>27</td>
        </tr>

        <tr id="We introduce a general framework for solving partial differential equations (PDEs) using generative diffusion models. In particular, we focus on the scenarios where we do not have the full knowledge of the scene necessary to apply classical solvers. Most existing forward or inverse PDE approaches perform poorly when the observations on the data or the underlying coefficients are incomplete, which is a common assumption for real-world measurements. In this work, we propose DiffusionPDE that can simultaneously fill in the missing information and solve a PDE by modeling the joint distribution of the solution and coefficient spaces. We show that the learned generative priors lead to a versatile framework for accurately solving a wide range of PDEs under partial observation, significantly outperforming the state-of-the-art methods for both forward and inverse directions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5c821763f76272b6deee95f9729107969ce0ae44" target='_blank'>
              DiffusionPDE: Generative PDE-Solving Under Partial Observation
              </a>
            </td>
          <td>
            Jiahe Huang, Guandao Yang, Zichen Wang, Jeong Joon Park
          </td>
          <td>2024-06-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="In order to accurately model the dynamics of non-linear electro-mechanical systems, it is imperative to consider the contributions of coupling terms and dissipation. The Lagrangian formulation alone is insufficient to fully capture the holistic behavior of the system. Coupling and dissipation mechanisms play a pivotal role in shaping the system's response. Consequently, to effectively capture the dynamics of inter-coupled electro-mechanical systems with dissipation, we propose an extended Lagrangian-informed deep neural network framework in this paper. Our approach leverages the underlying physics-based knowledge of the system, incorporating it into the neural network architecture. By employing the Euler-Lagrange equations as constraints in the training process, we ensure that the learned dynamics conform to the true behavior of the system. To validate the theoretical framework, we conduct simulation experiments on a DC motor with a cart system, which serves as a representative model of dissipative nonlinear electro-mechanical systems. The experimental results demonstrate the efficacy of our approach in accurately capturing and integrating the dynamics to solve the reference tracking model predictive control design.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9fec77456fc41a426a57f697c4e29a12b83d9962" target='_blank'>
              Extended Lagrangian-Informed Deep Learning and Control for Electro-mechanical Systems
              </a>
            </td>
          <td>
            Nikhil Pagar, Pegah Ghaf-Ghanbari, Atul Kelkar, Javad Mohammadpour
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Forecasting dynamical systems is of importance to numerous real-world applications. When possible, dynamical systems forecasts are constructed based on first-principles-based models such as through the use of differential equations. When these equations are unknown, non-intrusive techniques must be utilized to build predictive models from data alone. Machine learning (ML) methods have recently been used for such tasks. Moreover, ML methods provide the added advantage of significant reductions in time-to-solution for predictions in contrast with first-principle based models. However, many state-of-the-art ML-based methods for forecasting rely on neural networks, which may be expensive to train and necessitate requirements for large amounts of memory. In this work, we propose a quantum mechanics inspired ML modeling strategy for learning nonlinear dynamical systems that provides data-driven forecasts for complex dynamical systems with reduced training time and memory costs. This approach, denoted the quantum reservoir computing technique (QRC), is a hybrid quantum-classical framework employing an ensemble of interconnected small quantum systems via classical linear feedback connections. By mapping the dynamical state to a suitable quantum representation amenable to unitary operations, QRC is able to predict complex nonlinear dynamical systems in a stable and accurate manner. We demonstrate the efficacy of this framework through benchmark forecasts of the NOAA Optimal Interpolation Sea Surface Temperature dataset and compare the performance of QRC to other ML methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ff3c3b75e08bf25e53956e10e92ec03e5cda30f6" target='_blank'>
              Higher order quantum reservoir computing for non-intrusive reduced-order models
              </a>
            </td>
          <td>
            Vinamr Jain, R. Maulik
          </td>
          <td>2024-07-31</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>21</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8d69703a20ce4710f71900130dd935761bbf01fa" target='_blank'>
              Promising directions of machine learning for partial differential equations
              </a>
            </td>
          <td>
            Steve Brunton, J. Kutz
          </td>
          <td>2024-06-28</td>
          <td>Nature computational science</td>
          <td>3</td>
          <td>2</td>
        </tr>

        <tr id="Neural simulators for modeling complex dynamical systems have been extensively studied for various real-world applications, such as weather forecasting, ocean current prediction, and computational fluid dynamics simulation. Although they have demonstrated powerful fitting and predicting, most existing models are only built to learn single-system dynamics. Several advanced researches have considered learning dynamics across environments, which can exploit the potential commonalities among the dynamics across environments and adapt to new environments. However, these methods still are prone to scarcity problems where per-environment data is sparse or limited. Therefore, we propose a novel CoNDP (Context-Informed Neural ODE Processes) to achieve learning system dynamics from sparse observations across environments. It can fully use contextual information of each environment to better capture the intrinsic commonalities across environments and distinguishable differences among environments while modeling uncertainty of system evolution, producing more accurate predictions. Intensive experiments are conducted on five complex dynamical systems in various fields. Results show that the proposed CoNDP can achieve optimal results compared with common neural simulators and state-of-the-art cross-environmental models.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/40337006a651c2110229b8ae928a5d5fe9a01da1" target='_blank'>
              Stochastic Neural Simulator for Generalizing Dynamical Systems across Environments
              </a>
            </td>
          <td>
            Liu Jiaqi, Jiaxu Cui, Jiayi Yang, Bo Yang
          </td>
          <td>2024-08-01</td>
          <td>Proceedings of the Thirty-ThirdInternational Joint Conference on Artificial Intelligence</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="Uncertainty quantification (UQ) is a crucial but challenging task in many high-dimensional regression or learning problems to increase the confidence of a given predictor. We develop a new data-driven approach for UQ in regression that applies both to classical regression approaches such as the LASSO as well as to neural networks. One of the most notable UQ techniques is the debiased LASSO, which modifies the LASSO to allow for the construction of asymptotic confidence intervals by decomposing the estimation error into a Gaussian and an asymptotically vanishing bias component. However, in real-world problems with finite-dimensional data, the bias term is often too significant to be neglected, resulting in overly narrow confidence intervals. Our work rigorously addresses this issue and derives a data-driven adjustment that corrects the confidence intervals for a large class of predictors by estimating the means and variances of the bias terms from training data, exploiting high-dimensional concentration phenomena. This gives rise to non-asymptotic confidence intervals, which can help avoid overestimating uncertainty in critical applications such as MRI diagnosis. Importantly, our analysis extends beyond sparse regression to data-driven predictors like neural networks, enhancing the reliability of model-based deep learning. Our findings bridge the gap between established theory and the practical applicability of such debiased methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6b74e7097e6bf5e51f1391656df98c0c04de0d93" target='_blank'>
              Non-Asymptotic Uncertainty Quantification in High-Dimensional Learning
              </a>
            </td>
          <td>
            Frederik Hoppe, C. M. Verdun, Hannah Laus, Felix Krahmer, Holger Rauhut
          </td>
          <td>2024-07-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="In this paper, we propose a physics-informed learning-based Koopman modeling approach and present a Koopman-based self-tuning moving horizon estimation design for a class of nonlinear systems. Specifically, we train Koopman operators and two neural networks - the state lifting network and the noise characterization network - using both data and available physical information. The two neural networks account for the nonlinear lifting functions for Koopman modeling and describing system noise distributions, respectively. Accordingly, a stochastic linear Koopman model is established in the lifted space to forecast the dynamic behavior of the nonlinear system. Based on the Koopman model, a self-tuning linear moving horizon estimation (MHE) scheme is developed. The weighting matrices of the MHE design are updated using the pre-trained noise characterization network at each sampling instant. The proposed estimation scheme is computationally efficient because only convex optimization is involved during online implementation, and updating the weighting matrices of the MHE scheme does not require re-training the neural networks. We verify the effectiveness and evaluate the performance of the proposed method via the application to a simulated chemical process.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7f4e3675450b08e1344396a30181355d5565efe8" target='_blank'>
              Self-tuning moving horizon estimation of nonlinear systems via physics-informed machine learning Koopman modeling
              </a>
            </td>
          <td>
            Mingxue Yan, Minghao Han, A. Law, Xunyuan Yin
          </td>
          <td>2024-08-07</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>35</td>
        </tr>

        <tr id="Neural Ordinary Differential Equations (ODEs) represent a significant advancement at the intersection of machine learning and dynamical systems, offering a continuous-time analog to discrete neural networks. Despite their promise, deploying neural ODEs in practical applications often encounters the challenge of stiffness, a condition where rapid variations in some components of the solution demand prohibitively small time steps for explicit solvers. This work addresses the stiffness issue when employing neural ODEs for model order reduction by introducing a suitable reparametrization in time. The considered map is data-driven and it is induced by the adaptive time-stepping of an implicit solver on a reference solution. We show the map produces a nonstiff system that can be cheaply solved with an explicit time integration scheme. The original, stiff, time dynamic is recovered by means of a map learnt by a neural network that connects the state space to the time reparametrization. We validate our method through extensive experiments, demonstrating improvements in efficiency for the neural ODE inference while maintaining robustness and accuracy. The neural network model also showcases good generalization properties for times beyond the training data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/fc642cd2dc03d50f310399a91145bd5a14a7f646" target='_blank'>
              Neural Ordinary Differential Equations for Model Order Reduction of Stiff Systems
              </a>
            </td>
          <td>
            Matteo Caldana, J. Hesthaven
          </td>
          <td>2024-08-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>63</td>
        </tr>

        <tr id="Dynamical systems provide a comprehensive way to study complex and changing behaviors across various sciences. Many modern systems are too complicated to analyze directly or we do not have access to models, driving significant interest in learning methods. Koopman operators have emerged as a dominant approach because they allow the study of nonlinear dynamics using linear techniques by solving an infinite-dimensional spectral problem. However, current algorithms face challenges such as lack of convergence, hindering practical progress. This paper addresses a fundamental open question: \textit{When can we robustly learn the spectral properties of Koopman operators from trajectory data of dynamical systems, and when can we not?} Understanding these boundaries is crucial for analysis, applications, and designing algorithms. We establish a foundational approach that combines computational analysis and ergodic theory, revealing the first fundamental barriers -- universal for any algorithm -- associated with system geometry and complexity, regardless of data quality and quantity. For instance, we demonstrate well-behaved smooth dynamical systems on tori where non-trivial eigenfunctions of the Koopman operator cannot be determined by any sequence of (even randomized) algorithms, even with unlimited training data. Additionally, we identify when learning is possible and introduce optimal algorithms with verification that overcome issues in standard methods. These results pave the way for a sharp classification theory of data-driven dynamical systems based on how many limits are needed to solve a problem. These limits characterize all previous methods, presenting a unified view. Our framework systematically determines when and how Koopman spectral properties can be learned.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/eb7265ab4b5b6dce43f8b2a37e99d9fd03f2bef7" target='_blank'>
              Limits and Powers of Koopman Learning
              </a>
            </td>
          <td>
            Matthew J. Colbrook, Igor Mezi'c, Alexei Stepanenko
          </td>
          <td>2024-07-08</td>
          <td>ArXiv</td>
          <td>2</td>
          <td>16</td>
        </tr>

        <tr id="Complex dynamic systems are typically either modeled using expert knowledge in the form of differential equations, or via data-driven universal approximation models such as artificial neural networks (ANN). While the first approach has advantages with respect to interpretability, transparency, data-efficiency, and extrapolation, the second approach is able to learn completely unknown functional relations from data and may result in models that can be evaluated more efficiently. To combine the complementary advantages, universal differential equations (UDE) have been suggested, which replace unknown terms in the differential equations with ANN. These hybrid models allow to both encode prior domain knowledge such as first principles and to learn unknown mechanisms from data. Often, data for the training of UDE can only be obtained via costly experiments. We consider optimal experimental design (OED) for the planning of experiments and generation of data needed to train UDE. The number of weights in the embedded ANN usually leads to an overfitting of the regression problem. To make the OED problem tractable for optimization, we propose and compare dimension reduction methods that are based on lumping of weights and singular value decomposition of the Fisher information matrix (FIM), respectively. They result in lower-dimensional variational differential equations which are easier to solve and which yield regular FIM. Our numerical results showcase the advantages of OED for UDE, such as an increased data-efficiency and better extrapolation properties.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2230fd0495ec13469526bd77cb385acbdb4bddfa" target='_blank'>
              Optimal Experimental Design for Universal Differential Equations
              </a>
            </td>
          <td>
            Christoph Plate, Carl Julius Martensen, Sebastian Sager
          </td>
          <td>2024-08-13</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="This paper presents an algorithm for developing sparse surrogate models that satisfy mass/energy conservation even when the training data are noisy and violate the conservation laws. In the first step, we employ the Bayesian Identification of Dynamic Sparse Algebraic Model (BIDSAM) algorithm proposed in our previous work to obtain a set of hierarchically ranked sparse models which approximate system behaviors with linear combinations of a set of well-defined basis functions. Although the model building algorithm was shown to be robust to noisy data, conservation laws may not be satisfied by the surrogate models. In this work we propose an algorithm that augments a data reconciliation step with the BIDSAM model for satisfaction of conservation laws. This method relies only on known boundary conditions and hence is generic for any chemical system. Two case studies are considered-one focused on mass conservation and another on energy conservation. Results show that models with minimum bias are built by using the developed algorithm while exactly satisfying the conservation laws for all data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a3b228eccbfc381c1bf8429fb1e6ed55fe3fb34c" target='_blank'>
              Development of Mass/Energy Constrained Sparse Bayesian Surrogate Models from Noisy Data
              </a>
            </td>
          <td>
            Samuel Adeyemo, D. Bhattacharyya
          </td>
          <td>2024-07-09</td>
          <td>Systems and Control Transactions</td>
          <td>0</td>
          <td>29</td>
        </tr>

        <tr id="The modeling of dynamical systems is a pervasive concern for not only describing but also predicting and controlling natural phenomena and engineered systems. Current data-driven approaches often assume prior knowledge of the relevant state variables or result in overparameterized state spaces. Boyuan Chen and his co-authors proposed a neural network model that estimates the degrees of freedom and attempts to discover the state variables of a dynamical system. Despite its innovative approach, this baseline model lacks a connection to the physical principles governing the systems it analyzes, leading to unreliable state variables. This research proposes a method that leverages the physical characteristics of second-order Hamiltonian systems to constrain the baseline model. The proposed model outperforms the baseline model in identifying a minimal set of non-redundant and interpretable state variables.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ddabca2c86de837436088e84f6e03ca06d2c3870" target='_blank'>
              Physics-informed Discovery of State Variables in Second-Order and Hamiltonian Systems
              </a>
            </td>
          <td>
            Félix Chavelli, Zi-Yu Khoo, Dawen Wu, Jonathan Sze Choong Low, Stéphane Bressan
          </td>
          <td>2024-08-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Lifted linear predictor (LLP) is an artificial linear dynamical system designed to predict trajectories of a generally nonlinear dynamical system based on the current state (or measurements) and the input. The main benefit of the LLP is its potential ability to capture the nonlinear system's dynamics with precision superior to other linearization techniques, such as local linearization about the operation point. The idea of lifting is supported by the theory of Koopman Operators. For LLP identification, we focus on the data-driven method based on the extended dynamic mode decomposition (EDMD) algorithm. However, while the EDMD algorithm presents an extremely simple and efficient way to obtain the LLP, it can also yield poor results. In this paper, we present some less intuitive practical guidelines for data-driven identification of the LLPs, aiming at improving usability of LLPs for designing control. We support the guidelines with two motivating examples. The implementation of the examples are shared on a public repository.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bf1ce9a8c8346f1264e7cecb5aea44d98aa65af7" target='_blank'>
              Practical Guidelines for Data-driven Identification of Lifted Linear Predictors for Control
              </a>
            </td>
          <td>
            Loi Do, Adam Uchytil, Zdenvek Hur'ak
          </td>
          <td>2024-08-02</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>2</td>
        </tr>

        <tr id="Non-stationary systems are found throughout the world, from climate patterns under the influence of variation in carbon dioxide concentration, to brain dynamics driven by ascending neuromodulation. Accordingly, there is a need for methods to analyze non-stationary processes, and yet most time-series analysis methods that are used in practice, on important problems across science and industry, make the simplifying assumption of stationarity. One important problem in the analysis of non-stationary systems is the problem class that we refer to as Parameter Inference from a Non-stationary Unknown Process (PINUP). Given an observed time series, this involves inferring the parameters that drive non-stationarity of the time series, without requiring knowledge or inference of a mathematical model of the underlying system. Here we review and unify a diverse literature of algorithms for PINUP. We formulate the problem, and categorize the various algorithmic contributions. This synthesis will allow researchers to identify gaps in the literature and will enable systematic comparisons of different methods. We also demonstrate that the most common systems that existing methods are tested on - notably the non-stationary Lorenz process and logistic map - are surprisingly easy to perform well on using simple statistical features like windowed mean and variance, undermining the practice of using good performance on these systems as evidence of algorithmic performance. We then identify more challenging problems that many existing methods perform poorly on and which can be used to drive methodological advances in the field. Our results unify disjoint scientific contributions to analyzing non-stationary systems and suggest new directions for progress on the PINUP problem and the broader study of non-stationary phenomena.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/585c3c4f3b30a814bc05e6f9e38a5a28b702ee79" target='_blank'>
              Parameter inference from a non-stationary unknown process
              </a>
            </td>
          <td>
            Kieran S. Owens, Ben D. Fulcher
          </td>
          <td>2024-07-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="A physics-informed neural network (PINN) is used to produce a variety of self-trapped necklace solutions of the (2+1)-dimensional nonlinear Schr\"{o}dinger/Gross-Pitaevskii equation. We elaborate the analysis for the existence and evolution of necklace patterns with integer, half-integer, and fractional reduced orbital angular momenta by means of PINN. The patterns exhibit phenomena similar to rotation of rigid bodies and centrifugal force. Even though the necklaces slowly expand (or shrink), they preserve their structure in the course of the quasi-stable propagation over several diffraction lengths, which is completely different from the ordinary fast diffraction-dominated dynamics. By comparing different ingredients, including the training time, loss value and $\mathbb{L}_{2}$ error, PINN accurately predicts specific nonlinear dynamical properties of the evolving necklace patterns. Furthermore, we perform the data-driven discovery of parameters for both clean and perturbed training data, adding $1\%$ random noise in the latter case. The results reveal that PINN not only effectively emulates the solution of partial differential equations, but also offers applications for predicting the nonlinear dynamics of physically relevant types of patterns.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/27df54bec46e632334278c89b601027aa8a3cf9e" target='_blank'>
              Physics-informed neural network for nonlinear dynamics of self-trapped necklace beams
              </a>
            </td>
          <td>
            Dongshuai Liu, Wen Zhang, Yanxia Gao, Dianyuan Fan, B. Malomed, Lifu Zhang
          </td>
          <td>2024-08-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>79</td>
        </tr>

        <tr id="We introduce a method based on Gaussian process regression to identify discrete variational principles from observed solutions of a field theory. The method is based on the data-based identification of a discrete Lagrangian density. It is a geometric machine learning technique in the sense that the variational structure of the true field theory is reflected in the data-driven model by design. We provide a rigorous convergence statement of the method. The proof circumvents challenges posed by the ambiguity of discrete Lagrangian densities in the inverse problem of variational calculus. Moreover, our method can be used to quantify model uncertainty in the equations of motions and any linear observable of the discrete field theory. This is illustrated on the example of the discrete wave equation and Schr\"odinger equation. The article constitutes an extension of our previous article arXiv:2404.19626 for the data-driven identification of (discrete) Lagrangians for variational dynamics from an ode setting to the setting of discrete pdes.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e38b7de6c7022b28628627bbf045123b665619b4" target='_blank'>
              Machine learning of discrete field theories with guaranteed convergence and uncertainty quantification
              </a>
            </td>
          <td>
            Christian Offen
          </td>
          <td>2024-07-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="This paper examines the application of the Kernel Sum of Squares (KSOS) method for enhancing kernel learning from data, particularly in the context of dynamical systems. Traditional kernel-based methods, despite their theoretical soundness and numerical efficiency, frequently struggle with selecting optimal base kernels and parameter tuning, especially with gradient-based methods prone to local optima. KSOS mitigates these issues by leveraging a global optimization framework with kernel-based surrogate functions, thereby achieving more reliable and precise learning of dynamical systems. Through comprehensive numerical experiments on the Logistic Map, Henon Map, and Lorentz System, KSOS is shown to consistently outperform gradient descent in minimizing the relative-$\rho$ metric and improving kernel accuracy. These results highlight KSOS's effectiveness in predicting the behavior of chaotic dynamical systems, demonstrating its capability to adapt kernels to underlying dynamics and enhance the robustness and predictive power of kernel-based approaches, making it a valuable asset for time series analysis in various scientific fields.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/be7befd5338268cfdfa3b26e66bece3caef3b91d" target='_blank'>
              Kernel Sum of Squares for Data Adapted Kernel Learning of Dynamical Systems from Data: A global optimization approach
              </a>
            </td>
          <td>
            Daniel Lengyel, P. Parpas, B. Hamzi, H. Owhadi
          </td>
          <td>2024-08-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>36</td>
        </tr>

        <tr id="Stability is a basic requirement when studying the behavior of dynamical systems. However, stabilizing dynamical systems via reinforcement learning is challenging because only little data can be collected over short time horizons before instabilities are triggered and data become meaningless. This work introduces a reinforcement learning approach that is formulated over latent manifolds of unstable dynamics so that stabilizing policies can be trained from few data samples. The unstable manifolds are minimal in the sense that they contain the lowest dimensional dynamics that are necessary for learning policies that guarantee stabilization. This is in stark contrast to generic latent manifolds that aim to approximate all -- stable and unstable -- system dynamics and thus are higher dimensional and often require higher amounts of data. Experiments demonstrate that the proposed approach stabilizes even complex physical systems from few data samples for which other methods that operate either directly in the system state space or on generic latent manifolds fail.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/89660d65895827cad089c32e3f1a9f0b892601ff" target='_blank'>
              System stabilization with policy optimization on unstable latent manifolds
              </a>
            </td>
          <td>
            Steffen W. R. Werner, B. Peherstorfer
          </td>
          <td>2024-07-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>27</td>
        </tr>

        <tr id="Constraining a numerical weather prediction (NWP) model with observations via 4D variational (4D-Var) data assimilation is often difficult to implement in practice due to the need to develop and maintain a software-based tangent linear model and adjoint model. One of the most common 4D-Var algorithms uses an incremental update procedure, which has been shown to be an approximation of the Gauss-Newton method. Here we demonstrate that when using a forecast model that supports automatic differentiation, an efficient and in some cases more accurate alternative approximation of the Gauss-Newton method can be applied by combining backpropagation of errors with Hessian approximation. This approach can be used with either a conventional numerical model implemented within a software framework that supports automatic differentiation, or a machine learning (ML) based surrogate model. We test the new approach on a variety of Lorenz-96 and quasi-geostrophic models. The results indicate potential for a deeper integration of modeling, data assimilation, and new technologies in a next-generation of operational forecast systems that leverage weather models designed to support automatic differentiation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4b43d025345ba51dc1b8aa4bb1314e91f7a7174b" target='_blank'>
              4D-Var using Hessian approximation and backpropagation applied to automatically-differentiable numerical and machine learning models
              </a>
            </td>
          <td>
            Kylen Solvik, Stephen G. Penny, Stephan Hoyer
          </td>
          <td>2024-08-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="Significance Many complex data analysis problems within and beyond the scientific domain involve discovering graphical structures and functional relationships within data. Nonlinear variance decomposition with Gaussian Processes simplifies and automates this process. Other methods, such as artificial neural networks, lack this variance decomposition feature. Information-theoretic and causal inference methods suffer from super-exponential complexity with respect to the number of variables. The proposed technique performs this task in polynomial complexity. This unlocks the potential for applications involving the identification of a network of hidden relationships between variables without a parameterized model at a remarkable scale, scope, and complexity.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0003d69ffd2478d179e3ac4b333714034d604eb3" target='_blank'>
              Codiscovering graphical structure and functional relationships within data: A Gaussian Process framework for connecting the dots
              </a>
            </td>
          <td>
            Th'eo Bourdais, Pau Batlle, Xianjin Yang, Ricardo Baptista, Nicolas Rouquette, H. Owhadi
          </td>
          <td>2024-08-01</td>
          <td>Proceedings of the National Academy of Sciences of the United States of America</td>
          <td>0</td>
          <td>36</td>
        </tr>

        <tr id="The continuously increasing amount of noisy data demands the development of accurate and efficient models for analysis, modeling, and control. In this article, we propose a novel data-driven moment matching method which employs Tikhonov regularization in the Reproducing Kernel Hilbert Spaces (RKHSs). Specifically, considering a realistic scenario in which the system's plant is unknown and only noisy measured data are available, we provide an estimation of the moment of the unknown plant by solving a regularized optimization problem on RKHS. For, we first demonstrate that the estimation of the moment can be improved via tuning the regularization term, and further, we show under which condition the effect of the transient improves the performance of the estimation. Then, we construct a parameterized model characterized by a kernel-based output mapping. Finally, the proposed data-driven approach is validated and discussed by means of a DC-to-DC Cuk converter driven by a Van der Pol oscillator.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/970212021b4134e841e09f425053018067ffcdbb" target='_blank'>
              Nonlinear Data-Driven Moment Matching in Reproducing Kernel Hilbert Spaces
              </a>
            </td>
          <td>
            Alessio Moreschini, Matteo Scandella, Thomas Parisini
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Initial value problems -- a system of ordinary differential equations and corresponding initial conditions -- can be used to describe many physical phenomena including those arise in classical mechanics. We have developed a novel approach to solve physics-based initial value problems using unsupervised machine learning. We propose a deep learning framework that models the dynamics of a variety of mechanical systems through neural networks. Our framework is flexible, allowing us to solve non-linear, coupled, and chaotic dynamical systems. We demonstrate the effectiveness of our approach on systems including a free particle, a particle in a gravitational field, a classical pendulum, and the H\'enon--Heiles system (a pair of coupled harmonic oscillators with a non-linear perturbation, used in celestial mechanics). Our results show that deep neural networks can successfully approximate solutions to these problems, producing trajectories which conserve physical properties such as energy and those with stationary action. We note that probabilistic activation functions, as defined in this paper, are required to learn any solutions of initial value problems in their strictest sense, and we introduce coupled neural networks to learn solutions of coupled systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/71b2f475e6dd93def3f335fbbfac10259c5dba45" target='_blank'>
              Solving physics-based initial value problems with unsupervised machine learning
              </a>
            </td>
          <td>
            Jack Griffiths, S. A. Wrathmall, Simon A. Gardiner
          </td>
          <td>2024-07-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="We propose a randomized physics-informed neural network (PINN) or rPINN method for uncertainty quantification in inverse partial differential equation (PDE) problems with noisy data. This method is used to quantify uncertainty in the inverse PDE PINN solutions. Recently, the Bayesian PINN (BPINN) method was proposed, where the posterior distribution of the PINN parameters was formulated using the Bayes' theorem and sampled using approximate inference methods such as the Hamiltonian Monte Carlo (HMC) and variational inference (VI) methods. In this work, we demonstrate that HMC fails to converge for non-linear inverse PDE problems. As an alternative to HMC, we sample the distribution by solving the stochastic optimization problem obtained by randomizing the PINN loss function. The effectiveness of the rPINN method is tested for linear and non-linear Poisson equations, and the diffusion equation with a high-dimensional space-dependent diffusion coefficient. The rPINN method provides informative distributions for all considered problems. For the linear Poisson equation, HMC and rPINN produce similar distributions, but rPINN is on average 27 times faster than HMC. For the non-linear Poison and diffusion equations, the HMC method fails to converge because a single HMC chain cannot sample multiple modes of the posterior distribution of the PINN parameters in a reasonable amount of time.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9a72f5071131521363e3f04ad6b40fd9347a43b5" target='_blank'>
              Randomized Physics-Informed Neural Networks for Bayesian Data Assimilation
              </a>
            </td>
          <td>
            Yifei Zong, D. Barajas-Solano, A. Tartakovsky
          </td>
          <td>2024-07-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>41</td>
        </tr>

        <tr id="The goal of this paper is to make a strong point for the usage of dynamical models when using reinforcement learning (RL) for feedback control of dynamical systems governed by partial differential equations (PDEs). To breach the gap between the immense promises we see in RL and the applicability in complex engineering systems, the main challenges are the massive requirements in terms of the training data, as well as the lack of performance guarantees. We present a solution for the first issue using a data-driven surrogate model in the form of a convolutional Long-Short Term Memory network with actuation. We demonstrate that learning an actuated model in parallel to training the RL agent significantly reduces the total amount of required data sampled from the real system. Furthermore, we show that iteratively updating the model is of major importance to avoid biases in the RL training. Detailed ablation studies reveal the most important ingredients of the modeling process. We use the chaotic Kuramoto-Sivashinsky equation do demonstrate our findings.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/73d91c3ba7ba5d34e084bcd3bd2c0c397052d50a" target='_blank'>
              Numerical Evidence for Sample Efficiency of Model-Based Over Model-Free Reinforcement Learning Control of Partial Differential Equations
              </a>
            </td>
          <td>
            Stefan Werner, Sebastian Peitz
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Reduced Order Models (ROMs) form essential tools across engineering domains by virtue of their function as surrogates for computationally intensive digital twinning simulators. Although purely data-driven methods are available for ROM construction, schemes that allow to retain a portion of the physics tend to enhance the interpretability and generalization of ROMs. However, physics-based techniques can adversely scale when dealing with nonlinear systems that feature parametric dependencies. This study introduces a generative physics-based ROM that is suited for nonlinear systems with parametric dependencies and is additionally able to quantify the confidence associated with the respective estimates. A main contribution of this work is the conditioning of these parametric ROMs to features that can be derived from monitoring measurements, feasibly in an online fashion. This is contrary to most existing ROM schemes, which remain restricted to the prescription of the physics-based, and usually a priori unknown, system parameters. Our work utilizes conditional Variational Autoencoders to continuously map the required reduction bases to a feature vector extracted from limited output measurements, while additionally allowing for a probabilistic assessment of the ROM-estimated Quantities of Interest. An auxiliary task using a neural network-based parametrization of suitable probability distributions is introduced to re-establish the link with physical model parameters. We verify the proposed scheme on a series of simulated case studies incorporating effects of geometric and material nonlinearity under parametric dependencies related to system properties and input load characteristics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/eb8cb80fb7c1708ef89c5e655f1cf2a1a98b8f0a" target='_blank'>
              A Reduced Order Model conditioned on monitoring features for estimation and uncertainty quantification in engineered systems
              </a>
            </td>
          <td>
            Konstantinos Vlachas, Thomas Simpson, Anthony Garland, D. Quinn, C. Farhat, Eleni Chatzi
          </td>
          <td>2024-07-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Modeling the non-linear dynamics of a system from measurement data accurately is an open challenge. Over the past few years, various tools such as SINDy and DySMHO have emerged as approaches to distill dynamics from data. However, challenges persist in accurately capturing dynamics of a system especially when the physical knowledge about the system is unknown. A promising solution is to use a hybrid paradigm, that combines mechanistic and black-box models to leverage their respective strengths. In this study, we combine a hybrid modeling paradigm with sparse regression, to develop and identify models simultaneously. Two methods are explored, considering varying complexities, data quality, and availability and by comparing different case studies. In the first approach, we integrate SINDy-discovered models with neural ODE structures, to model unknown physics. In the second approach, we employ Multifidelity Surrogate Models (MFSMs) to construct composite models comprised of SINDy-discovered models and error-correction models.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4848ba60b88cc3dffed5030c77e9174131c7f918" target='_blank'>
              Integrating Hybrid Modeling and Multifidelity Approaches for Data-Driven Process Model Discovery
              </a>
            </td>
          <td>
            Suryateja Ravutla, Fani Boukouvala
          </td>
          <td>2024-07-09</td>
          <td>Systems and Control Transactions</td>
          <td>0</td>
          <td>25</td>
        </tr>

        <tr id="This proposed work introduces a data-assimilation-assisted approach to train neural networks, aimed at effectively reducing epistemic uncertainty in state estimates of separated flows. This method, referred to as model-consistent training, ensures that input features are derived directly from physics-based models, such as Reynolds Averaged Navier Stokes (RANS) turbulence models, to accurately represent the current state of the flow. Autoencoders have been selected for this task due to their capability to capture essential information from large datasets, making them particularly suitable for handling high-dimensional data with numerous discretization points in both spatial and temporal dimensions. This innovative approach integrates the ensemble Kalman method to enhance the training process, providing a robust framework for improving model accuracy and performance in turbulent flow predictions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8c44941f2e715c2b0202ef4e5d7ba0fe96659fe0" target='_blank'>
              Developing a Model-Consistent Reduced-Dimensionality training approach to quantify and reduce epistemic uncertainty in separated flows
              </a>
            </td>
          <td>
            Minghan Chu
          </td>
          <td>2024-07-31</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Reconstructing a nonlinear dynamical system from empirical time series is a fundamental task in data-driven analysis. One of the main challenges is the existence of hidden variables; we only have records for some variables, and those for hidden variables are unavailable. In this work, the techniques for Carleman linearization, phase-space embedding, and dynamic mode decomposition are integrated to rebuild an optimal dynamical system from time series for one specific variable. Using the Takens theorem, the embedding dimension is determined, which is adopted as the dynamical system's dimension. The Carleman linearization is then used to transform this finite nonlinear system into an infinite linear system, which is further truncated into a finite linear system using the dynamic mode decomposition technique. We illustrate the performance of this integrated technique using data generated by the well-known Lorenz model, the Duffing oscillator, and empirical records of electrocardiogram, electroencephalogram, and measles outbreaks. The results show that this solution accurately estimates the operators of the nonlinear dynamical systems. This work provides a new data-driven method to estimate the Carleman operator of nonlinear dynamical systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/dfecb35e8dbf1de60a32397c57f1dd761dcbe4ee" target='_blank'>
              Estimation of Carleman operator from a univariate time series.
              </a>
            </td>
          <td>
            Sherehe Semba, Huijie Yang, Xiaolu Chen, Huiyun Wan, C. Gu
          </td>
          <td>2024-08-01</td>
          <td>Chaos</td>
          <td>0</td>
          <td>18</td>
        </tr>

        <tr id="We consider the problem of data-driven stochastic optimal control of an unknown LTI dynamical system. Assuming the process noise is normally distributed, we pose the problem of steering the state's mean and covariance to a target normal distribution, under noisy data collected from the underlying system, a problem commonly referred to as covariance steering (CS). A novel framework for Data-driven Uncertainty quantification and density STeering (DUST) is presented that simultaneously characterizes the noise affecting the measured data and designs an optimal affine-feedback controller to steer the density of the state to a prescribed terminal value. We use both indirect and direct data-driven design approaches based on the notions of persistency of excitation and subspace predictors to exactly represent the mean and covariance dynamics of the state in terms of the data and noise realizations. Since both the mean and the covariance steering sub-problems are plagued with distributional uncertainty arising from noisy data collection, we first estimate the noise realization from this dataset and subsequently compute tractable upper bounds on the estimation errors. The moment steering problems are then solved to optimality using techniques from robust control and robust optimization. Lastly, we present an alternative control design approach based on the certainty equivalence principle and interpret the problem as one of CS under multiplicative uncertainties. We analyze the performance and efficacy of each of these data-driven approaches using a case study and compare them with their model-based counterparts.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/63a1f296701b24baf2d77272d401b9179d8d8312" target='_blank'>
              DUST: A Framework for Data-Driven Density Steering
              </a>
            </td>
          <td>
            Joshua Pilipovsky, Panagiotis Tsiotras
          </td>
          <td>2024-08-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="The development of data-driven approaches for solving differential equations has been followed by a plethora of applications in science and engineering across a multitude of disciplines and remains a central focus of active scientific inquiry. However, a large body of natural phenomena incorporates memory effects that are best described via fractional integro-differential equations (FIDEs), in which the integral or differential operators accept non-integer orders. Addressing the challenges posed by nonlinear FIDEs is a recognized difficulty, necessitating the application of generic methods with immediate practical relevance. This work introduces the Universal Fractional Integro-Differential Equation Solvers (UniFIDES), a comprehensive machine learning platform designed to expeditiously solve a variety of FIDEs in both forward and inverse directions, without the need for ad hoc manipulation of the equations. The effectiveness of UniFIDES is demonstrated through a collection of integer-order and fractional problems in science and engineering. Our results highlight UniFIDES' ability to accurately solve a wide spectrum of integro-differential equations and offer the prospect of using machine learning platforms universally for discovering and describing dynamical and complex systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/41fa0a29da947de99741b68960e6591a9bfd2771" target='_blank'>
              UniFIDES: Universal Fractional Integro-Differential Equation Solvers
              </a>
            </td>
          <td>
            Milad Saadat, Deepak Mangal, Safa Jamali
          </td>
          <td>2024-07-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Accurately modeling the mechanical behavior of materials is crucial for numerous engineering applications. The quality of these models depends directly on the accuracy of the constitutive law that defines the stress-strain relation. Discovering these constitutive material laws remains a significant challenge, in particular when only material deformation data is available. To address this challenge, unsupervised machine learning methods have been proposed. However, existing approaches have several limitations: they either fail to ensure that the learned constitutive relations are consistent with physical principles, or they rely on a predefined library of constitutive relations or manually crafted input features. These dependencies require significant expertise and specialized domain knowledge. Here, we introduce a machine learning approach called uLED, which overcomes the limitations by using the input convex neural network (ICNN) as the surrogate constitutive model. We improve the optimization strategy for training ICNN, allowing it to be trained end-to-end using direct strain invariants as input across various materials. Furthermore, we utilize the nodal force equilibrium at the internal domain as the training objective, which enables us to learn the constitutive relation solely from temporal displacement recordings. We validate the effectiveness of the proposed method on a diverse range of material laws. We demonstrate that it is robust to a significant level of noise and that it converges to the ground truth with increasing data resolution. We also show that the model can be effectively trained using a displacement field from a subdomain of the test specimen and that the learned constitutive relation from one material sample is transferable to other samples with different geometries. The developed methodology provides an effective tool for discovering constitutive relations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/66917df8a8f69b2b557c7f74ef2c576d38a94797" target='_blank'>
              Learning Physics-Consistent Material Behavior Without Prior Knowledge
              </a>
            </td>
          <td>
            Zhichao Han, Mohit Pundir, Olga Fink, David S. Kammer
          </td>
          <td>2024-07-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4648ca55b2c3ba80a310409f8b48533ab6d4a66a" target='_blank'>
              Learning interpretable dynamics of stochastic complex systems from experimental data
              </a>
            </td>
          <td>
            Tingting Gao, B. Barzel, Gang Yan
          </td>
          <td>2024-07-17</td>
          <td>Nature Communications</td>
          <td>0</td>
          <td>18</td>
        </tr>

        <tr id="Complex physical systems are often described by partial differential equations (PDEs) that depend on parameters such as the Reynolds number in fluid mechanics. In applications such as design optimization or uncertainty quantification, solutions of those PDEs need to be evaluated at numerous points in the parameter space. While physics-informed neural networks (PINNs) have emerged as a new strong competitor as a surrogate, their usage in this scenario remains underexplored due to the inherent need for repetitive and time-consuming training. In this paper, we address this problem by proposing a novel extension, parameterized physics-informed neural networks (P$^2$INNs). P$^2$INNs enable modeling the solutions of parameterized PDEs via explicitly encoding a latent representation of PDE parameters. With the extensive empirical evaluation, we demonstrate that P$^2$INNs outperform the baselines both in accuracy and parameter efficiency on benchmark 1D and 2D parameterized PDEs and are also effective in overcoming the known"failure modes".">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4ca0ec3e858b6f249c48d169370dee08ae38e713" target='_blank'>
              Parameterized Physics-informed Neural Networks for Parameterized PDEs
              </a>
            </td>
          <td>
            Woojin Cho, Minju Jo, Haksoo Lim, Kookjin Lee, Dongeun Lee, Sanghyun Hong, Noseong Park
          </td>
          <td>2024-08-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Machine learning presents opportunities to improve the scale-specific accuracy of mechanistic models in a data-driven manner. Here we demonstrate the use of a machine learning technique called Sparse Identification of Nonlinear Dynamics (SINDy) to improve a simple mechanistic model of algal growth. Time-series measurements of the microalga Chlorella Vulgaris were generated under controlled photobioreactor conditions at the University of Technology Sydney. A simple mechanistic growth model based on intensity of light and temperature was integrated over time and compared to the time-series data. While the mechanistic model broadly captured the overall growth trend, discrepancies remained between the model and data due to the model's simplicity and non-ideal behavior of real-world measurement. SINDy was applied to model the residual error by identifying an error derivative correction term. Addition of this SINDy-informed error dynamics term shows improvement to model accuracy while maintaining interpretability of the underlying mechanistic framework. This work demonstrates the potential for machine learning techniques like SINDy to aid simple mechanistic models in scale-specific predictive accuracy.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0efd19b71be3ac13e47f098d9a6e63082477a540" target='_blank'>
              Improving Mechanistic Model Accuracy with Machine Learning Informed Physics
              </a>
            </td>
          <td>
            Will Farlessyost, Shweta Singh
          </td>
          <td>2024-07-09</td>
          <td>Systems and Control Transactions</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="
 We introduce a novel neural network structure called Strongly Constrained Theory-Guided Neural Network (SCTgNN), to investigate the behaviours of the localized solutions of the generalized nonlinear Schrödinger (NLS) equation. This equation comprises four physically significant nonlinear evolution equations, namely, (i) NLS equation, Hirota equation Lakshmanan-Porsezian-Daniel (LPD) equation and fifth-order NLS equation. The generalized NLS equation demonstrates nonlinear effects up to quintic order, indicating rich and complex dynamics in various fields of physics. By combining concepts from the Physics-Informed Neural Network (PINN) and Theory-Guided Neural Network (TgNN) models, SCTgNN aims to enhance our understanding of complex phenomena, particularly within nonlinear systems that defy conventional patterns. To begin, we employ the TgNN method to predict the behaviours of localized waves, including solitons, rogue waves, and breathers, within the generalized NLS equation. We then use SCTgNN to predict the aforementioned localized solutions and calculate the mean square errors in both SCTgNN and TgNN in predicting these three localized solutions. Our findings reveal that both models excel in understanding complex behaviours and provide predictions across a wide variety of situations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e405cc588c01c3af8b8d5bde5f1526dd7d964ae3" target='_blank'>
              On examining the predictive capabilities of two variants of PINN in validating localised wave solutions in the generalized nonlinear Schrödinger equation
              </a>
            </td>
          <td>
            Thulasidharan K, Sinthuja N, Vishnu Priya N, Senthilvelan M
          </td>
          <td>2024-07-10</td>
          <td>Communications in Theoretical Physics</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Koopman operators and transfer operators represent nonlinear dynamics in state space through its induced action on linear spaces of observables and measures, respectively. This framework enables the use of linear operator theory for supervised and unsupervised learning of nonlinear dynamical systems, and has received considerable interest in recent years. Here, we propose a data-driven technique for spectral approximation of Koopman operators of continuous-time, measure-preserving ergodic systems that is asymptotically consistent and makes direct use of known equations of motion (physics). Our approach is based on a bounded transformation of the Koopman generator (an operator implementing directional derivatives of observables along the dynamical flow), followed by smoothing by a Markov semigroup of kernel integral operators. This results in a skew-adjoint, compact operator whose eigendecomposition is expressible as a variational generalized eigenvalue problem. We develop Galerkin methods to solve this eigenvalue problem and study their asymptotic consistency in the large-data limit. A key aspect of these methods is that they are physics-informed, in the sense of making direct use of dynamical vector field information through automatic differentiation of kernel functions. Solutions of the eigenvalue problem reconstruct evolution operators that preserve unitarity of the underlying Koopman group while spectrally converging to it in a suitable limit. In addition, the computed eigenfunctions have representatives in a reproducing kernel Hilbert space, enabling out-of-sample evaluation of learned dynamical features. Numerical experiments performed with this method on integrable and chaotic low-dimensional systems demonstrate its efficacy in extracting dynamically coherent observables under complex dynamics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7bfdb15c2217fa4993fd812bd48a56f8b7c2df5e" target='_blank'>
              Physics-informed spectral approximation of Koopman operators
              </a>
            </td>
          <td>
            C. Valva, Dimitrios Giannakis
          </td>
          <td>2024-08-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Port-Hamiltonian systems (pHS) allow for a structure-preserving modeling of dynamical systems. Coupling pHS via linear relations between input and output defines an overall pHS, which is structure preserving. However, in multiphysics applications, some subsystems do not allow for a physical pHS description, as (a) this is not available or (b) too expensive. Here, data-driven approaches can be used to deliver a pHS for such subsystems, which can then be coupled to the other subsystems in a structure-preserving way. In this work, we derive a data-driven identification approach for port-Hamiltonian differential algebraic equation (DAE) systems. The approach uses input and state space data to estimate nonlinear effort functions of pH-DAEs. As underlying technique, we us (multi-task) Gaussian processes. This work thereby extends over the current state of the art, in which only port-Hamiltonian ordinary differential equation systems could be identified via Gaussian processes. We apply this approach successfully to two applications from network design and constrained multibody system dynamics, based on pH-DAE system of index one and three, respectively.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f006ed4bbd09834cab7ba0f2c3258b36e07050c2" target='_blank'>
              Data-driven identification of port-Hamiltonian DAE systems by Gaussian processes
              </a>
            </td>
          <td>
            Peter Zaspel, Michael Günther
          </td>
          <td>2024-06-26</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>2</td>
        </tr>

        <tr id="Estimating and controlling dynamical systems from observable time-series data are essential for understanding and manipulating nonlinear dynamics. This paper proposes a probabilistic framework for simultaneously estimating and controlling nonlinear dynamics under noisy observation conditions. Our proposed method utilizes the particle filter not only as a state estimator and a prior estimator for the dynamics but also as a controller. This approach allows us to handle the nonlinearity of the dynamics and uncertainty of the latent state. We apply two distinct dynamics to verify the effectiveness of our proposed framework: a chaotic system defined by the Lorenz equation and a nonlinear neuronal system defined by the Morris–Lecar neuron model. The results indicate that our proposed framework can simultaneously estimate and control complex nonlinear dynamical systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/682bd11b89e6862f9721d25af1d528fadb6746f4" target='_blank'>
              Probabilistic Estimation and Control of Dynamical Systems Using Particle Filter with Adaptive Backward Sampling
              </a>
            </td>
          <td>
            Taketo Omi, Toshiaki Omori
          </td>
          <td>2024-07-30</td>
          <td>Entropy</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Predictive modeling involving simulation and sensor data at the same time, is a growing challenge in computational science. Even with large-scale finite element models, a mismatch to the sensor data often remains, which can be attributed to different sources of uncertainty. For such a scenario, the statistical finite element method (statFEM) can be used to condition a simulated field on given sensor data. This yields a posterior solution which resembles the data much better and additionally provides consistent estimates of uncertainty, including model misspecification. For frequency or parameter dependent problems, occurring, e.g. in acoustics or electromagnetism, solving the full order model at the frequency grid and conditioning it on data quickly results in a prohibitive computational cost. In this case, the introduction of a surrogate in form of a reduced order model yields much smaller systems of equations. In this paper, we propose a reduced order statFEM framework relying on Krylov-based moment matching. We introduce a data model which explicitly includes the bias induced by the reduced approximation, which is estimated by an inexpensive error indicator. The results of the new statistical reduced order method are compared to the standard statFEM procedure applied to a ROM prior, i.e. without explicitly accounting for the reduced order bias. The proposed method yields better accuracy and faster convergence throughout a given frequency range for different numerical examples.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f588cea58e6ea0186a8fce7486565f54ebfe99bb" target='_blank'>
              Statistical reduced order modelling for the parametric Helmholtz equation
              </a>
            </td>
          <td>
            Lucas Hermann, Matthias Bollhöfer, Ulrich Römer
          </td>
          <td>2024-07-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Estimation of cardiovascular model parameters from electronic health records (EHR) poses a significant challenge primarily due to lack of identifiability. Structural non-identifiability arises when a manifold in the space of parameters is mapped to a common output, while practical non-identifiability can result due to limited data, model misspecification, or noise corruption. To address the resulting ill-posed inverse problem, optimization-based or Bayesian inference approaches typically use regularization, thereby limiting the possibility of discovering multiple solutions. In this study, we use inVAErt networks, a neural network-based, data-driven framework for enhanced digital twin analysis of stiff dynamical systems. We demonstrate the flexibility and effectiveness of inVAErt networks in the context of physiological inversion of a six-compartment lumped parameter hemodynamic model from synthetic data to real data with missing components.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/67c8e46274eeee4c04799e3b1c472cd20b9b08e4" target='_blank'>
              InVAErt networks for amortized inference and identifiability analysis of lumped parameter hemodynamic models
              </a>
            </td>
          <td>
            Guoxiang Grayson Tong, Carlos A. Sing Long, D. Schiavazzi
          </td>
          <td>2024-08-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>15</td>
        </tr>

        <tr id="This paper is centered around the approximation of dynamical systems by means of Gaussian processes. To this end, trajectories of such systems must be collected to be used as training data. The measurements of these trajectories are typically noisy, which implies that both the regression inputs and outputs are corrupted by noise. However, most of the literature considers only noise in the regression outputs. In this paper, we show how to account for the noise in the regression inputs in an extended Gaussian process framework to approximate scalar and multidimensional systems. We demonstrate the potential of our framework by comparing it to different state-of-the-art methods in several simulation examples.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/38846e7a310d84235605314b8bccf8b65bf0580f" target='_blank'>
              Gaussian Processes with Noisy Regression Inputs for Dynamical Systems
              </a>
            </td>
          <td>
            Tobias M. Wolff, Victor G. Lopez, Matthias A. Muller
          </td>
          <td>2024-08-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Operator learning has become a powerful tool in machine learning for modeling complex physical systems governed by partial differential equations (PDEs). Although Deep Operator Networks (DeepONet) show promise, they require extensive data acquisition. Physics-informed DeepONets (PI-DeepONet) mitigate data scarcity but suffer from inefficient training processes. We introduce Separable Operator Networks (SepONet), a novel framework that significantly enhances the efficiency of physics-informed operator learning. SepONet uses independent trunk networks to learn basis functions separately for different coordinate axes, enabling faster and more memory-efficient training via forward-mode automatic differentiation. We provide a universal approximation theorem for SepONet proving that it generalizes to arbitrary operator learning problems, and then validate its performance through comprehensive benchmarking against PI-DeepONet. Our results demonstrate SepONet's superior performance across various nonlinear and inseparable PDEs, with SepONet's advantages increasing with problem complexity, dimension, and scale. For 1D time-dependent PDEs, SepONet achieves up to $112\times$ faster training and $82\times$ reduction in GPU memory usage compared to PI-DeepONet, while maintaining comparable accuracy. For the 2D time-dependent nonlinear diffusion equation, SepONet efficiently handles the complexity, achieving a 6.44\% mean relative $\ell_{2}$ test error, while PI-DeepONet fails due to memory constraints. This work paves the way for extreme-scale learning of continuous mappings between infinite-dimensional function spaces. Open source code is available at \url{https://github.com/HewlettPackard/separable-operator-networks}.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/df7ccff15abfd241fc963ea0b34062bc42a014fb" target='_blank'>
              Separable Operator Networks
              </a>
            </td>
          <td>
            Xinling Yu, S. Hooten, Z. Liu, Yequan Zhao, M. Fiorentino, T. Vaerenbergh, Zheng Zhang
          </td>
          <td>2024-07-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>11</td>
        </tr>

        <tr id="In this paper, we introduce a novel, data-driven approach for solving high-dimensional Bayesian inverse problems based on partial differential equations (PDEs), called Weak Neural Variational Inference (WNVI). The method complements real measurements with virtual observations derived from the physical model. In particular, weighted residuals are employed as probes to the governing PDE in order to formulate and solve a Bayesian inverse problem without ever formulating nor solving a forward model. The formulation treats the state variables of the physical model as latent variables, inferred using Stochastic Variational Inference (SVI), along with the usual unknowns. The approximate posterior employed uses neural networks to approximate the inverse mapping from state variables to the unknowns. We illustrate the proposed method in a biomedical setting where we infer spatially varying material properties from noisy tissue deformation data. We demonstrate that WNVI is not only as accurate and more efficient than traditional methods that rely on repeatedly solving the (non)linear forward problem as a black-box, but it can also handle ill-posed forward problems (e.g., with insufficient boundary conditions).">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b6a5444a6e705283d0bf77c5ab115e320bb0e419" target='_blank'>
              Weak neural variational inference for solving Bayesian inverse problems without forward models: applications in elastography
              </a>
            </td>
          <td>
            Vincent C. Scholz, Yaohua Zang, P. Koutsourelakis
          </td>
          <td>2024-07-30</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>21</td>
        </tr>

        <tr id="Learning linear and nonlinear dynamical systems from available data is a timely topic in scientific machine learning. Learning must be performed while enforcing the numerical stability of the learned model, the existing knowledge within an informed or augmented setting, or by taking into account the multiscale dynamics—for both linear and nonlinear dynamics. However, when the final objective of such a learned dynamical system is to be used for control purposes, learning transformed dynamics can be advantageous. Therefore, many alternatives exists, and the present paper focuses on two of them: the first based on the discovery and use of the so-called flat control and the second one based on the use of the Koopman theory. The main contributions when addressing the first is the discovery of the flat output transformation by using an original neural framework. Moreover, when using the Koopman theory, this paper proposes an original procedure for learning parametric dynamics in the latent space, which is of particular interest in control-based engineering applications.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bde1af4107f9ee8f6740e26e9c5d03b288c163cb" target='_blank'>
              Learning Transformed Dynamics for Efficient Control Purposes
              </a>
            </td>
          <td>
            C. Ghnatios, Joel Mouterde, Jerome Tomezyk, Joaquim Da Silva, F. Chinesta
          </td>
          <td>2024-07-19</td>
          <td>Mathematics</td>
          <td>0</td>
          <td>14</td>
        </tr>

        <tr id="The Realization Independent Iterative Rational Krylov Algorithm (TF-IRKA) is a frequency-based data-driven reduced order modeling (DDROM) method that constructs $\mathcal H_2$ optimal DDROMs. However, as the $\mathcal H_2$ optimal approximation theory dictates, TF-IRKA requires repeated sampling of frequency data, that is, values of the system transfer function and its derivative, outside the unit circle. This repeated evaluation of frequency data requires repeated full model computations and may not be feasible. The data-informativity framework for moment matching provides a method for obtaining such frequency data from a single time-domain simulation. However, this framework usually requires solving linear systems with prohibitively ill-conditioned matrices, especially when recovering frequency data from off the unit circle as required for optimality. In this paper, building upon our previous work with the data informativity framework for moment matching, we provide a formula for the nonzero extreme eigenvalues of a symmetric rank-$1$ perturbation to an orthogonal projection, which then leads to an optimal scaling of the aforementioned linear systems. We also establish connections between the underlying dynamical system and conditioning of these linear systems. This analysis then leads to our algorithmic development, time-domain IRKA, which allows us to implement a time-domain variant of TF-IRKA, constructing $\mathcal H_2$ optimal DDROMs from a single time-domain simulation without requiring repeated frequency data evaluations. The numerical examples illustrate the effectiveness of the proposed algorithm.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f90d4456bd8e538b620928a9ce87f5d39d48c1b7" target='_blank'>
              Time-Domain Iterative Rational Krylov Method
              </a>
            </td>
          <td>
            Michael S. Ackermann, S. Gugercin
          </td>
          <td>2024-07-17</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>38</td>
        </tr>

        <tr id="Multi-fidelity machine learning methods address the accuracy-efficiency trade-off by integrating scarce, resource-intensive high-fidelity data with abundant but less accurate low-fidelity data. We propose a practical multi-fidelity strategy for problems spanning low- and high-dimensional domains, integrating a non-probabilistic regression model for the low-fidelity with a Bayesian model for the high-fidelity. The models are trained in a staggered scheme, where the low-fidelity model is transfer-learned to the high-fidelity data and a Bayesian model is trained for the residual. This three-model strategy -- deterministic low-fidelity, transfer learning, and Bayesian residual -- leads to a prediction that includes uncertainty quantification both for noisy and noiseless multi-fidelity data. The strategy is general and unifies the topic, highlighting the expressivity trade-off between the transfer-learning and Bayesian models (a complex transfer-learning model leads to a simpler Bayesian model, and vice versa). We propose modeling choices for two scenarios, and argue in favor of using a linear transfer-learning model that fuses 1) kernel ridge regression for low-fidelity with Gaussian processes for high-fidelity; or 2) deep neural network for low-fidelity with a Bayesian neural network for high-fidelity. We demonstrate the effectiveness and efficiency of the proposed strategies and contrast them with the state-of-the-art based on various numerical examples. The simplicity of these formulations makes them practical for a broad scope of future engineering applications.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f0aac32171f95be4080bfb1caf4a77b613f4b14d" target='_blank'>
              Practical multi-fidelity machine learning: fusion of deterministic and Bayesian models
              </a>
            </td>
          <td>
            Jiaxiang Yi, Ji Cheng, Miguel A. Bessa
          </td>
          <td>2024-07-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="One of the most promising applications of machine learning (ML) in computational physics is to accelerate the solution of partial differential equations (PDEs). The key objective of ML-based PDE solvers is to output a sufficiently accurate solution faster than standard numerical methods, which are used as a baseline comparison. We first perform a systematic review of the ML-for-PDE solving literature. Of articles that use ML to solve a fluid-related PDE and claim to outperform a standard numerical method, we determine that 79% (60/76) compare to a weak baseline. Second, we find evidence that reporting biases, especially outcome reporting bias and publication bias, are widespread. We conclude that ML-for-PDE solving research is overoptimistic: weak baselines lead to overly positive results, while reporting biases lead to underreporting of negative results. To a large extent, these issues appear to be caused by factors similar to those of past reproducibility crises: researcher degrees of freedom and a bias towards positive results. We call for bottom-up cultural changes to minimize biased reporting as well as top-down structural reforms intended to reduce perverse incentives for doing so.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/fda0812099547cd3b91031851f644e1929b4b77c" target='_blank'>
              Weak baselines and reporting biases lead to overoptimism in machine learning for fluid-related partial differential equations
              </a>
            </td>
          <td>
            N. McGreivy, Ammar Hakim
          </td>
          <td>2024-07-09</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="The manipulation of deformable linear objects (DLOs) via model-based control requires an accurate and computationally efficient dynamics model. Yet, data-driven DLO dynamics models require large training data sets while their predictions often do not generalize, whereas physics-based models rely on good approximations of physical phenomena and often lack accuracy. To address these challenges, we propose a physics-informed neural ODE capable of predicting agile movements with significantly less data and hyper-parameter tuning. In particular, we model DLOs as serial chains of rigid bodies interconnected by passive elastic joints in which interaction forces are predicted by neural networks. The proposed model accurately predicts the motion of an robotically-actuated aluminium rod and an elastic foam cylinder after being trained on only thirty seconds of data. The project code and data are available at: \url{https://tinyurl.com/neuralprba}">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/815ff430d40660092c67ed599422c4c980a0db8d" target='_blank'>
              Learning deformable linear object dynamics from a single trajectory
              </a>
            </td>
          <td>
            Shamil Mamedov, A. R. Geist, Ruan Viljoen, Sebastian Trimpe, Jan Swevers
          </td>
          <td>2024-07-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="
 Sparse identification of nonlinear dynamics is a popular approach to system identification. In this approach system identification is reformulated as a sparse regression problem, and the use of a good sparse regression method is crucial. Sparse Bayesian learning based on collaborative neurodynamic optimization is a recent method that consistently produces high-quality solutions. In this article, we extensively assess how this method performs for ordinary differential equation identification. We find that it works very well compared with sparse regression algorithms currently used for this task in terms of the tradeoff between the approximation accuracy and the complexity of the identified system. We also propose a way to substantially reduce the computational complexity of this algorithm compared with its original implementation, thus making it even more practical.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/47eded588aeaefa1d9b8730359939cd75cf7620e" target='_blank'>
              Nonlinear system identification via sparse Bayesian regression based on collaborative neurodynamic optimization
              </a>
            </td>
          <td>
            Alexey Okunev, Evgeny Burnaev
          </td>
          <td>2024-08-04</td>
          <td>Journal of Inverse and Ill-posed Problems</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="In this study, we investigate the effect of reservoir computing training data on the reconstruction of chaotic dynamics. Our findings indicate that a training time series comprising a few periodic orbits of low periods can successfully reconstruct the Lorenz attractor. We also demonstrate that biased training data does not negatively impact reconstruction success. Our method's ability to reconstruct a physical measure is much better than the so-called cycle expansion approach, which relies on weighted averaging. Additionally, we demonstrate that fixed point attractors and chaotic transients can be accurately reconstructed by a model trained from a few periodic orbits, even when using different parameters.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f833e966a95961819f625f1095e380b4cf40eb4f" target='_blank'>
              Data-driven modeling from biased small training data using periodic orbits
              </a>
            </td>
          <td>
            Kengo Nakai, Yoshitaka Saiki
          </td>
          <td>2024-07-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="We introduce a generative learning framework to model high-dimensional parametric systems using gradient guidance and virtual observations. We consider systems described by Partial Differential Equations (PDEs) discretized with structured or unstructured grids. The framework integrates multi-level information to generate high fidelity time sequences of the system dynamics. We demonstrate the effectiveness and versatility of our framework with two case studies in incompressible, two dimensional, low Reynolds cylinder flow on an unstructured mesh and incompressible turbulent channel flow on a structured mesh, both parameterized by the Reynolds number. Our results illustrate the framework's robustness and ability to generate accurate flow sequences across various parameter settings, significantly reducing computational costs allowing for efficient forecasting and reconstruction of flow dynamics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9b9b5e0e75c28c80636b4adb2bd7786322e6e2a2" target='_blank'>
              Generative Learning of the Solution of Parametric Partial Differential Equations Using Guided Diffusion Models and Virtual Observations
              </a>
            </td>
          <td>
            Han Gao, Sebastian Kaltenbach, P. Koumoutsakos
          </td>
          <td>2024-07-31</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>78</td>
        </tr>

        <tr id="We introduce neural information field filter, a Bayesian state and parameter estimation method for high-dimensional nonlinear dynamical systems given large measurement datasets. Solving such a problem using traditional methods, such as Kalman and particle filters, is computationally expensive. Information field theory is a Bayesian approach that can efficiently reconstruct dynamical model state paths and calibrate model parameters from noisy measurement data. To apply the method, we parameterize the time evolution state path using the span of a finite linear basis. The existing method has to reparameterize the state path by initial states to satisfy the initial condition. Designing an expressive yet simple linear basis before knowing the true state path is crucial for inference accuracy but challenging. Moreover, reparameterizing the state path using the initial state is easy to perform for a linear basis, but is nontrivial for more complex and expressive function parameterizations, such as neural networks. The objective of this paper is to simplify and enrich the class of state path parameterizations using neural networks for the information field theory approach. To this end, we propose a generalized physics-informed conditional prior using an auxiliary initial state. We show the existing reparameterization is a special case. We parameterize the state path using a residual neural network that consists of a linear basis function and a Fourier encoding fully connected neural network residual function. The residual function aims to correct the error of the linear basis function. To sample from the intractable posterior distribution, we develop an optimization algorithm, nested stochastic variational inference, and a sampling algorithm, nested preconditioned stochastic gradient Langevin dynamics. A series of numerical and experimental examples verify and validate the proposed method.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4f1f25c26be1528226a494d8e61aceb48b888ac8" target='_blank'>
              Neural information field filter
              </a>
            </td>
          <td>
            Kairui Hao, Ilias Bilionis
          </td>
          <td>2024-07-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="This paper presents, for the first time, a framework for Kolmogorov-Arnold Networks (KANs) in power system applications. Inspired by the recently proposed KAN architecture, this paper proposes physics-informed Kolmogorov-Arnold Networks (PIKANs), a novel KAN-based physics-informed neural network (PINN) tailored to efficiently and accurately learn dynamics within power systems. The PIKANs present a promising alternative to conventional Multi-Layer Perceptrons (MLPs) based PINNs, achieving superior accuracy in predicting power system dynamics while employing a smaller network size. Simulation results on a single-machine infinite bus system and a 4-bus 2- generator system underscore the accuracy of the PIKANs in predicting rotor angle and frequency with fewer learnable parameters than conventional PINNs. Furthermore, the simulation results demonstrate PIKANs capability to accurately identify uncertain inertia and damping coefficients. This work opens up a range of opportunities for the application of KANs in power systems, enabling efficient determination of grid dynamics and precise parameter identification.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ba0e7f4ba7daa48bc5af967eba3f7af6be45476e" target='_blank'>
              Physics-Informed Kolmogorov-Arnold Networks for Power System Dynamics
              </a>
            </td>
          <td>
            H. Shuai, Fangxing Li
          </td>
          <td>2024-08-13</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="We investigate the ability to discover data assimilation (DA) schemes meant for chaotic dynamics with deep learning (DL). The focus is on learning the analysis step of sequential DA, from state trajectories and their observations, using a simple residual convolutional neural network, while assuming the dynamics to be known. Experiments are performed with the Lorenz 96 dynamics, which display spatiotemporal chaos and for which solid benchmarks for DA performance exist. The accuracy of the states obtained from the learned analysis approaches that of the best possibly tuned ensemble Kalman filter (EnKF), and is far better than that of variational DA alternatives. Critically, this can be achieved while propagating even just a single state in the forecast step. We investigate the reason for achieving ensemble filtering accuracy without an ensemble. We diagnose that the analysis scheme actually identifies key dynamical perturbations, mildly aligned with the unstable subspace, from the forecast state alone, without any ensemble-based covariances representation. This reveals that the analysis scheme has learned some multiplicative ergodic theorem associated to the DA process seen as a non-autonomous random dynamical system.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/049cb29c29c44d7bcd0b2872f2cc68742751159c" target='_blank'>
              Deep learning-based sequential data assimilation for chaotic dynamics identifies local instabilities from single state forecasts
              </a>
            </td>
          <td>
            Marc Bocquet, A. Farchi, Tobias S. Finn, Charlotte Durand, Sibo Cheng, Yumeng Chen, I. Pasmans, A. Carrassi
          </td>
          <td>2024-08-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>28</td>
        </tr>

        <tr id="There is overwhelming evidence that cognition, perception, and action rely on feedback control. However, if and how neural population dynamics are amenable to different control strategies is poorly understood, in large part because machine learning methods to directly assess controllability in neural population dynamics are lacking. To address this gap, we developed a novel dimensionality reduction method, Feedback Controllability Components Analysis (FCCA), that identifies subspaces of linear dynamical systems that are most feedback controllable based on a new measure of feedback controllability. We further show that PCA identifies subspaces of linear dynamical systems that maximize a measure of feedforward controllability. As such, FCCA and PCA are data-driven methods to identify subspaces of neural population data (approximated as linear dynamical systems) that are most feedback and feedforward controllable respectively, and are thus natural contrasts for hypothesis testing. We developed new theory that proves that non-normality of underlying dynamics determines the divergence between FCCA and PCA solutions, and confirmed this in numerical simulations. Applying FCCA to diverse neural population recordings, we find that feedback controllable dynamics are geometrically distinct from PCA subspaces and are better predictors of animal behavior. Our methods provide a novel approach towards analyzing neural population dynamics from a control theoretic perspective, and indicate that feedback controllable subspaces are important for behavior.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b12cb2ef2eca3c8ee46436c8d7fddcc5787df892" target='_blank'>
              Identifying Feedforward and Feedback Controllable Subspaces of Neural Population Dynamics
              </a>
            </td>
          <td>
            Ankit Kumar, Loren M. Frank, Kristofer E. Bouchard
          </td>
          <td>2024-08-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="Traditional partial differential equations with constant coefficients often struggle to capture abrupt changes in real-world phenomena, leading to the development of variable coefficient PDEs and Markovian switching models. Recently, research has introduced the concept of PDEs with Markov switching models, established their well-posedness and presented numerical methods. However, there has been limited discussion on parameter estimation for the jump coefficients in these models. This paper addresses this gap by focusing on parameter inference for the wave equation with Markovian switching. We propose a Bayesian statistical framework using discrete sparse Bayesian learning to establish its convergence and a uniform error bound. Our method requires fewer assumptions and enables independent parameter inference for each segment by allowing different underlying structures for the parameter estimation problem within each segmented time interval. The effectiveness of our approach is demonstrated through three numerical cases, which involve noisy spatiotemporal data from different wave equations with Markovian switching. The results show strong performance in parameter estimation for variable coefficient PDEs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5eda7824c0ecf7f45c2be3abef5f95f30fc1aafe" target='_blank'>
              Parameters Inference for Nonlinear Wave Equations with Markovian Switching
              </a>
            </td>
          <td>
            Yi Zhang, Zhikun Zhang, Xiangjun Wang
          </td>
          <td>2024-08-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="This paper presents the open-source stochastic model predictive control framework GRAMPC-S for nonlinear uncertain systems with chance constraints. It provides several uncertainty propagation methods to predict stochastic moments of the system state and can consider unknown parts of the system dynamics using Gaussian process regression. These methods are used to reformulate a stochastic MPC formulation as a deterministic one that is solved with GRAMPC. The performance of the presented framework is evaluated using examples from a wide range of technical areas. The experimental evaluation shows that GRAMPC-S can be used in practice for the control of nonlinear uncertain systems with sampling times in the millisecond range.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7c62a7baf784d003dda62b0480d24a61f0d5beb4" target='_blank'>
              A software framework for stochastic model predictive control of nonlinear continuous-time systems (GRAMPC-S)
              </a>
            </td>
          <td>
            D. Landgraf, Andreas Völz, Knut Graichen
          </td>
          <td>2024-07-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id="We propose sparse regression as an alternative to neural networks for the discovery of parsimonious constitutive models (CMs) from oscillatory shear experiments. Symmetry and frame-invariance are strictly imposed by using tensor basis functions to isolate and describe unknown nonlinear terms in the CMs. We generate synthetic experimental data using the Giesekus and Phan-Thien Tanner CMs, and consider two different scenarios. In the complete information scenario, we assume that the shear stress, along with the first and second normal stress differences, is measured. This leads to a sparse linear regression problem that can be solved efficiently using $l_1$ regularization. In the partial information scenario, we assume that only shear stress data is available. This leads to a more challenging sparse nonlinear regression problem, for which we propose a greedy two-stage algorithm. In both scenarios, the proposed methods fit and interpolate the training data remarkably well. Predictions of the inferred CMs extrapolate satisfactorily beyond the range of training data for oscillatory shear. They also extrapolate reasonably well to flow conditions like startup of steady and uniaxial extension that are not used in the identification of CMs. We discuss ramifications for experimental design, potential algorithmic improvements, and implications of the non-uniqueness of CMs inferred from partial information.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bd96f3e9f14d21556f8ed9e6e5bbdb683f62715c" target='_blank'>
              Sparse Regression for Discovery of Constitutive Models from Oscillatory Shear Measurements
              </a>
            </td>
          <td>
            Sachin Shanbhag, Gordon Erlebacher
          </td>
          <td>2024-08-20</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="We propose the Artificial Intelligence Velocimetry-Thermometry (AIVT) method to infer hidden temperature fields from experimental turbulent velocity data. This physics-informed machine learning method enables us to infer continuous temperature fields using only sparse velocity data, hence eliminating the need for direct temperature measurements. Specifically, AIVT is based on physics-informed Kolmogorov-Arnold Networks (not neural networks) and is trained by optimizing a combined loss function that minimizes the residuals of the velocity data, boundary conditions, and the governing equations. We apply AIVT to a unique set of experimental volumetric and simultaneous temperature and velocity data of Rayleigh-B\'enard convection (RBC) that we acquired by combining Particle Image Thermometry and Lagrangian Particle Tracking. This allows us to compare AIVT predictions and measurements directly. We demonstrate that we can reconstruct and infer continuous and instantaneous velocity and temperature fields from sparse experimental data at a fidelity comparable to direct numerical simulations (DNS) of turbulence. This, in turn, enables us to compute important quantities for quantifying turbulence, such as fluctuations, viscous and thermal dissipation, and QR distribution. This paradigm shift in processing experimental data using AIVT to infer turbulent fields at DNS-level fidelity is a promising avenue in breaking the current deadlock of quantitative understanding of turbulence at high Reynolds numbers, where DNS is computationally infeasible.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/eb6d8afffcc7bf5a551a6c5a5b9a454bde425d85" target='_blank'>
              Inferring turbulent velocity and temperature fields and their statistics from Lagrangian velocity measurements using physics-informed Kolmogorov-Arnold Networks
              </a>
            </td>
          <td>
            Juan Diego Toscano, Theo Kaufer, Zhibo Wang, Martin Maxey, Christian Cierpka, G. Karniadakis
          </td>
          <td>2024-07-22</td>
          <td>ArXiv</td>
          <td>2</td>
          <td>127</td>
        </tr>

        <tr id="
 The growing time-series data make it possible to glimpse the hidden dynamics in various fields. However, developing a computational toolbox with high interpretability to unveil the interaction dynamics from data remains a crucial challenge. Here, we propose a new computational approach called Automated Dynamical Model Inference based on Expression Trees (ADMIET), in which the machine learning algorithm, the numerical integration of ordinary differential equations and the interpretability from prior knowledge are embedded into the symbolic learning scheme to establish a general framework for revealing the hidden dynamics in time-series data. ADMIET takes full advantage of both machine learning algorithm and expression tree. Firstly, we translate the prior knowledge into constraints on the structure of expression tree, reducing the search space and enhancing the interpretability. Secondly, we utilize the proposed adaptive penalty function to ensure the convergence of gradient descent algorithm and the selection of the symbols. Compared to gene expression programming, ADMIET exhibits its remarkable capability in function fitting with higher accuracy and broader applicability. Moreover, ADMIET can better fit parameters in nonlinear forms compared to regression methods. Furthermore, we apply ADMIET to two typical biological systems and one real data with different prior knowledge to infer the dynamical equations. The results indicate that ADMIET can not only discover the interaction relationships but also provide accurate estimates of the parameters in the equations. These results demonstrate ADMIET's superiority in revealing interpretable dynamics from time-series biological data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9687aa0373c8e0262b0df16232ea9a08145ff46c" target='_blank'>
              Inferring dynamical models from time-series biological data using an interpretable machine learning method based on weighted expression trees
              </a>
            </td>
          <td>
            Yu Zhou, Xiufen Zou
          </td>
          <td>2024-07-09</td>
          <td>Inverse Problems</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The task of sampling from a probability density can be approached as transporting a tractable density function to the target, known as dynamical measure transport. In this work, we tackle it through a principled unified framework using deterministic or stochastic evolutions described by partial differential equations (PDEs). This framework incorporates prior trajectory-based sampling methods, such as diffusion models or Schr\"odinger bridges, without relying on the concept of time-reversals. Moreover, it allows us to propose novel numerical methods for solving the transport task and thus sampling from complicated targets without the need for the normalization constant or data samples. We employ physics-informed neural networks (PINNs) to approximate the respective PDE solutions, implying both conceptional and computational advantages. In particular, PINNs allow for simulation- and discretization-free optimization and can be trained very efficiently, leading to significantly better mode coverage in the sampling task compared to alternative methods. Moreover, they can readily be fine-tuned with Gauss-Newton methods to achieve high accuracy in sampling.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/be6b71f84d3c641029effa69aa23e0c32eb9de03" target='_blank'>
              Dynamical Measure Transport and Neural PDE Solvers for Sampling
              </a>
            </td>
          <td>
            Jingtong Sun, Julius Berner, Lorenz Richter, Marius Zeinhofer, Johannes Müller, K. Azizzadenesheli, A. Anandkumar
          </td>
          <td>2024-07-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>32</td>
        </tr>

        <tr id="This paper considers one of the fundamental parallel-in-time methods for the solution of ordinary differential equations, Parareal, and extends it by adopting a neural network as a coarse propagator. We provide a theoretical analysis of the convergence properties of the proposed algorithm and show its effectiveness for several examples, including Lorenz and Burgers' equations. In our numerical simulations, we further specialize the underpinning neural architecture to Random Projection Neural Networks (RPNNs), a 2-layer neural network where the first layer weights are drawn at random rather than optimized. This restriction substantially increases the efficiency of fitting RPNN's weights in comparison to a standard feedforward network without negatively impacting the accuracy, as demonstrated in the SIR system example.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/eaebe5bb24e5000559ea75022dafced6dc1f5440" target='_blank'>
              Parallel-in-Time Solutions with Random Projection Neural Networks
              </a>
            </td>
          <td>
            M. Betcke, L. Kreusser, Davide Murari
          </td>
          <td>2024-08-19</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>15</td>
        </tr>

        <tr id="
 The time evolution of physical systems is described by differential equations, which depend on abstract quantities like energy and force. Traditionally, these quantities are derived as functionals based on observables such as positions and velocities. Discovering these governing symbolic laws is the key to comprehending the interactions in nature. Here, we present a Hamiltonian graph neural network (HGNN), a physics-enforced GNN that learns the dynamics of systems directly from their trajectory. We demonstrate the performance of HGNN on n-springs, n-pendulums, gravitational systems, and binary Lennard Jones systems; HGNN learns the dynamics in excellent agreement with the ground truth from small amounts of data. We also evaluate the ability of HGNN to generalize to larger system sizes, and to a hybrid spring-pendulum system that is a combination of two original systems (spring and pendulum) on which the models are trained independently. Finally, employing symbolic regression on the learned HGNN, we infer the underlying equations relating to the energy functionals, even for complex systems such as the binary Lennard-Jones liquid. Our framework facilitates the interpretable discovery of interaction laws directly from physical system trajectories. Furthermore, this approach can be extended to other systems with topology-dependent dynamics, such as cells, polydisperse gels, or deformable bodies.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c632fd8fa34b6e12e92828eda9a171b587d0e51e" target='_blank'>
              DISCOVERING SYMBOLIC LAWS DIRECTLY FROM TRAJECTORIES WITH HAMILTONIAN GRAPH NEURAL NETWORKS
              </a>
            </td>
          <td>
            S. Bishnoi, Ravinder Bhattoo, Sayan Ranu, N. Krishnan
          </td>
          <td>2024-08-06</td>
          <td>Machine Learning: Science and Technology</td>
          <td>1</td>
          <td>10</td>
        </tr>

        <tr id="We introduce new machine-learning techniques for analyzing chaotic dynamical systems. The primary objectives of the study include the development of a new and simple method for calculating the Lyapunov exponent using only two trajectory data points unlike traditional methods that require an averaging procedure, the exploration of phase transition graphs from regular periodic to chaotic dynamics to identify"almost integrable"trajectories where conserved quantities deviate from whole numbers, and the identification of"integrable regions"within chaotic trajectories. These methods are applied and tested on two dynamical systems:"Two objects moving on a rod"and the"Henon-Heiles"systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8beba1025021fc988f71772e30840ce6845fdf65" target='_blank'>
              Deciphering Complexity: Machine Learning Insights into Chaotic Dynamical Systems
              </a>
            </td>
          <td>
            Lazare Osmanov
          </td>
          <td>2024-08-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="We present a neural operator architecture to simulate Lagrangian dynamics, such as fluid flow, granular flows, and elastoplasticity. Traditional numerical methods, such as the finite element method (FEM), suffer from long run times and large memory consumption. On the other hand, approaches based on graph neural networks are faster but still suffer from long computation times on dense graphs, which are often required for high-fidelity simulations. Our model, GIOROM or Graph Interaction Operator for Reduced-Order Modeling, learns temporal dynamics within a reduced-order setting, capturing spatial features from a highly sparse graph representation of the input and generalizing to arbitrary spatial locations during inference. The model is geometry-aware and discretization-agnostic and can generalize to different initial conditions, velocities, and geometries after training. We show that point clouds of the order of 100,000 points can be inferred from sparse graphs with $\sim$1000 points, with negligible change in computation time. We empirically evaluate our model on elastic solids, Newtonian fluids, Non-Newtonian fluids, Drucker-Prager granular flows, and von Mises elastoplasticity. On these benchmarks, our approach results in a 25$\times$ speedup compared to other neural network-based physics simulators while delivering high-fidelity predictions of complex physical systems and showing better performance on most benchmarks. The code and the demos are provided at https://github.com/HrishikeshVish/GIOROM.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b0931d26d7d6b637fece82e4653a754d6a28f5dc" target='_blank'>
              Reduced-Order Neural Operators: Learning Lagrangian Dynamics on Highly Sparse Graphs
              </a>
            </td>
          <td>
            Hrishikesh Viswanath, Yue Chang, Julius Berner, Peter Yichen Chen, Aniket Bera
          </td>
          <td>2024-07-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>28</td>
        </tr>

        <tr id="For mathematical and experimental ease, models with time varying parameters are often simplified to assume constant parameters. However, this simplification can potentially lead to identifiability issues (lack of uniqueness of parameter estimates). Methods have been developed to algebraically and numerically determine the identifiability of a model, as well as resolve identifiability issues. This specific type of simplification presents an alternate opportunity to instead use this information to resolve the unidentifiability. Given that re-parameterizing, collecting more data, and adding inputs can be potentially costly or impractical, this could present new alternatives. We present a method for resolving unidentifiability in a system by introducing a new data stream correlated with a parameter of interest. First, we demonstrate how and when non-constant input data can be introduced into any rational function ODE system without worsening the model identifiability. Then, we prove when these input functions improve structural and potentially also practical identifiability for a given model and relevant data. By utilizing pre-existing data streams, these methods can potentially reduce experimental costs, while still answering key questions. By connecting mathematical proofs to application, our framework removes guesswork from when, where, and how researchers can best introduce new data to improve model outcomes.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/fbc38cc84b188d260525dcc553f64371eca970c3" target='_blank'>
              Examining the impact of forcing function inputs on structural identifiability
              </a>
            </td>
          <td>
            Jessica R Conrad, Marisa C Eisenberg
          </td>
          <td>2024-07-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="This paper addresses the need for deep learning models to integrate well-defined constraints into their outputs, driven by their application in surrogate models, learning with limited data and partial information, and scenarios requiring flexible model behavior to incorporate non-data sample information. We introduce Bayesian Entropy Neural Networks (BENN), a framework grounded in Maximum Entropy (MaxEnt) principles, designed to impose constraints on Bayesian Neural Network (BNN) predictions. BENN is capable of constraining not only the predicted values but also their derivatives and variances, ensuring a more robust and reliable model output. To achieve simultaneous uncertainty quantification and constraint satisfaction, we employ the method of multipliers approach. This allows for the concurrent estimation of neural network parameters and the Lagrangian multipliers associated with the constraints. Our experiments, spanning diverse applications such as beam deflection modeling and microstructure generation, demonstrate the effectiveness of BENN. The results highlight significant improvements over traditional BNNs and showcase competitive performance relative to contemporary constrained deep learning methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4d74383a8ad720e106440e126defbad7231d316d" target='_blank'>
              Bayesian Entropy Neural Networks for Physics-Aware Prediction
              </a>
            </td>
          <td>
            R. Rathnakumar, Jiayu Huang, Hao Yan, Yongming Liu
          </td>
          <td>2024-07-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="We previously presented a novel loss formulation for efficient learning of complex dynamics from governing physics, typically described by partial differential equations (PDEs), using physics-informed neural networks (PINNs). In these experiments, the incorporation of a Boundary Connectivity (BCXN) loss function was shown to greatly improve physics-informed learning across many problems, especially those with complex geometries. However, this imposition may not always be ideal, as the previously presented BCXN-loss strongly enforces a linear local structure at the boundary. While this assumption helps facilitate faster learning with an order of magnitude sparser training samples, this can adversely impact convergence in other situations. Hence, we propose a modification of this BCXN-loss that reduces the imposed structure to a soft constraint, allowing for more flexible learning and convergence. We further demonstrate the potential for this method to improve the convergence and performance of LSA-PINN across additional numerical experiments, with much smaller errors than existing methods in terms of the standard L2-norm metric. In particular, we have applied this method to the modelling of flow past complex geometries such as airfoils, which serve as the basic building block for various applications in fluid dynamics and renewable energy (e.g., in wind and tidal turbine design).">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/535c64c537da066482154d77b3dfa4334e26bb4e" target='_blank'>
              Soft Constraint in Local Structure Approximation-PINN
              </a>
            </td>
          <td>
            Jian Cheng Wong, P. Chiu, C. Ooi, M. Dao
          </td>
          <td>2024-06-25</td>
          <td>2024 IEEE Conference on Artificial Intelligence (CAI)</td>
          <td>0</td>
          <td>13</td>
        </tr>

        <tr id="Many physical systems exhibit translational invariance, meaning that the underlying physical laws are independent of the position in space. Data driven approximations of the infinite dimensional but linear Koopman operator of non-linear dynamical systems need to be physically informed in order to respect such physical symmetries. In the current work, we introduce a translation invariant extended dynamic mode decomposition (tieDMD) for coupled non-linear systems on periodic domains. This is achieved by exploiting a block-diagonal structure of the Koopman operator in Fourier space. Variants of tieDMD are applied to data obtained on one-dimensional periodic domains from the non-linear phase-diffusion equation, the Burgers equation, the Korteweg-de Vries equation, and a coupled FitzHugh-Nagumo system of partial differential equations. The reconstruction capability of tieDMD is compared to existing linear and non-linear variants of the dynamic mode decomposition applied to the same data. For the regarded data, tieDMD consistently shows superior capabilities in data reconstruction.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c3bb71d64de3bbe99545b75cc623bacfad3e1e76" target='_blank'>
              Approximation of translation invariant Koopman operators for coupled non-linear systems.
              </a>
            </td>
          <td>
            Thomas Hochrainer, Gurudas Kar
          </td>
          <td>2024-08-01</td>
          <td>Chaos</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Bayesian analysis enables combining prior knowledge with measurement data to learn model parameters. Commonly, one resorts to computing the maximum a posteriori (MAP) estimate, when only a point estimate of the parameters is of interest. We apply MAP estimation in the context of structural dynamic models, where the system response can be described by the frequency response function. To alleviate high computational demands from repeated expensive model calls, we utilize a rational polynomial chaos expansion (RPCE) surrogate model that expresses the system frequency response as a rational of two polynomials with complex coefficients. We propose an extension to an existing sparse Bayesian learning approach for RPCE based on Laplace's approximation for the posterior distribution of the denominator coefficients. Furthermore, we introduce a Bayesian optimization approach, which allows to adaptively enrich the experimental design throughout the optimization process of MAP estimation. Thereby, we utilize the expected improvement acquisition function as a means to identify sample points in the input space that are possibly associated with large objective function values. The acquisition function is estimated through Monte Carlo sampling based on the posterior distribution of the expansion coefficients identified in the sparse Bayesian learning process. By combining the sparsity-inducing learning procedure with the sequential experimental design, we effectively reduce the number of model evaluations in the MAP estimation problem. We demonstrate the applicability of the presented methods on the parameter updating problem of an algebraic two-degree-of-freedom system and the finite element model of a cross-laminated timber plate.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9a03332f3ec82d4697eb9f8880eb0ae668a91b1a" target='_blank'>
              Maximum a Posteriori Estimation for Linear Structural Dynamics Models Using Bayesian Optimization with Rational Polynomial Chaos Expansions
              </a>
            </td>
          <td>
            Felix Schneider, I. Papaioannou, Bruno Sudret, Gerhard Muller
          </td>
          <td>2024-08-07</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>25</td>
        </tr>

        <tr id="Model predictive control (MPC) is a powerful control method for handling complex nonlinear systems that are subject to constraints. However, the real-time application of this approach can be severely limited by the need to solve constrained nonlinear optimization problems at each sampling time. To this end, this work introduces a novel learning-based iterative solver that provides highly accurate predictions, optimality certification, and fast evaluation of the MPC solution at each sampling time. To learn this iterative solver, we propose an unsupervised training algorithm that builds on the Karush-Kuhn-Tucker optimality conditions, modified by a Fischer-Burmeister formulation, and eliminates the need for prior sampling of exact optimizer solutions. By exploiting efficient vector-Jacobian and Jacobian-vector products via automatic differentiation, the proposed training algorithm can be efficiently executed. We demonstrate the potential of the proposed learning-based iterative solver on the example of nonlinear model predictive control of a nonlinear double integrator. We show its advantages when compared to exact optimizer solutions and with an imitation learning-based approach that directly obtains a data-based approximation of the MPC control law.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/04655a12d07dee491135aaae2f055b737e275291" target='_blank'>
              Learning Iterative Solvers for Accurate and Fast Nonlinear Model Predictive Control via Unsupervised Training
              </a>
            </td>
          <td>
            Lukas Lüken, Sergio Lucia
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Accurate estimate of long-term risk is critical for safe decision-making, but sampling from rare risk events and long-term trajectories can be prohibitively costly. Risk gradient can be used in many first-order techniques for learning and control methods, but gradient estimate is difficult to obtain using Monte Carlo (MC) methods because the infinitesimal divisor may significantly amplify sampling noise. Motivated by this gap, we propose an efficient method to evaluate long-term risk probabilities and their gradients using short-term samples without sufficient risk events. We first derive that four types of long-term risk probability are solutions of certain partial differential equations (PDEs). Then, we propose a physics-informed learning technique that integrates data and physics information (aforementioned PDEs). The physics information helps propagate information beyond available data and obtain provable generalization beyond available data, which in turn enables long-term risk to be estimated using short-term samples of safe events. Finally, we demonstrate in simulation that the proposed technique has improved sample efficiency, generalizes well to unseen regions, and adapts to changing system parameters.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b4b5d11c4861e28deddce08df1d92f4a1c23b924" target='_blank'>
              Generalizable Physics-Informed Learning for Stochastic Safety-Critical Systems
              </a>
            </td>
          <td>
            Zhuoyuan Wang, Albert Chern, Yorie Nakahira
          </td>
          <td>2024-07-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3038affaf44b0add1111bbe6e37030a4700bfe67" target='_blank'>
              Evaluating single multiplicative neuron models in physics-informed neural networks for differential equations
              </a>
            </td>
          <td>
            Melih Agraz
          </td>
          <td>2024-08-17</td>
          <td>Scientific Reports</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Many systems in biology, physics, and engineering are modeled by nonlinear dynamical systems where the states are usually unknown and only a subset of the state variables can be physically measured. Can we understand the full system from what we measure? In the mathematics literature, this question is framed as the observability problem. It has to do with recovering information about the state variables from the observed states (the measurements). In this paper, we relate the observability problem to another structural feature of many models relevant in the physical and biological sciences: the conserved quantity. For models based on systems of differential equations, conserved quantities offer desirable properties such as dimension reduction which simplifies model analysis. Here, we use differential embeddings to show that conserved quantities involving a set of special variables provide more flexibility in what can be measured to address the observability problem for systems of interest in biology. Specifically, we provide conditions under which a collection of conserved quantities make the system observable. We apply our methods to provide alternate measurable variables in models where conserved quantities have been used for model analysis historically in biological contexts.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ac75a2c31069a04d822b3532f120e93eba3378c7" target='_blank'>
              Observability of complex systems via conserved quantities
              </a>
            </td>
          <td>
            B. Karamched, Jack Schmidt, David Murrugarra
          </td>
          <td>2024-07-31</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id=""AI for Science"aims to solve fundamental scientific problems using AI techniques. As most physical phenomena can be described as Partial Differential Equations (PDEs) , approximating their solutions using neural networks has evolved as a central component of scientific-ML. Physics-Informed Neural Networks (PINNs) is the general method that has evolved for this task but its training is well-known to be very unstable. In this work we explore the possibility of changing the model being trained from being just a neural network to being a non-linear transformation of it - one that algebraically includes the boundary/initial conditions. This reduces the number of terms in the loss function than the standard PINN losses. We demonstrate that our modification leads to significant performance gains across a range of benchmark tasks, in various dimensions and without having to tweak the training algorithm. Our conclusions are based on conducting hundreds of experiments, in the fully unsupervised setting, over multiple linear and non-linear PDEs set to exactly solvable scenarios, which lends to a concrete measurement of our performance gains in terms of order(s) of magnitude lower fractional errors being achieved, than by standard PINNs. The code accompanying this manuscript is publicly available at, https://github.com/MorganREN/Improving-PINNs-By-Algebraic-Inclusion-of-Boundary-and-Initial-Conditions">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/50ec057bbac038765a71bbcf35743418ac73a1d3" target='_blank'>
              Improving PINNs By Algebraic Inclusion of Boundary and Initial Conditions
              </a>
            </td>
          <td>
            Mohan Ren, Zhihao Fang, Keren Li, Anirbit Mukherjee
          </td>
          <td>2024-07-30</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="Echo state network (ESN) implements an alternative paradigm called reservoir computing to train recurrent neural networks (RNNs), where internal weights are randomly generated and kept fixed, and only readout weights need to be trained, which greatly reduces the training complexity of RNNs. ESN not only facilitates the practical implementation of RNNs but also shows superior performance over fully trained RNNs across a range of applications. However, the conventional ESN suffers from the drawbacks of stringent conditions for weight convergence and slow convergence speed. This paper proposes a memory regressor extended learning method to update the readout weights of ESNs. By constructing and incorporating a generalized prediction error based on regressor extension and filtering, the capacity of ESN to utilize historical data can be greatly improved. In the discrete-time domain, it is proven that exponential convergence of readout weights is achieved under a condition termed interval excitation that is strictly weaker than the classical condition of persistent excitation. Simulation results on modeling a 10th-order nonlinear autoregressive moving-average (NARMA) system have revealed that the proposed approach accelerates weight convergence speed almost ten times higher compared to the conventional ESN.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4e0fa7b7dfe357970b3e72acb8d86266f028d299" target='_blank'>
              Memory Regressor Extended Echo State Networks for Nonlinear Dynamics Modeling
              </a>
            </td>
          <td>
            Kai Hu, Qian Wang, Tian Shi, Kohei Nakajima, Yongping Pan
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Understanding the dynamics of nonequilibrium quantum many-body systems is an important research topic in a wide range of fields across condensed matter physics, quantum optics, and high-energy physics. However, numerical studies of large-scale nonequilibrium phenomena in realistic materials face serious challenges due to intrinsic high-dimensionality of quantum many-body problems. The nonequilibrium properties of many-body systems can be described by the dynamics of the Green's function of the system, whose time evolution is given by a high-dimensional system of integro-differential equations, known as the Kadanoff-Baym equations (KBEs). The time-convolution term in KBEs, which needs to be recalculated at each time step, makes it difficult to perform long-time simulations. In this paper, we develop an operator-learning framework based on Recurrent Neural Networks (RNNs) to address this challenge. The proposed framework utilizes RNNs to learn the nonlinear mapping between Green's functions and convolution integrals in KBEs. By using the learned operators as a surrogate model in the KBE solver, we obtain a general machine-learning scheme for predicting the dynamics of nonequilibrium Green's functions. This new methodology reduces the temporal computational complexity from $O(N_t^3)$ to $O(N_t)$, where $N_t$ is the total time steps taken in a simulation, thereby making it possible to study large many-body problems which are currently infeasible with conventional KBE solvers. Through different numerical examples, we demonstrate the effectiveness of the operator-learning based approach in providing accurate predictions of physical observables such as the reduced density matrix and time-resolved photoemission spectra. Moreover, our framework exhibits clear numerical convergence and can be easily parallelized, thereby facilitating many possible further developments and applications.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/526a9cb7b29055f6d28d2a654e064ac8a68bb587" target='_blank'>
              Predicting nonequilibrium Green's function dynamics and photoemission spectra via nonlinear integral operator learning
              </a>
            </td>
          <td>
            Yuanran Zhu, Jia Yin, Cian C. Reeves, Chao Yang, Vojtěch Vlček
          </td>
          <td>2024-07-13</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="This paper proposes a generalized algorithmic approach for learning linear model representations for nonlinear systems within the Koopman framework. We focus on schemes that rely on learning the nonlinear transformation functions using deep neural networks. Beyond achieving dynamical accuracy, our primary objective is to develop models capable of simulating nonlinear systems across multiple time steps in the linear space. An algorithm that is based on recursive least squares is proposed to address the optimization complexities inherent in learning such models. In addition, we leverage the learned linear representation to design a linear quadratic regulator to control the original nonlinear system. The effectiveness of the proposed algorithm is demonstrated in two numerical examples.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1dc9bf823159462d30a9a2199b18f6959ef1ccd3" target='_blank'>
              Recursive Least Squares-Based Identification for Multi-Step Koopman Operators
              </a>
            </td>
          <td>
            Omar Sayed, Sergio Lucia
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>1</td>
          <td>1</td>
        </tr>

        <tr id="The effective inclusion of a priori knowledge when embedding known data in physics‐based models of dynamical systems can ensure that the reconstructed model respects physical principles, while simultaneously improving the accuracy of the solution in the previously unseen regions of state space. This paper presents a physics‐constrained data‐driven discrepancy modeling method that variationally embeds known data in the modeling framework. The hierarchical structure of the method yields fine scale variational equations that facilitate the derivation of residuals which are comprised of the first‐principles theory and sensor‐based data from the dynamical system. The embedding of the sensor data via residual terms leads to discrepancy‐informed closure models that yield a method which is driven not only by boundary and initial conditions, but also by measurements that are taken at only a few observation points in the target system. Specifically, the data‐embedding term serves as residual‐based least‐squares loss function, thus retaining variational consistency. Another important relation arises from the interpretation of the stabilization tensor as a kernel function, thereby incorporating a priori knowledge of the problem and adding computational intelligence to the modeling framework. Numerical test cases show that when known data is taken into account, the data driven variational (DDV) method can correctly predict the system response in the presence of several types of discrepancies. Specifically, the damped solution and correct energy time histories are recovered by including known data in the undamped situation. Morlet wavelet analyses reveal that the surrogate problem with embedded data recovers the fundamental frequency band of the target system. The enhanced stability and accuracy of the DDV method is manifested via reconstructed displacement and velocity fields that yield time histories of strain and kinetic energies which match the target systems. The proposed DDV method also serves as a procedure for restoring eigenvalues and eigenvectors of a deficient dynamical system when known data is taken into account, as shown in the numerical test cases presented here.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/dda505dc42399a19a75eff263166e84931a95cf6" target='_blank'>
              Data‐driven variational method for discrepancy modeling: Dynamics with small‐strain nonlinear elasticity and viscoelasticity
              </a>
            </td>
          <td>
            Arif Masud, Shoaib A. Goraya
          </td>
          <td>2024-07-04</td>
          <td>International Journal for Numerical Methods in Engineering</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="This paper proposes a fully data-driven approach for optimal control of nonlinear control-affine systems represented by a stochastic diffusion. The focus is on the scenario where both the nonlinear dynamics and stage cost functions are unknown, while only control penalty function and constraints are provided. Leveraging the theory of reproducing kernel Hilbert spaces, we introduce novel kernel mean embeddings (KMEs) to identify the Markov transition operators associated with controlled diffusion processes. The KME learning approach seamlessly integrates with modern convex operator-theoretic Hamilton-Jacobi-Bellman recursions. Thus, unlike traditional dynamic programming methods, our approach exploits the ``kernel trick'' to break the curse of dimensionality. We demonstrate the effectiveness of our method through numerical examples, highlighting its ability to solve a large class of nonlinear optimal control problems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/69ffcc674bf67738c50bad11d4a1a6996a25767b" target='_blank'>
              Data-Driven Optimal Feedback Laws via Kernel Mean Embeddings
              </a>
            </td>
          <td>
            Petar Bevanda, Nicolas Hoischen, Stefan Sosnowski, Sandra Hirche, Boris Houska
          </td>
          <td>2024-07-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>15</td>
        </tr>

        <tr id="A differential dynamic programming (DDP)-based framework for inverse reinforcement learning (IRL) is introduced to recover the parameters in the cost function, system dynamics, and constraints from demonstrations. Different from existing work, where DDP was used for the inner forward problem with inequality constraints, our proposed framework uses it for efficient computation of the gradient required in the outer inverse problem with equality and inequality constraints. The equivalence between the proposed method and existing methods based on Pontryagin's Maximum Principle (PMP) is established. More importantly, using this DDP-based IRL with an open-loop loss function, a closed-loop IRL framework is presented. In this framework, a loss function is proposed to capture the closed-loop nature of demonstrations. It is shown to be better than the commonly used open-loop loss function. We show that the closed-loop IRL framework reduces to a constrained inverse optimal control problem under certain assumptions. Under these assumptions and a rank condition, it is proven that the learning parameters can be recovered from the demonstration data. The proposed framework is extensively evaluated through four numerical robot examples and one real-world quadrotor system. The experiments validate the theoretical results and illustrate the practical relevance of the approach.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c9d2e45d49310cfdd8ea12901e2b14e2b24271b5" target='_blank'>
              A Differential Dynamic Programming Framework for Inverse Reinforcement Learning
              </a>
            </td>
          <td>
            Kun Cao, Xinhang Xu, Wanxin Jin, Karl H. Johansson, Lihua Xie
          </td>
          <td>2024-07-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="In this work, we present a novel methodology for performing the supervised classification of time-ordered noisy data; we call this methodology Entropic Sparse Probabilistic Approximation with Markov regularization (eSPA-Markov). It is an extension of entropic learning methodologies, allowing the simultaneous learning of segmentation patterns, entropy-optimal feature space discretizations, and Bayesian classification rules. We prove the conditions for the existence and uniqueness of the learning problem solution and propose a one-shot numerical learning algorithm that—in the leading order—scales linearly in dimension. We show how this technique can be used for the computationally scalable identification of persistent (metastable) regime affiliations and regime switches from high-dimensional non-stationary and noisy time series, i.e., when the size of the data statistics is small compared to their dimensionality and when the noise variance is larger than the variance in the signal. We demonstrate its performance on a set of toy learning problems, comparing eSPA-Markov to state-of-the-art techniques, including deep learning and random forests. We show how this technique can be used for the analysis of noisy time series from DNA and RNA Nanopore sequencing.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/eadfee466307a1a3b8e63299cb3e600477c1f902" target='_blank'>
              On Entropic Learning from Noisy Time Series in the Small Data Regime
              </a>
            </td>
          <td>
            Davide Bassetti, Lukás Pospísil, I. Horenko
          </td>
          <td>2024-06-28</td>
          <td>Entropy</td>
          <td>0</td>
          <td>26</td>
        </tr>

        <tr id="This paper introduces PDEformer-1, a versatile neural solver capable of simultaneously addressing various partial differential equations (PDEs). With the PDE represented as a computational graph, we facilitate the seamless integration of symbolic and numeric information inherent in a PDE. A graph Transformer and an implicit neural representation (INR) are employed subsequently to generate mesh-free predicted solutions. We generated a dataset with up to three million samples involving diverse one-dimensional PDEs to pretrain our model. Compared with baseline models trained specifically on benchmark datasets, our pretrained model achieves comparable accuracy via zero-shot inference, and the advantage expands after finetuning. For PDEs new or unseen in the pretraining stage, our model can adapt quickly by finetuning on a relatively small set of examples from the target equation. Additionally, PDEformer-1 demonstrates promising results in the inverse problem of PDE scalar coefficient recovery and coefficient field recovery.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/40c21c8b077c4c5aea793ff9f0cb0cf1332acd86" target='_blank'>
              PDEformer-1: A Foundation Model for One-Dimensional Partial Differential Equations
              </a>
            </td>
          <td>
            Zhanhong Ye, Xiang Huang, Leheng Chen, Zining Liu, Bingyang Wu, Hongsheng Liu, Zidong Wang, Bin Dong
          </td>
          <td>2024-07-09</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="Cyclostationary linear inverse models (CS-LIMs), generalized versions of the classical (stationary) LIM, are advanced data-driven techniques for extracting the first-order time-dependent dynamics and random forcing relevant information from complex non-linear stochastic processes. Though CS-LIMs lead to a breakthrough in climate sciences, their mathematical background and properties are worth further exploration. This study focuses on the mathematical perspective of CS-LIMs and introduces two variants: e-CS-LIM and l-CS-LIM. The former refines the original CS-LIM using the interval-wise linear Markov approximation, while the latter serves as an analytic inverse model for the linear periodic stochastic systems. Although relying on approximation, e-CS-LIM converges to l-CS-LIM under specific conditions and shows noise-robust performance. Numerical experiments demonstrate that each CS-LIM reveals the temporal structure of the system. The e-CS-LIM optimizes the original model for better dynamics performance, while l-CS-LIM excels in diffusion estimation due to reduced approximation reliance. Moreover, CS-LIMs are applied to real-world ENSO data, yielding a consistent result aligning with observations and current ENSO understanding.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7f20f17be02b5ed8df3e9de809737832dc15d7e7" target='_blank'>
              On the Cyclostationary Linear Inverse Models: A Mathematical Insight and Implication
              </a>
            </td>
          <td>
            Justin Lien, Yan-Ning Kuo, Hiroyasu Ando
          </td>
          <td>2024-07-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="In this study, we present a novel non-intrusive reduced-order model (ROM) for solving time-dependent stochastic partial differential equations (SPDEs). Utilizing proper orthogonal decomposition (POD), we extract spatial modes from high-fidelity solutions. A dynamic mode decomposition (DMD) method is then applied to vertically stacked matrices of projection coefficients for future prediction of coefficient fields. Polynomial chaos expansion (PCE) is employed to construct a mapping from random parameter inputs to the DMD-predicted coefficient field. These lead to the POD-DMD-PCE method. The innovation lies in vertically stacking projection coefficients, ensuring time-dimensional consistency in the coefficient matrix for DMD and facilitating parameter integration for PCE analysis. This method combines the model reduction of POD with the time extrapolation strengths of DMD, effectively recovering field solutions both within and beyond the training time interval. The efficiency and time extrapolation capabilities of the proposed method are validated through various nonlinear SPDEs. These include a reaction-diffusion equation with 19 parameters, a two-dimensional heat equation with two parameters, and a one-dimensional Burgers equation with three parameters.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f03b1ec02154fef08c7c119096855e273290c56c" target='_blank'>
              Non-intrusive reduced-order model for time-dependent stochastic partial differential equations utilizing dynamic mode decomposition and polynomial chaos expansion.
              </a>
            </td>
          <td>
            Shuman Wang, Afshan Batool, Xiang Sun, Xiaomin Pan
          </td>
          <td>2024-07-01</td>
          <td>Chaos</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="A dynamical system may be defined by a simple transition law - such as a map or a vector field. Most learning techniques primarily try to recreate the dynamic evolution law. This is a major shortcoming, as most dynamic properties of interest are asymptotic properties such as an attractor or invariant measure. One of the major theoretical challenges for numerical methods is that approximating the dynamical law may not be sufficient to approximate these asymptotic properties. This article presents a method of representing a discrete-time deterministic dynamical system as a Markov process. The procedure is completely data-driven. The technique is proved to be convergent -- the stationary density of the Markov process has a support that converges to the targeted invariant set. Thus invariant sets of arbitrary dynamical systems, even with complicated non-smooth topology, can be approximated by this technique. Under further assumptions of stochastic stability of the targeted system, the technique is also shown to provide a convergent statistical approximation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f7a9c8ed7750a7d4d14152ec7fe7c869a1655699" target='_blank'>
              Reconstructing dynamical systems as zero-noise limits
              </a>
            </td>
          <td>
            Suddhasattwa Das
          </td>
          <td>2024-07-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Abstract The advent of machine learning has led to innovative approaches in dealing with clinical data. Among these, Neural Ordinary Differential Equations (Neural ODEs), hybrid models merging mechanistic with deep learning models have shown promise in accurately modeling continuous dynamical systems. Although initial applications of Neural ODEs in the field of model‐informed drug development and clinical pharmacology are becoming evident, applying these models to actual clinical trial datasets—characterized by sparse and irregularly timed measurements—poses several challenges. Traditional models often have limitations with sparse data, highlighting the urgent need to address this issue, potentially through the use of assumptions. This review examines the fundamentals of Neural ODEs, their ability to handle sparse and irregular data, and their applications in model‐informed drug development.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d55a1a4acc93d905399f2126e7beb524fd64ec38" target='_blank'>
              Bridging pharmacology and neural networks: A deep dive into neural ordinary differential equations
              </a>
            </td>
          <td>
            Idris Bachali Losada, N. Terranova
          </td>
          <td>2024-07-11</td>
          <td>CPT: Pharmacometrics & Systems Pharmacology</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="This paper considers the data-driven stabilization of linear boundary controlled parabolic PDEs by making use of the Koopman operator. For this, a Koopman eigenstructure assignment problem is solved, which amounts to determine a feedback of the Koopman open-loop eigenfunctionals assigning a desired finite set of closed-loop Koopman eigenvalues and eigenfunctionals to the closed-loop system. It is shown that the designed controller only needs a finite number of open-loop Koopman eigenvalues and modes of the state. They are determined by extending the classical Krylov-DMD to parabolic systems. For this, only a finite number of pointlike outputs and their temporal samples as well as temporal samples of the inputs are required resulting in a data-driven solution of the eigenstructure assignment problem. Exponential stability of the closed-loop system in the presence of small Krylov-DMD errors is verified. An unstable diffusion-reaction system demonstrates the new data-driven controller design technique for distributed-parameter systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/03f995f29cd6086138895c91c94cd523bfb83873" target='_blank'>
              Data-Driven Control of Linear Parabolic Systems using Koopman Eigenstructure Assignment
              </a>
            </td>
          <td>
            Member Ieee Joachim Deutscher
          </td>
          <td>2024-06-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Most present stellarator designs are produced by costly two-stage optimization: the first for an optimized equilibrium, and the second for a coil design reproducing its magnetic configuration. Few proxies for coil complexity and forces exist at the equilibrium stage. Rapid initial state finding for both stages is a topic of active research. Most present convex coil optimization codes use the least square winding surface method by Merkel (NESCOIL), with recent improvement in conditioning, regularization , sparsity and physics objectives. While elegant, the method is limited to modeling the norms of linear functions in coil current. We present QUADCOIL, a fast, global coil optimization method that targets combinations of linear and quadratic functions of the current. It can directly constrain and/or minimize a wide range of physics objectives unavailable in NESCOIL and REGCOIL, including the Lorentz force, magnetic energy, curvature, field-current alignment, and the maximum density of a dipole array. QUADCOIL requires no initial guess and runs nearly $10^2\times$ faster than filament optimization. Integrating it in the equilibrium optimization stage can potentially exclude equilibria with difficult-to-design coils, without significantly increasing the computation time per iteration. QUADCOIL finds the exact, global minimum in a large parameter space when possible, and otherwise finds a well-performing approximate global minimum. It supports most regularization techniques developed for NESCOIL and REGCOIL. We demonstrate QUADCOIL's effectiveness in coil topology control, minimizing non-convex penalties, and predicting filament coil complexity with three numerical examples.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/085cc4a71b811a7efa88595f98cb5a706cc34bee" target='_blank'>
              Global Stellarator Coil Optimization with Quadratic Constraints and Objectives
              </a>
            </td>
          <td>
            Lanke Fu, Elizabeth J. Paul, A. Kaptanoglu, Amitava Bhattacharjee
          </td>
          <td>2024-08-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="This paper develops a novel Bayesian approach for nonlinear regression with symmetric matrix predictors, often used to encode connectivity of different nodes. Unlike methods that vectorize matrices as predictors that result in a large number of model parameters and unstable estimation, we propose a Bayesian multi-index regression method, resulting in a projection-pursuit-type estimator that leverages the structure of matrix-valued predictors. We establish the model identifiability conditions and impose a sparsity-inducing prior on the projection directions for sparse sampling to prevent overfitting and enhance interpretability of the parameter estimates. Posterior inference is conducted through Bayesian backfitting. The performance of the proposed method is evaluated through simulation studies and a case study investigating the relationship between brain connectivity features and cognitive scores.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8dea5688399617e45f7c7a63c6cf65ec61bb3cf0" target='_blank'>
              Projection-pursuit Bayesian regression for symmetric matrix predictors
              </a>
            </td>
          <td>
            Xiaomeng Ju, Hyung Park, T. Tarpey
          </td>
          <td>2024-07-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>22</td>
        </tr>

        <tr id="In the field of machine learning, comprehending the intricate training dynamics of neural networks poses a significant challenge. This paper explores the training dynamics of neural networks, particularly whether these dynamics can be expressed in a general closed-form solution. We demonstrate that the dynamics of the gradient flow in two-layer narrow networks is not an integrable system. Integrable systems are characterized by trajectories confined to submanifolds defined by level sets of first integrals (invariants), facilitating predictable and reducible dynamics. In contrast, non-integrable systems exhibit complex behaviors that are difficult to predict. To establish the non-integrability, we employ differential Galois theory, which focuses on the solvability of linear differential equations. We demonstrate that under mild conditions, the identity component of the differential Galois group of the variational equations of the gradient flow is non-solvable. This result confirms the system's non-integrability and implies that the training dynamics cannot be represented by Liouvillian functions, precluding a closed-form solution for describing these dynamics. Our findings highlight the necessity of employing numerical methods to tackle optimization problems within neural networks. The results contribute to a deeper understanding of neural network training dynamics and their implications for machine learning optimization strategies.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0ddef324ecc792db4cfe809ea02647e7e5e7d877" target='_blank'>
              Absence of Closed-Form Descriptions for Gradient Flow in Two-Layer Narrow Networks
              </a>
            </td>
          <td>
            Yeachan Park
          </td>
          <td>2024-08-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="A machine-learning strategy for investigating the stability of fluid flow problems is proposed herein. The computational procedure is demonstrably robust and does not require parameter tuning. The essential feature of the strategy is that the computational solution of the Navier--Stokes equations is a reliable proxy for laboratory experiments investigating sensitivity to flow parameters. The applicability of our bifurcation detection strategy is demonstrated by an investigation of two classical examples of flow instability associated with thermal convection. The codes used to generate the numerical results are available online.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ada3b0ba98c9f07f4ec32419fa6e2cd617f9cbce" target='_blank'>
              Machine learning for hydrodynamic stability
              </a>
            </td>
          <td>
            David J. Silvester
          </td>
          <td>2024-07-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The objective of system identification is to derive models from input/output data. To extend advancements in regularization techniques for linear finite impulse response (FIR) models to the nonlinear domain, we employ local model networks (LMNs) with locally regularized FIR models to identify nonlinear processes. The training of the LMN is performed using the local linear model tree (LOLIMOT) algorithm, resulting in both the partitioning of the model space and the estimation of the corresponding linear local models for each region. One key advantage of this algorithm lies in its ability to create separate input spaces for the linear models (x-space) and the validity functions (z-space) comprising the partitioning. While the most straightforward choice (x-space = z-space) results in an extremely high-dimensional z-space for local FIR models, we ad-dress this drawback by proposing different z-spaces spanned by the input spaces of autoregressive with exogenous inputs (ARX) models or Laguerre filter models, respectively. The theoretical capabilities for the proposed z-spaces are characterized. The superiority in terms of computation time, as well as comparable performance for Laguerre z-spaces and FIR z-spaces, is demon-strated through numerical examples. Additionally, the limitations for the utilization of ARX z-spaces are highlighted. Finally, all z-spaces have been evaluated on real-world data of a Wiener-Hammerstein benchmark. The FIR and Laguerre z- space showed comparable performance, while the ARX z-space performed worse.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9d7f2bb8d2c64f0e73154c706dc8921696b583cb" target='_blank'>
              On the Choice of the Scheduling Variables for Dynamic Local Model Networks with Local Regularized FIR Models
              </a>
            </td>
          <td>
            Christopher Illg, T. Kösters, Oliver Nelles
          </td>
          <td>2024-06-30</td>
          <td>2024 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Filtering - the task of estimating the conditional distribution of states of a dynamical system given partial, noisy, observations - is important in many areas of science and engineering, including weather and climate prediction. However, the filtering distribution is generally intractable to obtain for high-dimensional, nonlinear systems. Filters used in practice, such as the ensemble Kalman filter (EnKF), are biased for nonlinear systems and have numerous tuning parameters. Here, we present a framework for learning a parameterized analysis map - the map that takes a forecast distribution and observations to the filtering distribution - using variational inference. We show that this methodology can be used to learn gain matrices for filtering linear and nonlinear dynamical systems, as well as inflation and localization parameters for an EnKF. Future work will apply this framework to learn new filtering algorithms.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0caedb45ee3429ec36e56edd056c7ae412f7b6b8" target='_blank'>
              Learning Optimal Filters Using Variational Inference
              </a>
            </td>
          <td>
            Enoch Luk, Eviatar Bach, Ricardo Baptista, Andrew Stuart
          </td>
          <td>2024-06-26</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>10</td>
        </tr>

        <tr id="Reliable uncertainty measures are required when using data based machine learning interatomic potentials (MLIPs) for atomistic simulations. In this work, we propose for sparse Gaussian Process Regression type MLIP a stochastic uncertainty measure akin to the query-by-committee approach often used in conjunction with neural network based MLIPs. The uncertainty measure is coined \textit{"label noise"} ensemble uncertainty as it emerges from adding noise to the energy labels in the training data. We find that this method of calculating an ensemble uncertainty is as well calibrated as the one obtained from the closed-form expression for the posterior variance when the sparse GPR is treated as a projected process. Comparing the two methods, our proposed ensemble uncertainty is, however, faster to evaluate than the closed-form expression. Finally, we demonstrate that the proposed uncertainty measure acts better to support a Bayesian search for optimal structure of Au$_{20}$ clusters.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/cbe74de7bdeef59e212d49ccb746e4deaac70d5f" target='_blank'>
              Efficient ensemble uncertainty estimation in Gaussian Processes Regression
              </a>
            </td>
          <td>
            Mads-Peter V. Christiansen, Nikolaj Rønne, Bjork Hammer
          </td>
          <td>2024-07-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="We introduce data to predictive control, D2PC, a framework to facilitate the design of robust and predictive controllers from data. The proposed framework is designed for discrete-time stochastic linear systems with output measurements and provides a principled design of a predictive controller based on data. The framework starts with a parameter identification method based on the Expectation-Maximization algorithm, which incorporates pre-defined structural constraints. Additionally, we provide an asymptotically correct method to quantify uncertainty in parameter estimates. Next, we develop a strategy to synthesize robust dynamic output-feedback controllers tailored to the derived uncertainty characterization. Finally, we introduce a predictive control scheme that guarantees recursive feasibility and satisfaction of chance constraints. This framework marks a significant advancement in integrating data into robust and predictive control schemes. We demonstrate the efficacy of D2PC through a numerical example involving a $10$-dimensional spring-mass-damper system.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2ea52a361e1eddc6fae9770357307a43f124b006" target='_blank'>
              From Data to Predictive Control: A Framework for Stochastic Linear Systems with Output Measurements
              </a>
            </td>
          <td>
            Haldun Balim, Andrea Carron, M. Zeilinger, Johannes Kohler
          </td>
          <td>2024-07-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>36</td>
        </tr>

        <tr id="When modeling biological responses using Bayesian non-parametric regression, prior information may be available on the shape of the response in the form of non-linear function spaces that define the general shape of the response. To incorporate such information into the analysis, we develop a non-linear functional shrinkage (NLFS) approach that uniformly shrinks the non-parametric fitted function into a non-linear function space while allowing for fits outside of this space when the data suggest alternative shapes. This approach extends existing functional shrinkage approaches into linear subspaces to shrinkage into non-linear function spaces using a Taylor series expansion and corresponding updating of non-linear parameters. We demonstrate this general approach on the Hill model, a popular, biologically motivated model, and show that shrinkage into combined function spaces, i.e., where one has two or more non-linear functions a priori, is straightforward. We demonstrate this approach through synthetic and real data. Computational details on the underlying MCMC sampling are provided with data and analysis available in an online supplement.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/417f5830105bd8fb2b43c0bd3ec685ee87776362" target='_blank'>
              Bayesian non-linear subspace shrinkage using horseshoe priors
              </a>
            </td>
          <td>
            Julia Christin Duda, Matthew Wheeler
          </td>
          <td>2024-07-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Computer simulations based on partial differential equations (PDEs) describing physical phenomena, are widely used for analyzing the performance of high voltage insulation. Such simulation models require access to physical model parameters, which are often hard to obtain. The purpose of the present paper is to explore how Physics-Informed Neural Network (PINN) tailored for specific PDEs, can be used to extract relevant physical parameters from synthetic data. Electric potential or charge distributions in 1-dimensional coaxial and Cartesian domains were used as training data for PINN models. The following physical parameters were successfully extracted: (i) space charge profiles, (ii) mobilities of ions, and (iii) the radius of the inner electrode in the coaxial geometry. The impact of noisy training data on the accuracy was also studied for the different cases. The main finding is that PINN models can successfully be used to extract model parameters for electrical charge transport problems using synthetic data as input. This approach has large potential to strengthen the research on charge dynamics in gas, liquid, and solid insulation as well as other topics related to high voltage insulation systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f9d44af663a8e4f7e16a2dffe2c289b99726e746" target='_blank'>
              Usage of Physics-Informed Neural Network to Extract Physical Parameters From High Voltage Experiments
              </a>
            </td>
          <td>
            O. Hjortstam, C. Björnson, F. Ågren, T. Hammarström, Y. V. Serdyuk, C. Häger
          </td>
          <td>2024-06-30</td>
          <td>2024 IEEE 5th International Conference on Dielectrics (ICD)</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="We study the model reduction by moment matching problem for linear systems in a data-driven framework. We show that reduced-order models can be directly computed from data without knowledge of the structure of the signal generator or of its internal state. The reduced-order models thus obtained match the moments of the unknown underlying system asymptotically. Our construction provides a simple way to enforce additional constraints in the reduced-order model. We demonstrate the applicability of the results using data from a high-dimensional model of a building.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/83399652779edc533b785a20de6431d8d0060e66" target='_blank'>
              Data-Driven Model Reduction by Moment Matching for Linear Systems Driven by an Unknown Implicit Signal Generator
              </a>
            </td>
          <td>
            Debraj Bhattacharjee, Alessandro Astolfi
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="The Koopman operator framework is a promising direction of analysis and synthesis of systems with nonlinear dynamics based on (linear) Koopman operators. In this paper, we address the resolvent of a Koopman operator for a nonlinear autonomous discrete-time system, which we call the Koopman resolvent, and its identification problem. First, we show that for the nonlinear system with a scalar-valued output, the $z$- transform of the output is represented by the action of Koop-man resolvent. Second, we describe an identification method of the Koopman resolvent directly from time-series data of the output, in which we estimate parameters of the resolvent as well as poles and residues of the z-transform of the output. By combining the so-called frequency-domain Prony method with the Vandermonde-Cauchy form in the Dynamic Mode Decomposition (DMD), we propose the method which we call the frequency-domain DMD, in which all the unknowns can be estimated in the frequency domain.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/df691892a89d4f0c1e7b43d373b04818f75bcc0b" target='_blank'>
              Koopman Resolvents of Nonlinear Discrete-Time Systems: Formulation and Identification
              </a>
            </td>
          <td>
            Yoshihiko Susuki, A. Mauroy, Z. Drmač
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>20</td>
        </tr>

        <tr id="Studies show that artificial intelligence (AI) with embedded physics solvers has improved the accuracy of predictions on various physics problems, especially those associated with fluid dynamics. The crucial element in optimizing weight training for estimating flow fields within the AI network lies in the choice of the loss function. In addressing regression-type problems, particularly those involving the temporal evolution of flow fields, the mean square error (MSE) loss function is commonly employed at the current and single time step. However, an issue arises in existing methodologies that utilize MSE-based loss functions with single-time step information for predicting unsteady flow. Most of these approaches overlook the significance of incorporating the temporal history of the flow, a factor that cannot be disregarded in the context of numerical solvers. Hence, in this work, a physics-based AI (PbAI) method with higher-order loss functions is applied to unsteady scenarios, in particular to two distinct turbulent flows where a multitude of fine structures is present, namely, forced and decaying turbulence. Direct numerical simulations on uniform Cartesian grids are conducted to simulate these scenarios, generating two distinct datasets for training and inference. Each dataset comprises 32 randomly initialized conditions spanning 4, 848 time steps for each turbulent flow type. Five distinct models are devised, incorporating features such as rollouts from coarse numerical solvers and temporal considerations in the loss function calculation. The constructed PbAI models demonstrate consistent improvements in predictive performance over the entire temporal domain. These findings are further corroborated through vorticity correlation analyses. The empirical result demonstrates that the accuracy of the baseline case improves by up to 48% and 30% for forced and decaying turbulence, respectively. These results significantly underscore the importance of the temporal histories of flow in the loss function in enhancing predictive capabilities for complex and unsteady turbulent flows.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e6a508269bfb08f5c8c66413efa4d444da72838f" target='_blank'>
              Multi-Order Loss Functions For Accelerating Unsteady Flow Simulations with Physics-Based AI
              </a>
            </td>
          <td>
            Wei Xian Lim, Naheed Anjum Arafat, Wai Lee Chan, Adams Kong
          </td>
          <td>2024-06-25</td>
          <td>2024 IEEE Conference on Artificial Intelligence (CAI)</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Noise-induced synchronization is a pervasive phenomenon observed in a multitude of natural and engineering systems. Here, we devise a machine learning framework with the aim of devising noise controllers to achieve synchronization in diverse complex physical systems. We find the implicit energy regularization phenomenon of the formulated framework that engenders energy-saving artificial noise and we rigorously elucidate the underlying mechanism driving this phenomenon. We substantiate the practical feasibility and efficacy of this framework by testing it across various representative systems of physical and biological significance, each influenced by distinct constraints reflecting real-world scenarios.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ed8a0eb1d7b929532812639977db5fabe42eb620" target='_blank'>
              Machine-learning-coined noise induces energy-saving synchrony.
              </a>
            </td>
          <td>
            Jingdong Zhang, Luan Yang, Qunxi Zhu, Celso Grebogi, Wei Lin
          </td>
          <td>2024-07-01</td>
          <td>Physical review. E</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/dcaa44f8b49302272e5cab62125e644f57aefae1" target='_blank'>
              Characterizing the dynamics of multi-scale global high impact weather events
              </a>
            </td>
          <td>
            L. R. Frank, V. Galinsky, Zhenhai Zhang, F. M. Ralph
          </td>
          <td>2024-08-15</td>
          <td>Scientific Reports</td>
          <td>0</td>
          <td>13</td>
        </tr>

        <tr id="Beyond estimating parameters of interest from data, one of the key goals of statistical inference is to properly quantify uncertainty in these estimates. In Bayesian inference, this uncertainty is provided by the posterior distribution, the computation of which typically involves an intractable high-dimensional integral. Among available approximation methods, sampling-based approaches come with strong theoretical guarantees but scale poorly to large problems, while variational approaches scale well but offer few theoretical guarantees. In particular, variational methods are known to produce overconfident estimates of posterior uncertainty and are typically non-identifiable, with many latent variable configurations generating equivalent predictions. Here, we address these challenges by showing how diffusion-based models (DBMs), which have recently produced state-of-the-art performance in generative modeling tasks, can be repurposed for performing calibrated, identifiable Bayesian inference. By exploiting a previously established connection between the stochastic and probability flow ordinary differential equations (pfODEs) underlying DBMs, we derive a class of models, inflationary flows, that uniquely and deterministically map high-dimensional data to a lower-dimensional Gaussian distribution via ODE integration. This map is both invertible and neighborhood-preserving, with controllable numerical error, with the result that uncertainties in the data are correctly propagated to the latent space. We demonstrate how such maps can be learned via standard DBM training using a novel noise schedule and are effective at both preserving and reducing intrinsic data dimensionality. The result is a class of highly expressive generative models, uniquely defined on a low-dimensional latent space, that afford principled Bayesian inference.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/17907a21b0ea22f5a5548076e21700dea63c3931" target='_blank'>
              Inflationary Flows: Calibrated Bayesian Inference with Diffusion-Based Models
              </a>
            </td>
          <td>
            Daniela de Albuquerque, John Pearson
          </td>
          <td>2024-07-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="There is a growing interest in methods for detecting and interpreting changes in experimental time evolution data. Based on measured time series, the quantitative characterization of dynamical phase transitions at bifurcation points of the underlying chaotic systems is a notoriously difficult task. Building on prior theoretical studies that focus on the discontinuities at $q=1$ in the order-$q$ R\'enyi-entropy of the trajectory space, we measure the derivative of the spectrum. We derive within the general context of Markov processes a computationally efficient closed-form expression for this measure. We investigate its properties through well-known dynamical systems exploring its scope and limitations. The proposed mathematical instrument can serve as a predictor of dynamical phase transitions in time series.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/68dbc71449fe5142fd6c84de4af2b46f1f3412b9" target='_blank'>
              Measuring dynamical phase transitions in time series
              </a>
            </td>
          <td>
            Bulcs'u S'andor, Andr'as Rusu, K'aroly D'enes, M'aria Ercsey-Ravasz, Zs.I. L'az'ar
          </td>
          <td>2024-07-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Equations of State model relations between thermodynamic variables and are ubiquitous in scientific modelling, appearing in modern day applications ranging from Astrophysics to Climate Science. The three desired properties of a general Equation of State model are adherence to the Laws of Thermodynamics, incorporation of phase transitions, and multiscale accuracy. Analytic models that adhere to all three are hard to develop and cumbersome to work with, often resulting in sacrificing one of these elements for the sake of efficiency. In this work, two deep-learning methods are proposed that provably satisfy the first and second conditions on a large-enough region of thermodynamic variable space. The first is based on learning the generating function (thermodynamic potential) while the second is based on structure-preserving, symplectic neural networks, respectively allowing modifications near or on phase transition regions. They can be used either"from scratch"to learn a full Equation of State, or in conjunction with a pre-existing consistent model, functioning as a modification that better adheres to experimental data. We formulate the theory and provide several computational examples to justify both approaches, and highlight their advantages and shortcomings.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6515ce69075cc8fe93c06073e12dcf389d87c37b" target='_blank'>
              Neural Network Representations of Multiphase Equations of State
              </a>
            </td>
          <td>
            George A. Kevrekidis, Daniel A. Serino, Alexander Kaltenborn, J. Gammel, J. Burby, Marc L. Klasky
          </td>
          <td>2024-06-28</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>16</td>
        </tr>

        <tr id="Due to their flexibility and ease of use, Dynamical Movement Primitives (DMPs) are widely used in robotics applications and research. DMPs combine linear dynamical systems to achieve robustness to perturbations and adaptation to moving targets with non-linear function approximators to fit a wide range of demonstrated trajectories.We propose a novel DMP formulation with a generalized logistic function as a delayed goal system. This formulation inherently has low initial jerk, and generates the bell-shaped velocity profiles that are typical of human movement. As the novel formulation is more expressive, it is able to fit a wide range of human demonstrations well, also without a non-linear forcing term. We exploit this increased expressiveness by automating the fitting of the dynamical system parameters through opti-mization. Our experimental evaluation demonstrates that this optimization regularizes the forcing term, and improves the interpolation accuracy of parametric DMPs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/904213d0ea3643d20cba8b38f58690176de07076" target='_blank'>
              Fitting Parameters of Linear Dynamical Systems to Regularize Forcing Terms in Dynamical Movement Primitives
              </a>
            </td>
          <td>
            F. Stulp, Adrià Colomé, Carme Torras
          </td>
          <td>2024-05-13</td>
          <td>2024 IEEE International Conference on Robotics and Automation (ICRA)</td>
          <td>0</td>
          <td>32</td>
        </tr>

        <tr id="Inferring parameters of models of biochemical kinetics from single-cell data remains challenging because of the uncertainty arising from the intractability of the likelihood function of stochastic reaction networks. Such uncertainty falls beyond current error quantification measures, which focus on the effects of finite sample size and identifiability but lack theoretical guarantees when likelihood approximations are needed. Here, we propose an inference method for stochastic reaction networks with nonlinear and rational propensities at steady state that provides bounds on the parameters via convex optimisation over sets constrained by moment equations and moment matrices. Our approach takes observations from the stochastic reaction network and forms moment intervals, which are then used to constrain parameters through convex sets. The bounds on the parameters contain the true parameters under the condition that the moment intervals contain the true stationary moments, thus providing uncertainty quantification and error guarantees. Our approach does not need to predict moments and distributions for given parameters (i.e., it avoids solving or simulating the forward problem), and hence circumvents intractable likelihood computations or computationally expensive simulations. We demonstrate its use for uncertainty quantification, data integration and prediction of latent species statistics through synthetic data from common nonlinear biochemical models including the Schl\"ogl model, the toggle switch and post-transcriptional regulation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/de4b88b799eae872be620beb74ef0b6049b65d90" target='_blank'>
              Moment-based parameter inference with error guarantees for stochastic reaction networks
              </a>
            </td>
          <td>
            Zekai Li, Mauricio Barahona, Philipp Thomas
          </td>
          <td>2024-06-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="We introduce mochi_class, an extension of the Einstein-Boltzmann solver hi_class, designed to unlock the full phenomenological potential of Horndeski gravity. This extension allows for general input functions of time without the need for hard-coded parametrisations or covariant Lagrangians. By replacing the traditional $\alpha$-parametrisation with a set of stable basis functions, mochi_class ensures that the resulting effective theories are inherently free from gradient and ghost instabilities. Additionally, mochi_class features a quasi-static approximation implemented at the level of modified metric potentials, enhancing prediction accuracy, especially for models transitioning between a super- and sub-Compton regime. mochi_class can robustly handle a wide range of models without fine-tuning, and introduces a new approximation scheme that activates modifications to the standard cosmology deep in the matter-dominated era. Furthermore, it incorporates viability conditions on the equation of motion for the scalar field fluctuations, aiding in the identification of numerical instabilities. Through comprehensive validation against other Einstein-Boltzmann solvers, mochi_class demonstrates excellent performance and accuracy, broadening the scope of hi_class by facilitating the study of specific modified gravity models and enabling exploration of previously inaccessible regions of the Horndeski landscape. The code is publicly available at https://github.com/mcataneo/mochi_class_public">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/45c44ba92da169b2eb987805f3b6ad66528aeee4" target='_blank'>
              mochi_class: Modelling Optimisation to Compute Horndeski In class
              </a>
            </td>
          <td>
            Matteo Cataneo, Emilio Bellini
          </td>
          <td>2024-07-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Variational Physics-Informed Neural Networks often suffer from poor convergence when using stochastic gradient-descent-based optimizers. By introducing a Least Squares solver for the weights of the last layer of the neural network, we improve the convergence of the loss during training in most practical scenarios. This work analyzes the computational cost of the resulting hybrid Least-Squares/Gradient-Descent optimizer and explains how to implement it efficiently. In particular, we show that a traditional implementation based on backward-mode automatic differentiation leads to a prohibitively expensive algorithm. To remedy this, we propose using either forward-mode automatic differentiation or an ultraweak-type scheme that avoids the differentiation of trial functions in the discrete weak formulation. The proposed alternatives are up to 100 times faster than the traditional one, recovering a computational cost-per-iteration similar to that of a conventional gradient-descent-based optimizer alone. To support our analysis, we derive computational estimates and conduct numerical experiments in one- and two-dimensional problems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/17eda77a3cdea99de9f795c5bb3e5312a9f5c667" target='_blank'>
              Optimizing Variational Physics-Informed Neural Networks Using Least Squares
              </a>
            </td>
          <td>
            C. Uriarte, Manuela Bastidas, David Pardo, Jamie M. Taylor, Sergio Rojas
          </td>
          <td>2024-07-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="The research topic is: data-driven Bayesian state estimation with compressed measurement (BSCM) of model-free process, say for a (causal) tracking application. The dimension of the temporal measurement vector is lower than the dimension of the temporal state vector to be estimated. Hence the state estimation problem is an underdetermined inverse problem. The state-space-model (SSM) of the underlying dynamical process is assumed to be unknown and hence, we use the terminology 'model-free process'. In absence of the SSM, we can not employ traditional model-driven methods like Kalman Filter (KF) and Particle Filter (PF) and instead require data-driven methods. We first experimentally show that two existing unsupervised learning-based data-driven methods fail to address the BSCM problem for model-free process; they are data-driven nonlinear state estimation (DANSE) method and deep Markov model (DMM) method. The unsupervised learning uses unlabelled data comprised of only noisy measurements. While DANSE provides a good predictive performance to model the temporal measurement data as time-series, its unsupervised learning lacks a regularization for state estimation. We then investigate use of a semi-supervised learning approach, and develop a semi-supervised learning-based DANSE method, referred to as SemiDANSE. In the semi-supervised learning, we use a limited amount of labelled data along-with a large amount of unlabelled data, and that helps to bring the desired regularization for BSCM problem in the absence of SSM. The labelled data means pairwise measurement-and-state data. Using three chaotic dynamical systems (or processes) with nonlinear SSMs as benchmark, we show that the data-driven SemiDANSE provides competitive performance for BSCM against three SSM-informed methods - a hybrid method called KalmanNet, and two traditional model-driven methods called extended KF and unscented KF.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f2671168e70fb8ea79bbef366bd1d59fc9ae9415" target='_blank'>
              Data-driven Bayesian State Estimation with Compressed Measurement of Model-free Process using Semi-supervised Learning
              </a>
            </td>
          <td>
            Anubhab Ghosh, Y. Eldar, Saikat Chatterjee
          </td>
          <td>2024-07-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>27</td>
        </tr>

        <tr id="We study the problem of estimating the states of a linear system based on measured data. We investigate the problem in both deterministic and stochastic settings. In the deterministic case, we develop data-driven conditions under which we can reconstruct state trajectories uniquely. Also, we discuss the case in which we have some missing data in the given input/output measurements. In the stochastic case, we develop a Kalman filter-like algorithm to recursively estimate both states and outputs. Finally, we consider a multi-input multi-output system to elucidate the developed results.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/344c27f38393d70906627a195cc65ea2636e5a14" target='_blank'>
              Data-Driven State Estimation for Linear Systems
              </a>
            </td>
          <td>
            Vikas Kumar Mishra, S. Hiremath, N. Bajçinca
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>15</td>
        </tr>

        <tr id="High-precision control for nonlinear systems is impeded by the low-fidelity dynamical model and external disturbance. Especially, the intricate coupling between internal uncertainty and external disturbance is usually difficult to be modeled explicitly. Here we show an effective and convergent algorithm enabling accurate estimation of the coupled disturbance via combining control and learning philosophies. Specifically, by resorting to Chebyshev series expansion, the coupled disturbance is firstly decomposed into an unknown parameter matrix and two known structures depending on system state and external disturbance respectively. A Regularized Least Squares (RLS) algorithm is subsequently formalized to learn the parameter matrix by using historical time-series data. Finally, a higher-order disturbance observer (HODO) is developed to achieve a high-precision estimation of the coupled disturbance by utilizing the learned portion. The efficiency of the proposed algorithm is evaluated through extensive simulations. We believe this work can offer a new option to merge learning schemes into the control framework for addressing existing intractable control problems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2c2b582f6ad335402a40cb9dffeaea1baf4781dd" target='_blank'>
              Disturbance Observer for Estimating Coupled Disturbances
              </a>
            </td>
          <td>
            Jindou Jia, Yuhang Liu, Kexin Guo, Xiang Yu, Lihua Xie, Lei Guo
          </td>
          <td>2024-07-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="Data driven system identification is the technique for learning models from input/output data. To increase the robustness of the model estimation, prior knowledge can be incorporated, the so-called gray-box identification. In finite impulse response (FIR) models, prior knowledge of the process under investigation can be introduced by regularization. In the regularization term basic impulse response characteristics such as smoothness and exponentially decaying behavior can be incorporated. For estimation of time-delay systems, the novel impulse response and time-delay preserving (IRDP) regularization matrix is proposed. In this contribution this method is extended to the estimation of multiple input single output (MISO) processes and is compared to other state-of-the-art approaches. A linear process with four inputs and different input dynamics and time-delays is investigated. The focus of the evaluation is placed on model quality, time-delay estimation, and computation time. The simulation results point out the superiority of the novel regularization approach in comparison to state-of-the-art methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a8735d69bbb91950534f1fe2742f48352fd17202" target='_blank'>
              Handling of Time Delays in MISO Processes with Regularized Finite Impulse Response Models
              </a>
            </td>
          <td>
            Christopher Illg, T. Kösters, Oliver Nelles
          </td>
          <td>2024-06-25</td>
          <td>2024 European Control Conference (ECC)</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Many application areas rely on models that can be readily simulated but lack a closed-form likelihood, or an accurate approximation under arbitrary parameter values. Existing parameter estimation approaches in this setting are generally approximate. Recent work on using neural network models to reconstruct the mapping from the data space to the parameters from a set of synthetic parameter-data pairs suffers from the curse of dimensionality, resulting in inaccurate estimation as the data size grows. We propose a dimension-reduced approach to likelihood-free estimation which combines the ideas of reconstruction map estimation with dimension-reduction approaches based on subject-specific knowledge. We examine the properties of reconstruction map estimation with and without dimension reduction and explore the trade-off between approximation error due to information loss from reducing the data dimension and approximation error. Numerical examples show that the proposed approach compares favorably with reconstruction map estimation, approximate Bayesian computation, and synthetic likelihood estimation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e928447f6c322a7beac72466a09947bc31240ec4" target='_blank'>
              Dimension-reduced Reconstruction Map Learning for Parameter Estimation in Likelihood-Free Inference Problems
              </a>
            </td>
          <td>
            Rui Zhang, O. Chkrebtii, Dongbin Xiu
          </td>
          <td>2024-07-19</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id="An important class of dynamical systems with several practical applications is linear systems with quadratic outputs. These models have the same state equation as standard linear time-invariant systems but differ in their output equations, which are nonlinear quadratic functions of the system states. When dealing with models of exceptionally high order, the computational demands for simulation and analysis can become overwhelming. In such cases, model order reduction proves to be a useful technique, as it allows for constructing a reduced-order model that accurately represents the essential characteristics of the original high-order system while significantly simplifying its complexity. In time-limited model order reduction, the main goal is to maintain the output response of the original system within a specific time range in the reduced-order model. To assess the error within this time interval, a mathematical expression for the time-limited $\mathcal{H}_2$-norm is derived in this paper. This norm acts as a measure of the accuracy of the reduced-order model within the specified time range. Subsequently, the necessary conditions for achieving a local optimum of the time-limited $\mathcal{H}_2$ norm error are derived. The inherent inability to satisfy these optimality conditions within the Petrov-Galerkin projection framework is also discussed. After that, a stationary point iteration algorithm based on the optimality conditions and Petrov-Galerkin projection is proposed. Upon convergence, this algorithm fulfills three of the four optimality conditions. To demonstrate the effectiveness of the proposed algorithm, a numerical example is provided that showcases its ability to effectively approximate the original high-order model within the desired time interval.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/453cc6fa0226bcae491e1382228e2ce965de279b" target='_blank'>
              Time-limited H2-optimal Model Order Reduction of Linear Systems with Quadratic Outputs
              </a>
            </td>
          <td>
            Umair Zulfiqar, Zhi-Hua Xiao, Qiuyan Song, Mohammad Monir Uddin, Victor Sreeram
          </td>
          <td>2024-08-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="Within the family of explainable machine-learning, we present Fredholm neural networks (Fredholm NNs), deep neural networks (DNNs) which replicate fixed point iterations for the solution of linear and nonlinear Fredholm Integral Equations (FIE) of the second kind. Applications of FIEs include the solution of ordinary, as well as partial differential equations (ODEs, PDEs) and many more. We first prove that Fredholm NNs provide accurate solutions. We then provide insight into the values of the hyperparameters and trainable/explainable weights and biases of the DNN, by directly connecting their values to the underlying mathematical theory. For our illustrations, we use Fredholm NNs to solve both linear and nonlinear problems, including elliptic PDEs and boundary value problems. We show that the proposed scheme achieves significant numerical approximation accuracy across both the domain and boundary. The proposed methodology provides insight into the connection between neural networks and classical numerical methods, and we posit that it can have applications in fields such as Uncertainty Quantification (UQ) and explainable artificial intelligence (XAI). Thus, we believe that it will trigger further advances in the intersection between scientific machine learning and numerical analysis.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/82492de625c8a8250784a5764f6391b1b8426bbb" target='_blank'>
              Fredholm Neural Networks
              </a>
            </td>
          <td>
            Kyriakos Georgiou, Constantinos Siettos, A. Yannacopoulos
          </td>
          <td>2024-08-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="We study nonequilibrium quantum dynamics of spin chains by employing principal component analysis (PCA) on data sets of wave function snapshots and examine how information propagates within these data sets. The quantities we employ are derived from the spectrum of the sample second moment matrix, built directly from data sets. Our investigations on several interacting spin chains featuring distinct spin or energy transport reveal that the growth of data information spreading follows the same dynamical exponents as that of the underlying quantum transport of spin or energy. Specifically, our approach enables an easy, data-driven, and importantly interpretable diagnostic to track energy transport with a limited number of samples, which is usually challenging without any assumption on the Hamiltonian form. These observations are obtained at a modest finite size and evolution time, which aligns with experimental and numerical constraints. Our framework directly applies to experimental quantum simulator data sets of dynamics in higher-dimensional systems, where classical simulation methods usually face significant limitations and apply equally to both near- and far-from-equilibrium quenches.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/94b4a5b7b344b91f9543dbd6c577fd548f273348" target='_blank'>
              Diagnosing quantum transport from wave function snapshots
              </a>
            </td>
          <td>
            D. S. Bhakuni, Roberto Verdel, Cristiano Muzzi, Riccardo Andreoni, Monika Aidelsburger, Marcello Dalmonte
          </td>
          <td>2024-07-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="This work proposes a data‐driven state observation algorithm for nonlinear dynamical systems, when the true state trajectory is not measurable and hence the states information needs to be reconstructed from input and output measurements. Such a reduction is formed by kernel canonical correlation analysis (KCCA), which (i) implicitly maps the available input–output data into a higher‐dimensional feature space, namely the reproducing kernel Hilbert space (RKHS); (ii) finds a projection of the past input–output data and a projection of the future input–output data with maximal correlation; and (iii) identifies the projected inputs and outputs, namely the canonical variates, as the observed states. We adopt a least squares support vector machine (LS‐SVM) formulation for KCCA, which imposes regularization on the vectors that specify the projections and is amenable to convex optimization. We prove theoretically that, based on the statistical consistency of KCCA, the observed states determined by the proposed state observer has a guaranteed correlativity with the actual states (when properly transformed). Furthermore, such observed states, when supplemented with the information of succeeding inputs, can be used to predict the succeeding outputs with guaranteed upper bound on the prediction error. Case studies are performed on two numerical examples and an exothermic continuously stirred tank reactor (CSTR).">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/afc53bd0e86a21cb48431210cc83dc9943ac1742" target='_blank'>
              Data‐driven nonlinear state observation for controlled systems: A kernel method and its analysis
              </a>
            </td>
          <td>
            Moritz Woelk, Wentao Tang
          </td>
          <td>2024-07-08</td>
          <td>The Canadian Journal of Chemical Engineering</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="To understand and control the dynamics of coupled oscillators, it is important to reveal the structure of the interaction network from observed data. While various techniques have been developed for inferring the network of asynchronous systems, it remains challenging to infer the network of synchronized oscillators without external stimulations. In this study, we develop a method for non-invasively inferring the network of synchronized and/or de-synchronized oscillators. An approach to network inference would be to fit the data to a set of differential equations describing the dynamics of phase oscillators. However, we show that this method fails to infer the true network due to the problems that arise when we use short-time phase differences. Therefore, we propose a method based on the circle map, which describes the phase change in one oscillatory cycle. We demonstrate the efficacy of the proposed method through the successful inference of the network structure from simulated data of limit cycle oscillator models. Our method provides a unified and concise framework for network estimation for a wide class of oscillator systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a85617c5e51b81ee7f45457c35d92af54f040aed" target='_blank'>
              Network inference from oscillatory signals based on circle map
              </a>
            </td>
          <td>
            Akari Matsuki, Hiroshi Kori, Ryota Kobayashi
          </td>
          <td>2024-07-10</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>2</td>
        </tr>

        <tr id="We propose a meta-learning method for modeling Hamiltonian dynamics from a limited number of data. Although Hamiltonian neural networks have been successfully used for modeling dynamics that obey the energy conservation law, they require many data to achieve high performance. The proposed method meta-learns our neural network-based model using datasets in various dynamical systems, such that our model can predict vector fields of unseen systems. In our model, a system representation is inferred from given small data using an encoder network. Then, the system-specific vector field is predicted by modeling the Hamiltonian using a Gaussian process (GP) with neural network-based mean and kernel functions that depend on the inferred system representation. This GP-based Hamiltonian allows us to analytically obtain predictions that are adapted to small data while imposing the constraint of the conservation law. The neural networks are shared across systems, which enables us to learn knowledge from multiple systems, and use it for unseen systems. In our experiments, we demonstrate that the proposed method outperforms existing methods for predicting dynamics from a small number of observations in target systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/37ac3a5b751bd136ecb4369b5f0c68f06bf4a91f" target='_blank'>
              Symplectic Neural Gaussian Processes for Meta-learning Hamiltonian Dynamics
              </a>
            </td>
          <td>
            Tomoharu Iwata, Yusuke Tanaka
          </td>
          <td>2024-08-01</td>
          <td>Proceedings of the Thirty-ThirdInternational Joint Conference on Artificial Intelligence</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Gaussian Processes (GPs) and Linear Dynamical Systems (LDSs) are essential time series and dynamic system modeling tools. GPs can handle complex, nonlinear dynamics but are computationally demanding, while LDSs offer efficient computation but lack the expressive power of GPs. To combine their benefits, we introduce a universal method that allows an LDS to mirror stationary temporal GPs. This state-space representation, known as the Markovian Gaussian Process (Markovian GP), leverages the flexibility of kernel functions while maintaining efficient linear computation. Unlike existing GP-LDS conversion methods, which require separability for most multi-output kernels, our approach works universally for single- and multi-output stationary temporal kernels. We evaluate our method by computing covariance, performing regression tasks, and applying it to a neuroscience application, demonstrating that our method provides an accurate state-space representation for stationary temporal GPs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f45b6ab8336d143d48c626e23d36a99a22707758" target='_blank'>
              Markovian Gaussian Process: A Universal State-Space Representation for Stationary Temporal Gaussian Process
              </a>
            </td>
          <td>
            Weihan Li, Yule Wang, Chengrui Li, Anqi Wu
          </td>
          <td>2024-06-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Localized vibrations, arising from nonlinearities or symmetry breaking, pose a challenge in engineering, as the resulting high-amplitude vibrations may result in component failure due to fatigue. During operation, the emergence of localization is difficult to predict, partly because of changing parameters over the life cycle of a system. This work proposes a novel, network-based approach to predicting an imminent localized vibration. Synthetic measurement data is used to generate a functional network, which captures the dynamic interplay of the machine parts, complementary to their geometric coupling. Analysis of these functional networks reveals an impending localized vibration and its location. The method is demonstrated using a model system for a bladed disk, a ring composed of coupled nonlinear Duffing oscillators. Results indicate that the proposed method is robust against small parameter uncertainties, added measurement noise, and the length of the measurement data samples. The source code for this work is available.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/afd5a5cef7da7db6985f9d39e5bc1778cb55539f" target='_blank'>
              Exploring localization in nonlinear oscillator systems through network-based predictions
              </a>
            </td>
          <td>
            Charlotte Geier, Norbert Hoffmann . Hamburg University of Technology, I. -. London
          </td>
          <td>2024-07-07</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>30</td>
        </tr>

        <tr id="In this study, we delve into the Structured State Space Model (S4), Change Point Detection methodologies, and the Switching Non-linear Dynamics System (SNLDS). Our central proposition is an enhanced inference technique and long-range dependency method for SNLDS. The cornerstone of our approach is the fusion of S4 and SNLDS, leveraging the strengths of both models to effectively address the intricacies of long-range dependencies in switching time series. Through rigorous testing, we demonstrate that our proposed methodology adeptly segments and reproduces long-range dependencies in both the 1-D Lorenz dataset and the 2-D bouncing ball dataset. Notably, our integrated approach outperforms the standalone SNLDS in these tasks.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/737fccae30a52b719925aa3bdefbccf7758f66f5" target='_blank'>
              Long Range Switching Time Series Prediction via State Space Model
              </a>
            </td>
          <td>
            Jiaming Zhang, Yang Ding, Yunfeng Gao
          </td>
          <td>2024-07-27</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The probability that a configuration of a physical system reacts, or transitions from one metastable state to another, is quantified by the committor function. This function contains richly detailed mechanistic information about transition pathways, but a full parameterization of the committor requires building representing a high-dimensional function, a generically challenging task. Recent efforts to leverage neural networks as a means to solve high-dimensional partial differential equations, often called"physics-informed"machine learning, have brought the committor into computational reach. Here, we build on the semigroup approach to learning the committor and assess its utility for predicting dynamical quantities such as transition rates. We show that a careful reframing of the objective function and improved adaptive sampling strategies provide highly accurate representations of the committor. Furthermore, by directly applying the Hill relation, we show that these committors provide accurate transition rates for molecular system.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/61781a644a9abeb378998d8505d6add714bb238b" target='_blank'>
              Committor guided estimates of molecular transition rates
              </a>
            </td>
          <td>
            Andrew R. Mitchell, Grant M. Rotskoff
          </td>
          <td>2024-08-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>24</td>
        </tr>

        <tr id="Macroscopic features of dynamical systems such as almost-invariant sets and coherent sets provide crucial high-level information on how the dynamics organises phase space. We introduce a method to identify time-parameterised families of almost-invariant sets in time-dependent dynamical systems, as well as the families' emergence and disappearance. In contrast to coherent sets, which may freely move about in phase space over time, our technique focuses on families of metastable sets that are quasi-stationary in space. Our straightforward approach extends successful transfer operator methods for almost-invariant sets to time-dependent dynamics and utilises the Ulam scheme for the generator of the transfer operator on a time-expanded domain. The new methodology is illustrated with an idealised fluid flow and with atmospheric velocity data. We identify atmospheric blocking events in the 2003 European heatwave and compare our technique to existing geophysical methods of blocking diagnosis.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/85cdef684e76e594fd24e0e2863fe622d0a8314d" target='_blank'>
              Identifying the onset and decay of quasi-stationary families of almost-invariant sets with an application to atmospheric blocking events
              </a>
            </td>
          <td>
            Aleksandar Badza, Gary Froyland School of Mathematics, Statistics Unsw Sydney Nsw Australia
          </td>
          <td>2024-07-09</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="We propose kernel-based approaches for the construction of a single-step and multi-step predictor of the velocity form of nonlinear (NL) systems, which describes the time-difference dynamics of the corresponding NL system and admits a highly structured representation. The predictors in turn allow to formulate completely data-driven representations of the velocity form. The kernel-based formulation that we derive, inherently respects the structured quasi-linear and specific time-dependent relationship of the velocity form. This results in an efficient multi-step predictor for the velocity form and hence for nonlinear systems. Moreover, by using the velocity form, our methods open the door for data-driven behavioral analysis and control of nonlinear systems with global stability and performance guarantees.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6b4583a2f8fb5852420ac4a8c1d46a5e7cd4adf9" target='_blank'>
              Kernel-based multi-step predictors for data-driven analysis and control of nonlinear systems through the velocity form
              </a>
            </td>
          <td>
            C. Verhoek, Roland T'oth
          </td>
          <td>2024-08-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Multi-fidelity models are becoming more prevalent in engineering, particularly in aerospace, as they combine both the computational efficiency of low-fidelity models with the high accuracy of higher-fidelity simulations. Various state-of-the-art techniques exist for fusing data from different fidelity sources, including Co-Kriging and transfer learning in neural networks. This paper aims to implement a multi-fidelity Bayesian neural network model that applies transfer learning to fuse data generated by models at different fidelities. Bayesian neural networks use probability distributions over network weights, enabling them to provide predictions along with estimates of their confidence. This approach harnesses the predictive and data fusion capabilities of neural networks while also quantifying uncertainty. The results demonstrate that the multi-fidelity Bayesian model outperforms the state-of-the-art Co-Kriging in terms of overall accuracy and robustness on unseen data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ed6014a35e0347af074b9acce63c1ec0c20d68aa" target='_blank'>
              Multi-Fidelity Bayesian Neural Network for Uncertainty Quantification in Transonic Aerodynamic Loads
              </a>
            </td>
          <td>
            Andrea Vaiuso, Gabriele Immordino, Marcello Righi, A. Ronch
          </td>
          <td>2024-07-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>22</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1e47886cf1fed1baf5e2839789863c0355296cdc" target='_blank'>
              The Distance Between: An Algorithmic Approach to Comparing Stochastic Models to Time-Series Data
              </a>
            </td>
          <td>
            Brock D. Sherlock, Marko A. A. Boon, Maria Vlasiou, A. Coster
          </td>
          <td>2024-07-26</td>
          <td>Bulletin of Mathematical Biology</td>
          <td>0</td>
          <td>25</td>
        </tr>

        <tr id="In this paper, we study efficient approximate sampling for probability distributions known up to normalization constants. We specifically focus on a problem class arising in Bayesian inference for large-scale inverse problems in science and engineering applications. The computational challenges we address with the proposed methodology are: (i) the need for repeated evaluations of expensive forward models; (ii) the potential existence of multiple modes; and (iii) the fact that gradient of, or adjoint solver for, the forward model might not be feasible. While existing Bayesian inference methods meet some of these challenges individually, we propose a framework that tackles all three systematically. Our approach builds upon the Fisher-Rao gradient flow in probability space, yielding a dynamical system for probability densities that converges towards the target distribution at a uniform exponential rate. This rapid convergence is advantageous for the computational burden outlined in (i). We apply Gaussian mixture approximations with operator splitting techniques to simulate the flow numerically; the resulting approximation can capture multiple modes thus addressing (ii). Furthermore, we employ the Kalman methodology to facilitate a derivative-free update of these Gaussian components and their respective weights, addressing the issue in (iii). The proposed methodology results in an efficient derivative-free sampler flexible enough to handle multi-modal distributions: Gaussian Mixture Kalman Inversion (GMKI). The effectiveness of GMKI is demonstrated both theoretically and numerically in several experiments with multimodal target distributions, including proof-of-concept and two-dimensional examples, as well as a large-scale application: recovering the Navier-Stokes initial condition from solution data at positive times.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0d77575c529cb455ba8ac5289fe0e14615a7c4f1" target='_blank'>
              Efficient, Multimodal, and Derivative-Free Bayesian Inference With Fisher-Rao Gradient Flows
              </a>
            </td>
          <td>
            Yifan Chen, Daniel Zhengyu Huang, Jiaoyang Huang, Sebastian Reich, Andrew M. Stuart
          </td>
          <td>2024-06-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id="Many real-world applications demand accurate and fast predictions, as well as reliable uncertainty estimates. However, quantifying uncertainty on high-dimensional predictions is still a severely under-invested problem, especially when input-output relationships are non-linear. To handle this problem, the present work introduces an innovative approach that combines autoencoder deep neural networks with the probabilistic regression capabilities of Gaussian processes. The autoencoder provides a low-dimensional representation of the solution space, while the Gaussian process is a Bayesian method that provides a probabilistic mapping between the low-dimensional inputs and outputs. We validate the proposed framework for its application to surrogate modeling of non-linear finite element simulations. Our findings highlight that the proposed framework is computationally efficient as well as accurate in predicting non-linear deformations of solid bodies subjected to external forces, all the while providing insightful uncertainty assessments.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c5ebe3e35ead48c1cec6afd16f55a4873eabdbd1" target='_blank'>
              Gaussian process regression + deep neural network autoencoder for probabilistic surrogate modeling in nonlinear mechanics of solids
              </a>
            </td>
          <td>
            Saurabh Deshpande, Hussein Rappel, Mark Hobbs, Stéphane P. A. Bordas, Jakub Lengiewicz
          </td>
          <td>2024-07-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="A surrogate model approximates the outputs of a solver of Partial Differential Equations (PDEs) with a low computational cost. In this article, we propose a method to build learning-based surrogates in the context of parameterized PDEs, which are PDEs that depend on a set of parameters but are also temporal and spatial processes. Our contribution is a method hybridizing the Proper Orthogonal Decomposition and several Support Vector Regression machines. This method is conceived to work in real-time, thus aimed for being used in the context of digital twins, where a user can perform an interactive analysis of results based on the proposed surrogate. We present promising results on two use cases concerning electrical machines. These use cases are not toy examples but are produced an industrial computational code, they use meshes representing non-trivial geometries and contain non-linearities.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e63bc34c8490fd304b6cbb27c3dc5e2405d617e2" target='_blank'>
              A Fast Learning-Based Surrogate of Electrical Machines using a Reduced Basis
              </a>
            </td>
          <td>
            Alejandro Rib'es, Nawfal Benchekroun, Théo Delagnes
          </td>
          <td>2024-06-27</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Piecewise regression is a versatile approach used in various disciplines to approximate complex functions from limited, potentially noisy data points. In control, piecewise regression is, e.g., used to approximate the optimal control law of model predictive control (MPC), the optimal value function, or unknown system dynamics. Neural networks are a common choice to solve the piecewise regression problem. However, due to their nonlinear structure, training is often based on gradient-based methods, which may fail to find a global optimum or even a solution that leads to a small approximation error. To overcome this problem and to find a global optimal solution, methods based on mixed-integer programming (MIP) can be used. However, the known MIP-based methods are either limited to a special class of functions, e.g., convex piecewise affine functions, or they lead to complex approximations in terms of the number of regions of the piecewise defined function. Both complicate a usage in the framework of control. We propose a new MIP-based method that is not restricted to a particular class of piecewise defined functions and leads to functions that are fast to evaluate and can be used within an optimization problem, making them well suited for use in control.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3495f4f53381c1f71128c6163d253c8da3ee307f" target='_blank'>
              Piecewise regression via mixed-integer programming for MPC
              </a>
            </td>
          <td>
            Dieter Teichrib, M. S. Darup
          </td>
          <td>2024-07-09</td>
          <td>ArXiv, DBLP</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="Data assimilation has become a crucial technique aiming to combine physical models with observational data to estimate state variables. Traditional assimilation algorithms often face challenges of high nonlinearity brought by both the physical and observational models. In this work, we propose a novel data-driven assimilation algorithm based on generative models to address such concerns. Our State-Observation Augmented Diffusion (SOAD) model is designed to handle nonlinear physical and observational models more effectively. The marginal posterior associated with SOAD has been derived and then proved to match the real posterior under mild assumptions, which shows theoretical superiority over previous score-based assimilation works. Experimental results also indicate that our SOAD model may offer improved accuracy over existing data-driven methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/06992e29f3f9438fb0b625f488e2c927eb32806a" target='_blank'>
              State-observation augmented diffusion model for nonlinear assimilation
              </a>
            </td>
          <td>
            Zhuoyuan Li, Bin Dong, Pingwen Zhang
          </td>
          <td>2024-07-31</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="A novel combination of physics-based and data-driven post-processing techniques is proposed to extract acoustic-related shear-layer perturbation responses directly from spatio-temporally resolved schlieren video. The physics-based component is derived from a momentum potential theory extension that extracts irrotational (acoustic and thermal) information from density gradients embedded in schlieren pixel intensities. For the unheated shear layer, the method spotlights acoustic structures and tones otherwise hidden. The filtered data is then subjected to a data-driven Dynamic Mode Decomposition Reduced Order Model (DMD-ROM), which provides the response to forced perturbations. This method applies a learned linear model to isolate and quantify growth rates of acoustic phenomena suited for efficient parametric studies. A shear-layer comprised of two streams at Mach 2.461 and 0.175, corresponding to a convective Mach number 0.88 and containing shocks, is adopted for illustration. The overall perturbation response is first obtained using an impulse forcing in the wall normal direction of the splitter plate, extending in both subsonic and supersonic streams. Subsequently, impulse and harmonic forcings are independently applied in a local pixel-by-pixel manner for a precise receptivity study. The acoustic response shows a convective wavepacket and an acoustic burst from the splitter plate. The interaction with the primary shock and associated wave dispersion emits a second, slower, acoustic wave. Harmonic forcing indicates higher frequency-dependent sensitivity in the supersonic stream, with the most sensitive location near the outer boundary layer region. Excitation here yields an order of magnitude larger acoustic response compared to disturbances in the subsonic stream. Some receptive forcing inputs do not generate significant acoustic waves, which may guide excitation with low noise impact.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b8906440f571ab8811f84b816c5b972b3fb1cd49" target='_blank'>
              Shear-Layer Perturbation Responses from Time-Resolved Schlieren Data
              </a>
            </td>
          <td>
            Spencer L. Stahl, Chandan Kumar, D. Gaitonde
          </td>
          <td>2024-07-07</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>42</td>
        </tr>

        <tr id="The treatment of Hall-effect thrusters as nonlinear, dynamical systems has emerged as a new perspective to understand and analyze data acquired from the thrusters. The acquisition of high-speed data that can resolve the characteristic high-frequency oscillations of these thruster enables additional levels of classification in these thrusters. Notably, these signals may serve as unique indicators for the full state of the system that can aid digital representations of thrusters and predictions of thruster dynamics. In this work, a Reservoir Computing framework is explored to build surrogate models from experimental time-series measurements of a Hall-effect thruster. Such a framework has shown immense promise for predicting the behavior of low-dimensional yet chaotic dynamical systems. In particular, the surrogates created by the Reservoir Computing framework are capable of both predicting the observed behavior of the thruster and estimating the values of certain measurements from others, known as inference.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/408d323572dab3c6a6dc96e645703d0f78eee449" target='_blank'>
              Time-Resolved Data-Driven Surrogates of Hall-effect Thrusters
              </a>
            </td>
          <td>
            Adrian S. Wong, Christine M. Greve, Daniel Q. Eckhardt
          </td>
          <td>2024-08-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="This article focuses on drawing computationally-efficient predictive inference from Gaussian process (GP) regressions with a large number of features when the response is conditionally independent of the features given the projection to a noisy low dimensional manifold. Bayesian estimation of the regression relationship using Markov Chain Monte Carlo and subsequent predictive inference is computationally prohibitive and may lead to inferential inaccuracies since accurate variable selection is essentially impossible in such high-dimensional GP regressions. As an alternative, this article proposes a strategy to sketch the high-dimensional feature vector with a carefully constructed sketching matrix, before fitting a GP with the scalar outcome and the sketched feature vector to draw predictive inference. The analysis is performed in parallel with many different sketching matrices and smoothing parameters in different processors, and the predictive inferences are combined using Bayesian predictive stacking. Since posterior predictive distribution in each processor is analytically tractable, the algorithm allows bypassing the robustness issues due to convergence and mixing of MCMC chains, leading to fast implementation with very large number of features. Simulation studies show superior performance of the proposed approach with a wide variety of competitors. The approach outperforms competitors in drawing point prediction with predictive uncertainties of outdoor air pollution from satellite images.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/81e2aa3ab7c3f8c3faca1f0ea9bad83384b3678d" target='_blank'>
              Data Sketching and Stacking: A Confluence of Two Strategies for Predictive Inference in Gaussian Process Regressions with High-Dimensional Features
              </a>
            </td>
          <td>
            Samuel Gailliot, Rajarshi Guhaniyogi, Roger D. Peng
          </td>
          <td>2024-06-26</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>15</td>
        </tr>

        <tr id="Latent dynamical systems have been widely used to characterize the dynamics of neural population activity in the brain. However, these models typically ignore the fact that the brain contains multiple cell types. This limits their ability to capture the functional roles of distinct cell classes, or to accurately predict the effects of cell-specific optogenetic perturbations on neural activity or behavior. To overcome these limitations, we introduce the “cell-type dynamical systems” (CTDS) model. This model extends latent linear dynamical systems to contain distinct latent variables for each cell class, with biologically inspired constraints on both dynamics and emissions. To illustrate our approach, we consider neural recordings with distinct excitatory (E) and inhibitory (I) populations. The CTDS model defines separate latents for E and I cells, and constrains the dynamics so that E (I) latents have a strictly positive (negative) effects on other latents. We applied CTDS to recordings from rat frontal orienting fields (FOF) and anterior dorsal striatum (ADS) during an auditory decision-making task. The model achieved higher accuracy than a standard linear dynamical system (LDS), and revealed that both E and I latents could be used to decode the animal’s choice, showing that choice-related information is not restricted to a single cell class. We also performed in-silico optogenetic perturbation experiments in the FOF and ADS, and found that CTDS was able to replicate the causal effects of different perturbations on behavior, whereas a standard LDS model—which lacks the ability to capture cell-specific perturbations—did not. Crucially, our model allowed us to understand the effects of these perturbations by revealing the dynamics of different cell-specific latents. Finally, CTDS can also be used to identify cell types for neurons whose class labels are unknown in electrophysiological recordings. These results illustrate the power of the CTDS model to provide more accurate and more biologically interpretable descriptions of neural population dynamics and their relationship to behavior.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/31c1cd3d2f0ffab7d6fe212ee7ca7fdd655d8dfa" target='_blank'>
              Disentangling the Roles of Distinct Cell Classes with Cell-Type Dynamical Systems
              </a>
            </td>
          <td>
            Aditi Jha, Diksha Gupta, C. Brody, Jonathan W. Pillow
          </td>
          <td>2024-07-11</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>45</td>
        </tr>

        <tr id="Time-varying optimization problems are central to many engineering applications, where performance metrics and system constraints evolve dynamically with time. A number of algorithms have been proposed in recent years to solve such problems; a common feature of all these methods is that they implicitly require precise knowledge of the temporal variability of the solutions in order to exactly track the optimizers. In this paper, we seek to lift these stringent assumptions. Our main result is a fundamental characterization, showing that an algorithm can track an optimal trajectory if and only if it contains a model of the temporal variability of the problem. We refer to this concept to as the internal model principle of time-varying optimization. By recasting the optimization objective as a nonlinear regulation problem and using tools from center manifold theory, we provide necessary and sufficient conditions both for an optimization algorithm to achieve exact asymptotic tracking and for such an algorithm to exist. We illustrate the applicability of the approach numerically on both synthetic problems as well as practical problems in transportation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8aee1c4d1d9bfe7e68a03ee2eb770d81f18d112d" target='_blank'>
              The Internal Model Principle of Time-Varying Optimization
              </a>
            </td>
          <td>
            G. Bianchin, Bryan Van Scoy
          </td>
          <td>2024-07-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>11</td>
        </tr>

        <tr id="We apply two data assimilation (DA) methods, a smoother and a filter, and a model-free machine learning (ML) shallow network to forecast two weakly turbulent systems. We analyse the effect of the spatial sparsity of observations on accuracy of the predictions obtained from these data-driven methods. Based on the results, we divide the spatial sparsity levels in three zones. First is the good-predictions zone in which both DA and ML methods work. We find that in the good-predictions zone the observations remain dense enough to accurately capture the fractal manifold of the system's dynamics, which is measured using the correlation dimension. The accuracy of the DA methods in this zone remains almost as good as for full-resolution observations. Second is the reasonable-predictions zone in which the DA methods still work but at reduced prediction accuracy. Third is the bad-predictions zone in which even the DA methods fail. We find that the sparsity level up to which the DA methods work is almost the same up to which chaos synchronisation of these systems can be achieved. The main implications of these results are that they (i) firmly establish the spatial resolution up to which the data-driven methods can be utilised, (ii) provide measures to determine if adding more sensors will improve the predictions, and (iii) quantify the advantage (in terms of the required measurement resolution) of using the governing equations within data-driven methods. We also discuss the applicability of these results to fully developed turbulence.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f37955fcf738b892c9cedb2952e279d466fad9b8" target='_blank'>
              Predictability of weakly turbulent systems from spatially sparse observations using data assimilation and machine learning
              </a>
            </td>
          <td>
            Vikrant Gupta, Yuanqing Chen, Minping Wan
          </td>
          <td>2024-07-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="An open problem in artificial intelligence is how systems can flexibly learn discrete abstractions that are useful for solving inherently continuous problems. Previous work has demonstrated that a class of hybrid state-space model known as recurrent switching linear dynamical systems (rSLDS) discover meaningful behavioural units via the piecewise linear decomposition of complex continuous dynamics (Linderman et al., 2016). Furthermore, they model how the underlying continuous states drive these discrete mode switches. We propose that the rich representations formed by an rSLDS can provide useful abstractions for planning and control. We present a novel hierarchical model-based algorithm inspired by Active Inference in which a discrete MDP sits above a low-level linear-quadratic controller. The recurrent transition dynamics learned by the rSLDS allow us to (1) specify temporally-abstracted sub-goals in a method reminiscent of the options framework, (2) lift the exploration into discrete space allowing us to exploit information-theoretic exploration bonuses and (3) `cache' the approximate solutions to low-level problems in the discrete planner. We successfully apply our model to the sparse Continuous Mountain Car task, demonstrating fast system identification via enhanced exploration and non-trivial planning through the delineation of abstract sub-goals.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/99e1f3993989229883bf003f4fb9d78a71048c30" target='_blank'>
              Hybrid Recurrent Models Support Emergent Descriptions for Hierarchical Planning and Control
              </a>
            </td>
          <td>
            Poppy Collis, Ryan Singh, Paul F Kinghorn, Christopher L. Buckley
          </td>
          <td>2024-08-20</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Model parameter inference is a universal problem across science. This challenge is particularly pronounced in developmental biology, where faithful mechanistic descriptions require spatial-stochastic models with numerous parameters, yet quantitative empirical data often lack sufficient granularity due to experimental limitations. Parameterizing such complex models thus necessitates methods that elaborate on classical Bayesian inference by incorporating notions of optimality and goal-orientation through low-dimensional objective functions that quantitatively capture the target behavior of the underlying system. In this study, we contrast two such inference workflows and apply them to biophysics-inspired spatial-stochastic models. Technically, both workflows are simulation-based inference (SBI) methods. The first method leverages a modern deep-learning technique known as sequential neural posterior estimation (SNPE), while the second is based on a classical optimization technique called simulated annealing (SA). We evaluate these workflows by inferring the parameters of two complementary models for the inner cell mass (ICM) lineage differentiation in the blastocyst-stage mouse embryo. This developmental biology system serves as a paradigmatic example of a highly robust and reproducible cell-fate proportioning process that self-organizes under strongly stochastic conditions, such as intrinsic biochemical noise and cell-cell signaling delays. Our results indicate that while both methods largely agree in their predictions, the modern SBI workflow provides substantially richer inferred distributions at an equivalent computational cost. We identify the computational scenarios that favor the modern SBI method over its classical counterpart. Finally, we propose a plausible approach to integrate these two methods, thereby synergistically exploiting their parameter space exploration capabilities.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/64ec5827bd7f9a7b3d935cb3a63d276e77e4cbb9" target='_blank'>
              Comparing AI versus Optimization Workflows for Simulation-Based Inference of Spatial-Stochastic Systems
              </a>
            </td>
          <td>
            Michael A. Ramirez-Sierra, T. Sokolowski
          </td>
          <td>2024-07-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="In this work, we describe a novel approach to building a neural PDE solver leveraging recent advances in transformer based neural network architectures. Our model can provide solutions for different values of PDE parameters without any need for retraining the network. The training is carried out in a self-supervised manner, similar to pretraining approaches applied in language and vision tasks. We hypothesize that the model is in effect learning a family of operators (for multiple parameters) mapping the initial condition to the solution of the PDE at any future time step t. We compare this approach with the Fourier Neural Operator (FNO), and demonstrate that it can generalize over the space of PDE parameters, despite having a higher prediction error for individual parameter values compared to the FNO. We show that performance on a specific parameter can be improved by finetuning the model with very small amounts of data. We also demonstrate that the model scales with data as well as model size.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/629ea9c7440dd696fb2129b9994297e01c3d883e" target='_blank'>
              Self-supervised Pretraining for Partial Differential Equations
              </a>
            </td>
          <td>
            Varun Madhavan, Amal S Sebastian, Bharath Ramsundar, Venkat Viswanathan
          </td>
          <td>2024-07-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>19</td>
        </tr>

        <tr id="Areas of computational mechanics such as uncertainty quantification and optimization usually involve repeated evaluation of numerical models that represent the behavior of engineering systems. In the case of complex nonlinear systems however, these models tend to be expensive to evaluate, making surrogate models quite valuable. Artificial neural networks approximate systems very well by taking advantage of the inherent information of its given training data. In this context, this paper investigates the improvement of the training process by including sensitivity information, which are partial derivatives w.r.t. inputs, as outlined by Sobolev training. In computational mechanics, sensitivities can be applied to neural networks by expanding the training loss function with additional loss terms, thereby improving training convergence resulting in lower generalisation error. This improvement is shown in two examples of linear and non-linear material behavior. More specifically, the Sobolev designed loss function is expanded with residual weights adjusting the effect of each loss on the training step. Residual weighting is the given scaling to the different training data, which in this case are response and sensitivities. These residual weights are optimized by an adaptive scheme, whereby varying objective functions are explored, with some showing improvements in accuracy and precision of the general training convergence.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bc84ce2dba59d576dd4d3f10a9b0f7b62826171a" target='_blank'>
              Sobolev neural network with residual weighting as a surrogate in linear and non-linear mechanics
              </a>
            </td>
          <td>
            A.O.M. Kilicsoy, J. Liedmann, M. Valdebenito, F. Barthold, M. Faes
          </td>
          <td>2024-07-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>24</td>
        </tr>

        <tr id="In recent years, surrogate models based on deep neural networks have been widely used to solve partial differential equations for fluid flow physics. This kind of model focuses on global interpolation of the training data and thus requires a large network structure. The process is both time consuming and computationally costly. In the present study, we develop a neural network with local converging input (NNLCI) for high-fidelity prediction using unstructured data. The framework uses the local domain of dependence with converging coarse solutions as input, thereby greatly reducing computational resource and training time. As a validation case, the NNLCI method is applied to study two-dimensional inviscid supersonic flows in channels with bumps. Different bump geometries and locations are examined to benchmark the effectiveness and versatility of this new approach. The NNLCI method can accurately and efficiently capture the structure and dynamics of the entire flowfield, including regions with shock discontinuities. For a new bump configuration, the method can perform prediction with only one neural network, eliminating the need for repeated training of multiple networks for different geometries. A saving of computing wall time is achieved by several orders of magnitude against the high-fidelity simulation with the same level of accuracy. The demand on training data is modest, and the training data can be allocated sparsely. These features are especially advantageous compared with conventional global-to-global deep learning methods and physics-informed methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/88415c3817a7058d9678f49a393b306a231a9953" target='_blank'>
              Neural Network with Local Converging Input for Unstructured-Grid Computational Fluid Dynamics
              </a>
            </td>
          <td>
            Weiming Ding, Haoxiang Huang, T. Lee, Yingjie Liu, Vigor Yang
          </td>
          <td>2024-07-01</td>
          <td>AIAA Journal</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Overparameterized stochastic differential equation (SDE) models have achieved remarkable success in various complex environments, such as PDE-constrained optimization, stochastic control and reinforcement learning, financial engineering, and neural SDEs. These models often feature system evolution coefficients that are parameterized by a high-dimensional vector $\theta \in \mathbb{R}^n$, aiming to optimize expectations of the SDE, such as a value function, through stochastic gradient ascent. Consequently, designing efficient gradient estimators for which the computational complexity scales well with $n$ is of significant interest. This paper introduces a novel unbiased stochastic gradient estimator--the generator gradient estimator--for which the computation time remains stable in $n$. In addition to establishing the validity of our methodology for general SDEs with jumps, we also perform numerical experiments that test our estimator in linear-quadratic control problems parameterized by high-dimensional neural networks. The results show a significant improvement in efficiency compared to the widely used pathwise differentiation method: Our estimator achieves near-constant computation times, increasingly outperforms its counterpart as $n$ increases, and does so without compromising estimation variance. These empirical findings highlight the potential of our proposed methodology for optimizing SDEs in contemporary applications.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6fc1545e20fb78c9271560d34a3512c20ad26286" target='_blank'>
              An Efficient High-dimensional Gradient Estimator for Stochastic Differential Equations
              </a>
            </td>
          <td>
            Shengbo Wang, Jose Blanchet, Peter Glynn
          </td>
          <td>2024-07-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

    </tbody>
    <tfoot>
      <tr>
          <th>Abstract</th>
          <th>Title</th>
          <th>Authors</th>
          <th>Publication Date</th>
          <th>Journal/Conference</th>
          <th>Citation count</th>
          <th>Highest h-index</th>
      </tr>
    </tfoot>
    </table>
    </p>
  </div>

</body>

<script>

  function create_author_list(author_list) {
    let td_author_element = document.getElementById();
    for (let i = 0; i < author_list.length; i++) {
          // tdElements[i].innerHTML = greet(tdElements[i].innerHTML);
          alert (author_list[i]);
      }
  }

  var trace1 = {
    x: ['2024'],
    y: [20],
    name: 'Num of citations',
    yaxis: 'y1',
    type: 'scatter'
  };

  var data = [trace1];

  var layout = {
    yaxis: {
      title: 'Num of citations',
      }
  };
  Plotly.newPlot('myDiv1', data, layout);
</script>
<script>
var dataTableOptions = {
        initComplete: function () {
        this.api()
            .columns()
            .every(function () {
                let column = this;

                // Create select element
                let select = document.createElement('select');
                select.add(new Option(''));
                column.footer().replaceChildren(select);

                // Apply listener for user change in value
                select.addEventListener('change', function () {
                    column
                        .search(select.value, {exact: true})
                        .draw();
                });

                // keep the width of the select element same as the column
                select.style.width = '100%';

                // Add list of options
                column
                    .data()
                    .unique()
                    .sort()
                    .each(function (d, j) {
                        select.add(new Option(d));
                    });
            });
    },
    scrollX: true,
    scrollCollapse: true,
    paging: true,
    fixedColumns: true,
    columnDefs: [
        {"className": "dt-center", "targets": "_all"},
        // set width for both columns 0 and 1 as 25%
        { width: '7%', targets: 0 },
        { width: '30%', targets: 1 },
        { width: '25%', targets: 2 },
        { width: '15%', targets: 4 }

      ],
    pageLength: 10,
    layout: {
        topStart: {
            buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
        }
    }
  }
  new DataTable('#table1', dataTableOptions);
  new DataTable('#table2', dataTableOptions);

  var table1 = $('#table1').DataTable();
  $('#table1 tbody').on('click', 'td:first-child', function () {
    var tr = $(this).closest('tr');
    var row = table1.row( tr );

    var rowId = tr.attr('id');
    // alert(rowId);

    if (row.child.isShown()) {
      // This row is already open - close it.
      row.child.hide();
      tr.removeClass('shown');
      tr.find('td:first-child').html('<i class="material-icons">visibility_off</i>');
    } else {
      // Open row.
      // row.child('foo').show();
      tr.find('td:first-child').html('<i class="material-icons">visibility</i>');
      var content = '<div class="child-row-content"><strong>Abstract:</strong> ' + rowId + '</div>';
      row.child(content).show();
      tr.addClass('shown');
    }
  });
  var table2 = $('#table2').DataTable();
  $('#table2 tbody').on('click', 'td:first-child', function () {
    var tr = $(this).closest('tr');
    var row = table2.row( tr );

    var rowId = tr.attr('id');
    // alert(rowId);

    if (row.child.isShown()) {
      // This row is already open - close it.
      row.child.hide();
      tr.removeClass('shown');
      tr.find('td:first-child').html('<i class="material-icons">visibility_off</i>');
    } else {
      // Open row.
      // row.child('foo').show();
      var content = '<div class="child-row-content"><strong>Abstract:</strong> ' + rowId + '</div>';
      row.child(content).show();
      tr.addClass('shown');
      tr.find('td:first-child').html('<i class="material-icons">visibility</i>');
    }
  });
</script>
<style>
  .child-row-content {
    text-align: justify;
    text-justify: inter-word;
    word-wrap: break-word; /* Ensure long words are broken */
    white-space: normal; /* Ensure text wraps to the next line */
    max-width: 100%; /* Ensure content does not exceed the table width */
    padding: 10px; /* Optional: add some padding for better readability */
    /* font size */
    font-size: small;
  }
</style>
</html>







  
  




  



                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.top", "navigation.tabs"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    

      <script src="../assets/javascripts/bundle.c8d2eff1.min.js"></script>
      
    
<script>
  // Execute intro.js when a button with id 'intro' is clicked
  function startIntro(){
      introJs().setOptions({
          tooltipClass: 'customTooltip'
      }).start();
  }
</script>
<script>
  

  // new DataTable('#table1', {
  //   order: [[5, 'desc']],
  //   "columnDefs": [
  //       {"className": "dt-center", "targets": "_all"},
  //       { width: '30%', targets: 0 }
  //     ],
  //   pageLength: 10,
  //   layout: {
  //       topStart: {
  //           buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
  //       }
  //   }
  // });

  // new DataTable('#table2', {
  //   order: [[3, 'desc']],
  //   "columnDefs": [
  //       {"className": "dt-center", "targets": "_all"},
  //       { width: '30%', targets: 0 }
  //     ],
  //   pageLength: 10,
  //   layout: {
  //       topStart: {
  //           buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
  //       }
  //   }
  // });
  new DataTable('#table3', {
    initComplete: function () {
        this.api()
            .columns()
            .every(function () {
                let column = this;
 
                // Create select element
                let select = document.createElement('select');
                select.add(new Option(''));
                column.footer().replaceChildren(select);
 
                // Apply listener for user change in value
                select.addEventListener('change', function () {
                    column
                        .search(select.value, {exact: true})
                        .draw();
                });

                // keep the width of the select element same as the column
                select.style.width = '100%';
 
                // Add list of options
                column
                    .data()
                    .unique()
                    .sort()
                    .each(function (d, j) {
                        select.add(new Option(d));
                    });
            });
    },
    // order: [[3, 'desc']],
    "columnDefs": [
        {"className": "dt-center", "targets": "_all"},
        { width: '30%', targets: 0 }
      ],
    pageLength: 10,
    layout: {
        topStart: {
            buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
        }
    }
  });
  new DataTable('#table4', {
    initComplete: function () {
        this.api()
            .columns()
            .every(function () {
                let column = this;
 
                // Create select element
                let select = document.createElement('select');
                select.add(new Option(''));
                column.footer().replaceChildren(select);
 
                // Apply listener for user change in value
                select.addEventListener('change', function () {
                    column
                        .search(select.value, {exact: true})
                        .draw();
                });

                // keep the width of the select element same as the column
                select.style.width = '100%';
 
                // Add list of options
                column
                    .data()
                    .unique()
                    .sort()
                    .each(function (d, j) {
                        select.add(new Option(d));
                    });
            });
    },
    // order: [[3, 'desc']],
    "columnDefs": [
        {"className": "dt-center", "targets": "_all"},
        { width: '30%', targets: 0 }
      ],
    pageLength: 10,
    layout: {
        topStart: {
            buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
        }
    }
  });
</script>


  </body>
</html>