<!DOCTYPE html>

<html lang="en">


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../Time-series%20forecasting/">
      
      
        <link rel="next" href="../Neural%20ODEs/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.12">
    
    
<title>Literature Survey (VPE)</title>

    
      <link rel="stylesheet" href="../assets/stylesheets/main.7e359304.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
  <!-- Add scripts that need to run before here -->
  <!-- Add jquery script -->
  <script src="https://code.jquery.com/jquery-3.7.1.js"></script>
  <!-- Add data table libraries -->
  <script src="https://cdn.datatables.net/2.0.1/js/dataTables.js"></script>
  <link rel="stylesheet" href="https://cdn.datatables.net/2.0.1/css/dataTables.dataTables.css">
  <!-- Load plotly.js into the DOM -->
	<script src='https://cdn.plot.ly/plotly-2.29.1.min.js'></script>
  <link rel="stylesheet" href="https://cdn.datatables.net/buttons/3.0.1/css/buttons.dataTables.css">
  <!-- fixedColumns -->
  <script src="https://cdn.datatables.net/fixedcolumns/5.0.0/js/dataTables.fixedColumns.js"></script>
  <script src="https://cdn.datatables.net/fixedcolumns/5.0.0/js/fixedColumns.dataTables.js"></script>
  <link rel="stylesheet" href="https://cdn.datatables.net/fixedcolumns/5.0.0/css/fixedColumns.dataTables.css">
  <!-- Already specified in mkdocs.yml -->
  <!-- <link rel="stylesheet" href="../docs/custom.css"> -->
  <script src="https://cdn.datatables.net/buttons/3.0.1/js/dataTables.buttons.js"></script>
  <script src="https://cdn.datatables.net/buttons/3.0.1/js/buttons.dataTables.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.1/jszip.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdfmake/0.2.7/pdfmake.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdfmake/0.2.7/vfs_fonts.js"></script>
  <script src="https://cdn.datatables.net/buttons/3.0.1/js/buttons.html5.min.js"></script>
  <script src="https://cdn.datatables.net/buttons/3.0.1/js/buttons.print.min.js"></script>
  <!-- Google fonts -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
  <!-- Intro.js -->
  <script src="https://cdn.jsdelivr.net/npm/intro.js@7.2.0/intro.min.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/intro.js@7.2.0/minified/introjs.min.css">


  <!-- 
      
     -->
  <!-- Add scripts that need to run afterwards here -->

    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../custom.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="black">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Literature Survey (VPE)" class="md-header__button md-logo" aria-label="Literature Survey (VPE)" data-md-component="logo">
      
  <img src="../assets/VPE.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Literature Survey (VPE)
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Symbolic regression
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="black"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="white" data-md-color-accent="black"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/VirtualPatientEngine/literatureSurvey" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    VPE/LiteratureSurvey
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href=".." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../Time-series%20forecasting/" class="md-tabs__link">
        
  
    
  
  Time-series forecasting

      </a>
    </li>
  

      
        
  
  
    
  
  
    <li class="md-tabs__item md-tabs__item--active">
      <a href="./" class="md-tabs__link">
        
  
    
  
  Symbolic regression

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../Neural%20ODEs/" class="md-tabs__link">
        
  
    
  
  Neural ODEs

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../Physics-based%20GNNs/" class="md-tabs__link">
        
  
    
  
  Physics-based GNNs

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../Latent%20space%20simulators/" class="md-tabs__link">
        
  
    
  
  Latent space simulators

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../Parametrizing%20using%20ML/" class="md-tabs__link">
        
  
    
  
  Parametrizing using ML

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../PINNs/" class="md-tabs__link">
        
  
    
  
  PINNs

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../Koopman%20operator/" class="md-tabs__link">
        
  
    
  
  Koopman operator

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
                
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" hidden>
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Literature Survey (VPE)" class="md-nav__button md-logo" aria-label="Literature Survey (VPE)" data-md-component="logo">
      
  <img src="../assets/VPE.png" alt="logo">

    </a>
    Literature Survey (VPE)
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/VirtualPatientEngine/literatureSurvey" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    VPE/LiteratureSurvey
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Time-series%20forecasting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Time-series forecasting
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Symbolic regression
  </span>
  

      </a>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Neural%20ODEs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Neural ODEs
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Physics-based%20GNNs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Physics-based GNNs
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Latent%20space%20simulators/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Latent space simulators
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Parametrizing%20using%20ML/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Parametrizing using ML
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../PINNs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PINNs
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Koopman%20operator/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Koopman operator
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
                
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>Symbolic regression</h1>

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
</head>

<body>
  <p>
  <i class="footer">This page was last updated on 2024-06-07 12:57:16 UTC</i>
  </p>

  <div class="note info" onclick="startIntro()">
    <p>
      <button type="button" class="buttons">
        <div style="display: flex; align-items: center;">
        Click here for a quick intro of the page! <i class="material-icons">help</i>
        </div>
      </button>
    </p>
  </div>

  <!--
  <div data-intro='Table of contents'>
    <p>
    <h3>Table of Contents</h3>
      <a href="#plot1">1. Citations over time on Symbolic regression</a><br>
      <a href="#manually_curated_articles">2. Manually curated articles on Symbolic regression</a><br>
      <a href="#recommended_articles">3. Recommended articles on Symbolic regression</a><br>
    <p>
  </div>

  <div data-intro='Plot displaying number of citations over time 
                  on the given topic based on recommended articles'>
    <p>
    <h3 id="plot1">1. Citations over time on Symbolic regression</h3>
      <div id='myDiv1'>
      </div>
    </p>
  </div>
  -->

  <div data-intro='Manually curated articles on the given topic'>
    <p>
    <h3 id="manually_curated_articles">Manually curated articles on <i>Symbolic regression</i></h3>
    <table id="table1" class="display" style="width:100%">
    <thead>
      <tr>
          <th data-intro='Click to view the abstract (if available)'>Abstract</th>
          <th>Title</th>
          <th>Authors</th>
          <th>Publication Date</th>
          <th>Journal/ Conference</th>
          <th>Citation count</th>
          <th data-intro='Highest h-index among the authors'>Highest h-index</th>
          <th data-intro='Recommended articles extracted by considering
                          only the given article'>
              View recommendations
              </th>
      </tr>
    </thead>
    <tbody>

        <tr id="Significance Understanding dynamic constraints and balances in nature has facilitated rapid development of knowledge and enabled technology, including aircraft, combustion engines, satellites, and electrical power. This work develops a novel framework to discover governing equations underlying a dynamical system simply from data measurements, leveraging advances in sparsity techniques and machine learning. The resulting models are parsimonious, balancing model complexity with descriptive ability while avoiding overfitting. There are many critical data-driven problems, such as understanding cognition from neural recordings, inferring climate patterns, determining stability of financial markets, predicting and suppressing the spread of disease, and controlling turbulence for greener transportation and energy. With abundant data and elusive laws, data-driven discovery of dynamics will continue to play an important role in these efforts. Extracting governing equations from data is a central challenge in many diverse areas of science and engineering. Data are abundant whereas models often remain elusive, as in climate science, neuroscience, ecology, finance, and epidemiology, to name only a few examples. In this work, we combine sparsity-promoting techniques and machine learning with nonlinear dynamical systems to discover governing equations from noisy measurement data. The only assumption about the structure of the model is that there are only a few important terms that govern the dynamics, so that the equations are sparse in the space of possible functions; this assumption holds for many physical systems in an appropriate basis. In particular, we use sparse regression to determine the fewest terms in the dynamic governing equations required to accurately represent the data. This results in parsimonious models that balance accuracy with model complexity to avoid overfitting. We demonstrate the algorithm on a wide range of problems, from simple canonical systems, including linear and nonlinear oscillators and the chaotic Lorenz system, to the fluid vortex shedding behind an obstacle. The fluid example illustrates the ability of this method to discover the underlying dynamics of a system that took experts in the community nearly 30 years to resolve. We also show that this method generalizes to parameterized systems and systems that are time-varying or have external forcing.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5d150cec2775f9bc863760448f14104cc8f42368" target='_blank'>
                Discovering governing equations from data by sparse identification of nonlinear dynamical systems
                </a>
              </td>
          <td>
            S. Brunton, J. Proctor, J. Kutz
          </td>
          <td>2015-09-11</td>
          <td>Proceedings of the National Academy of Sciences of the United States of America, Proceedings of the National Academy of Sciences</td>
          <td>3019</td>
          <td>62</td>

            <td><a href='../recommendations/5d150cec2775f9bc863760448f14104cc8f42368' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/60d0d998fa038182b3b69a57adb9b2f82d40589c" target='_blank'>
                Robust learning from noisy, incomplete, high-dimensional experimental data via physically constrained symbolic regression
                </a>
              </td>
          <td>
            Patrick A. K. Reinbold, Logan Kageorge, M. Schatz, R. Grigoriev
          </td>
          <td>2021-02-24</td>
          <td>Nature Communications</td>
          <td>81</td>
          <td>23</td>

            <td><a href='../recommendations/60d0d998fa038182b3b69a57adb9b2f82d40589c' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Significance Governing equations are essential to the study of physical systems, providing models that can generalize to predict previously unseen behaviors. There are many systems of interest across disciplines where large quantities of data have been collected, but the underlying governing equations remain unknown. This work introduces an approach to discover governing models from data. The proposed method addresses a key limitation of prior approaches by simultaneously discovering coordinates that admit a parsimonious dynamical model. Developing parsimonious and interpretable governing models has the potential to transform our understanding of complex systems, including in neuroscience, biology, and climate science. The discovery of governing equations from scientific data has the potential to transform data-rich fields that lack well-characterized quantitative descriptions. Advances in sparse regression are currently enabling the tractable identification of both the structure and parameters of a nonlinear dynamical system from data. The resulting models have the fewest terms necessary to describe the dynamics, balancing model complexity with descriptive ability, and thus promoting interpretability and generalizability. This provides an algorithmic approach to Occam’s razor for model discovery. However, this approach fundamentally relies on an effective coordinate system in which the dynamics have a simple representation. In this work, we design a custom deep autoencoder network to discover a coordinate transformation into a reduced space where the dynamics may be sparsely represented. Thus, we simultaneously learn the governing equations and the associated coordinate system. We demonstrate this approach on several example high-dimensional systems with low-dimensional behavior. The resulting modeling framework combines the strengths of deep neural networks for flexible representation and sparse identification of nonlinear dynamics (SINDy) for parsimonious models. This method places the discovery of coordinates and models on an equal footing.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3c9961153493370500020c81527b3548c96f81e0" target='_blank'>
                Data-driven discovery of coordinates and governing equations
                </a>
              </td>
          <td>
            Kathleen P. Champion, Bethany Lusch, J. Kutz, S. Brunton
          </td>
          <td>2019-03-29</td>
          <td>Proceedings of the National Academy of Sciences of the United States of America</td>
          <td>569</td>
          <td>62</td>

            <td><a href='../recommendations/3c9961153493370500020c81527b3548c96f81e0' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3df50e9b73cc2937dfd651f4c3344bc99b7ed3f2" target='_blank'>
                Chaos as an intermittently forced linear system
                </a>
              </td>
          <td>
            S. Brunton, Bingni W. Brunton, J. Proctor, E. Kaiser, J. Kutz
          </td>
          <td>2016-08-18</td>
          <td>Nature Communications</td>
          <td>429</td>
          <td>62</td>

            <td><a href='../recommendations/3df50e9b73cc2937dfd651f4c3344bc99b7ed3f2' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Data-driven discovery of dynamics via machine learning is pushing the frontiers of modelling and control efforts, providing a tremendous opportunity to extend the reach of model predictive control (MPC). However, many leading methods in machine learning, such as neural networks (NN), require large volumes of training data, may not be interpretable, do not easily include known constraints and symmetries, and may not generalize beyond the attractor where models are trained. These factors limit their use for the online identification of a model in the low-data limit, for example following an abrupt change to the system dynamics. In this work, we extend the recent sparse identification of nonlinear dynamics (SINDY) modelling procedure to include the effects of actuation and demonstrate the ability of these models to enhance the performance of MPC, based on limited, noisy data. SINDY models are parsimonious, identifying the fewest terms in the model needed to explain the data, making them interpretable and generalizable. We show that the resulting SINDY-MPC framework has higher performance, requires significantly less data, and is more computationally efficient and robust to noise than NN models, making it viable for online training and execution in response to rapid system changes. SINDY-MPC also shows improved performance over linear data-driven models, although linear models may provide a stopgap until enough data is available for SINDY. SINDY-MPC is demonstrated on a variety of dynamical systems with different challenges, including the chaotic Lorenz system, a simple model for flight control of an F8 aircraft, and an HIV model incorporating drug treatment.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b2eb064f432557c59ce99834d7dc7817e4687271" target='_blank'>
                Sparse identification of nonlinear dynamics for model predictive control in the low-data limit
                </a>
              </td>
          <td>
            E. Kaiser, J. Kutz, S. Brunton
          </td>
          <td>2017-11-15</td>
          <td>Proceedings. Mathematical, Physical, and Engineering Sciences, Proceedings of the Royal Society A</td>
          <td>406</td>
          <td>62</td>

            <td><a href='../recommendations/b2eb064f432557c59ce99834d7dc7817e4687271' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Inferring the structure and dynamics of network models is critical to understanding the functionality and control of complex systems, such as metabolic and regulatory biological networks. The increasing quality and quantity of experimental data enable statistical approaches based on information theory for model selection and goodness-of-fit metrics. We propose an alternative data-driven method to infer networked nonlinear dynamical systems by using sparsity-promoting optimization to select a subset of nonlinear interactions representing dynamics on a network. In contrast to standard model selection methods-based upon information content for a finite number of heuristic models (order 10 or less), our model selection procedure discovers a parsimonious model from a combinatorially large set of models, without an exhaustive search. Our particular innovation is appropriate for many biological networks, where the governing dynamical systems have rational function nonlinearities with cross terms, thus requiring an implicit formulation and the equations to be identified in the null-space of a library of mixed nonlinearities, including the state and derivative terms. This method, implicit-SINDy, succeeds in inferring three canonical biological models: 1) Michaelis-Menten enzyme kinetics; 2) the regulatory network for competence in bacteria; and 3) the metabolic network for yeast glycolysis.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/06a0ba437d41a7c82c08a9636a4438c1b5031378" target='_blank'>
                Inferring Biological Networks by Sparse Identification of Nonlinear Dynamics
                </a>
              </td>
          <td>
            N. Mangan, S. Brunton, J. Proctor, J. Kutz
          </td>
          <td>2016-05-26</td>
          <td>IEEE Transactions on Molecular Biological and Multi-Scale Communications, IEEE Transactions on Molecular, Biological and Multi-Scale Communications</td>
          <td>306</td>
          <td>62</td>

            <td><a href='../recommendations/06a0ba437d41a7c82c08a9636a4438c1b5031378' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Accurately modelling the nonlinear dynamics of a system from measurement data is a challenging yet vital topic. The sparse identification of nonlinear dynamics (SINDy) algorithm is one approach to discover dynamical systems models from data. Although extensions have been developed to identify implicit dynamics, or dynamics described by rational functions, these extensions are extremely sensitive to noise. In this work, we develop SINDy-PI (parallel, implicit), a robust variant of the SINDy algorithm to identify implicit dynamics and rational nonlinearities. The SINDy-PI framework includes multiple optimization algorithms and a principled approach to model selection. We demonstrate the ability of this algorithm to learn implicit ordinary and partial differential equations and conservation laws from limited and noisy data. In particular, we show that the proposed approach is several orders of magnitude more noise robust than previous approaches, and may be used to identify a class of ODE and PDE dynamics that were previously unattainable with SINDy, including for the double pendulum dynamics and simplified model for the Belousov–Zhabotinsky (BZ) reaction.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4971f9abd024e40fbbdff2e9492745b68a6bca01" target='_blank'>
                SINDy-PI: a robust algorithm for parallel implicit sparse identification of nonlinear dynamics
                </a>
              </td>
          <td>
            Kadierdan Kaheman, J. Kutz, S. Brunton
          </td>
          <td>2020-04-05</td>
          <td>Proceedings. Mathematical, Physical, and Engineering Sciences, Proceedings of the Royal Society A</td>
          <td>178</td>
          <td>62</td>

            <td><a href='../recommendations/4971f9abd024e40fbbdff2e9492745b68a6bca01' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="A key task in the field of modeling and analyzing nonlinear dynamical systems is the recovery of unknown governing equations from measurement data only. There is a wide range of application areas for this important instance of system identification, ranging from industrial engineering and acoustic signal processing to stock market models. In order to find appropriate representations of underlying dynamical systems, various data-driven methods have been proposed by different communities. However, if the given data sets are high-dimensional, then these methods typically suffer from the curse of dimensionality. To significantly reduce the computational costs and storage consumption, we propose the method multidimensional approximation of nonlinear dynamical systems (MANDy) which combines data-driven methods with tensor network decompositions. The efficiency of the introduced approach will be illustrated with the aid of several high-dimensional nonlinear dynamical systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2b2aa13d4959073f61ad70555bc8c7da7d116196" target='_blank'>
                Multidimensional Approximation of Nonlinear Dynamical Systems
                </a>
              </td>
          <td>
            Patrick Gelß, Stefan Klus, J. Eisert, Christof Schutte
          </td>
          <td>2018-09-07</td>
          <td>Journal of Computational and Nonlinear Dynamics</td>
          <td>60</td>
          <td>75</td>

            <td><a href='../recommendations/2b2aa13d4959073f61ad70555bc8c7da7d116196' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="First principles modeling of physical systems has led to significant technological advances across all branches of science. For nonlinear systems, however, small modeling errors can lead to significant deviations from the true, measured behavior. Even in mechanical systems, where the equations are assumed to be well-known, there are often model discrepancies corresponding to nonlinear friction, wind resistance, etc. Discovering models for these discrepancies remains an open challenge for many complex systems. In this work, we use the sparse identification of nonlinear dynamics (SINDy) algorithm to discover a model for the discrepancy between a simplified model and measurement data. In particular, we assume that the model mismatch can be sparsely represented in a library of candidate model terms. We demonstrate the efficacy of our approach on several examples including experimental data from a double pendulum on a cart. We further design and implement a feed-forward controller in simulations, showing improvement with a discrepancy model.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/73dd9c49f205280991826b2ea4b50344203916b4" target='_blank'>
                Learning Discrepancy Models From Experimental Data
                </a>
              </td>
          <td>
            Kadierdan Kaheman, E. Kaiser, B. Strom, J. Kutz, S. Brunton
          </td>
          <td>2019-09-18</td>
          <td>arXiv.org, ArXiv</td>
          <td>28</td>
          <td>62</td>

            <td><a href='../recommendations/73dd9c49f205280991826b2ea4b50344203916b4' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Machine learning (ML) and artificial intelligence (AI) algorithms are now being used to automate the discovery of physics principles and governing equations from measurement data alone. However, positing a universal physical law from data is challenging without simultaneously proposing an accompanying discrepancy model to account for the inevitable mismatch between theory and measurements. By revisiting the classic problem of modeling falling objects of different size and mass, we highlight a number of nuanced issues that must be addressed by modern data-driven methods for automated physics discovery. Specifically, we show that measurement noise and complex secondary physical mechanisms, like unsteady fluid drag forces, can obscure the underlying law of gravitation, leading to an erroneous model. We use the sparse identification of non-linear dynamics (SINDy) method to identify governing equations for real-world measurement data and simulated trajectories. Incorporating into SINDy the assumption that each falling object is governed by a similar physical law is shown to improve the robustness of the learned models, but discrepancies between the predictions and observations persist due to subtleties in drag dynamics. This work highlights the fact that the naive application of ML/AI will generally be insufficient to infer universal physical laws without further modification.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/35e2571c17246577e0bc1b9de57a314c3b60e220" target='_blank'>
                Discovery of Physics From Data: Universal Laws and Discrepancies
                </a>
              </td>
          <td>
            Brian M. de Silva, D. Higdon, S. Brunton, J. Kutz
          </td>
          <td>2019-06-19</td>
          <td>Frontiers in Artificial Intelligence</td>
          <td>64</td>
          <td>62</td>

            <td><a href='../recommendations/35e2571c17246577e0bc1b9de57a314c3b60e220' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Researchers propose sparse regression for identifying governing partial differential equations for spatiotemporal systems. We propose a sparse regression method capable of discovering the governing partial differential equation(s) of a given system by time series measurements in the spatial domain. The regression framework relies on sparsity-promoting techniques to select the nonlinear and partial derivative terms of the governing equations that most accurately represent the data, bypassing a combinatorially large search through all possible candidate models. The method balances model complexity and regression accuracy by selecting a parsimonious model via Pareto analysis. Time series measurements can be made in an Eulerian framework, where the sensors are fixed spatially, or in a Lagrangian framework, where the sensors move with the dynamics. The method is computationally efficient, robust, and demonstrated to work on a variety of canonical problems spanning a number of scientific domains including Navier-Stokes, the quantum harmonic oscillator, and the diffusion equation. Moreover, the method is capable of disambiguating between potentially nonunique dynamical terms by using multiple time series taken with different initial data. Thus, for a traveling wave, the method can distinguish between a linear wave equation and the Korteweg–de Vries equation, for instance. The method provides a promising new technique for discovering governing equations and physical laws in parameterized spatiotemporal systems, where first-principles derivations are intractable.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0acd117521ef5aafb09fed02ab415523b330b058" target='_blank'>
                Data-driven discovery of partial differential equations
                </a>
              </td>
          <td>
            S. Rudy, S. Brunton, J. Proctor, J. Kutz
          </td>
          <td>2016-09-21</td>
          <td>Science Advances</td>
          <td>1130</td>
          <td>62</td>

            <td><a href='../recommendations/0acd117521ef5aafb09fed02ab415523b330b058' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Sparse model identification enables the discovery of nonlinear dynamical systems purely from data; however, this approach is sensitive to noise, especially in the low-data limit. In this work, we leverage the statistical approach of bootstrap aggregating (bagging) to robustify the sparse identification of the nonlinear dynamics (SINDy) algorithm. First, an ensemble of SINDy models is identified from subsets of limited and noisy data. The aggregate model statistics are then used to produce inclusion probabilities of the candidate functions, which enables uncertainty quantification and probabilistic forecasts. We apply this ensemble-SINDy (E-SINDy) algorithm to several synthetic and real-world datasets and demonstrate substantial improvements to the accuracy and robustness of model discovery from extremely noisy and limited data. For example, E-SINDy uncovers partial differential equations models from data with more than twice as much measurement noise as has been previously reported. Similarly, E-SINDy learns the Lotka Volterra dynamics from remarkably limited data of yearly lynx and hare pelts collected from 1900 to 1920. E-SINDy is computationally efficient, with similar scaling as standard SINDy. Finally, we show that ensemble statistics from E-SINDy can be exploited for active learning and improved model predictive control.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/883547fdbd88552328a6615ec620f96e39c57018" target='_blank'>
                Ensemble-SINDy: Robust sparse model discovery in the low-data, high-noise limit, with active learning and control
                </a>
              </td>
          <td>
            Urban Fasel, J. Kutz, Bingni W. Brunton, S. Brunton
          </td>
          <td>2021-11-22</td>
          <td>Proceedings. Mathematical, Physical, and Engineering Sciences, Proceedings of the Royal Society A</td>
          <td>144</td>
          <td>62</td>

            <td><a href='../recommendations/883547fdbd88552328a6615ec620f96e39c57018' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e6f0a85009481dcfd93aaa43ed3f980e5033b0d8" target='_blank'>
                Learning sparse nonlinear dynamics via mixed-integer optimization
                </a>
              </td>
          <td>
            D. Bertsimas, Wes Gurnee
          </td>
          <td>2022-06-01</td>
          <td>Nonlinear Dynamics</td>
          <td>25</td>
          <td>90</td>

            <td><a href='../recommendations/e6f0a85009481dcfd93aaa43ed3f980e5033b0d8' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Regularized regression problems are ubiquitous in statistical modeling, signal processing, and machine learning. Sparse regression, in particular, has been instrumental in scientific model discovery, including compressed sensing applications, variable selection, and high-dimensional analysis. We propose a broad framework for sparse relaxed regularized regression, called SR3. The key idea is to solve a relaxation of the regularized problem, which has three advantages over the state-of-the-art: 1) solutions of the relaxed problem are superior with respect to errors, false positives, and conditioning; 2) relaxation allows extremely fast algorithms for both convex and nonconvex formulations; and 3) the methods apply to composite regularizers, essential for total variation (TV) as well as sparsity-promoting formulations using tight frames. We demonstrate the advantages of SR3 (computational efficiency, higher accuracy, faster convergence rates, and greater flexibility) across a range of regularized regression problems with synthetic and real data, including applications in compressed sensing, LASSO, matrix completion, TV regularization, and group sparsity. Following standards of reproducible research, we also provide a companion MATLAB package that implements these examples.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c0fc3882a9976f6a9cdc3a724bce184b786503da" target='_blank'>
                A Unified Framework for Sparse Relaxed Regularized Regression: SR3
                </a>
              </td>
          <td>
            P. Zheng, T. Askham, S. Brunton, J. Kutz, A. Aravkin
          </td>
          <td>2018-07-14</td>
          <td>IEEE Access</td>
          <td>112</td>
          <td>62</td>

            <td><a href='../recommendations/c0fc3882a9976f6a9cdc3a724bce184b786503da' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

    </tbody>
    <tfoot>
      <tr>
          <th>Abstract</th>
          <th>Title</th>
          <th>Authors</th>
          <th>Publication Date</th>
          <th>Journal/ Conference</th>
          <th>Citation count</th>
          <th>Highest h-index</th>
          <th>View recommendations</th>
      </tr>
    </tfoot>
    </table>
    </p>
  </div>

  <div data-intro='Recommended articles extracted by contrasting
                  articles that are relevant against not relevant for Symbolic regression'>
    <p>
    <h3 id="recommended_articles">Recommended articles on <i>Symbolic regression</i></h3>
    <table id="table2" class="display" style="width:100%">
    <thead>
      <tr>
          <th>Abstract</th>
          <th>Title</th>
          <th>Authors</th>
          <th>Publication Date</th>
          <th>Journal/Conference</th>
          <th>Citation count</th>
          <th>Highest h-index</th>
      </tr>
    </thead>
    <tbody>

        <tr id="The sparse identification of nonlinear dynamics (SINDy) has been established as an effective technique to produce interpretable models of dynamical systems from time-resolved state data via sparse regression. However, to model parameterized systems, SINDy requires data from transient trajectories for various parameter values over the range of interest, which are typically difficult to acquire experimentally. In this work, we extend SINDy to be able to leverage data on fixed points and/or limit cycles to reduce the number of transient trajectories needed for successful system identification. To achieve this, we incorporate the data on these attractors at various parameter values as constraints in the optimization problem. First, we show that enforcing these as hard constraints leads to an ill-conditioned regression problem due to the large number of constraints. Instead, we implement soft constraints by modifying the cost function to be minimized. This leads to the formulation of a multi-objective sparse regression problem where we simultaneously seek to minimize the error of the fit to the transients trajectories and to the data on attractors, while penalizing the number of terms in the model. Our extension, demonstrated on several numerical examples, is more robust to noisy measurements and requires substantially less training data than the original SINDy method to correctly identify a parameterized dynamical system.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0c03c126b4d641a81099470f03a7d5215a2a6820" target='_blank'>
              Multi-objective SINDy for parameterized model discovery from single transient trajectory data
              </a>
            </td>
          <td>
            Javier A. Lemus, Benjamin Herrmann
          </td>
          <td>2024-05-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Identifying partial differential equations (PDEs) from data is crucial for understanding the governing mechanisms of natural phenomena, yet it remains a challenging task. We present an extension to the ARGOS framework, ARGOS-RAL, which leverages sparse regression with the recurrent adaptive lasso to identify PDEs from limited prior knowledge automatically. Our method automates calculating partial derivatives, constructing a candidate library, and estimating a sparse model. We rigorously evaluate the performance of ARGOS-RAL in identifying canonical PDEs under various noise levels and sample sizes, demonstrating its robustness in handling noisy and non-uniformly distributed data. We also test the algorithm's performance on datasets consisting solely of random noise to simulate scenarios with severely compromised data quality. Our results show that ARGOS-RAL effectively and reliably identifies the underlying PDEs from data, outperforming the sequential threshold ridge regression method in most cases. We highlight the potential of combining statistical methods, machine learning, and dynamical systems theory to automatically discover governing equations from collected data, streamlining the scientific modeling process.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8e6ba94461e38ca92209eaa1e802d6a39c777186" target='_blank'>
              Automating the Discovery of Partial Differential Equations in Dynamical Systems
              </a>
            </td>
          <td>
            Weizhen Li, Rui Carvalho
          </td>
          <td>2024-04-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Identifying Ordinary Differential Equations (ODEs) from measurement data requires both fitting the dynamics and assimilating, either implicitly or explicitly, the measurement data. The Sparse Identification of Nonlinear Dynamics (SINDy) method involves a derivative estimation step (and optionally, smoothing) and a sparse regression step on a library of candidate ODE terms. Kalman smoothing is a classical framework for assimilating the measurement data with known noise statistics. Previously, derivatives in SINDy and its python package, pysindy, had been estimated by finite difference, L1 total variation minimization, or local filters like Savitzky-Golay. In contrast, Kalman allows discovering ODEs that best recreate the essential dynamics in simulation, even in cases when it does not perform as well at recovering coefficients, as measured by their F1 score and mean absolute error. We have incorporated Kalman smoothing, along with hyperparameter optimization, into the existing pysindy architecture, allowing for rapid adoption of the method. Numerical experiments on a number of dynamical systems show Kalman smoothing to be the most amenable to parameter selection and best at preserving problem structure in the presence of noise.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5435325a3ad3a24c95b8947ff93859f828f47937" target='_blank'>
              Learning Nonlinear Dynamics Using Kalman Smoothing
              </a>
            </td>
          <td>
            Jacob Stevens-Haas, Yash Bhangale, Aleksandr Y Aravkin, Nathan Kutz
          </td>
          <td>2024-05-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="There exist endless examples of dynamical systems with vast available data and unsatisfying mathematical descriptions. Sparse regression applied to symbolic libraries has quickly emerged as a powerful tool for learning governing equations directly from data; these learned equations balance quantitative accuracy with qualitative simplicity and human interpretability. Here, I present a general purpose, model agnostic sparse regression algorithm that extends a recently proposed exhaustive search leveraging iterative Singular Value Decompositions (SVD). This accelerated scheme, Scalable Pruning for Rapid Identification of Null vecTors (SPRINT), uses bisection with analytic bounds to quickly identify optimal rank-1 modifications to null vectors. It is intended to maintain sensitivity to small coefficients and be of reasonable computational cost for large symbolic libraries. A calculation that would take the age of the universe with an exhaustive search but can be achieved in a day with SPRINT.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8f8ccf22995f032ef4f3f34e6540383da7d52b4c" target='_blank'>
              Scalable Sparse Regression for Model Discovery: The Fast Lane to Insight
              </a>
            </td>
          <td>
            Matthew Golden
          </td>
          <td>2024-05-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The simulation of many complex phenomena in engineering and science requires solving expensive, high-dimensional systems of partial differential equations (PDEs). To circumvent this, reduced-order models (ROMs) have been developed to speed up computations. However, when governing equations are unknown or partially known, typically ROMs lack interpretability and reliability of the predicted solutions. In this work we present a data-driven, non-intrusive framework for building ROMs where the latent variables and dynamics are identified in an interpretable manner and uncertainty is quantified. Starting from a limited amount of high-dimensional, noisy data the proposed framework constructs an efficient ROM by leveraging variational autoencoders for dimensionality reduction along with a newly introduced, variational version of sparse identification of nonlinear dynamics (SINDy), which we refer to as Variational Identification of Nonlinear Dynamics (VINDy). In detail, the method consists of Variational Encoding of Noisy Inputs (VENI) to identify the distribution of reduced coordinates. Simultaneously, we learn the distribution of the coefficients of a pre-determined set of candidate functions by VINDy. Once trained offline, the identified model can be queried for new parameter instances and new initial conditions to compute the corresponding full-time solutions. The probabilistic setup enables uncertainty quantification as the online testing consists of Variational Inference naturally providing Certainty Intervals (VICI). In this work we showcase the effectiveness of the newly proposed VINDy method in identifying interpretable and accurate dynamical system for the R\"ossler system with different noise intensities and sources. Then the performance of the overall method - named VENI, VINDy, VICI - is tested on PDE benchmarks including structural mechanics and fluid dynamics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/85d8b58d1657768ca3e0c17e25857d87f0cc6850" target='_blank'>
              VENI, VINDy, VICI: a variational reduced-order modeling framework with uncertainty quantification
              </a>
            </td>
          <td>
            Paolo Conti, Jonas Kneifl, Andrea Manzoni, A. Frangi, Jörg Fehr, S. Brunton, J. Kutz
          </td>
          <td>2024-05-31</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>62</td>
        </tr>

        <tr id="The sparse identification of nonlinear dynamical systems (SINDy) is a data-driven technique employed for uncovering and representing the fundamental dynamics of intricate systems based on observational data. However, a primary obstacle in the discovery of models for nonlinear partial differential equations (PDEs) lies in addressing the challenges posed by the curse of dimensionality and large datasets. Consequently, the strategic selection of the most informative samples within a given dataset plays a crucial role in reducing computational costs and enhancing the effectiveness of SINDy-based algorithms. To this aim, we employ a greedy sampling approach to the snapshot matrix of a PDE to obtain its valuable samples, which are suitable to train a deep neural network (DNN) in a SINDy framework. SINDy based algorithms often consist of a data collection unit, constructing a dictionary of basis functions, computing the time derivative, and solving a sparse identification problem which ends to regularised least squares minimization. In this paper, we extend the results of a SINDy based deep learning model discovery (DeePyMoD) approach by integrating greedy sampling technique in its data collection unit and new sparsity promoting algorithms in the least squares minimization unit. In this regard we introduce the greedy sampling neural network in sparse identification of nonlinear partial differential equations (GN-SINDy) which blends a greedy sampling method, the DNN, and the SINDy algorithm. In the implementation phase, to show the effectiveness of GN-SINDy, we compare its results with DeePyMoD by using a Python package that is prepared for this purpose on numerous PDE discovery">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9f2e0f138fdb706edb87999a79e0c8ba055c75b7" target='_blank'>
              GN-SINDy: Greedy Sampling Neural Network in Sparse Identification of Nonlinear Partial Differential Equations
              </a>
            </td>
          <td>
            A. Forootani, Peter Benner
          </td>
          <td>2024-05-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Data-driven modelling and scientific machine learning have been responsible for significant advances in determining suitable models to describe data. Within dynamical systems, neural ordinary differential equations (ODEs), where the system equations are set to be governed by a neural network, have become a popular tool for this challenge in recent years. However, less emphasis has been placed on systems that are only partially-observed. In this work, we employ a hybrid neural ODE structure, where the system equations are governed by a combination of a neural network and domain-specific knowledge, together with symbolic regression (SR), to learn governing equations of partially-observed dynamical systems. We test this approach on two case studies: A 3-dimensional model of the Lotka-Volterra system and a 5-dimensional model of the Lorenz system. We demonstrate that the method is capable of successfully learning the true underlying governing equations of unobserved states within these systems, with robustness to measurement noise.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8e5f91324b2ca816ed10e0d9a1d6565fb12a4a1f" target='_blank'>
              Learning Governing Equations of Unobserved States in Dynamical Systems
              </a>
            </td>
          <td>
            Gevik Grigorian, Sandip V. George, S. Arridge
          </td>
          <td>2024-04-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Observed data from a dynamic system can be assimilated into a predictive model by means of Kalman filters. Nonlinear extensions of the Kalman filter, such as the Extended Kalman Filter (EKF), are required to enable the joint estimation of (possibly nonlinear) system dynamics and of input parameters. To construct the evolution model used in the prediction phase of the EKF, we propose to rely on the Sparse Identification of Nonlinear Dynamics (SINDy). The numerical integration of a SINDy model leads to great computational savings compared to alternate strategies based on, e.g., finite elements. Indeed, SINDy allows for the immediate definition of the Jacobian matrices required by the EKF to identify system dynamics and properties, a derivation that is usually extremely involved with physical models. As a result, combining the EKF with SINDy provides a computationally efficient, easy-to-apply approach for the identification of nonlinear systems, capable of robust operation even outside the range of training of SINDy. To demonstrate the potential of the approach, we address the identification of a linear non-autonomous system consisting of a shear building model excited by real seismograms, and the identification of a partially observed nonlinear system. The challenge arising from applying SINDy when the system state is not accessible has been relieved by means of time-delay embedding. The great accuracy and the small uncertainty associated with the state identification, where the state has been augmented to include system properties, underscores the great potential of the proposed strategy, paving the way for the development of predictive digital twins in different fields.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2bef5ad9ed2a3bdfdaf5ec8957c692fcbb9132f7" target='_blank'>
              EKF-SINDy: Empowering the extended Kalman filter with sparse identification of nonlinear dynamics
              </a>
            </td>
          <td>
            Luca Rosafalco, Paolo Conti, Andrea Manzoni, Stefano Mariani, A. Frangi
          </td>
          <td>2024-04-11</td>
          <td>ArXiv</td>
          <td>3</td>
          <td>7</td>
        </tr>

        <tr id="Despite the advancements in learning governing differential equations from observations of dynamical systems, data-driven methods are often unaware of fundamental physical laws, such as frame invariance. As a result, these algorithms may search an unnecessarily large space and discover equations that are less accurate or overly complex. In this paper, we propose to leverage symmetry in automated equation discovery to compress the equation search space and improve the accuracy and simplicity of the learned equations. Specifically, we derive equivariance constraints from the time-independent symmetries of ODEs. Depending on the types of symmetries, we develop a pipeline for incorporating symmetry constraints into various equation discovery algorithms, including sparse regression and genetic programming. In experiments across a diverse range of dynamical systems, our approach demonstrates better robustness against noise and recovers governing equations with significantly higher probability than baselines without symmetry.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/294f1e8ba8fdeee906321b73f3e14bd0b704a7e0" target='_blank'>
              Symmetry-Informed Governing Equation Discovery
              </a>
            </td>
          <td>
            Jianwei Yang, Wang Rao, Nima Dehmamy, R. Walters, Rose Yu
          </td>
          <td>2024-05-27</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>20</td>
        </tr>

        <tr id="Using symbolic regression to discover physical laws from observed data is an emerging field. In previous work, we combined genetic algorithm (GA) and machine learning to present a data-driven method for discovering a wave equation. Although it managed to utilize the data to discover the two-dimensional (x,z) acoustic constant-density wave equation u_tt=v^2(u_xx+u_zz) (subscripts of the wavefield, u, are second derivatives in time and space) in a homogeneous medium, it did not provide the complete equation form, where the velocity term is represented by a coefficient rather than directly given by v^2. In this work, we redesign the framework, encoding both velocity information and candidate functional terms simultaneously. Thus, we use GA to simultaneously evolve the candidate functional and coefficient terms in the library. Also, we consider here the physics rationality and interpretability in the randomly generated potential wave equations, by ensuring that both-hand sides of the equation maintain balance in their physical units. We demonstrate this redesigned framework using the acoustic wave equation as an example, showing its ability to produce physically reasonable expressions of wave equations from noisy and sparsely observed data in both homogeneous and inhomogeneous media. Also, we demonstrate that our method can effectively discover wave equations from a more realistic observation scenario.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/50e879c5c0a3fe3bed1e0fee100d86b8ec2435d5" target='_blank'>
              Discovery of physically interpretable wave equations
              </a>
            </td>
          <td>
            Shijun Cheng, T. Alkhalifah
          </td>
          <td>2024-04-27</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>40</td>
        </tr>

        <tr id="A new knowledge-based and machine learning hybrid modeling approach, called conditional Gaussian neural stochastic differential equation (CGNSDE), is developed to facilitate modeling complex dynamical systems and implementing analytic formulae of the associated data assimilation (DA). In contrast to the standard neural network predictive models, the CGNSDE is designed to effectively tackle both forward prediction tasks and inverse state estimation problems. The CGNSDE starts by exploiting a systematic causal inference via information theory to build a simple knowledge-based nonlinear model that nevertheless captures as much explainable physics as possible. Then, neural networks are supplemented to the knowledge-based model in a specific way, which not only characterizes the remaining features that are challenging to model with simple forms but also advances the use of analytic formulae to efficiently compute the nonlinear DA solution. These analytic formulae are used as an additional computationally affordable loss to train the neural networks that directly improve the DA accuracy. This DA loss function promotes the CGNSDE to capture the interactions between state variables and thus advances its modeling skills. With the DA loss, the CGNSDE is more capable of estimating extreme events and quantifying the associated uncertainty. Furthermore, crucial physical properties in many complex systems, such as the translate-invariant local dependence of state variables, can significantly simplify the neural network structures and facilitate the CGNSDE to be applied to high-dimensional systems. Numerical experiments based on chaotic systems with intermittency and strong non-Gaussian features indicate that the CGNSDE outperforms knowledge-based regression models, and the DA loss further enhances the modeling skills of the CGNSDE.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a639323a3ab8c39800f9e9f42ae3d95438cb1ec6" target='_blank'>
              CGNSDE: Conditional Gaussian Neural Stochastic Differential Equation for Modeling Complex Systems and Data Assimilation
              </a>
            </td>
          <td>
            Chuanqi Chen, Nan Chen, Jingbo Wu
          </td>
          <td>2024-04-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="We present a data-driven pipeline for model building that combines interpretable machine learning, hydrodynamic theories, and microscopic models. The goal is to uncover the underlying processes governing nonlinear dynamics experiments. We exemplify our method with data from microfluidic experiments where crystals of streaming droplets support the propagation of nonlinear waves absent in passive crystals. By combining physics-inspired neural networks, known as neural operators, with symbolic regression tools, we generate the solution, as well as the mathematical form, of a nonlinear dynamical system that accurately models the experimental data. Finally, we interpret this continuum model from fundamental physics principles. Informed by machine learning, we coarse grain a microscopic model of interacting droplets and discover that non-reciprocal hydrodynamic interactions stabilise and promote nonlinear wave propagation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/687a2bdf4046a679f876d2b660bf758b24b136f2" target='_blank'>
              Interpreting neural operators: how nonlinear waves propagate in non-reciprocal solids
              </a>
            </td>
          <td>
            Jonathan Colen, Alexis Poncet, Denis Bartolo, Vincenzo Vitelli
          </td>
          <td>2024-04-19</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>6</td>
        </tr>

        <tr id="Adjoint methods have been the pillar of gradient-based optimization for decades. They enable the accurate computation of a gradient (sensitivity) of a quantity of interest with respect to all system's parameters in one calculation. When the gradient is embedded in an optimization routine, the quantity of interest can be optimized for the system to have the desired behaviour. Adjoint methods require the system's Jacobian, whose computation can be cumbersome, and is problem dependent. We propose a computational strategy to infer the adjoint sensitivities from data (observables), which bypasses the need of the Jacobian of the physical system. The key component of this strategy is an echo state network, which learns the dynamics of nonlinear regimes with varying parameters, and evolves dynamically via a hidden state. Although the framework is general, we focus on thermoacoustics governed by nonlinear and time-delayed systems. First, we show that a parameter-aware Echo State Network (ESN) infers the parameterized dynamics. Second, we derive the adjoint of the ESN to compute the sensitivity of time-averaged cost functionals. Third, we propose the Thermoacoustic Echo State Network (T-ESN), which hard constrains the physical knowledge in the network architecture. Fourth, we apply the framework to a variety of nonlinear thermoacoustic regimes of a prototypical system. We show that the T-ESN accurately infers the correct adjoint sensitivities of the time-averaged acoustic energy with respect to the flame parameters. The results are robust to noisy data, from periodic, through quasiperiodic, to chaotic regimes. A single network predicts the nonlinear bifurcations on unseen scenarios, and so the inferred adjoint sensitivities are employed to suppress an instability via steepest descent. This work opens new possibilities for gradient-based data-driven design optimization.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0daae2897c821b15dac81a757826d1009a038ffb" target='_blank'>
              Data-driven computation of adjoint sensitivities without adjoint solvers: An application to thermoacoustics
              </a>
            </td>
          <td>
            D. E. Ozan, Luca Magri
          </td>
          <td>2024-04-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="The discovery of linear embedding is the key to the synthesis of linear control techniques for nonlinear systems. In recent years, while Koopman operator theory has become a prominent approach for learning these linear embeddings through data-driven methods, these algorithms often exhibit limitations in generalizability beyond the distribution captured by training data and are not robust to changes in the nominal system dynamics induced by intrinsic or environmental factors. To overcome these limitations, this study presents an adaptive Koopman architecture capable of responding to the changes in system dynamics online. The proposed framework initially employs an autoencoder-based neural network that utilizes input-output information from the nominal system to learn the corresponding Koopman embedding offline. Subsequently, we augment this nominal Koopman architecture with a feed-forward neural network that learns to modify the nominal dynamics in response to any deviation between the predicted and observed lifted states, leading to improved generalization and robustness to a wide range of uncertainties and disturbances compared to contemporary methods. Extensive tracking control simulations, which are undertaken by integrating the proposed scheme within a Model Predictive Control framework, are used to highlight its robustness against measurement noise, disturbances, and parametric variations in system dynamics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/302db61f58f8a2e62340fcfaacbceec2620e551a" target='_blank'>
              Adaptive Koopman Embedding for Robust Control of Complex Nonlinear Dynamical Systems
              </a>
            </td>
          <td>
            Rajpal Singh, Chandan Kumar Sah, J. Keshavan
          </td>
          <td>2024-05-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Decision formation in perceptual decision-making involves sensory evidence accumulation instantiated by the temporal integration of an internal decision variable towards some decision criterion or threshold, as described by sequential sampling theoretical models. The decision variable can be represented in the form of experimentally observable neural activities. Hence, elucidating the appropriate theoretical model becomes crucial to understanding the mechanisms underlying perceptual decision formation. Existing computational methods are limited to either fitting of choice behavioural data or linear model estimation from neural activity data. In this work, we made use of sparse identification of nonlinear dynamics (SINDy), a data-driven approach, to elucidate the deterministic linear and nonlinear components of often-used stochastic decision models within reaction time task paradigms. Based on the simulated decision variable activities of the models, SINDy, enhanced with a trial-averaging approach, could readily uncover the dynamical equations of the models while predicting the models' choice accuracy and decision time across a range of signal-to-noise ratio values. In particular, SINDy performed relatively better for decision models which have an accelerating dynamical component during decision formation, as expressed by a metastable linear competing accumulator model and a nonlinear bistable model. Taken together, our work suggests that SINDy can be a useful tool for uncovering the dynamics in perceptual decision-making, and more generally, for first-passage time problems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6da667b4777d1fc6625bb8ec370ebee165493251" target='_blank'>
              Uncovering dynamical equations of stochastic decision models using data-driven SINDy algorithm
              </a>
            </td>
          <td>
            Brendan Lenfesty, Saugat Bhattacharyya, KongFatt Wong-Lin
          </td>
          <td>2024-06-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Nonlinear differential equations are encountered as models of fluid flow, spiking neurons, and many other systems of interest in the real world. Common features of these systems are that their behaviors are difficult to describe exactly and invariably unmodeled dynamics present challenges in making precise predictions. In many cases the models exhibit extremely complicated behavior due to bifurcations and chaotic regimes. In this paper, we present a novel data-driven linear estimator that uses Koopman operator theory to extract finite-dimensional representations of complex nonlinear systems. The extracted model is used together with a deep reinforcement learning network that learns the optimal stepwise actions to predict future states of the original nonlinear system. Our estimator is also adaptive to a diffeomorphic transformation of the nonlinear system which enables transfer learning to compute state estimates of the transformed system without relearning from scratch.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/253489dec37ed05e844568d9dae4237b151b936f" target='_blank'>
              Koopman-based Deep Learning for Nonlinear System Estimation
              </a>
            </td>
          <td>
            Zexin Sun, Mingyu Chen, John Baillieul
          </td>
          <td>2024-05-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Large-scale recordings of neural activity over broad anatomical areas with high spatial and temporal resolution are increasingly common in modern experimental neuroscience. Recently, recurrent switching dynamical systems have been used to tackle the scale and complexity of these data. However, an important challenge remains in providing insights into the existence and structure of recurrent linear dynamics in neural time series data. Here we test a scalable approach to time-varying autoregression with low-rank tensors to recover the recurrent dynamics in stochastic neural mass models with multiple stable attractors. We demonstrate that the sparse representation of time-varying system matrices in terms of temporal modes can recover the attractor structure of simple systems via clustering. We then consider simulations based on a human brain connectivity matrix in high and low global connection strength regimes, and reveal the hierarchical clustering structure of the dynamics. Finally, we explain the impact of the forecast time delay on the estimation of the underlying rank and temporal variability of the time series dynamics. This study illustrates that prediction error minimization is not sufficient to recover meaningful dynamic structure and that it is crucial to account for the three key timescales arising from dynamics, noise processes, and attractor switching.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f088ebb7f9998f3b1ef7d954c5cb202f1bab50bc" target='_blank'>
              Identification of Recurrent Dynamics in Distributed Neural Populations
              </a>
            </td>
          <td>
            R. Osuna-Orozco, Edward Castillo, K. Harris, Samantha R. Santacruz
          </td>
          <td>2024-06-01</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>15</td>
        </tr>

        <tr id="Digital twins require computationally-efficient reduced-order models (ROMs) that can accurately describe complex dynamics of physical assets. However, constructing ROMs from noisy high-dimensional data is challenging. In this work, we propose a data-driven, non-intrusive method that utilizes stochastic variational deep kernel learning (SVDKL) to discover low-dimensional latent spaces from data and a recurrent version of SVDKL for representing and predicting the evolution of latent dynamics. The proposed method is demonstrated with two challenging examples -- a double pendulum and a reaction-diffusion system. Results show that our framework is capable of (i) denoising and reconstructing measurements, (ii) learning compact representations of system states, (iii) predicting system evolution in low-dimensional latent spaces, and (iv) quantifying modeling uncertainties.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1e646edf723e20c982f81d29cf479c056b6d42cb" target='_blank'>
              Recurrent Deep Kernel Learning of Dynamical Systems
              </a>
            </td>
          <td>
            N. Botteghi, Paolo Motta, Andrea Manzoni, P. Zunino, Mengwu Guo
          </td>
          <td>2024-05-30</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Koopman operators are infinite-dimensional operators that linearize nonlinear dynamical systems, facilitating the study of their spectral properties and enabling the prediction of the time evolution of observable quantities. Recent methods have aimed to approximate Koopman operators while preserving key structures. However, approximating Koopman operators typically requires a dictionary of observables to capture the system's behavior in a finite-dimensional subspace. The selection of these functions is often heuristic, may result in the loss of spectral information, and can severely complicate structure preservation. This paper introduces Multiplicative Dynamic Mode Decomposition (MultDMD), which enforces the multiplicative structure inherent in the Koopman operator within its finite-dimensional approximation. Leveraging this multiplicative property, we guide the selection of observables and define a constrained optimization problem for the matrix approximation, which can be efficiently solved. MultDMD presents a structured approach to finite-dimensional approximations and can more accurately reflect the spectral properties of the Koopman operator. We elaborate on the theoretical framework of MultDMD, detailing its formulation, optimization strategy, and convergence properties. The efficacy of MultDMD is demonstrated through several examples, including the nonlinear pendulum, the Lorenz system, and fluid dynamics data, where we demonstrate its remarkable robustness to noise.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0cc59f7258cc0c3e219e7edb0f6cbaf13b67c680" target='_blank'>
              Multiplicative Dynamic Mode Decomposition
              </a>
            </td>
          <td>
            Nicolas Boull'e, Matthew J. Colbrook
          </td>
          <td>2024-05-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>16</td>
        </tr>

        <tr id="Identifying differential operators from data is essential for the mathematical modeling of complex physical and biological systems where massive datasets are available. These operators must be stable for accurate predictions for dynamics forecasting problems. In this article, we propose a novel methodology for learning sparse differential operators that are theoretically linearly stable by solving a constrained regression problem. These underlying constraints are obtained following linear stability for dynamical systems. We further extend this approach for learning nonlinear differential operators by determining linear stability constraints for linearized equations around an equilibrium point. The applicability of the proposed method is demonstrated for both linear and nonlinear partial differential equations such as 1-D scalar advection-diffusion equation, 1-D Burgers equation and 2-D advection equation. The results indicated that solutions to constrained regression problems with linear stability constraints provide accurate and linearly stable sparse differential operators.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4ff687c7535d984211e6b3fc207c4c872443a9a0" target='_blank'>
              Data-driven identification of stable differential operators using constrained regression
              </a>
            </td>
          <td>
            Aviral Prakash, Yongjie Jessica Zhang
          </td>
          <td>2024-04-30</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Identifying latent interactions within complex systems is key to unlocking deeper insights into their operational dynamics, including how their elements affect each other and contribute to the overall system behavior. For instance, in neuroscience, discovering neuron-to-neuron interactions is essential for understanding brain function; in ecology, recognizing the interactions among populations is key for understanding complex ecosystems. Such systems, often modeled as dynamical systems, typically exhibit noisy high-dimensional and non-stationary temporal behavior that renders their identification challenging. Existing dynamical system identification methods often yield operators that accurately capture short-term behavior but fail to predict long-term trends, suggesting an incomplete capture of the underlying process. Methods that consider extended forecasts (e.g., recurrent neural networks) lack explicit representations of element-wise interactions and require substantial training data, thereby failing to capture interpretable network operators. Here we introduce Lookahead-driven Inference of Networked Operators for Continuous Stability (LINOCS), a robust learning procedure for identifying hidden dynamical interactions in noisy time-series data. LINOCS integrates several multi-step predictions with adaptive weights during training to recover dynamical operators that can yield accurate long-term predictions. We demonstrate LINOCS' ability to recover the ground truth dynamical operators underlying synthetic time-series data for multiple dynamical systems models (including linear, piece-wise linear, time-changing linear systems' decomposition, and regularized linear time-varying systems) as well as its capability to produce meaningful operators with robust reconstructions through various real-world examples.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f005c8b19ca1d9171afc191fc78b81f136ddfb8c" target='_blank'>
              LINOCS: Lookahead Inference of Networked Operators for Continuous Stability
              </a>
            </td>
          <td>
            Noga Mudrik, Eva Yezerets, Yenho Chen, Christopher Rozell, Adam Charles
          </td>
          <td>2024-04-28</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>2</td>
        </tr>

        <tr id="We introduce the optimized dynamic mode decomposition algorithm for constructing an adaptive and computationally efficient reduced order model and forecasting tool for global atmospheric chemistry dynamics. By exploiting a low-dimensional set of global spatio-temporal modes, interpretable characterizations of the underlying spatial and temporal scales can be computed. Forecasting is also achieved with a linear model that uses a linear superposition of the dominant spatio-temporal features. The DMD method is demonstrated on three months of global chemistry dynamics data, showing its significant performance in computational speed and interpretability. We show that the presented decomposition method successfully extracts known major features of atmospheric chemistry, such as summertime surface pollution and biomass burning activities. Moreover, the DMD algorithm allows for rapid reconstruction of the underlying linear model, which can then easily accommodate non-stationary data and changes in the dynamics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/eafb6d2897f54e1cb6786f47eb557bb66835ba35" target='_blank'>
              Optimized Dynamic Mode Decomposition for Reconstruction and Forecasting of Atmospheric Chemistry Data
              </a>
            </td>
          <td>
            Meghana Velegar, Christoph Keller, J. Kutz
          </td>
          <td>2024-04-13</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>31</td>
        </tr>

        <tr id="Data-driven modeling of dynamical systems often faces numerous data-related challenges. A fundamental requirement is the existence of a unique set of parameters for a chosen model structure, an issue commonly referred to as identifiability. Although this problem is well studied for ordinary differential equations (ODEs), few studies have focused on the more general class of systems described by differential-algebraic equations (DAEs). Examples of DAEs include dynamical systems with algebraic equations representing conservation laws or approximating fast dynamics. This work introduces a novel identifiability test for models characterized by nonlinear DAEs. Unlike previous approaches, our test only requires prior knowledge of the system equations and does not need nonlinear transformation, index reduction, or numerical integration of the DAEs. We employed our identifiability analysis across a diverse range of DAE models, illustrating how system identifiability depends on the choices of sensors, experimental conditions, and model structures. Given the added challenges involved in identifying DAEs when compared to ODEs, we anticipate that our findings will have broad applicability and contribute significantly to the development and validation of data-driven methods for DAEs and other structure-preserving models.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/37947bd9315cd7b127f395007520d352fb1efed0" target='_blank'>
              Identifiability of Differential-Algebraic Systems
              </a>
            </td>
          <td>
            A. Montanari, Franccois Lamoline, Robert Bereza, Jorge Gonccalves
          </td>
          <td>2024-05-22</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Linearity of Koopman operators and simplicity of their estimators coupled with model-reduction capabilities has lead to their great popularity in applications for learning dynamical systems. While nonparametric Koopman operator learning in infinite-dimensional reproducing kernel Hilbert spaces is well understood for autonomous systems, its control system analogues are largely unexplored. Addressing systems with control inputs in a principled manner is crucial for fully data-driven learning of controllers, especially since existing approaches commonly resort to representational heuristics or parametric models of limited expressiveness and scalability. We address the aforementioned challenge by proposing a universal framework via control-affine reproducing kernels that enables direct estimation of a single operator even for control systems. The proposed approach, called control-Koopman operator regression (cKOR), is thus completely analogous to Koopman operator regression of the autonomous case. First in the literature, we present a nonparametric framework for learning Koopman operator representations of nonlinear control-affine systems that does not suffer from the curse of control input dimensionality. This allows for reformulating the infinite-dimensional learning problem in a finite-dimensional space based solely on data without apriori loss of precision due to a restriction to a finite span of functions or inputs as in other approaches. For enabling applications to large-scale control systems, we also enhance the scalability of control-Koopman operator estimators by leveraging random projections (sketching). The efficacy of our novel cKOR approach is demonstrated on both forecasting and control tasks.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6527db73e0af15e2dff15cbf1ecfc8adfcdd5716" target='_blank'>
              Nonparametric Control-Koopman Operator Learning: Flexible and Scalable Models for Prediction and Control
              </a>
            </td>
          <td>
            Petar Bevanda, Bas Driessen, Lucian-Cristian Iacob, Roland Toth, Stefan Sosnowski, Sandra Hirche
          </td>
          <td>2024-05-12</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>15</td>
        </tr>

        <tr id="In one calculation, adjoint sensitivity analysis provides the gradient of a quantity of interest with respect to all system's parameters. Conventionally, adjoint solvers need to be implemented by differentiating computational models, which can be a cumbersome task and is code-specific. To propose an adjoint solver that is not code-specific, we develop a data-driven strategy. We demonstrate its application on the computation of gradients of long-time averages of chaotic flows. First, we deploy a parameter-aware echo state network (ESN) to accurately forecast and simulate the dynamics of a dynamical system for a range of system's parameters. Second, we derive the adjoint of the parameter-aware ESN. Finally, we combine the parameter-aware ESN with its adjoint version to compute the sensitivities to the system parameters. We showcase the method on a prototypical chaotic system. Because adjoint sensitivities in chaotic regimes diverge for long integration times, we analyse the application of ensemble adjoint method to the ESN. We find that the adjoint sensitivities obtained from the ESN match closely with the original system. This work opens possibilities for sensitivity analysis without code-specific adjoint solvers.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/553a6afc439089894b231b44d32efab776f1e7b8" target='_blank'>
              Adjoint Sensitivities of Chaotic Flows without Adjoint Solvers: A Data-Driven Approach
              </a>
            </td>
          <td>
            D. E. Ozan, Luca Magri
          </td>
          <td>2024-04-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Data-driven modelling techniques provide a method for deriving models of dynamical systems directly from complicated data streams. However, tracking and forecasting such data streams poses a significant challenge to most methods, as they assume the underlying process and model does not change over time. In this paper, we apply one such data-driven method, the Koopman autoencoder (KAE), to high-dimensional oscillatory data to generate a low-dimensional latent space and model, where the system's dynamics appear linear. This allows one to accurately track and forecast systems where the underlying model may change over time. States and the model in the reduced order latent space can then be efficiently updated as new data becomes available, using data assimilation techniques such as the ensemble Kalman filter (EnKF), in a technique we call the KAE EnKF. We demonstrate that this approach is able to effectively track and forecast time-varying, nonlinear dynamical systems in synthetic examples. We then apply the KAE EnKF to a video of a physical pendulum, and achieve a significant improvement over current state-of-the-art methods. By generating effective latent space reconstructions, we find that we are able to construct accurate short-term forecasts and efficient adaptations to externally forced changes to the pendulum's frequency.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/be5728bd13fd3650c966df73ef5772bf8b905261" target='_blank'>
              Tracking and forecasting oscillatory data streams using Koopman autoencoders and Kalman filtering
              </a>
            </td>
          <td>
            Stephen A Falconer, David J. B. Lloyd, N. Santitissadeekorn
          </td>
          <td>2024-05-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>11</td>
        </tr>

        <tr id="Throughout many fields, practitioners often rely on differential equations to model systems. Yet, for many applications, the theoretical derivation of such equations and/or accurate resolution of their solutions may be intractable. Instead, recently developed methods, including those based on parameter estimation, operator subset selection, and neural networks, allow for the data-driven discovery of both ordinary and partial differential equations (PDEs), on a spectrum of interpretability. The success of these strategies is often contingent upon the correct identification of representative equations from noisy observations of state variables and, as importantly and intertwined with that, the mathematical strategies utilized to enforce those equations. Specifically, the latter has been commonly addressed via unconstrained optimization strategies. Representing the PDE as a neural network, we propose to discover the PDE by solving a constrained optimization problem and using an intermediate state representation similar to a Physics-Informed Neural Network (PINN). The objective function of this constrained optimization problem promotes matching the data, while the constraints require that the PDE is satisfied at several spatial collocation points. We present a penalty method and a widely used trust-region barrier method to solve this constrained optimization problem, and we compare these methods on numerical examples. Our results on the Burgers' and the Korteweg-De Vreis equations demonstrate that the latter constrained method outperforms the penalty method, particularly for higher noise levels or fewer collocation points. For both methods, we solve these discovered neural network PDEs with classical methods, such as finite difference methods, as opposed to PINNs-type methods relying on automatic differentiation. We briefly highlight other small, yet crucial, implementation details.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6963a35d67c967bd32de2a44d317d62f7394fba6" target='_blank'>
              Constrained or Unconstrained? Neural-Network-Based Equation Discovery from Data
              </a>
            </td>
          <td>
            Grant Norman, Jacqueline Wentz, H. Kolla, K. Maute, Alireza Doostan
          </td>
          <td>2024-05-30</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>51</td>
        </tr>

        <tr id="Deep learning algorithms provide a new paradigm to study high-dimensional dynamical behaviors, such as those in fusion plasma systems. Development of novel model reduction methods, coupled with detection of abnormal modes with plasma physics, opens a unique opportunity for building efficient models to identify plasma instabilities for real-time control. Our Fusion Transfer Learning (FTL) model demonstrates success in reconstructing nonlinear kink mode structures by learning from a limited amount of nonlinear simulation data. The knowledge transfer process leverages a pre-trained neural encoder-decoder network, initially trained on linear simulations, to effectively capture nonlinear dynamics. The low-dimensional embeddings extract the coherent structures of interest, while preserving the inherent dynamics of the complex system. Experimental results highlight FTL's capacity to capture transitional behaviors and dynamical features in plasma dynamics -- a task often challenging for conventional methods. The model developed in this study is generalizable and can be extended broadly through transfer learning to address various magnetohydrodynamics (MHD) modes.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c07715bd86e219597bf8c42b1d974b4316c9ebd8" target='_blank'>
              FTL: Transfer Learning Nonlinear Plasma Dynamic Transitions in Low Dimensional Embeddings via Deep Neural Networks
              </a>
            </td>
          <td>
            Zhe Bai, Xishuo Wei, William Tang, L. Oliker, Zhihong Lin, Samuel Williams
          </td>
          <td>2024-04-26</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>45</td>
        </tr>

        <tr id="In many real-world applications where the system dynamics has an underlying interdependency among its variables (such as power grid, economics, neuroscience, omics networks, environmental ecosystems, and others), one is often interested in knowing whether the past values of one time series influences the future of another, known as Granger causality, and the associated underlying dynamics. This paper introduces a Koopman-inspired framework that leverages neural networks for data-driven learning of the Koopman bases, termed NeuroKoopman Dynamic Causal Discovery (NKDCD), for reliably inferring the Granger causality along with the underlying nonlinear dynamics. NKDCD employs an autoencoder architecture that lifts the nonlinear dynamics to a higher dimension using data-learned bases, where the lifted time series can be reliably modeled linearly. The lifting function, the linear Granger causality lag matrices, and the projection function (from lifted space to base space) are all represented as multilayer perceptrons and are all learned simultaneously in one go. NKDCD also utilizes sparsity-inducing penalties on the weights of the lag matrices, encouraging the model to select only the needed causal dependencies within the data. Through extensive testing on practically applicable datasets, it is shown that the NKDCD outperforms the existing nonlinear Granger causality discovery approaches.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2063b00f6c1d0ea80dc4fa01e9b3b3bddc847ea9" target='_blank'>
              NeuroKoopman Dynamic Causal Discovery
              </a>
            </td>
          <td>
            Rahmat Adesunkanmi, Balaji Sesha Srikanth Pokuri, Ratnesh Kumar
          </td>
          <td>2024-04-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Symbolic Regression (SR) is a widely studied field of research that aims to infer symbolic expressions from data. A popular approach for SR is the Sparse Identification of Nonlinear Dynamical Systems (\sindy) framework, which uses sparse regression to identify governing equations from data. This study introduces an enhanced method, Nested SINDy, that aims to increase the expressivity of the SINDy approach thanks to a nested structure. Indeed, traditional symbolic regression and system identification methods often fail with complex systems that cannot be easily described analytically. Nested SINDy builds on the SINDy framework by introducing additional layers before and after the core SINDy layer. This allows the method to identify symbolic representations for a wider range of systems, including those with compositions and products of functions. We demonstrate the ability of the Nested SINDy approach to accurately find symbolic expressions for simple systems, such as basic trigonometric functions, and sparse (false but accurate) analytical representations for more complex systems. Our results highlight Nested SINDy's potential as a tool for symbolic regression, surpassing the traditional SINDy approach in terms of expressivity. However, we also note the challenges in the optimization process for Nested SINDy and suggest future research directions, including the designing of a more robust methodology for the optimization process. This study proves that Nested SINDy can effectively discover symbolic representations of dynamical systems from data, offering new opportunities for understanding complex systems through data-driven methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5ef8aa10b07c62bde12d142106068d2ffd9e7414" target='_blank'>
              Generalizing the SINDy approach with nested neural networks
              </a>
            </td>
          <td>
            Camilla Fiorini, Cl'ement Flint, Louis Fostier, Emmanuel Franck, Reyhaneh Hashemi, Victor Michel-Dansac, Wassim Tenachi
          </td>
          <td>2024-04-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Several related works have introduced Koopman-based Machine Learning architectures as a surrogate model for dynamical systems. These architectures aim to learn non-linear measurements (also known as observables) of the system's state that evolve by a linear operator and are, therefore, amenable to model-based linear control techniques. So far, mainly simple systems have been targeted, and Koopman architectures as reduced-order models for more complex dynamics have not been fully explored. Hence, we use a Koopman-inspired architecture called the Linear Recurrent Autoencoder Network (LRAN) for learning reduced-order dynamics in convection flows of a Rayleigh B\'enard Convection (RBC) system at different amounts of turbulence. The data is obtained from direct numerical simulations of the RBC system. A traditional fluid dynamics method, the Kernel Dynamic Mode Decomposition (KDMD), is used to compare the LRAN. For both methods, we performed hyperparameter sweeps to identify optimal settings. We used a Normalized Sum of Square Error measure for the quantitative evaluation of the models, and we also studied the model predictions qualitatively. We obtained more accurate predictions with the LRAN than with KDMD in the most turbulent setting. We conjecture that this is due to the LRAN's flexibility in learning complicated observables from data, thereby serving as a viable surrogate model for the main structure of fluid dynamics in turbulent convection settings. In contrast, KDMD was more effective in lower turbulence settings due to the repetitiveness of the convection flow. The feasibility of Koopman-based surrogate models for turbulent fluid flows opens possibilities for efficient model-based control techniques useful in a variety of industrial settings.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b14d40f8f539b3f8e07c3779360a96930d9f97db" target='_blank'>
              Koopman-Based Surrogate Modelling of Turbulent Rayleigh-B\'enard Convection
              </a>
            </td>
          <td>
            Thorben Markmann, Michiel Straat, Barbara Hammer
          </td>
          <td>2024-05-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="The rapid expansion of wind power worldwide underscores the critical significance of engineering-focused analytical wake models in both the design and operation of wind farms. These theoretically-derived ana lytical wake models have limited predictive capabilities, particularly in the near-wake region close to the turbine rotor, due to assumptions that do not hold. Knowledge discovery methods can bridge these gaps by extracting insights, adjusting for theoretical assumptions, and developing accurate models for physical processes. In this study, we introduce a genetic symbolic regression (SR) algorithm to discover an interpretable mathematical expression for the mean velocity deficit throughout the wake, a previously unavailable insight. By incorporating a double Gaussian distribution into the SR algorithm as domain knowledge and designing a hierarchical equation structure, the search space is reduced, thus efficiently finding a concise, physically informed, and robust wake model. The proposed mathematical expression (equation) can predict the wake velocity deficit at any location in the full-wake region with high precision and stability. The model's effectiveness and practicality are validated through experimental data and high-fidelity numerical simulations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e537a524b33a90230cd36129f3bb9df0fd47f910" target='_blank'>
              Discovering an interpretable mathematical expression for a full wind-turbine wake with artificial intelligence enhanced symbolic regression
              </a>
            </td>
          <td>
            Ding Wang, Yuntian Chen, Shiyi Chen
          </td>
          <td>2024-06-02</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Increasing effort is put into the development of methods for learning mechanistic models from data. This task entails not only the accurate estimation of parameters, but also a suitable model structure. Recent work on the discovery of dynamical systems formulates this problem as a linear equation system. Here, we explore several simulation-based optimization approaches, which allow much greater freedom in the objective formulation and weaker conditions on the available data. We show that even for relatively small stochastic population models, simultaneous estimation of parameters and structure poses major challenges for optimization procedures. Particularly, we investigate the application of the local stochastic gradient descent method, commonly used for training machine learning models. We demonstrate accurate estimation of models but find that enforcing the inference of parsimonious, interpretable models drastically increases the difficulty. We give an outlook on how this challenge can be overcome.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/69f3306c5d346d91ce086b55f87d085d98c721dd" target='_blank'>
              Towards Learning Stochastic Population Models by Gradient Descent
              </a>
            </td>
          <td>
            J. N. Kreikemeyer, Philipp Andelfinger, A. Uhrmacher
          </td>
          <td>2024-04-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>31</td>
        </tr>

        <tr id="
 In this work, we consider the problem of learning a reduced-order model of a high-dimensional stochastic nonlinear system with control inputs from noisy data. In particular, we develop a hybrid parametric/non-parametric model that learns the “average” linear dynamics in the data using dynamic mode decomposition with control (DMDc) and the nonlinearities and model uncertainties using Gaussian process (GP) regression and compare it with total least squares dynamic mode decomposition, extended here to systems with control inputs (tlsDMDc). The proposed approach is also compared with existing methods, such as DMDc-only and GP-only models, in two tasks: controlling the stochastic nonlinear Stuart-Landau equation and predicting the flowfield induced by a jet-like body force field in a turbulent boundary layer using data from large-scale numerical simulations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3159326ad063440b49d097ce814e17712e736c69" target='_blank'>
              Dynamic Mode Decomposition with Gaussian Process Regression for Control of High-Dimensional Nonlinear Systems
              </a>
            </td>
          <td>
            Alexandros Tsolovikos, E. Bakolas, David Goldstein
          </td>
          <td>2024-05-24</td>
          <td>Journal of Dynamic Systems, Measurement and Control</td>
          <td>1</td>
          <td>19</td>
        </tr>

        <tr id="In this paper, we consider the design of data-driven predictive controllers for nonlinear systems from input-output data via linear-in-control input Koopman lifted models. Instead of identifying and simulating a Koopman model to predict future outputs, we design a subspace predictive controller in the Koopman space. This allows us to learn the observables minimizing the multi-step output prediction error of the Koopman subspace predictor, preventing the propagation of prediction errors. To avoid losing feasibility of our predictive control scheme due to prediction errors, we compute a terminal cost and terminal set in the Koopman space and we obtain recursive feasibility guarantees through an interpolated initial state. As a third contribution, we introduce a novel regularization cost yielding input-to-state stability guarantees with respect to the prediction error for the resulting closed-loop system. The performance of the developed Koopman data-driven predictive control methodology is illustrated on a nonlinear benchmark example from the literature.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bf5ac27ebe1f37285c1d7a4518dacc14d7c81c12" target='_blank'>
              Koopman Data-Driven Predictive Control with Robust Stability and Recursive Feasibility Guarantees
              </a>
            </td>
          <td>
            T. D. Jong, V. Breschi, Maarten Schoukens, Mircea Lazar
          </td>
          <td>2024-05-02</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Fluid dynamics systems driven by dominant, nearly periodic large-scale dynamics are common across wakes, jets, rotating machinery, and high-speed flows. Traditional decomposition techniques such as proper orthogonal decomposition and dynamic mode decomposition have been used to gain insight into these flows, but can require many modes to represent physical processes. With the aim of generating modes that intuitively convey the underlying physical mechanisms, we propose an intrinsic phase-based proper orthogonal decomposition (IPhaB POD) method. IPhaB POD creates energetically ranked modes that evolve along a characteristic cycle of a driving near-periodic large scale. Our proposed formulation is set in the time domain, which is particularly useful in cases where the large-scale dynamics are imperfectly periodic. We formally derive IPhaB POD within a proper orthogonal decomposition framework, and it inherits the optimal representation inherent to POD. As part of this derivation, a dynamical systems representation of the large scale is utilized, facilitating a definition of phase relative to the large scale within the time domain. An expectation operator and inner product are also constructed relative to this definition of phase in a manner that allows for the various cycles within the data to demonstrate imperfect periodicity. The formulation is tested on two sample problems: a simple, low Reynolds number airfoil wake, and a complex, high-speed pulsating shock wave problem. The resulting modes are shown to better isolate the large-scale dynamics in the first mode than space-only proper orthogonal decomposition, and to highlight meaningful small-scale dynamics in higher modes for the shock flow problem.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8599bb13ba943daa8faca82ff974b128401e0ae4" target='_blank'>
              Intrinsic phase based proper orthogonal decomposition (IPhaB POD): a method for physically interpretable modes in near-periodic systems
              </a>
            </td>
          <td>
            A. Borra, Zoey Flynn, Andres Goza, T. Saxton-Fox
          </td>
          <td>2024-05-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Modeling complex systems using standard neural ordinary differential equations (NODEs) often faces some essential challenges, including high computational costs and susceptibility to local optima. To address these challenges, we propose a simulation-free framework, called Fourier NODEs (FNODEs), that effectively trains NODEs by directly matching the target vector field based on Fourier analysis. Specifically, we employ the Fourier analysis to estimate temporal and potential high-order spatial gradients from noisy observational data. We then incorporate the estimated spatial gradients as additional inputs to a neural network. Furthermore, we utilize the estimated temporal gradient as the optimization objective for the output of the neural network. Later, the trained neural network generates more data points through an ODE solver without participating in the computational graph, facilitating more accurate estimations of gradients based on Fourier analysis. These two steps form a positive feedback loop, enabling accurate dynamics modeling in our framework. Consequently, our approach outperforms state-of-the-art methods in terms of training time, dynamics prediction, and robustness. Finally, we demonstrate the superior performance of our framework using a number of representative complex systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/96bedb3203006239c598b64a69777f9f9b9613ed" target='_blank'>
              From Fourier to Neural ODEs: Flow Matching for Modeling Complex Systems
              </a>
            </td>
          <td>
            Xin Li, Jingdong Zhang, Qunxi Zhu, Chengli Zhao, Xue Zhang, Xiaojun Duan, Wei Lin
          </td>
          <td>2024-05-19</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="The sudden onset of deleterious and oscillatory dynamics (often called instabilities) is a known challenge in many fluid, plasma, and aerospace systems. These dynamics are difficult to address because they are nonlinear, chaotic, and are often too fast for active control schemes. In this work, we develop an alternative active controls system using an iterative, trajectory-optimization and parameter-tuning approach based on Iterative Learning Control (ILC), Time-Lagged Phase Portraits (TLPP) and Gaussian Process Regression (GPR). The novelty of this approach is that it can control a system's dynamics despite the controller being much slower than the dynamics. We demonstrate this controller on the Lorenz system of equations where it iteratively adjusts (tunes) the system's input parameters to successfully reproduce a desired oscillatory trajectory or state. Additionally, we investigate the system's dynamical sensitivity to its control parameters, identify continuous and bounded regions of desired dynamical trajectories, and demonstrate that the controller is robust to missing information and uncontrollable parameters as long as certain requirements are met. The controller presented in this work provides a framework for low-speed control for a variety of fast, nonlinear systems that may aid in instability suppression and mitigation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/806d268cbe72c61b22fdea616e8a5d1253679d77" target='_blank'>
              Iterative Learning Control of Fast, Nonlinear, Oscillatory Dynamics (Preprint)
              </a>
            </td>
          <td>
            John W. Brooks, Christine M. Greve
          </td>
          <td>2024-05-30</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="A problem in nonlinear and complex dynamical systems with broad applications is forecasting the occurrence of a critical transition based solely on data without knowledge about the system equations. When such a transition leads to system collapse, as often is the case, all the available data are from the pre-critical regime where the system still functions normally, making the prediction problem challenging. In recent years, a machine-learning based approach tailored to solving this difficult prediction problem, adaptable reservoir computing, has been articulated. This Perspective introduces the basics of this machine-learning scheme and describes representative results. The general setting is that the system dynamics live on a normal attractor with oscillatory dynamics at the present time and, as a bifurcation parameter changes into the future, a critical transition can occur after which the system switches to a completely different attractor, signifying system collapse. To predict a critical transition, it is essential that the reservoir computer not only learns the dynamical "climate" of the system of interest at some specific parameter value but, more importantly, discovers how the system dynamics changes with the bifurcation parameter. It is demonstrated that this capability can be endowed into the machine through a training process with time series from a small number of distinct, pre-critical parameter values, thereby enabling accurate and reliable prediction of the catastrophic critical transition. Three applications are presented: predicting crisis, forecasting amplitude death, and creating digital twins of nonlinear dynamical systems. Limitations and future perspectives are discussed.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f1749f284391bc6f9be0f2b8f564c797144a8e75" target='_blank'>
              Adaptable reservoir computing: A paradigm for model-free data-driven prediction of critical transitions in nonlinear dynamical systems.
              </a>
            </td>
          <td>
            Shirin Panahi, Ying-Cheng Lai
          </td>
          <td>2024-05-01</td>
          <td>Chaos</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Reduced order modeling lowers the computational cost of solving PDEs by learning a low-order spatial representation from data and dynamically evolving these representations using manifold projections of the governing equations. While commonly used, linear subspace reduced-order models (ROMs) are often suboptimal for problems with a slow decay of Kolmogorov $n$-width, such as advection-dominated fluid flows at high Reynolds numbers. There has been a growing interest in nonlinear ROMs that use state-of-the-art representation learning techniques to accurately capture such phenomena with fewer degrees of freedom. We propose smooth neural field ROM (SNF-ROM), a nonlinear reduced modeling framework that combines grid-free reduced representations with Galerkin projection. The SNF-ROM architecture constrains the learned ROM trajectories to a smoothly varying path, which proves beneficial in the dynamics evaluation when the reduced manifold is traversed in accordance with the governing PDEs. Furthermore, we devise robust regularization schemes to ensure the learned neural fields are smooth and differentiable. This allows us to compute physics-based dynamics of the reduced system nonintrusively with automatic differentiation and evolve the reduced system with classical time-integrators. SNF-ROM leads to fast offline training as well as enhanced accuracy and stability during the online dynamics evaluation. We demonstrate the efficacy of SNF-ROM on a range of advection-dominated linear and nonlinear PDE problems where we consistently outperform state-of-the-art ROMs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ebfe58e219e7e8e09cb69349f7a2730818dcf028" target='_blank'>
              SNF-ROM: Projection-based nonlinear reduced order modeling with smooth neural fields
              </a>
            </td>
          <td>
            Vedant Puri, Aviral Prakash, L. Kara, Yongjie Jessica Zhang
          </td>
          <td>2024-05-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>28</td>
        </tr>

        <tr id="Data assimilation aims to estimate the states of a dynamical system by optimally combining sparse and noisy observations of the physical system with uncertain forecasts produced by a computational model. The states of many dynamical systems of interest obey nonlinear physical constraints, and the corresponding dynamics is confined to a certain sub-manifold of the state space. Standard data assimilation techniques applied to such systems yield posterior states lying outside the manifold, violating the physical constraints. This work focuses on particle flow filters which use stochastic differential equations to evolve state samples from a prior distribution to samples from an observation-informed posterior distribution. The variational Fokker-Planck (VFP) -- a generic particle flow filtering framework -- is extended to incorporate non-linear, equality state constraints in the analysis. To this end, two algorithmic approaches that modify the VFP stochastic differential equation are discussed: (i) VFPSTAB, to inexactly preserve constraints with the addition of a stabilizing drift term, and (ii) VFPDAE, to exactly preserve constraints by treating the VFP dynamics as a stochastic differential-algebraic equation (SDAE). Additionally, an implicit-explicit time integrator is developed to evolve the VFPDAE dynamics. The strength of the proposed approach for constraint preservation in data assimilation is demonstrated on three test problems: the double pendulum, Korteweg-de-Vries, and the incompressible Navier-Stokes equations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/15f8d797779bc932cdc0bb4020bb6cb273b8cfa5" target='_blank'>
              Preserving Nonlinear Constraints in Variational Flow Filtering Data Assimilation
              </a>
            </td>
          <td>
            Amit N. Subrahmanya, Andrey A. Popov, Reid J. Gomillion, Adrian Sandu
          </td>
          <td>2024-05-07</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Delay Differential Equations (DDEs) are a class of differential equations that can model diverse scientific phenomena. However, identifying the parameters, especially the time delay, that make a DDE's predictions match experimental results can be challenging. We introduce DDE-Find, a data-driven framework for learning a DDE's parameters, time delay, and initial condition function. DDE-Find uses an adjoint-based approach to efficiently compute the gradient of a loss function with respect to the model parameters. We motivate and rigorously prove an expression for the gradients of the loss using the adjoint. DDE-Find builds upon recent developments in learning DDEs from data and delivers the first complete framework for learning DDEs from data. Through a series of numerical experiments, we demonstrate that DDE-Find can learn DDEs from noisy, limited data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/cefa8b57028db46c2e35c60bea8a1a30100e7143" target='_blank'>
              DDE-Find: Learning Delay Differential Equations from Noisy, Limited Data
              </a>
            </td>
          <td>
            Robert Stephany
          </td>
          <td>2024-05-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The ability to automatically discover interpretable mathematical models from data could forever change how we model soft matter systems. For convex discovery problems with a unique global minimum, model discovery is well-established. It uses a classical top-down approach that first calculates a dense parameter vector, and then sparsifies the vector by gradually removing terms. For non-convex discovery problems with multiple local minima, this strategy is infeasible since the initial parameter vector is generally non-unique. Here we propose a novel bottom-up approach that starts with a sparse single-term vector, and then densifies the vector by systematically adding terms. Along the way, we discover models of gradually increasing complexity, a strategy that we call best-in-class modeling. To identify successful candidate terms, we reverse-engineer a library of sixteen functional building blocks that integrate a century of knowledge in material modeling with recent trends in machine learning and artificial intelligence. Yet, instead of solving the discrete combinatorial problem with 65,536 possible combinations of terms, best-in-class modeling starts with the best one-term model and iteratively repeats adding terms, until the objective function meets a user-defined convergence criterion. Strikingly, we achieve good convergence with only one or two terms. We illustrate the best-in-class one- and two-term models for a variety of soft matter systems including rubber, brain, artificial meat, skin, and arteries. Our discovered models display distinct and unexpected features for each family of materials, and suggest that best-in-class modeling is an efficient, robust, and easy-to-use strategy to discover the mechanical signatures of traditional and unconventional soft materials. We anticipate that our technology will generalize naturally to other classes of natural and man-made soft matter.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/200655dc975e870e69368b9f30fdb78bdcd351ea" target='_blank'>
              Best-in-class modeling: A novel strategy to discover constitutive models for soft matter systems
              </a>
            </td>
          <td>
            K. Linka, E. Kuhl
          </td>
          <td>2024-04-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>19</td>
        </tr>

        <tr id="Pharmacometric models are pivotal across drug discovery and development, playing a decisive role in determining the progression of candidate molecules. However, the derivation of mathematical equations governing the system is a labor-intensive trial-and-error process, often constrained by tight timelines. In this study, we introduce PKINNs, a novel purely data-driven pharmacokinetic-informed neural network model. PKINNs efficiently discovers and models intrinsic multi-compartment-based pharmacometric structures, reliably forecasting their derivatives. The resulting models are both interpretable and explainable through Symbolic Regression methods. Our computational framework demonstrates the potential for closed-form model discovery in pharmacometric applications, addressing the labor-intensive nature of traditional model derivation. With the increasing availability of large datasets, this framework holds the potential to significantly enhance model-informed drug discovery.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1ecec2c77f9d85a4e75c8a8de808c4d916ca0015" target='_blank'>
              Discovering intrinsic multi-compartment pharmacometric models using Physics Informed Neural Networks
              </a>
            </td>
          <td>
            I. Nasim, Adam Nasim
          </td>
          <td>2024-04-30</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="One of the central goals of neuroscience is to gain a mechanistic understanding of how the dynamics of neural circuits give rise to their observed function. A popular approach towards this end is to train recurrent neural networks (RNNs) to reproduce experimental recordings of neural activity. These trained RNNs are then treated as surrogate models of biological neural circuits, whose properties can be dissected via dynamical systems analysis. How reliable are the mechanistic insights derived from this procedure? While recent advances in population-level recording technologies have allowed simultaneous recording of up to tens of thousands of neurons, this represents only a tiny fraction of most cortical circuits. Here we show that observing only a subset of neurons in a circuit can create mechanistic mismatches between a simulated teacher network and a data-constrained student, even when the two networks have matching single-unit dynamics. In particular, partial observation of models of low-dimensional cortical dynamics based on functionally feedforward or low-rank connectivity can lead to surrogate models with spurious attractor structure. Our results illustrate the challenges inherent in accurately uncovering neural mechanisms from single-trial data, and suggest the need for new methods of validating data-constrained models for neural dynamics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d6ff706d2507265f316f84e0d354f6a7ce5c6f8a" target='_blank'>
              Partial observation can induce mechanistic mismatches in data-constrained models of neural dynamics
              </a>
            </td>
          <td>
            William Qian, Jacob A. Zavatone-Veth, Benjamin S. Ruben, C. Pehlevan
          </td>
          <td>2024-05-26</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>24</td>
        </tr>

        <tr id="Partial differential equation parameter estimation is a mathematical and computational process used to estimate the unknown parameters in a partial differential equation model from observational data. This paper employs a greedy sampling approach based on the Discrete Empirical Interpolation Method to identify the most informative samples in a dataset associated with a partial differential equation to estimate its parameters. Greedy samples are used to train a physics-informed neural network architecture which maps the nonlinear relation between spatio-temporal data and the measured values. To prove the impact of greedy samples on the training of the physics-informed neural network for parameter estimation of a partial differential equation, their performance is compared with random samples taken from the given dataset. Our simulation results show that for all considered partial differential equations, greedy samples outperform random samples, i.e., we can estimate parameters with a significantly lower number of samples while simultaneously reducing the relative estimation error. A Python package is also prepared to support different phases of the proposed algorithm, including data prepossessing, greedy sampling, neural network training, and comparison.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9ec87e0f1b224783d185d7b296dcb80121b11493" target='_blank'>
              GS-PINN: Greedy Sampling for Parameter Estimation in Partial Differential Equations
              </a>
            </td>
          <td>
            A. Forootani, Harshit Kapadia, Sridhar Chellappa, P. Goyal, Peter Benner
          </td>
          <td>2024-05-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>14</td>
        </tr>

        <tr id="The ability to measure differences in collected data is of fundamental importance for quantitative science and machine learning, motivating the establishment of metrics grounded in physical principles. In this study, we focus on the development of such metrics for viscoelastic fluid flows governed by a large class of linear and nonlinear stress models. To do this, we introduce a kernel function corresponding to a given viscoelastic stress model that implicitly embeds flowfield snapshots into a Reproducing Kernel Hilbert Space (RKHS) whose squared norm equals the total mechanical energy. Working implicitly with lifted representations in the RKHS via the kernel function provides natural and unambiguous metrics for distances and angles between flowfields without the need for hyperparameter tuning. Additionally, we present a solution to the preimage problem for our kernels, enabling accurate reconstruction of flowfields from their RKHS representations. Through numerical experiments on an unsteady viscoelastic lid-driven cavity flow, we demonstrate the utility of our kernels for extracting energetically-dominant coherent structures in viscoelastic flows across a range of Reynolds and Weissenberg numbers. Specifically, the features extracted by Kernel Principal Component Analysis (KPCA) of flowfield snapshots using our kernel functions yield reconstructions with superior accuracy in terms of mechanical energy compared to conventional methods such as ordinary Principal Component Analysis (PCA) with na\"ively-defined state vectors or KPCA with ad-hoc choices of kernel functions. Our findings underscore the importance of principled choices of metrics in both scientific and machine learning investigations of complex fluid systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/fa0602282d2da4dfe0c28a52a63f971fa7313c78" target='_blank'>
              Machine Learning in Viscoelastic Fluids via Energy-Based Kernel Embedding
              </a>
            </td>
          <td>
            Samuel E. Otto, C. Oishi, Fabio Amaral, S. Brunton, J. Kutz
          </td>
          <td>2024-04-22</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>62</td>
        </tr>

        <tr id="Most works related to the identification of mathematical nonlinear systems suggest that such approaches can always be directly applied to any nonlinear system. This misconception is greatly discouraging when the obtained results are not expected. Thus, the current work hypothesizes that the more information one has about the mathematical structure of the model, the most precise the identification result. Therefore, a variant of the Sparse Identification of Nonlinear Dynamics (SINDY) approach is presented to obtain the full mathematical nonlinear model of a high-order system with coupled dynamics, namely, a commercial quadcopter. Furthermore, due to its high sensitivity to inputs, a control system is devised using the identified model to stabilize the quadcopter. This illustrates the effectiveness of the proposed identification method.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1f45ada23e332855a44656d4370f8837a1a19d8d" target='_blank'>
              Identification of High-Order Nonlinear Coupled Systems Using a Data-Driven Approach
              </a>
            </td>
          <td>
            Rodolfo Daniel Velázquez-Sánchez, J. O. Escobedo-Alva, Raymundo Peña-García, R. Tapia-Herrera, J. Meda-Campaña
          </td>
          <td>2024-04-30</td>
          <td>Applied Sciences</td>
          <td>0</td>
          <td>19</td>
        </tr>

        <tr id="Systems biology tackles the challenge of understanding the high complexity in the internal regulation of homeostasis in the human body through mathematical modelling. These models can aid in the discovery of disease mechanisms and potential drug targets. However, on one hand the development and validation of knowledge-based mechanistic models is time-consuming and does not scale well with increasing features in medical data. On the other hand, more data-driven approaches such as machine learning models require large volumes of data to produce generalizable models. The integration of neural networks and mechanistic models, forming universal differential equation (UDE) models, enables the automated learning of unknown model terms with less data than the neural network alone. Nevertheless, estimating parameters for these hybrid models remains difficult with sparse data and limited sampling durations that are common in biological applications. In this work, we propose the use of physiology-informed regularization, penalizing biologically implausible model behavior to guide the UDE towards more physiologically plausible regions of the solution space. In a simulation study we show that physiology-informed regularization not only results in a more accurate forecasting of model behaviour, but also supports training with less data. We also applied this technique to learn a representation of the rate of glucose appearance in the glucose minimal model using meal response data measured in healthy people. In that case, the inclusion of regularization reduces variability between UDE-embedded neural networks that were trained from different initial parameter guesses. Author summary Systems biology concerns the modelling and analysis of biological processes, by viewing these as interconnected systems. Modelling is typically done either using mechanistic differential equations that are derived from experiments and known biology, or using machine learning on large biological datasets. While mathematical modelling from biological experiments can provide useful insights with limited data, building and validating these models takes a long time and often requires highly invasive measurements in humans. Efforts to combine this classical technique with machine learning have resulted in a framework termed universal differential equations, where the model equations contain a neural network to describe unknown biological interactions. While these methods have shown success in numerous fields, applications in biology are more challenging due to limited data-availability, high data sparsity. In this work, we have introduced physiology-informed regularization to overcome these instabilities and to constrain the model to biologically plausible behavior. Our results show that by using physiology-informed regularization, we can accurately predict future unseen observations in a simulated example, with much more limited data than a similar model without regularization. Additionally, we show an application of this technique on human data, applying a neural network to learn the appearance of glucose in the blood plasma after a meal.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0ddf0dda21d3a8fbe599f98eed4fe943aa342f41" target='_blank'>
              Physiology-informed regularization enables training of universal differential equation systems for biological applications
              </a>
            </td>
          <td>
            Max de Rooij, Balázs Erdős, N. V. van Riel, Shauna D. O’Donovan
          </td>
          <td>2024-06-01</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="The meaningful problem of improving crane safety, reliability, and efficiency is extensively studied in the literature and targeted via various model-based control approaches. In recent years, crane data-driven modeling has attracted much attention compared to physics-based models, particularly due to its potential in real-time crane control applications, specifically in model predictive control. This paper proposes grammar-guided genetic programming with sparse regression (G3P-SR) to identify the nonlinear dynamics of an underactuated crane system. G3P-SR uses grammars to bias the search space and produces a fixed number of candidate model terms, while a local search method based on an l0-regularized regression results in a sparse solution, thereby also reducing model complexity as well as reducing the probability of overfitting. Identification is performed on experimental data obtained from a laboratory-scale overhead crane. The proposed method is compared with multi-gene genetic programming (MGGP), NARX neural network, and Takagi-Sugeno fuzzy (TSF) ARX models in terms of model complexity, prediction accuracy, and sensitivity. The G3P-SR algorithm evolved a model with a maximum mean square error (MSE) of crane velocity and sway prediction of 1.1860 × 10−4 and 4.8531 × 10−4, respectively, in simulations for different testing data sets, showing better accuracy than the TSF ARX and MGGP models. Only the NARX neural network model with velocity and sway maximum MSEs of 1.4595 × 10−4 and 4.8571 × 10−4 achieves a similar accuracy or an even better one in some testing scenarios, but at the cost of increasing the total number of parameters to be estimated by over 300% and the number of output lags compared to the G3P-SR model. Moreover, the G3P-SR model is proven to be notably less sensitive, exhibiting the least deviation from the nominal trajectory for deviations in the payload mass by approximately a factor of 10.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/00bf9e290faaf044d2f3b2e4bd7d2212b064df14" target='_blank'>
              Data-Driven Identification of Crane Dynamics Using Regularized Genetic Programming
              </a>
            </td>
          <td>
            Tom Kusznir, Jarosław Smoczek, Bolesław Karwat
          </td>
          <td>2024-04-20</td>
          <td>Applied Sciences</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="
 This paper proposes a method for identifying an initial gap in piecewise-linear systems from data. Piecewise-linear systems appear in many engineered systems such as degraded mechanical systems and infrastructures, and are known to show strong nonlinearities. To analyze the behavior of such piecewise-linear systems, it is necessary to identify the initial gap, at which the system behavior switches. The proposed method identifies the initial gap by discovering the governing equations using sparse regression and calculating the gap based on the universal approximation theorem. A key step to achieve this is to approximate a piecewise-linear function by a finite sum of piecewise-linear functions in sparse regression. Equivalent gap is then calculated from the coefficients of the multiple piecewise-linear functions and their respective switching points in the obtained equation. The proposed method was first applied to a numerical model to confirm its applicability to piecewise-linear systems. Experimental validation of the proposed method has then been conducted with a simple mass-spring-hopping system, where the method successfully identified the initial gap in the system with high accuracy.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5a7cf566128d78555b90b41c0018785824ea9693" target='_blank'>
              Data-Driven Initial Gap Identification of Piecewise-Linear Systems Using Sparse Regression and Universal Approximation Theorem
              </a>
            </td>
          <td>
            Ryosuke Kanki, Akira Saito
          </td>
          <td>2024-05-03</td>
          <td>Journal of Computational and Nonlinear Dynamics</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The paper shows that the application of the fixed-effect multiple linear regression model to an overparameterized dataset is equivalent to fitting the data with a hyper-curve parameterized by a single scalar parameter. This equivalence allows for a predictor-focused approach, where each predictor is described by a function of the chosen parameter. It is proven that a linear model will produce exact predictions even in the presence of nonlinear dependencies that violate the model assumptions. Parameterization in terms of the dependent variable and the monomial basis in the predictor function space are applied here to both synthetic and experimental data. The hyper-curve approach is especially suited for the regularization of problems with noise in predictor variables and can be used to remove noisy and"improper"predictors from the model.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c48065145498deecb1ee0af55f1364e8a05f2111" target='_blank'>
              Overparameterized Multiple Linear Regression as Hyper-Curve Fitting
              </a>
            </td>
          <td>
            E. Atza, N. Budko
          </td>
          <td>2024-04-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="In engineering, accurately modeling nonlinear dynamic systems from data contaminated by noise is both essential and complex. Established Sequential Monte Carlo (SMC) methods, used for the Bayesian identification of these systems, facilitate the quantification of uncertainty in the parameter identification process. A significant challenge in this context is the numerical integration of continuous-time ordinary differential equations (ODEs), crucial for aligning theoretical models with discretely sampled data. This integration introduces additional numerical uncertainty, a factor that is often over looked. To address this issue, the field of probabilistic numerics combines numerical methods, such as numerical integration, with probabilistic modeling to offer a more comprehensive analysis of total uncertainty. By retaining the accuracy of classical deterministic methods, these probabilistic approaches offer a deeper understanding of the uncertainty inherent in the inference process. This paper demonstrates the application of a probabilistic numerical method for solving ODEs in the joint parameter-state identification of nonlinear dynamic systems. The presented approach efficiently identifies latent states and system parameters from noisy measurements. Simultaneously incorporating probabilistic solutions to the ODE in the identification challenge. The methodology's primary advantage lies in its capability to produce posterior distributions over system parameters, thereby representing the inherent uncertainties in both the data and the identification process.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e4efea4bf1104a19ed944ebb003f83b9b8977a1c" target='_blank'>
              Probabilistic Numeric SMC Sampling for Bayesian Nonlinear System Identification in Continuous Time
              </a>
            </td>
          <td>
            Joe D. Longbottom, M.D. Champneys, T. J. Rogers
          </td>
          <td>2024-04-19</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="We investigate the reconstruction of time series from dynamical networks that are partially observed. In particular, we address the extent to which the time series at a node of the network can be successfully reconstructed when measuring from another node, or subset of nodes, corrupted by observational noise. We will assume the dynamical equations of the network are known, and that the dynamics are not necessarily low-dimensional. The case of linear dynamics is treated first, and leads to a definition of observation error magnification factor (OEMF) that measures the magnification of noise in the reconstruction process. Subsequently, the definition is applied to nonlinear and chaotic dynamics. Comparison of OEMF for different target/observer combinations can lead to better understanding of how to optimally observe a network. As part of the study, a computational method for reconstructing time series from partial observations is presented and analyzed.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b5532acea4ab11e2370e2a90bab5192572801c7e" target='_blank'>
              Reconstruction of network dynamics from partial observations
              </a>
            </td>
          <td>
            Tyrus Berry, Timothy Sauer
          </td>
          <td>2024-04-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>18</td>
        </tr>

        <tr id="This study presents the extension of the data-driven optimal prediction approach to the dynamical system with control. The optimal prediction is used to analyze dynamical systems in which the states consist of resolved and unresolved variables. The latter variables can not be measured explicitly. They may have smaller amplitudes and affect the resolved variables that can be measured. The optimal prediction approach recovers the averaged trajectories of the resolved variables by computing conditional expectations, while the distribution of the unresolved variables is assumed to be known. We consider such dynamical systems and introduce their additional control functions. To predict the targeted trajectories numerically, we develop a data-driven method based on the dynamic mode decomposition. The proposed approach takes the $\mathit{measured}$ trajectories of the resolved variables, constructs an approximate linear operator from the Mori-Zwanzig decomposition, and reconstructs the $\mathit{averaged}$ trajectories of the same variables. It is demonstrated that the method is much faster than the Monte Carlo simulations and it provides a reliable prediction. We experimentally confirm the efficacy of the proposed method for two Hamiltonian dynamical systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ff61c47f507c82d3e09807eb5ccbe742fb5c6272" target='_blank'>
              Data-driven optimal prediction with control
              </a>
            </td>
          <td>
            Aleksandr Katrutsa, Ivan V. Oseledets, Sergey Utyuzhnikov
          </td>
          <td>2024-06-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="This paper explores the efficacy of diffusion-based generative models as neural operators for partial differential equations (PDEs). Neural operators are neural networks that learn a mapping from the parameter space to the solution space of PDEs from data, and they can also solve the inverse problem of estimating the parameter from the solution. Diffusion models excel in many domains, but their potential as neural operators has not been thoroughly explored. In this work, we show that diffusion-based generative models exhibit many properties favourable for neural operators, and they can effectively generate the solution of a PDE conditionally on the parameter or recover the unobserved parts of the system. We propose to train a single model adaptable to multiple tasks, by alternating between the tasks during training. In our experiments with multiple realistic dynamical systems, diffusion models outperform other neural operators. Furthermore, we demonstrate how the probabilistic diffusion model can elegantly deal with systems which are only partially identifiable, by producing samples corresponding to the different possible solutions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/93f7dd73bdb8cf078d6f19120987ab3c21100bc5" target='_blank'>
              Diffusion models as probabilistic neural operators for recovering unobserved states of dynamical systems
              </a>
            </td>
          <td>
            Katsiaryna Haitsiukevich, O. Poyraz, Pekka Marttinen, Alexander Ilin
          </td>
          <td>2024-05-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Multi-layer perceptrons (MLP's) have been extensively utilized in discovering Deep Koopman operators for linearizing nonlinear dynamics. With the emergence of Kolmogorov-Arnold Networks (KANs) as a more efficient and accurate alternative to the MLP Neural Network, we propose a comparison of the performance of each network type in the context of learning Koopman operators with control. In this work, we propose a KANs-based deep Koopman framework with applications to an orbital Two-Body Problem (2BP) and the pendulum for data-driven discovery of linear system dynamics. KANs were found to be superior in nearly all aspects of training; learning 31 times faster, being 15 times more parameter efficiency, and predicting 1.25 times more accurately as compared to the MLP Deep Neural Networks (DNNs) in the case of the 2BP. Thus, KANs shows potential for being an efficient tool in the development of Deep Koopman Theory.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/74898d1fcce93c0bebf147547ee71f14d84dd010" target='_blank'>
              Leveraging KANs For Enhanced Deep Koopman Operator Discovery
              </a>
            </td>
          <td>
            George Nehma, Madhur Tiwari
          </td>
          <td>2024-06-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Causal representation learning promises to extend causal models to hidden causal variables from raw entangled measurements. However, most progress has focused on proving identifiability results in different settings, and we are not aware of any successful real-world application. At the same time, the field of dynamical systems benefited from deep learning and scaled to countless applications but does not allow parameter identification. In this paper, we draw a clear connection between the two and their key assumptions, allowing us to apply identifiable methods developed in causal representation learning to dynamical systems. At the same time, we can leverage scalable differentiable solvers developed for differential equations to build models that are both identifiable and practical. Overall, we learn explicitly controllable models that isolate the trajectory-specific parameters for further downstream tasks such as out-of-distribution classification or treatment effect estimation. We experiment with a wind simulator with partially known factors of variation. We also apply the resulting model to real-world climate data and successfully answer downstream causal questions in line with existing literature on climate change.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/012edc12bb8f81586eba3ee451de916124498e06" target='_blank'>
              Marrying Causal Representation Learning with Dynamical Systems for Science
              </a>
            </td>
          <td>
            Dingling Yao, Caroline Muller, Francesco Locatello
          </td>
          <td>2024-05-22</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Formulating dynamical models for physical phenomena is essential for understanding the interplay between the different mechanisms and predicting the evolution of physical states. However, a dynamical model alone is often insufficient to address these fundamental tasks, as it suffers from model errors and uncertainties. One common remedy is to rely on data assimilation, where the state estimate is updated with observations of the true system. Ensemble filters sequentially assimilate observations by updating a set of samples over time. They operate in two steps: a forecast step that propagates each sample through the dynamical model and an analysis step that updates the samples with incoming observations. For accurate and robust predictions of dynamical systems, discrete solutions must preserve their critical invariants. While modern numerical solvers satisfy these invariants, existing invariant-preserving analysis steps are limited to Gaussian settings and are often not compatible with classical regularization techniques of ensemble filters, e.g., inflation and covariance tapering. The present work focuses on preserving linear invariants, such as mass, stoichiometric balance of chemical species, and electrical charges. Using tools from measure transport theory (Spantini et al., 2022, SIAM Review), we introduce a generic class of nonlinear ensemble filters that automatically preserve desired linear invariants in non-Gaussian filtering problems. By specializing this framework to the Gaussian setting, we recover a constrained formulation of the Kalman filter. Then, we show how to combine existing regularization techniques for the ensemble Kalman filter (Evensen, 1994, J. Geophys. Res.) with the preservation of the linear invariants. Finally, we assess the benefits of preserving linear invariants for the ensemble Kalman filter and nonlinear ensemble filters.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d141c58886abcc457131832eb29eed4ce25f26e6" target='_blank'>
              Preserving linear invariants in ensemble filtering methods
              </a>
            </td>
          <td>
            M. Provost, Jan Glaubitz, Youssef Marzouk
          </td>
          <td>2024-04-22</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="Many complicated dynamical events may be broken down into simpler pieces and efficiently described by a system that shifts among a variety of conditionally dynamical modes. Building on switching linear dynamical systems, we develop a new model that extends the switching linear dynamical systems for better discovering these dynamical modes. In the proposed model, the linear dynamics of latent variables can be described by a higher-order vector autoregressive process, which makes it feasible to evaluate the higher-order dependency relationships in the dynamics. In addition, the transition of switching states is determined by a stick-breaking logistic regression, overcoming the limitation of a restricted geometric state duration and recovering the symmetric dependency between the switching states and the latent variables from asymmetric relationships. Furthermore, logistic regression evidence potentials can appear as conditionally Gaussian potentials by utilizing the Pólya-gamma augmentation strategy. Filtering and smoothing algorithms and Bayesian inference for parameter learning in the proposed model are presented. The utility and versatility of the proposed model are demonstrated on synthetic data and public functional magnetic resonance imaging data. Our model improves the current methods for learning the switching linear dynamical modes, which will facilitate the identification and assessment of the dynamics of complex systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f180f44aa0cab4e14882a44aef54b3e4ae757688" target='_blank'>
              Bayesian Inference of Recurrent Switching Linear Dynamical Systems with Higher-Order Dependence
              </a>
            </td>
          <td>
            Houxiang Wang, Jiaqing Chen
          </td>
          <td>2024-04-13</td>
          <td>Symmetry</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/13748f95702f1668a03d437341052124aeb44184" target='_blank'>
              Probabilistic response determination of high-dimensional nonlinear dynamical systems enforced by parametric multiple Poisson white noises
              </a>
            </td>
          <td>
            Jian-Bing Chen, Meng-Ze Lyu
          </td>
          <td>2024-05-20</td>
          <td>Nonlinear Dynamics</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Autonomous systems often encounter environments and scenarios beyond the scope of their training data, which underscores a critical challenge: the need to generalize and adapt to unseen scenarios in real time. This challenge necessitates new mathematical and algorithmic tools that enable adaptation and zero-shot transfer. To this end, we leverage the theory of function encoders, which enables zero-shot transfer by combining the flexibility of neural networks with the mathematical principles of Hilbert spaces. Using this theory, we first present a method for learning a space of dynamics spanned by a set of neural ODE basis functions. After training, the proposed approach can rapidly identify dynamics in the learned space using an efficient inner product calculation. Critically, this calculation requires no gradient calculations or retraining during the online phase. This method enables zero-shot transfer for autonomous systems at runtime and opens the door for a new class of adaptable control algorithms. We demonstrate state-of-the-art system modeling accuracy for two MuJoCo robot environments and show that the learned models can be used for more efficient MPC control of a quadrotor.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f116a6da3fbd691c6355c87e9f75c42ef5145170" target='_blank'>
              Zero-Shot Transfer of Neural ODEs
              </a>
            </td>
          <td>
            Tyler Ingebrand, Adam J. Thorpe, U. Topcu
          </td>
          <td>2024-05-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>47</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c53a64b37da477c06468da0f1b359b77e2e273e9" target='_blank'>
              Biologically informed NeuralODEs for genome-wide regulatory dynamics
              </a>
            </td>
          <td>
            Intekhab Hossain, Viola Fanfani, Jonas Fischer, John Quackenbush, R. Burkholz
          </td>
          <td>2024-05-21</td>
          <td>Genome Biology</td>
          <td>0</td>
          <td>13</td>
        </tr>

        <tr id="The URANS equations provide a computationally efficient tool to simulate unsteady turbulent flows for a wide range of applications. To account for the errors introduced by the turbulence closure model, recent works have adopted data assimilation (DA) to enhance their predictive capabilities. Recognizing the challenges posed by the computational cost of 4DVar DA for unsteady flows, we propose a 3DVar DA framework that incorporates a time-discrete Fourier transform of the URANS equations, facilitating the use of the stationary discrete adjoint method in Fourier space. Central to our methodology is the introduction of a corrective, divergence-free, and unsteady forcing term, derived from a Fourier series expansion, into the URANS equations. This term aims at mitigating discrepancies in the modeled divergence of Reynolds stresses, allowing for the tuning of stationary parameters across different Fourier modes. Our implementation is built upon an extended version of the coupled URANS solver in OpenFOAM, enhanced to compute adjoint variables and gradients. This design choice ensures straightforward applicability to various flow setups and solvers, eliminating the need for specialized harmonic solvers. A gradient-based optimizer is employed to minimize discrepancies between simulated results and sparse velocity reference data. The effectiveness of our approach is demonstrated through its application to flow around a two-dimensional circular cylinder at a Reynolds number of 3900. Our results highlight the method's ability to reconstruct mean flow accurately and improve the vortex shedding frequency through the assimilation of zeroth mode data. Additionally, the assimilation of first mode data further enhances the simulation's capability to capture low-frequency dynamics of the flow, and finally, it runs efficiently by leveraging a coarse mesh.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/79f2c286d577f405d3917469b28ce749ca216e6f" target='_blank'>
              Spectral adjoint-based assimilation of sparse data in unsteady simulations of turbulent flows
              </a>
            </td>
          <td>
            Justin Plogmann, Oliver Brenner, Patrick Jenny
          </td>
          <td>2024-05-30</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/39a4abed8031137161277512e595c8105316e865" target='_blank'>
              Dominant subspaces of high-fidelity polynomial structured parametric dynamical systems and model reduction
              </a>
            </td>
          <td>
            P. Goyal, I. P. Duff, Peter Benner
          </td>
          <td>2024-05-03</td>
          <td>Adv. Comput. Math.</td>
          <td>1</td>
          <td>14</td>
        </tr>

        <tr id="We developed a novel reservoir characterization workflow that addresses reservoir history matching by coupling a physics-informed neural operator (PINO) forward model with a mixture of experts' approach, termed cluster classify regress (CCR). The inverse modelling is achieved via an adaptive Regularized Ensemble Kalman inversion (aREKI) method, ideal for rapid inverse uncertainty quantification during history matching. We parametrize unknown permeability and porosity fields for non-Gaussian posterior measures using a variational convolution autoencoder and a denoising diffusion implicit model (DDIM) exotic priors. The CCR works as a supervised model with the PINO surrogate to replicate nonlinear Peaceman well equations. The CCR's flexibility allows any independent machine-learning algorithm for each stage. The PINO reservoir surrogate's loss function is derived from supervised data loss and losses from the initial conditions and residual of the governing black oil PDE. The PINO-CCR surrogate outputs pressure, water, and gas saturations, along with oil, water, and gas production rates. The methodology was compared to a standard numerical black oil simulator for a waterflooding case on the Norne field, showing similar outputs. This PINO-CCR surrogate was then used in the aREKI history matching workflow, successfully recovering the unknown permeability, porosity and fault multiplier, with simulations up to 6000 times faster than conventional methods. Training the PINO-CCR surrogate on an NVIDIA H100 with 80G memory takes about 5 hours for 100 samples of the Norne field. This workflow is suitable for ensemble-based approaches, where posterior density sampling, given an expensive likelihood evaluation, is desirable for uncertainty quantification.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3674d06c524c713fc2c4d956ddcdbea4f5c3261c" target='_blank'>
              Reservoir History Matching of the Norne field with generative exotic priors and a coupled Mixture of Experts -- Physics Informed Neural Operator Forward Model
              </a>
            </td>
          <td>
            C. Etienam, Juntao Yang, O. Ovcharenko, Issam Said
          </td>
          <td>2024-06-02</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Quantifying relationships between components of a complex system is critical to understanding the rich network of interactions that characterize the behavior of the system. Traditional methods for detecting pairwise dependence of time series, such as Pearson correlation, Granger causality, and mutual information, are computed directly in the space of measured time-series values. But for systems in which interactions are mediated by statistical properties of the time series (`time-series features') over longer timescales, this approach can fail to capture the underlying dependence from limited and noisy time-series data, and can be challenging to interpret. Addressing these issues, here we introduce an information-theoretic method for detecting dependence between time series mediated by time-series features that provides interpretable insights into the nature of the interactions. Our method extracts a candidate set of time-series features from sliding windows of the source time series and assesses their role in mediating a relationship to values of the target process. Across simulations of three different generative processes, we demonstrate that our feature-based approach can outperform a traditional inference approach based on raw time-series values, especially in challenging scenarios characterized by short time-series lengths, high noise levels, and long interaction timescales. Our work introduces a new tool for inferring and interpreting feature-mediated interactions from time-series data, contributing to the broader landscape of quantitative analysis in complex systems research, with potential applications in various domains including but not limited to neuroscience, finance, climate science, and engineering.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/12f3c361e744917f4e1048b2d48b5b095a601df3" target='_blank'>
              A feature-based information-theoretic approach for detecting interpretable, long-timescale pairwise interactions from time series
              </a>
            </td>
          <td>
            Aria Nguyen, Oscar McMullin, J. Lizier, Ben D. Fulcher
          </td>
          <td>2024-04-09</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>41</td>
        </tr>

        <tr id="Turbulent flows are chaotic and multi-scale dynamical systems, which have large numbers of degrees of freedom. Turbulent flows, however, can be modelled with a smaller number of degrees of freedom when using the appropriate coordinate system, which is the goal of dimensionality reduction via nonlinear autoencoders. Autoencoders are expressive tools, but they are difficult to interpret. The goal of this paper is to propose a method to aid the interpretability of autoencoders. This is the decoder decomposition. First, we propose the decoder decomposition, which is a post-processing method to connect the latent variables to the coherent structures of flows. Second, we apply the decoder decomposition to analyse the latent space of synthetic data of a two-dimensional unsteady wake past a cylinder. We find that the dimension of latent space has a significant impact on the interpretability of autoencoders. We identify the physical and spurious latent variables. Third, we apply the decoder decomposition to the latent space of wind-tunnel experimental data of a three-dimensional turbulent wake past a bluff body. We show that the reconstruction error is a function of both the latent space dimension and the decoder size, which are correlated. Finally, we apply the decoder decomposition to rank and select latent variables based on the coherent structures that they represent. This is useful to filter unwanted or spurious latent variables, or to pinpoint specific coherent structures of interest. The ability to rank and select latent variables will help users design and interpret nonlinear autoencoders.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b0d533f9a79dba8eb27c8b9aeb89ecbe15955407" target='_blank'>
              Decoder Decomposition for the Analysis of the Latent Space of Nonlinear Autoencoders With Wind-Tunnel Experimental Data
              </a>
            </td>
          <td>
            Yaxin Mo, Tullio Traverso, L. Magri
          </td>
          <td>2024-04-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Friction modeling has always been a challenging problem due to the complexity of real physical systems. Although a few state-of-the-art structured data-driven methods show their efficiency in nonlinear system modeling, deterministic passivity as one of the significant characteristics of friction is rarely considered in these methods. To address this issue, we propose a Gaussian Process based model that preserves the inherent structural properties such as passivity. A matrix-vector physical structure is considered in our approaches to ensure physical consistency, in particular, enabling a guarantee of positive semi-definiteness of the damping matrix. An aircraft benchmark simulation is employed to demonstrate the efficacy of our methodology. Estimation accuracy and data efficiency are increased substantially by considering and enforcing more structured physical knowledge. Also, the fulfillment of the dissipative nature of the aerodynamics is validated numerically.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/532cfa2bc06887b8b4c4b161c8fa7029f7483f51" target='_blank'>
              Physically Consistent Modeling&Identification of Nonlinear Friction with Dissipative Gaussian Processes
              </a>
            </td>
          <td>
            Rui Dai, Giulio Evangelisti, Sandra Hirche
          </td>
          <td>2024-05-27</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>1</td>
        </tr>

        <tr id="In chemical engineering, process data is often expensive to acquire, and complex phenomena are difficult to model rigorously, rendering both entirely data-driven and purely mechanistic modeling approaches impractical. We explore using physics-informed neural networks (PINNs) for modeling dynamic processes governed by differential-algebraic equation systems when process data is scarce and complete mechanistic knowledge is missing. In particular, we focus on estimating states for which neither direct observational data nor constitutive equations are available. For demonstration purposes, we study a continuously stirred tank reactor and a liquid-liquid separator. We find that PINNs can infer unmeasured states with reasonable accuracy, and they generalize better in low-data scenarios than purely data-driven models. We thus show that PINNs, similar to hybrid mechanistic/data-driven models, are capable of modeling processes when relatively few experimental data and only partially known mechanistic descriptions are available, and conclude that they constitute a promising avenue that warrants further investigation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7e4e0161b8d6befa3c8a0687b96bbfc9b32e40f7" target='_blank'>
              Physics-Informed Neural Networks for Dynamic Process Operations with Limited Physical Knowledge and Data
              </a>
            </td>
          <td>
            M. Velioglu, Song Zhai, Sophia Rupprecht, Alexander Mitsos, Andreas Jupke, M. Dahmen
          </td>
          <td>2024-06-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>13</td>
        </tr>

        <tr id="Heart rate variability (HRV) series reflects the dynamical variation of heartbeat-to-heartbeat intervals in time and is one of the outputs of the cardiovascular system. Over the years, this system has been recognized for generating nonlinear and complex heartbeat dynamics, with the latter referring to a high sensitivity to small -- theoretically infinitesimal -- input changes. While early research associated chaotic behavior with the cardiovascular system, evidence of stochastic inputs to the system, i.e., a physiological noise, invalidated those conclusions. To date, a comprehensive characterization of the cardiovascular system dynamics, accounting for dynamical noise input, has not been undertaken. In this study, we propose a novel methodological framework for evaluating the presence of regular or chaotic dynamics in noisy dynamical systems. The method relies on the estimation of asymptotic growth rate of noisy mean square displacement series in a two-dimensional phase space. We validated the proposed method using synthetic series comprising well-known regular and chaotic maps. We applied the method to real HRV series from healthy subjects, as well as patients with atrial fibrillation and congestive heart failure, during unstructured long-term activity. Results indicate that HRV series are consistently generated by a regular system driven by dynamical noise.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/709fa5a23a94e279f51b9fdab9e8b2b559b0d9e1" target='_blank'>
              Heart Rate Variability Series is the Output of a non-Chaotic System driven by Dynamical Noise
              </a>
            </td>
          <td>
            M. Bianco, A. Scarciglia, C. Bonanno, G. Valenza
          </td>
          <td>2024-04-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="The use of model order reduction techniques in combination with ensemble-based methods for estimating the state of systems described by nonlinear partial differential equations has been of great interest in recent years in the data assimilation community. Methods such as the multi-fidelity ensemble Kalman filter (MF-EnKF) and the multi-level ensemble Kalman filter (ML-EnKF) are recognized as state-of-the-art techniques. However, in many cases, the construction of low-fidelity models in an offline stage, before solving the data assimilation problem, prevents them from being both accurate and computationally efficient. In our work, we investigate the use of {\it{adaptive}} reduced basis techniques in which the approximation space is modified online based on the information that is extracted from a limited number of full order solutions and that is carried by the past models. This allows to simultaneously ensure good accuracy and low cost for the employed models and thus improve the performance of the multi-fidelity and multi-level methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f96f0401ab767d0dd4023e4c19c8614c5dc2c2e7" target='_blank'>
              An adaptive hierarchical ensemble Kalman filter with reduced basis models
              </a>
            </td>
          <td>
            Francesco A. B. Silva, Cecilia Pagliantini, K. Veroy
          </td>
          <td>2024-04-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>18</td>
        </tr>

        <tr id="Physics-Informed Neural Networks (PINNs) integrate physical principles-typically mathematical models expressed as differential equations-into the machine learning (ML) processes to guarantee the physical validity of ML model solutions. This approach has gained traction in science and engineering for modeling a wide range of physical phenomena. Nonetheless, the effectiveness of PINNs in solving nonlinear hyperbolic partial differential equations (PDEs), is found challenging due to discontinuities inherent in such PDE solutions. While previous research has focused on advancing training algorithms, our study highlights that encoding precise physical laws into PINN framework suffices to address the challenge. By coupling well-constructed governing equations into the most basic, simply structured PINNs, this research tackles both data-independent solution and data-driven discovery of the Buckley-Leverett equation, a typical hyperbolic PDE central to modeling multi-phase fluid flow in porous media. Our results reveal that vanilla PINNs are adequate to solve the Buckley-Leverett equation with superior precision and even handling more complex scenarios including variations in fluid mobility ratios, the addition of a gravity term to the original governing equation, and the presence of multiple discontinuities in the solution. This capability of PINNs enables accurate, efficient modeling and prediction of practical engineering problems, such as water flooding, polymer flooding, inclined flooding, and carbon dioxide injection into saline aquifers. Furthermore, the forward PINN framework with slight modifications can be adapted for inverse problems, allowing the estimation of PDE parameters in the Buckley-Leverett equation from observed data. Sensitivity analysis demonstrate that PINNs remain effective under conditions of slight data scarcity and up to a 5% data impurity.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/fe5c6f3dbb888098634905b6c0c768843e99d8c6" target='_blank'>
              Advancing Petroleum Engineering Solutions: Integrating Physics-Informed Neural Networks for Enhanced Buckley-Leverett Model Analysis
              </a>
            </td>
          <td>
            Jingjing Zhang, U. Braga-Neto, E. Gildin
          </td>
          <td>2024-04-18</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>35</td>
        </tr>

        <tr id="Kolmogorov-Arnold Networks (KANs) were recently introduced as an alternative representation model to MLP. Herein, we employ KANs to construct physics-informed machine learning models (PIKANs) and deep operator models (DeepOKANs) for solving differential equations for forward and inverse problems. In particular, we compare them with physics-informed neural networks (PINNs) and deep operator networks (DeepONets), which are based on the standard MLP representation. We find that although the original KANs based on the B-splines parameterization lack accuracy and efficiency, modified versions based on low-order orthogonal polynomials have comparable performance to PINNs and DeepONet although they still lack robustness as they may diverge for different random seeds or higher order orthogonal polynomials. We visualize their corresponding loss landscapes and analyze their learning dynamics using information bottleneck theory. Our study follows the FAIR principles so that other researchers can use our benchmarks to further advance this emerging topic.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/35b3979d5f824009a38f93604ef05a0d7ed09395" target='_blank'>
              A comprehensive and FAIR comparison between MLP and KAN representations for differential equations and operator networks
              </a>
            </td>
          <td>
            K. Shukla, Juan Diego Toscano, Zhicheng Wang, Zongren Zou, G. Karniadakis
          </td>
          <td>2024-06-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>126</td>
        </tr>

        <tr id="Approximation of solutions to partial differential equations (PDE) is an important problem in computational science and engineering. Using neural networks as an ansatz for the solution has proven a challenge in terms of training time and approximation accuracy. In this contribution, we discuss how sampling the hidden weights and biases of the ansatz network from data-agnostic and data-dependent probability distributions allows us to progress on both challenges. In most examples, the random sampling schemes outperform iterative, gradient-based optimization of physics-informed neural networks regarding training time and accuracy by several orders of magnitude. For time-dependent PDE, we construct neural basis functions only in the spatial domain and then solve the associated ordinary differential equation with classical methods from scientific computing over a long time horizon. This alleviates one of the greatest challenges for neural PDE solvers because it does not require us to parameterize the solution in time. For second-order elliptic PDE in Barron spaces, we prove the existence of sampled networks with $L^2$ convergence to the solution. We demonstrate our approach on several time-dependent and static PDEs. We also illustrate how sampled networks can effectively solve inverse problems in this setting. Benefits compared to common numerical schemes include spectral convergence and mesh-free construction of basis functions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6ea3ed2a0840d388a270a6cf6722fb68fd8a79ee" target='_blank'>
              Solving partial differential equations with sampled neural networks
              </a>
            </td>
          <td>
            Chinmay Datar, Taniya Kapoor, Abhishek Chandra, Qing Sun, Iryna Burak, Erik Lien Bolager, Anna Veselovska, Massimo Fornasier, Felix Dietrich
          </td>
          <td>2024-05-31</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e9ac2c4cb35db6f74b769c21e2f2938e4cf1b363" target='_blank'>
              Empirical modeling and prediction of neuronal dynamics
              </a>
            </td>
          <td>
            Pau Fisco-Compte, David Aquilué-Llorens, Nestor Roqueiro, Enric Fossas, Antoni Guillamon
          </td>
          <td>2024-04-10</td>
          <td>Biological Cybernetics</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Partial differential equations (PDEs) are instrumental for modeling dynamical systems in science and engineering. The advent of neural networks has initiated a significant shift in tackling these complexities though challenges in accuracy persist, especially for initial value problems. In this paper, we introduce the $\textit{Time-Evolving Natural Gradient (TENG)}$, generalizing time-dependent variational principles and optimization-based time integration, leveraging natural gradient optimization to obtain high accuracy in neural-network-based PDE solutions. Our comprehensive development includes algorithms like TENG-Euler and its high-order variants, such as TENG-Heun, tailored for enhanced precision and efficiency. TENG's effectiveness is further validated through its performance, surpassing current leading methods and achieving $\textit{machine precision}$ in step-by-step optimizations across a spectrum of PDEs, including the heat equation, Allen-Cahn equation, and Burgers' equation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ecc56a1b67361349c21c1fd5c588dc93f8ce39fc" target='_blank'>
              TENG: Time-Evolving Natural Gradient for Solving PDEs with Deep Neural Net
              </a>
            </td>
          <td>
            Zhuo Chen, Jacob McCarran, Esteban Vizcaino, Marin Soljacic, Di Luo
          </td>
          <td>2024-04-16</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>3</td>
        </tr>

        <tr id="There is a growing attention given to utilizing Lagrangian and Hamiltonian mechanics with network training in order to incorporate physics into the network. Most commonly, conservative systems are modeled, in which there are no frictional losses, so the system may be run forward and backward in time without requiring regularization. This work addresses systems in which the reverse direction is ill-posed because of the dissipation that occurs in forward evolution. The novelty is the use of Morse-Feshbach Lagrangian, which models dissipative dynamics by doubling the number of dimensions of the system in order to create a mirror latent representation that would counterbalance the dissipation of the observable system, making it a conservative system, albeit embedded in a larger space. We start with their formal approach by redefining a new Dissipative Lagrangian, such that the unknown matrices in the Euler-Lagrange's equations arise as partial derivatives of the Lagrangian with respect to only the observables. We then train a network from simulated training data for dissipative systems such as Fickian diffusion that arise in materials sciences. It is shown by experiments that the systems can be evolved in both forward and reverse directions without regularization beyond that provided by the Morse-Feshbach Lagrangian. Experiments of dissipative systems, such as Fickian diffusion, demonstrate the degree to which dynamics can be reversed.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4a579ed4a18e0a0b6f52b6908e3f00349d0e966e" target='_blank'>
              Lagrangian Neural Networks for Reversible Dissipative Evolution
              </a>
            </td>
          <td>
            V. Sundararaghavan, Megna N. Shah, Jeff P. Simmons
          </td>
          <td>2024-05-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>32</td>
        </tr>

        <tr id="Foundation models, such as large language models, have demonstrated success in addressing various language and image processing tasks. In this work, we introduce a multi-modal foundation model for scientific problems, named PROSE-PDE. Our model, designed for bi-modality to bi-modality learning, is a multi-operator learning approach which can predict future states of spatiotemporal systems while concurrently learning the underlying governing equations of the physical system. Specifically, we focus on multi-operator learning by training distinct one-dimensional time-dependent nonlinear constant coefficient partial differential equations, with potential applications to many physical applications including physics, geology, and biology. More importantly, we provide three extrapolation studies to demonstrate that PROSE-PDE can generalize physical features through the robust training of multiple operators and that the proposed model can extrapolate to predict PDE solutions whose models or data were unseen during the training. Furthermore, we show through systematic numerical experiments that the utilization of the symbolic modality in our model effectively resolves the well-posedness problems with training multiple operators and thus enhances our model's predictive capabilities.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/819bc0d5e0ea2efadac1364064e40b76cf3a3a11" target='_blank'>
              Towards a Foundation Model for Partial Differential Equations: Multi-Operator Learning and Extrapolation
              </a>
            </td>
          <td>
            Jingmin Sun, Yuxuan Liu, Zecheng Zhang, Hayden Schaeffer
          </td>
          <td>2024-04-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>15</td>
        </tr>

        <tr id="Uncertainty quantification (UQ) in scientific machine learning (SciML) combines the powerful predictive power of SciML with methods for quantifying the reliability of the learned models. However, two major challenges remain: limited interpretability and expensive training procedures. We provide a new interpretation for UQ problems by establishing a new theoretical connection between some Bayesian inference problems arising in SciML and viscous Hamilton-Jacobi partial differential equations (HJ PDEs). Namely, we show that the posterior mean and covariance can be recovered from the spatial gradient and Hessian of the solution to a viscous HJ PDE. As a first exploration of this connection, we specialize to Bayesian inference problems with linear models, Gaussian likelihoods, and Gaussian priors. In this case, the associated viscous HJ PDEs can be solved using Riccati ODEs, and we develop a new Riccati-based methodology that provides computational advantages when continuously updating the model predictions. Specifically, our Riccati-based approach can efficiently add or remove data points to the training set invariant to the order of the data and continuously tune hyperparameters. Moreover, neither update requires retraining on or access to previously incorporated data. We provide several examples from SciML involving noisy data and \textit{epistemic uncertainty} to illustrate the potential advantages of our approach. In particular, this approach's amenability to data streaming applications demonstrates its potential for real-time inferences, which, in turn, allows for applications in which the predicted uncertainty is used to dynamically alter the learning process.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4134838398ace7c1614eb021aca6dc028e137505" target='_blank'>
              Leveraging viscous Hamilton-Jacobi PDEs for uncertainty quantification in scientific machine learning
              </a>
            </td>
          <td>
            Zongren Zou, Tingwei Meng, Paula Chen, J. Darbon, G. Karniadakis
          </td>
          <td>2024-04-12</td>
          <td>ArXiv</td>
          <td>2</td>
          <td>126</td>
        </tr>

        <tr id="The construction of bifurcation diagrams is an essential component of understanding nonlinear dynamical systems. The task can be challenging when one knows the equations of the dynamical system and becomes much more difficult if only the underlying data associated with the system are available. In this work, we present a transformer-based method to directly estimate the bifurcation diagram using only noisy data associated with an arbitrary dynamical system. By splitting a bifurcation diagram into segments at bifurcation points, the transformer is trained to simultaneously predict how many segments are present and to minimize the loss with respect to the predicted position, shape, and asymptotic stability of each predicted segment. The trained model is shown, both quantitatively and qualitatively, to reliably estimate the structure of the bifurcation diagram for arbitrarily generated one- and two-dimensional systems experiencing a codimension-one bifurcation with as few as 30 trajectories. We show that the method is robust to noise in both the state variable and the system parameter.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/06e38917deafc4e934ebae972b0c466999eebe0f" target='_blank'>
              Inferring bifurcation diagrams with transformers.
              </a>
            </td>
          <td>
            Lyra Zhornyak, M. A. Hsieh, Eric Forgoston
          </td>
          <td>2024-05-01</td>
          <td>Chaos</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="Aggressive and accurate control of complex dynamical systems, such as soft robots, is especially challenging due to the difficulty of obtaining an accurate and tractable model for realtime control. Learned dynamic models are incredibly useful because they do not require derivation of an analytical model, they can represent complex, nonlinear behavior directly from data, and they can be evaluated quickly on graphics-processing units (GPUs). In this paper, we present an open-source Python library to further current research in model-based control of soft robot systems. Our library for Modeling of Learned Dynamics (MoLDy), is designed to generate learned forward models of complex systems through a data-driven approach to hyperparameter optimization and learned model training. Included in the MoLDy library, we present an open-source version of NEMPC (Nonlinear Evo-lutionary Model Predictive Control), a previously published control algorithm validated on soft robots. We demonstrate the ability of MoLDy and NEMPC to accurately perform model-based control on a physical pneumatic continuum joint. We also present a benchmarking study on the effect of the loss metric used in model training on control performance. The results of this paper serve to guide other researchers in creating learned dynamic models of novel systems and using them in closed-loop control tasks.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4aa4c90aabcf78109a03b886ea51fa528b96a24d" target='_blank'>
              MoLDy: Open-Source Library for Data-Based Modeling and Nonlinear Model Predictive Control of Soft Robots
              </a>
            </td>
          <td>
            Daniel G. Cheney, Marc D. Killpack
          </td>
          <td>2024-04-14</td>
          <td>2024 IEEE 7th International Conference on Soft Robotics (RoboSoft)</td>
          <td>0</td>
          <td>20</td>
        </tr>

        <tr id="Spatiotemporal processes are a fundamental tool for modeling dynamics across various domains, from heat propagation in materials to oceanic and atmospheric flows. However, currently available neural network-based modeling approaches fall short when faced with data collected randomly over time and space, as is often the case with sensor networks in real-world applications like crowdsourced earthquake detection or pollution monitoring. In response, we developed a new spatiotemporal method that effectively handles such randomly sampled data. Our model integrates techniques from amortized variational inference, neural differential equations, neural point processes, and implicit neural representations to predict both the dynamics of the system and the probabilistic locations and timings of future observations. It outperforms existing methods on challenging spatiotemporal datasets by offering substantial improvements in predictive accuracy and computational efficiency, making it a useful tool for modeling and understanding complex dynamical systems observed under realistic, unconstrained conditions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3672c7dfec49ffe06ab53ce52945c37c38e785c8" target='_blank'>
              Modeling Randomly Observed Spatiotemporal Dynamical Systems
              </a>
            </td>
          <td>
            V. Iakovlev, Harri Lahdesmaki
          </td>
          <td>2024-06-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="We present an algorithm for constructing efficient surrogate frequency‐domain models of (nonlinear) parametric dynamical systems in a non‐intrusive way. To capture the dependence of the underlying system on frequency and parameters, our proposed approach combines rational approximation and smooth interpolation. In the approximation effort, locally adaptive sparse grids are applied to effectively explore the parameter domain even if the number of parameters is modest or high. Adaptivity is also employed to build rational approximations that efficiently capture the frequency dependence of the problem. These two features enable our method to build surrogate models that achieve a user‐prescribed approximation accuracy, without wasting resources in “oversampling” the frequency and parameter domains. Thanks to its non‐intrusiveness, our proposed method, as opposed to projection‐based techniques for model order reduction, can be applied regardless of the complexity of the underlying physical model. Notably, our algorithm for adaptive sampling can be used even when prior knowledge of the problem structure is not available. To showcase the effectiveness of our approach, we apply it in the study of an aerodynamic bearing. Our method allows us to build surrogate models that adequately identify the bearing's behavior with respect to both design and operational parameters, while still achieving significant speedups.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/071dd64f8fb372d9b51bd3b285c8518554a143a0" target='_blank'>
              Plug‐and‐play adaptive surrogate modeling of parametric nonlinear dynamics in frequency domain
              </a>
            </td>
          <td>
            Phillip Huwiler, Davide Pradovera, Jürg Schiffmann
          </td>
          <td>2024-04-16</td>
          <td>International Journal for Numerical Methods in Engineering</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Data-driven DEs has gained popularity in the past few years. This work proposes the new framework, named Adam Gannet Optimization Algorithm (AdamGOA), that combines Adam Optimization and Gannet Optimization Algorithm (GOA) to improve a stability, solve higher order Differential Equations (DE) and accuracy of DE. Adam is a first-order gradient-based methods, optimizes stochastic objectives using adaptive lower-order moments. In contrast, GOA represents a different distinct action of a gannets mathematically during foraging and is employed to facilitate exploitation and exploration. In addition, a Shepard Convolutional Neural Network (ShCNN) processed data to construct meta-data and estimate derivatives. After that, the unified integral form is established to determine optimal structure. Heterogeneous parameters are used to estimate and are labeled as constants or variables. Furthermore, the experimental findings showed that the AdamGOA_ ShCNN beat leading models in Accuracy, Convergence, and Mean Square Error (MSE), with values of 0.989, 4, and 0.539, respectively.    ">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f280058cd9a4a65ddc6cda4ca2beaa354c89811e" target='_blank'>
              Research on the Data-Driven Differential Equation-Solving Algorithm Based on Artificial Intelligence
              </a>
            </td>
          <td>
            Guoxing Si
          </td>
          <td>2024-04-29</td>
          <td>Journal of Electrical Systems</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="A dynamical systems approach to turbulence envisions the flow as a trajectory through a high-dimensional state space [Hopf, Commun. Appl. Maths 1, 303 (1948)]. The chaotic dynamics are shaped by the unstable simple invariant solutions populating the inertial manifold. The hope has been to turn this picture into a predictive framework where the statistics of the flow follow from a weighted sum of the statistics of each simple invariant solution. Two outstanding obstacles have prevented this goal from being achieved: 1) paucity of known solutions and 2) the lack of a rational theory for predicting the required weights. Here, we describe a method to substantially solve these problems, and thereby provide compelling evidence that the probability density functions (PDFs) of a fully developed turbulent flow can be reconstructed with a set of unstable periodic orbits. Our method for finding solutions uses automatic differentiation, with high-quality guesses constructed by minimizing a trajectory-dependent loss function. We use this approach to find hundreds of solutions in turbulent, two-dimensional Kolmogorov flow. Robust statistical predictions are then computed by learning weights after converting a turbulent trajectory into a Markov chain for which the states are individual solutions, and the nearest solution to a given snapshot is determined using a deep convolutional autoencoder. In this study, the PDFs of a spatiotemporally chaotic system have been successfully reproduced with a set of simple invariant states, and we provide a fascinating connection between self-sustaining dynamical processes and the more well-known statistical properties of turbulence.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a683d2b33355ec533ba4069765cd0a43756888e5" target='_blank'>
              Recurrent flow patterns as a basis for two-dimensional turbulence: Predicting statistics from structures.
              </a>
            </td>
          <td>
            Jacob Page, Peter Norgaard, Michael P. Brenner, R. Kerswell
          </td>
          <td>2024-05-31</td>
          <td>Proceedings of the National Academy of Sciences of the United States of America</td>
          <td>0</td>
          <td>43</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/22a46186cfa337e51d671a8ac45c149e5f0bf01b" target='_blank'>
              Data-driven modeling of interrelated dynamical systems
              </a>
            </td>
          <td>
            Yonatan Elul, Eyal Rozenberg, Amit Boyarski, Yael Yaniv, Assaf Schuster, A. M. Bronstein
          </td>
          <td>2024-05-01</td>
          <td>Communications Physics</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Neural Ordinary Differential Equations typically struggle to generalize to new dynamical behaviors created by parameter changes in the underlying system, even when the dynamics are close to previously seen behaviors. The issue gets worse when the changing parameters are unobserved, i.e., their value or influence is not directly measurable when collecting data. We introduce Neural Context Flow (NCF), a framework that encodes said unobserved parameters in a latent context vector as input to a vector field. NCFs leverage differentiability of the vector field with respect to the parameters, along with first-order Taylor expansion to allow any context vector to influence trajectories from other parameters. We validate our method and compare it to established Multi-Task and Meta-Learning alternatives, showing competitive performance in mean squared error for in-domain and out-of-distribution evaluation on the Lotka-Volterra, Glycolytic Oscillator, and Gray-Scott problems. This study holds practical implications for foundational models in science and related areas that benefit from conditional neural ODEs. Our code is openly available at https://github.com/ddrous/ncflow.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2c738e0450649ed6c04ff7e82d993987c381e35a" target='_blank'>
              Neural Context Flows for Learning Generalizable Dynamical Systems
              </a>
            </td>
          <td>
            Roussel Desmond Nzoyem, David A.W. Barton, Tom Deakin
          </td>
          <td>2024-05-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Machine learning techniques are being used as an alternative to traditional numerical discretization methods for solving hyperbolic partial differential equations (PDEs) relevant to fluid flow. Whilst numerical methods are higher fidelity, they are computationally expensive. Machine learning methods on the other hand are lower fidelity but provide significant speed-ups. The emergence of physics-informed neural networks (PINNs) in fluid dynamics has allowed scientists to directly use PDEs for evaluating loss functions in an unsupervised manner. The downfall of this approach is that the differential form of systems is invalid at regions of shock inherent in hyperbolic PDEs such as the compressible Euler equations. To circumvent this problem we propose a modification to PDE-based PINN losses by using a finite volume-based loss function that incorporates the flux of Godunov-type methods. These Godunov-type methods are also known as approximate Riemann solvers and evaluate intercell fluxes in an entropy-satisfying manner, yielding more physically accurate shocks. Our approach increases fidelity compared to using regularized PDE-based PINN losses, as tested on the 2D Riemann problem.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7f9de7e2760476db603d1b4eafe262b6e8cbba1d" target='_blank'>
              Godunov Loss Functions for Modelling of Hyperbolic Conservation Laws
              </a>
            </td>
          <td>
            R. G. Cassia, R. Kerswell
          </td>
          <td>2024-05-19</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>43</td>
        </tr>

        <tr id="Physics-informed neural networks (PINNs) have recently emerged as a novel and popular approach for solving forward and inverse problems involving partial differential equations (PDEs). However, achieving stable training and obtaining correct results remain a challenge in many cases, often attributed to the ill-conditioning of PINNs. Nonetheless, further analysis is still lacking, severely limiting the progress and applications of PINNs in complex engineering problems. Drawing inspiration from the ill-conditioning analysis in traditional numerical methods, we establish a connection between the ill-conditioning of PINNs and the ill-conditioning of the Jacobian matrix of the PDE system. Specifically, for any given PDE system, we construct its controlled system. This controlled system allows for adjustment of the condition number of the Jacobian matrix while retaining the same solution as the original system. Our numerical findings suggest that the ill-conditioning observed in PINNs predominantly stems from the Jacobian matrix. As the condition number of the Jacobian matrix decreases, PINNs exhibit faster convergence rates and higher accuracy. Building upon this understanding and the natural extension of controlled systems, we present a general approach to mitigate the ill-conditioning of PINNs, leading to successful simulations of the three-dimensional flow around the M6 wing at a Reynolds number of 5,000. To the best of our knowledge, this is the first time that PINNs have been successful in simulating such complex systems, offering a promising new technique for addressing industrial complexity problems. Our findings also offer valuable insights guiding the future development of PINNs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/786bc6af5f479b59f91b560760a8ed56ed691f9f" target='_blank'>
              An analysis and solution of ill-conditioning in physics-informed neural networks
              </a>
            </td>
          <td>
            W. Cao, Weiwei Zhang
          </td>
          <td>2024-05-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Solving partial differential equations (PDEs) in Euclidean space with closed-form symbolic solutions has long been a dream for mathematicians. Inspired by deep learning, Physics-Informed Neural Networks (PINNs) have shown great promise in numerically solving PDEs. However, since PINNs essentially approximate solutions within the continuous function space, their numerical solutions fall short in both precision and interpretability compared to symbolic solutions. This paper proposes a novel framework: a closed-form \textbf{Sym}bolic framework for \textbf{PDE}s (SymPDE), exploring the use of deep reinforcement learning to directly obtain symbolic solutions for PDEs. SymPDE alleviates the challenges PINNs face in fitting high-frequency and steeply changing functions. To our knowledge, no prior work has implemented this approach. Experiments on solving the Poisson's equation and heat equation in time-independent and spatiotemporal dynamical systems respectively demonstrate that SymPDE can provide accurate closed-form symbolic solutions for various types of PDEs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/21f2e9b563c24b42d70f04813caf69fba9a40ef7" target='_blank'>
              Closed-form Symbolic Solutions: A New Perspective on Solving Partial Differential Equations
              </a>
            </td>
          <td>
            Shu Wei, Yanjie Li, Lina Yu, Min Wu, Weijun Li, Meilan Hao, Wenqiang Li, Jingyi Liu, Yusong Deng
          </td>
          <td>2024-05-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="Time-dependent flow fields are typically generated by a computational fluid dynamics (CFD) method, which is an extremely time-consuming process. However, the latent relationship between the flow fields is governed by the Navier-Stokes equations and can be described by an operator. We therefore train a deep operator network, or simply DeepONet, to learn the temporal evolution between flow snapshots. Once properly trained, given a few consecutive snapshots as input, the network has a great potential to generate the next snapshot accurately and quickly. Using the output as a new input, the network iterates the process, generating a series of successive snapshots with little wall time. Specifically, we consider 2D flow around a circular cylinder at Reynolds number 1000, and prepare a set of high-fidelity data using a high-order spectral/hp element method as ground truth. Although the flow fields are periodic, there are many small-scale features in the wake flow that are difficult to generate accurately. Furthermore, any discrepancy between the prediction and the ground truth for the first snapshots can easily accumulate during the iterative process, which eventually amplifies the overall deviations. Therefore, we propose two alternative techniques to improve the training of DeepONet. The first one enhances the feature extraction of the network by harnessing the"multi-head non-local block". The second one refines the network parameters by leveraging the local smooth optimization technique. Both techniques prove to be highly effective in reducing the cumulative errors and our results outperform those of the dynamic mode decomposition method.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bb1100bf83e3489a2cc3c232b47b40267da64f5f" target='_blank'>
              Data-driven modeling of unsteady flow based on deep operator network
              </a>
            </td>
          <td>
            Heming Bai, Zhicheng Wang, Xuesen Chu, J.Q. Deng, Xin Bian
          </td>
          <td>2024-04-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="State estimation for nonlinear state space models is a challenging task. Existing assimilation methodologies predominantly assume Gaussian posteriors on physical space, where true posteriors become inevitably non-Gaussian. We propose Deep Bayesian Filtering (DBF) for data assimilation on nonlinear state space models (SSMs). DBF constructs new latent variables $h_t$ on a new latent (``fancy'') space and assimilates observations $o_t$. By (i) constraining the state transition on fancy space to be linear and (ii) learning a Gaussian inverse observation operator $q(h_t|o_t)$, posteriors always remain Gaussian for DBF. Quite distinctively, the structured design of posteriors provides an analytic formula for the recursive computation of posteriors without accumulating Monte-Carlo sampling errors over time steps. DBF seeks the Gaussian inverse observation operators $q(h_t|o_t)$ and other latent SSM parameters (e.g., dynamics matrix) by maximizing the evidence lower bound. Experiments show that DBF outperforms model-based approaches and latent assimilation methods in various tasks and conditions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d9c707a02615f64ce381c18da72191f9638d116e" target='_blank'>
              Deep Bayesian Filter for Bayes-faithful Data Assimilation
              </a>
            </td>
          <td>
            Yuta Tarumi, Keisuke Fukuda, Shin-ichi Maeda
          </td>
          <td>2024-05-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Neural operators extend data-driven models to map between infinite-dimensional functional spaces. While these operators perform effectively in either the time or frequency domain, their performance may be limited when applied to non-stationary spatial or temporal signals whose frequency characteristics change with time. Here, we introduce Complex Neural Operator (CoNO) that parameterizes the integral kernel using Fractional Fourier Transform (FrFT), better representing non-stationary signals in a complex-valued domain. Theoretically, we prove the universal approximation capability of CoNO. We perform an extensive empirical evaluation of CoNO on seven challenging partial differential equations (PDEs), including regular grids, structured meshes, and point clouds. Empirically, CoNO consistently attains state-of-the-art performance, showcasing an average relative gain of 10.9%. Further, CoNO exhibits superior performance, outperforming all other models in additional tasks such as zero-shot super-resolution and robustness to noise. CoNO also exhibits the ability to learn from small amounts of data -- giving the same performance as the next best model with just 60% of the training data. Altogether, CoNO presents a robust and superior model for modeling continuous dynamical systems, providing a fillip to scientific machine learning.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/95ae0fd0ecd3160ef6c0f799a22f398702eca929" target='_blank'>
              CoNO: Complex Neural Operator for Continous Dynamical Physical Systems
              </a>
            </td>
          <td>
            Karn Tiwari, N. M. A. Krishnan, A. P. Prathosh
          </td>
          <td>2024-06-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="The article introduces a method to learn dynamical systems that are governed by Euler--Lagrange equations from data. The method is based on Gaussian process regression and identifies continuous or discrete Lagrangians and is, therefore, structure preserving by design. A rigorous proof of convergence as the distance between observation data points converges to zero is provided. Next to convergence guarantees, the method allows for quantification of model uncertainty, which can provide a basis of adaptive sampling techniques. We provide efficient uncertainty quantification of any observable that is linear in the Lagrangian, including of Hamiltonian functions (energy) and symplectic structures, which is of interest in the context of system identification. The article overcomes major practical and theoretical difficulties related to the ill-posedness of the identification task of (discrete) Lagrangians through a careful design of geometric regularisation strategies and through an exploit of a relation to convex minimisation problems in reproducing kernel Hilbert spaces.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/62f5043fbad579fdcc9ee3d3f2353a98feac5ae8" target='_blank'>
              Machine learning of continuous and discrete variational ODEs with convergence guarantee and uncertainty quantification
              </a>
            </td>
          <td>
            Christian Offen
          </td>
          <td>2024-04-30</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Numerous phenomenological nuclear models have been proposed to describe specific observables within different regions of the nuclear chart. However, developing a unified model that describes the complex behavior of all nuclei remains an open challenge. Here, we explore whether novel symbolic Machine Learning (ML) can rediscover traditional nuclear physics models or identify alternatives with improved simplicity, fidelity, and predictive power. To address this challenge, we developed a Multi-objective Iterated Symbolic Regression approach that handles symbolic regressions over multiple target observables, accounts for experimental uncertainties and is robust against high-dimensional problems. As a proof of principle, we applied this method to describe the nuclear binding energies and charge radii of light and medium mass nuclei. Our approach identified simple analytical relationships based on the number of protons and neutrons, providing interpretable models with precision comparable to state-of-the-art nuclear models. Additionally, we integrated this ML-discovered model with an existing complementary model to estimate the limits of nuclear stability. These results highlight the potential of symbolic ML to develop accurate nuclear models and guide our description of complex many-body problems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a8d656f91564bc4890b5508d23b62a145931e92c" target='_blank'>
              Discovering Nuclear Models from Symbolic Machine Learning
              </a>
            </td>
          <td>
            Jose M. Munoz, S. Udrescu, Ronald F. Garcia Ruiz
          </td>
          <td>2024-04-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id="In this paper, we present a novel sufficient condition for the stability of discrete-time linear systems that can be represented as a set of piecewise linear constraints, which make them suitable for quadratic programming optimization problems. More specifically, we tackle the problem of imposing asymptotic stability to a Koopman matrix learned from data during iterative gradient descent optimization processes. We show that this sufficient condition can be decoupled by rows of the system matrix, and propose a control barrier function-based projected gradient descent to enforce gradual evolution towards the stability set by running an optimization-in-the-loop during the iterative learning process. We compare the performance of our algorithm with other two recent approaches in the literature, and show that we get close to state-of-the-art performance while providing the added flexibility of allowing the optimization problem to be further customized for specific applications.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/04474198011a7b91ea2d87230d979871d8f91839" target='_blank'>
              Learning deep Koopman operators with convex stability constraints
              </a>
            </td>
          <td>
            M. Mitjans, Liangting Wu, Roberto Tron
          </td>
          <td>2024-04-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="The joint prediction of continuous fields and statistical estimation of the underlying discrete parameters is a common problem for many physical systems, governed by PDEs. Hitherto, it has been separately addressed by employing operator learning surrogates for field prediction while using simulation-based inference (and its variants) for statistical parameter determination. Here, we argue that solving both problems within the same framework can lead to consistent gains in accuracy and robustness. To this end, We propose a novel and flexible formulation of the operator learning problem that allows jointly predicting continuous quantities and inferring distributions of discrete parameters, and thus amortizing the cost of both the inverse and the surrogate models to a joint pre-training step. We present the capabilities of the proposed methodology for predicting continuous and discrete biomarkers in full-body haemodynamics simulations under different levels of missing information. We also consider a test case for atmospheric large-eddy simulation of a two-dimensional dry cold bubble, where we infer both continuous time-series and information about the systems conditions. We present comparisons against different baselines to showcase significantly increased accuracy in both the inverse and the surrogate tasks.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1e0710094b90aeeb6ed231170f016ff0f9672c27" target='_blank'>
              FUSE: Fast Unified Simulation and Estimation for PDEs
              </a>
            </td>
          <td>
            Levi E. Lingsch, Dana Grund, Siddhartha Mishra, Georgios Kissas
          </td>
          <td>2024-05-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="In this study, we investigate the application of fractional calculus to the mathematical modeling of biological systems, focusing on fractional-order-in-time partial differential equations (FTPDEs). Fractional derivatives, especially those defined in the Caputo sense, provide a useful tool for modeling memory and hereditary characteristics, which are problems that are frequently faced with integer-order models. We use the Chebyshev spectral approach for spatial derivatives, which is known for its faster convergence rate, in conjunction with the L1 scheme for time-fractional derivatives because of its high accuracy and robustness in handling nonlocal effects. A detailed theoretical analysis, followed by a number of numerical experiments, is performed to confirmed the theoretical justification. Our simulation results show that our numerical technique significantly improves the convergence rates, effectively tackles computing difficulties, and provides a realistic simulation of biological population dynamics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/571fa6dc3eb953cfb98a8c34794a4c18f8a5b1f5" target='_blank'>
              Dynamical Analysis of Two-Dimensional Fractional-Order-in-Time Biological Population Model Using Chebyshev Spectral Method
              </a>
            </td>
          <td>
            Ishtiaq Ali
          </td>
          <td>2024-05-29</td>
          <td>Fractal and Fractional</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Living organisms exhibit remarkable adaptations across all scales, from molecules to ecosystems. We believe that many of these adaptations correspond to optimal solutions driven by evolution, training, and underlying physical and chemical laws and constraints. While some argue against such optimality principles due to their potential ambiguity, we propose generalized inverse optimal control to infer them directly from data. This novel approach incorporates multi-criteria optimality, nestedness of objective functions on different scales, the presence of active constraints, the possibility of switches of optimality principles during the observed time horizon, maximization of robustness, and minimization of time as important special cases, as well as uncertainties involved with the mathematical modeling of biological systems. This data-driven approach ensures that optimality principles are not merely theoretical constructs but are firmly rooted in experimental observations. Furthermore, the inferred principles can be used in forward optimal control to predict and manipulate biological systems, with possible applications in bio-medicine, biotechnology, and agriculture. As discussed and illustrated, the well-posed problem formulation and the inference are challenging and require a substantial interdisciplinary effort in the development of theory and robust numerical methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8e4280fd4998f275db90da926b44eac2001bb2e0" target='_blank'>
              Generalized Inverse Optimal Control and its Application in Biology
              </a>
            </td>
          <td>
            J. Banga, Sebastian Sager
          </td>
          <td>2024-05-31</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>54</td>
        </tr>

        <tr id="We present a novel method for generating sequential parameter estimates and quantifying epistemic uncertainty in dynamical systems within a data-consistent (DC) framework. The DC framework differs from traditional Bayesian approaches due to the incorporation of the push-forward of an initial density, which performs selective regularization in parameter directions not informed by the data in the resulting updated density. This extends a previous study that included the linear Gaussian theory within the DC framework and introduced the maximal updated density (MUD) estimate as an alternative to both least squares and maximum a posterior (MAP) estimates. In this work, we introduce algorithms for operational settings of MUD estimation in real or near-real time where spatio-temporal datasets arrive in packets to provide updated estimates of parameters and identify potential parameter drift. Computational diagnostics within the DC framework prove critical for evaluating (1) the quality of the DC update and MUD estimate and (2) the detection of parameter value drift. The algorithms are applied to estimate (1) wind drag parameters in a high-fidelity storm surge model, (2) thermal diffusivity field for a heat conductivity problem, and (3) changing infection and incubation rates of an epidemiological model.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/deac584d1ccb0e916dc387a12089fd1c83b78509" target='_blank'>
              Sequential Maximal Updated Density Parameter Estimation for Dynamical Systems with Parameter Drift
              </a>
            </td>
          <td>
            C. Del-Castillo-Negrete, Rylan Spence, Troy Butler, Clint Dawson
          </td>
          <td>2024-05-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="We present a novel approach for the control of uncertain, linear time-invariant systems, which are perturbed by potentially unbounded, additive disturbances. We propose a \emph{doubly robust} data-driven state-feedback controller to ensure reliable performance against both model mismatch and disturbance distribution uncertainty. Our controller, which leverages the System Level Synthesis parameterization, is designed as the solution to a distributionally robust finite-horizon optimal control problem. The goal is to minimize a cost function while satisfying constraints against the worst-case realization of the uncertainty, which is quantified using distributional ambiguity sets. The latter are defined as balls in the Wasserstein metric centered on the predictive empirical distribution computed from a set of collected trajectory data. By harnessing techniques from robust control and distributionally robust optimization, we characterize the distributional shift between the predictive and the actual closed-loop distributions, and highlight its dependency on the model mismatch and the uncertainty about the disturbance distribution. We also provide bounds on the number of samples required to achieve a desired confidence level and propose a tractable approximate formulation for the doubly robust data-driven controller. To demonstrate the effectiveness of our approach, we present a numerical example showcasing the performance of the proposed algorithm.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7ad17f1041183d5ddd239b96f165ef9f2e21b4e8" target='_blank'>
              Data-Driven Distributionally Robust System Level Synthesis
              </a>
            </td>
          <td>
            Francesco Micheli, Anastasios Tsiamis, John Lygeros
          </td>
          <td>2024-05-28</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="The first step toward advancing our understanding of complex networks involves determining their connectivity structures from the time series data. These networks are often high-dimensional, and in practice, only a limited amount of data can be collected. In this work, we formulate the network inference task as a bilinear optimization problem and propose an iterative algorithm with sequential initialization to solve this bilinear program. We demonstrate the scalability of our approach to network size and its robustness against measurement noise, hyper-parameter variation, and deviations from the network model. Results across experimental and simulated datasets, comprising oscillatory, non-oscillatory, and chaotic dynamics, showcase the superior inference accuracy of our technique compared to existing methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/23e9502df007ec30faf3152e8def11f2d8e8eb9f" target='_blank'>
              Identification of network interactions from time series data: An iterative approach.
              </a>
            </td>
          <td>
            Bharat Singhal, Shicheng Li, Jr-Shin Li
          </td>
          <td>2024-05-01</td>
          <td>Chaos</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e8ece1ef179d8e22b18256e49d0f7c2e2fa99c91" target='_blank'>
              Enhanced network inference from sparse incomplete time series through automatically adapted L1 regularization
              </a>
            </td>
          <td>
            Zhongqi Cai, Enrico Gerding, Markus Brede
          </td>
          <td>2024-04-30</td>
          <td>Appl. Netw. Sci.</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="This paper details how the Bayesian-network structure of the posterior distribution of state-space models can be exploited to build improved parameterizations for system identification using variational inference. Three different parameterizations of the assumed state-path posterior distribution are proposed based on this representation: time-varying, steady-state, and convolution-smoother; each resulting in a different parameter estimation method. In contrast to existing methods for variational system identification, the proposed estimators can be implemented with unconstrained optimization methods. Furthermore, when applied to mini-batches in conjunction with stochastic optimization methods, the convolution-smoother formulation enables identification of large linear and nonlinear state-space systems from very large datasets. For linear systems, the method achieves the same performance as the inherently sequential prediction-error methods using and embarrassingly parallel algorithm that benefits from large speedups when computed in modern graphical processing units (GPUs). The ability of the proposed estimators to identify large models, work with large datasets split into mini-batches, and be work in parallel on GPUs make them well-suited for identifying deep models for applications in systems and control.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b901b2ba77f44c7b2e434be5f4559d0d932e3815" target='_blank'>
              Bayesian Networks for Variational System Identification
              </a>
            </td>
          <td>
            Dimas Abreu Archanjo Dutra
          </td>
          <td>2024-04-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="This paper is about learning the parameter-to-solution map for systems of partial differential equations (PDEs) that depend on a potentially large number of parameters covering all PDE types for which a stable variational formulation (SVF) can be found. A central constituent is the notion of variationally correct residual loss function meaning that its value is always uniformly proportional to the squared solution error in the norm determined by the SVF, hence facilitating rigorous a posteriori accuracy control. It is based on a single variational problem, associated with the family of parameter dependent fiber problems, employing the notion of direct integrals of Hilbert spaces. Since in its original form the loss function is given as a dual test norm of the residual a central objective is to develop equivalent computable expressions. A first critical role is played by hybrid hypothesis classes, whose elements are piecewise polynomial in (low-dimensional) spatio-temporal variables with parameter-dependent coefficients that can be represented, e.g. by neural networks. Second, working with first order SVFs, we distinguish two scenarios: (i) the test space can be chosen as an $L_2$-space (e.g. for elliptic or parabolic problems) so that residuals live in $L_2$ and can be evaluated directly; (ii) when trial and test spaces for the fiber problems (e.g. for transport equations) depend on the parameters, we use ultraweak formulations. In combination with Discontinuous Petrov Galerkin concepts the hybrid format is then instrumental to arrive at variationally correct computable residual loss functions. Our findings are illustrated by numerical experiments representing (i) and (ii), namely elliptic boundary value problems with piecewise constant diffusion coefficients and pure transport equations with parameter dependent convection field.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ab54aab98b268d8cd8839aee03c4012354a36e8a" target='_blank'>
              Variationally Correct Neural Residual Regression for Parametric PDEs: On the Viability of Controlled Accuracy
              </a>
            </td>
          <td>
            M. Bachmayr, Wolfgang Dahmen, Mathias Oster
          </td>
          <td>2024-05-30</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="The increasing availability of time series data depicting the evolution of physical system properties has prompted the development of methods focused on extracting insights into the system behavior over time, discerning whether it stems from deterministic or stochastic dynamical systems. Surrogate data testing plays a crucial role in this process by facilitating robust statistical assessments. This ensures that the observed results are not mere occurrences by chance, but genuinely reflect the inherent characteristics of the underlying system. The initial process involves formulating a null hypothesis, which is tested using surrogate data in cases where assumptions about the underlying distributions are absent. A discriminating statistic is then computed for both the original data and each surrogate data set. Significantly deviating values between the original data and the surrogate data ensemble lead to the rejection of the null hypothesis. In this work, we present various surrogate methods designed to assess specific statistical properties in random processes. Specifically, we introduce methods for evaluating the presence of autodependencies and nonlinear dynamics within individual processes, using Information Storage as a discriminating statistic. Additionally, methods are introduced for detecting coupling and nonlinearities in bivariate processes, employing the Mutual Information Rate for this purpose. The surrogate methods introduced are first tested through simulations involving univariate and bivariate processes exhibiting both linear and nonlinear dynamics. Then, they are applied to physiological time series of Heart Period (RR intervals) and respiratory flow (RESP) variability measured during spontaneous and paced breathing. Simulations demonstrated that the proposed methods effectively identify essential dynamical features of stochastic systems. The real data application showed that paced breathing, at low breathing rate, increases the predictability of the individual dynamics of RR and RESP and dampens nonlinearity in their coupled dynamics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b02bf1949b1f6b7b4e3b12ad7076d696c985ae48" target='_blank'>
              Testing dynamic correlations and nonlinearity in bivariate time series through information measures and surrogate data analysis
              </a>
            </td>
          <td>
            Hélder Pinto, Ivan Lazic, Y. Antonacci, R. Pernice, Danlei Gu, Chiara Barà, L. Faes, Ana Paula Rocha
          </td>
          <td>2024-05-21</td>
          <td>Frontiers in Network Physiology</td>
          <td>0</td>
          <td>45</td>
        </tr>

        <tr id="When developing empirical equations, domain experts require these to be accurate and adhere to physical laws. Often, constants with unknown units need to be discovered alongside the equations. Traditional unit-aware genetic programming (GP) approaches cannot be used when unknown constants with undetermined units are included. This paper presents a method for dimensional analysis that propagates unknown units as ''jokers'' and returns the magnitude of unit violations. We propose three methods, namely evolutive culling, a repair mechanism, and a multi-objective approach, to integrate the dimensional analysis in the GP algorithm. Experiments on datasets with ground truth demonstrate comparable performance of evolutive culling and the multi-objective approach to a baseline without dimensional analysis. Extensive analysis of the results on datasets without ground truth reveals that the unit-aware algorithms make only low sacrifices in accuracy, while producing unit-adherent solutions. Overall, we presented a promising novel approach for developing unit-adherent empirical equations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4408590f9ce2cd86bf0dd0ef43c6988dd257a245" target='_blank'>
              Unit-Aware Genetic Programming for the Development of Empirical Equations
              </a>
            </td>
          <td>
            J. Reuter, Viktor Martinek, Roland Herzog, Sanaz Mostaghim
          </td>
          <td>2024-05-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>28</td>
        </tr>

        <tr id="Mathematical equations have been unreasonably effective in describing complex natural phenomena across various scientific disciplines. However, discovering such insightful equations from data presents significant challenges due to the necessity of navigating extremely high-dimensional combinatorial and nonlinear hypothesis spaces. Traditional methods of equation discovery, commonly known as symbolic regression, largely focus on extracting equations from data alone, often neglecting the rich domain-specific prior knowledge that scientists typically depend on. To bridge this gap, we introduce LLM-SR, a novel approach that leverages the extensive scientific knowledge and robust code generation capabilities of Large Language Models (LLMs) to discover scientific equations from data in an efficient manner. Specifically, LLM-SR treats equations as programs with mathematical operators and combines LLMs' scientific priors with evolutionary search over equation programs. The LLM iteratively proposes new equation skeleton hypotheses, drawing from its physical understanding, which are then optimized against data to estimate skeleton parameters. We demonstrate LLM-SR's effectiveness across three diverse scientific domains, where it discovers physically accurate equations that provide significantly better fits to in-domain and out-of-domain data compared to the well-established symbolic regression baselines. Incorporating scientific prior knowledge also enables LLM-SR to search the equation space more efficiently than baselines. Code is available at: https://github.com/deep-symbolic-mathematics/LLM-SR">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/860ba78f9789bbfc99c299b18558ca19430d8fea" target='_blank'>
              LLM-SR: Scientific Equation Discovery via Programming with Large Language Models
              </a>
            </td>
          <td>
            Parshin Shojaee, Kazem Meidani, Shashank Gupta, A. Farimani, Chandan K. Reddy
          </td>
          <td>2024-04-29</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>33</td>
        </tr>

        <tr id="The nonlinear sine-Gordon equation is a prevalent feature in numerous scientific and engineering problems. In this paper, we propose a machine learning-based approach, physics-informed neural networks (PINNs), to investigate and explore the solution of the generalized non-linear sine-Gordon equation, encompassing Dirichlet and Neumann boundary conditions. To incorporate physical information for the sine-Gordon equation, a multiobjective loss function has been defined consisting of the residual of governing partial differential equation (PDE), initial conditions, and various boundary conditions. Using multiple densely connected independent artificial neural networks (ANNs), called feedforward deep neural networks designed to handle partial differential equations, PINNs have been trained through automatic differentiation to minimize a loss function that incorporates the given PDE that governs the physical laws of phenomena. To illustrate the effectiveness, validity, and practical implications of our proposed approach, two computational examples from the nonlinear sine-Gordon are presented. We have developed a PINN algorithm and implemented it using Python software. Various experiments were conducted to determine an optimal neural architecture. The network training was employed by using the current state-of-the-art optimization methods in machine learning known as Adam and L-BFGS-B minimization techniques. Additionally, the solutions from the proposed method are compared with the established analytical solutions found in the literature. The findings show that the proposed method is a computational machine learning approach that is accurate and efficient for solving nonlinear sine-Gordon equations with a variety of boundary conditions as well as any complex nonlinear physical problems across multiple disciplines.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2fa94192e360572ae7bfd3cff18118b6634e19da" target='_blank'>
              Exploring Physics-Informed Neural Networks for the Generalized Nonlinear Sine-Gordon Equation
              </a>
            </td>
          <td>
            Alemayehu Tamirie Deresse, T. T. Dufera
          </td>
          <td>2024-04-30</td>
          <td>Appl. Comput. Intell. Soft Comput.</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="The ecological literature often features phenomenological dynamic models lacking robust validation against observational data. Reverse engineering is an alternative approach, where time series data are utilized to infer or fit a stochastic differential equation. This process, known as system reconstruction, presents significant challenges. This paper addresses the estimation of the (often) non-linear deterministic and stochastic parts of Langevin models, one of the simplest yet commonly used stochastic differential equations. We introduce a Maximum Likelihood Estimation (MLE) inference method, termed Euler reconstruction, tailored for time series data with medium to high resolution. However, the Euler approach is not reliable for low-resolution data. To fill the gap for sparsely sampled data, we present an MLE inference method pioneered by Aït-Sahalia, that we term Hermite reconstruction. We employ a powerful modeling framework utilizing splines to detect inherent nonlinearities in the unknown data-generating system to achieve high accuracy with minimal computational burden. Applying Euler and Hermite reconstructions to a range of simulated, ecological, and climate datasets, we demonstrate their efficacy and versatility. We provide a user-friendly tutorial and a MATLAB package called the ‘MATLAB reconstruction package’.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/918c6cc11f61545450cd060301361e2d282df772" target='_blank'>
              Reconstructing Langevin systems from high and low-resolution time series using Euler and Hermite reconstructions
              </a>
            </td>
          <td>
            Babak M. S. Arani, Stephen R Carpenter, E. V. van Nes
          </td>
          <td>2024-06-02</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>47</td>
        </tr>

        <tr id="In some fields of AI, machine learning and statistics, the validation of new methods and algorithms is often hindered by the scarcity of suitable real-world datasets. Researchers must often turn to simulated data, which yields limited information about the applicability of the proposed methods to real problems. As a step forward, we have constructed two devices that allow us to quickly and inexpensively produce large datasets from non-trivial but well-understood physical systems. The devices, which we call causal chambers, are computer-controlled laboratories that allow us to manipulate and measure an array of variables from these physical systems, providing a rich testbed for algorithms from a variety of fields. We illustrate potential applications through a series of case studies in fields such as causal discovery, out-of-distribution generalization, change point detection, independent component analysis, and symbolic regression. For applications to causal inference, the chambers allow us to carefully perform interventions. We also provide and empirically validate a causal model of each chamber, which can be used as ground truth for different tasks. All hardware and software is made open source, and the datasets are publicly available at causalchamber.org or through the Python package causalchamber.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/af3c49fc6d1721352862629a9a568765b77c42d0" target='_blank'>
              The Causal Chambers: Real Physical Systems as a Testbed for AI Methodology
              </a>
            </td>
          <td>
            Juan L. Gamella, Jonas Peters, Peter Buhlmann
          </td>
          <td>2024-04-17</td>
          <td>ArXiv</td>
          <td>2</td>
          <td>3</td>
        </tr>

        <tr id="This paper examines the alignment of inductive biases in machine learning (ML) with structural models of economic dynamics. Unlike dynamical systems found in physical and life sciences, economics models are often specified by differential equations with a mixture of easy-to-enforce initial conditions and hard-to-enforce infinite horizon boundary conditions (e.g. transversality and no-ponzi-scheme conditions). Traditional methods for enforcing these constraints are computationally expensive and unstable. We investigate algorithms where those infinite horizon constraints are ignored, simply training unregularized kernel machines and neural networks to obey the differential equations. Despite the inherent underspecification of this approach, our findings reveal that the inductive biases of these ML models innately enforce the infinite-horizon conditions necessary for the well-posedness. We theoretically demonstrate that (approximate or exact) min-norm ML solutions to interpolation problems are sufficient conditions for these infinite-horizon boundary conditions in a wide class of problems. We then provide empirical evidence that deep learning and ridgeless kernel methods are not only theoretically sound with respect to economic assumptions, but may even dominate classic algorithms in low to medium dimensions. More importantly, these results give confidence that, despite solving seemingly ill-posed problems, there are reasons to trust the plethora of black-box ML algorithms used by economists to solve previously intractable, high-dimensional dynamical systems -- paving the way for future work on estimation of inverse problems with embedded optimal control problems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ea77e3ea1cbcdc65fdeab71d987d86833d4f8a9f" target='_blank'>
              How Inductive Bias in Machine Learning Aligns with Optimality in Economic Dynamics
              </a>
            </td>
          <td>
            Mahdi Ebrahimi Kahou, James Yu, Jesse Perla, Geoff Pleiss
          </td>
          <td>2024-06-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="The study of neural operators has paved the way for the development of efficient approaches for solving partial differential equations (PDEs) compared with traditional methods. However, most of the existing neural operators lack the capability to provide uncertainty measures for their predictions, a crucial aspect, especially in data-driven scenarios with limited available data. In this work, we propose a novel Neural Operator-induced Gaussian Process (NOGaP), which exploits the probabilistic characteristics of Gaussian Processes (GPs) while leveraging the learning prowess of operator learning. The proposed framework leads to improved prediction accuracy and offers a quantifiable measure of uncertainty. The proposed framework is extensively evaluated through experiments on various PDE examples, including Burger's equation, Darcy flow, non-homogeneous Poisson, and wave-advection equations. Furthermore, a comparative study with state-of-the-art operator learning algorithms is presented to highlight the advantages of NOGaP. The results demonstrate superior accuracy and expected uncertainty characteristics, suggesting the promising potential of the proposed framework.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0197704fc0e18ed51f63eda29b27b3cb01285ad6" target='_blank'>
              Neural Operator induced Gaussian Process framework for probabilistic solution of parametric partial differential equations
              </a>
            </td>
          <td>
            Sawan Kumar, R. Nayek, Souvik Chakraborty
          </td>
          <td>2024-04-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="The evolution of artificial intelligence (AI) and neural network theories has revolutionized the way software is programmed, shifting from a hard-coded series of codes to a vast neural network. However, this transition in engineering software has faced challenges such as data scarcity, multi-modality of data, low model accuracy, and slow inference. Here, we propose a new network based on interpolation theories and tensor decomposition, the interpolating neural network (INN). Instead of interpolating training data, a common notion in computer science, INN interpolates interpolation points in the physical space whose coordinates and values are trainable. It can also extrapolate if the interpolation points reside outside of the range of training data and the interpolation functions have a larger support domain. INN features orders of magnitude fewer trainable parameters, faster training, a smaller memory footprint, and higher model accuracy compared to feed-forward neural networks (FFNN) or physics-informed neural networks (PINN). INN is poised to usher in Engineering Software 2.0, a unified neural network that spans various domains of space, time, parameters, and initial/boundary conditions. This has previously been computationally prohibitive due to the exponentially growing number of trainable parameters, easily exceeding the parameter size of ChatGPT, which is over 1 trillion. INN addresses this challenge by leveraging tensor decomposition and tensor product, with adaptable network architecture.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f46b616f2d4f751eb39cc409fca579edb610cd7e" target='_blank'>
              Engineering software 2.0 by interpolating neural networks: unifying training, solving, and calibration
              </a>
            </td>
          <td>
            Chanwook Park, Sourav Saha, Jiachen Guo, Xiaoyu Xie, S. Mojumder, M. Bessa, Dong Qian, Wei Chen, Gregory J. Wagner, Jian Cao, Wing Kam Liu
          </td>
          <td>2024-04-16</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>18</td>
        </tr>

        <tr id="In Data Assimilation, observations are fused with simulations to obtain an accurate estimate of the state and parameters for a given physical system. Combining data with a model, however, while accurately estimating uncertainty, is computationally expensive and infeasible to run in real-time for complex systems. Here, we present a novel particle filter methodology, the Deep Latent Space Particle filter or D-LSPF, that uses neural network-based surrogate models to overcome this computational challenge. The D-LSPF enables filtering in the low-dimensional latent space obtained using Wasserstein AEs with modified vision transformer layers for dimensionality reduction and transformers for parameterized latent space time stepping. As we demonstrate on three test cases, including leak localization in multi-phase pipe flow and seabed identification for fully nonlinear water waves, the D-LSPF runs orders of magnitude faster than a high-fidelity particle filter and 3-5 times faster than alternative methods while being up to an order of magnitude more accurate. The D-LSPF thus enables real-time data assimilation with uncertainty quantification for physical systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/02d07732dd3696286a60f2be29a2faed94e35411" target='_blank'>
              The Deep Latent Space Particle Filter for Real-Time Data Assimilation with Uncertainty Quantification
              </a>
            </td>
          <td>
            Nikolaj T. Mucke, Sander M. Boht'e, C. Oosterlee
          </td>
          <td>2024-06-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>47</td>
        </tr>

        <tr id="Thermodynamics-informed neural networks employ inductive biases for the enforcement of the first and second principles of thermodynamics. To construct these biases, a metriplectic evolution of the system is assumed. This provides excellent results, when compared to uninformed, black box networks. While the degree of accuracy can be increased in one or two orders of magnitude, in the case of graph networks, this requires assembling global Poisson and dissipation matrices, which breaks the local structure of such networks. In order to avoid this drawback, a local version of the metriplectic biases has been developed in this work, which avoids the aforementioned matrix assembly, thus preserving the node-by-node structure of the graph networks. We apply this framework for examples in the fields of solid and fluid mechanics. Our approach demonstrates significant computational efficiency and strong generalization capabilities, accurately making inferences on examples significantly different from those encountered during training.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/15fd8e32ee00bcac84f21f3d06d5c1ef1f8e9337" target='_blank'>
              Graph neural networks informed locally by thermodynamics
              </a>
            </td>
          <td>
            Alicia Tierz, Ic´ıar Alfaro, David Gonz'alez, Francisco Chinesta, Elías Cueto
          </td>
          <td>2024-05-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>13</td>
        </tr>

        <tr id="We revisit the problem of predicting the output of an LTI system directly using offline input-output data (and without the use of a parametric model) in the behavioral setting. Existing works calculate the output predictions by projecting the recent samples of the input and output signals onto the column span of a Hankel matrix consisting of the offline input-output data. However, if the offline data is corrupted by noise, the output prediction is no longer exact. While some prior works propose mitigating noisy data through matrix low-ranking approximation heuristics, such as truncated singular value decomposition, the ensuing prediction accuracy remains unquantified. This paper fills these gaps by introducing two upper bounds on the prediction error under the condition that the noise is sufficiently small relative to the offline data's magnitude. The first bound pertains to prediction using the raw offline data directly, while the second one applies to the case of low-ranking approximation heuristic. Notably, the bounds do not require the ground truth about the system output, relying solely on noisy measurements with a known noise level and system order. Extensive numerical simulations show that both bounds decrease monotonically (and linearly) as a function of the noise level. Furthermore, our results demonstrate that applying the de-noising heuristic in the output error setup does not generally lead to a better prediction accuracy as compared to using raw data directly, nor a smaller upper bound on the prediction error. However, it allows for a more general upper bound, as the first upper bound requires a specific condition on the partitioning of the Hankel matrix.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3e3cbb6f4a227b0706f257adf13813cce0321c2c" target='_blank'>
              Uncertainty Quantification of Data-Driven Output Predictors in the Output Error Setting
              </a>
            </td>
          <td>
            Farzan Kaviani, Ivan Markovsky, Hamid Ossareh
          </td>
          <td>2024-04-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Parametric data-driven modeling is relevant for many applications in which the model depends on parameters that can potentially vary in both space and time. In this paper, we present a method to obtain a global parametric model based on snapshots of the parameter space. The parameter snapshots are interpolated using the classical univariate Loewner framework and the global bivariate transfer function is extracted using a linear fractional transformation (LFT). Rank bounds for the minimal order of the global realization are also derived. The results are supported by various numerical examples.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6f9ad2c0eef766d60843158a7cce5734f7a4512d" target='_blank'>
              Snapshot-driven Rational Interpolation of Parametric Systems
              </a>
            </td>
          <td>
            Art J. R. Pelling, Karim Cherifi, I. V. Gosea, E. Sarradj
          </td>
          <td>2024-06-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>25</td>
        </tr>

        <tr id="Lyapunov-Schmidt reduction is a dimensionality reduction technique in nonlinear systems analysis that is commonly utilised in the study of bifurcation problems in high-dimensional systems. The method is a systematic procedure for reducing the dimensionality of systems of algebraic equations that have singular points, preserving essential features of their solution sets. In this article, we establish estimates for the region of validity of the reduction by applying bounds on the implicit function theorem derived in [https://doi.org/10.1007/s00498-023-00370-5]. We then apply these bounds to an illustrative example of a two-dimensional system with a pitchfork bifurcation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/78108a359841c23ed9779266a93f80612ca86454" target='_blank'>
              Estimates on the domain of validity for Lyapunov-Schmidt reduction
              </a>
            </td>
          <td>
            Pranav Gupta, Anastasia Bizyaeva, Ravi Banavar
          </td>
          <td>2024-05-30</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Physical models often contain unknown functions and relations. The goal of our work is to answer the question of how one should excite or control a system under consideration in an appropriate way to be able to reconstruct an unknown nonlinear relation. To answer this question, we propose a greedy reconstruction algorithm within an offline-online strategy. We apply this strategy to a two-dimensional semilinear elliptic model. Our identification is based on the application of several space-dependent excitations (also called controls). These specific controls are designed by the algorithm in order to obtain a deeper insight into the underlying physical problem and a more precise reconstruction of the unknown relation. We perform numerical simulations that demonstrate the effectiveness of our approach which is not limited to the current type of equation. Since our algorithm provides not only a way to determine unknown operators by existing data but also protocols for new experiments, it is a holistic concept to tackle the problem of improving physical models.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/444637f77c6bb46c9277165f2c7f0b97cf9c43d0" target='_blank'>
              Reconstruction of unknown nonlinear operators in semilinear elliptic models using optimal inputs
              </a>
            </td>
          <td>
            Jan Bartsch, S. Buchwald, G. Ciaramella, Stefan Volkwein
          </td>
          <td>2024-05-20</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="The stable numerical integration of shocks in compressible flow simulations relies on the reduction or elimination of Gibbs phenomena (unstable, spurious oscillations). A popular method to virtually eliminate Gibbs oscillations caused by numerical discretization in under-resolved simulations is to use a flux limiter. A wide range of flux limiters has been studied in the literature, with recent interest in their optimization via machine learning methods trained on high-resolution datasets. The common use of flux limiters in numerical codes as plug-and-play blackbox components makes them key targets for design improvement. Moreover, while aleatoric (inherent randomness) and epistemic (lack of knowledge) uncertainty is commonplace in fluid dynamical systems, these effects are generally ignored in the design of flux limiters. Even for deterministic dynamical models, numerical uncertainty is introduced via coarse-graining required by insufficient computational power to solve all scales of motion. Here, we introduce a conceptually distinct type of flux limiter that is designed to handle the effects of randomness in the model and uncertainty in model parameters. This new, {\it probabilistic flux limiter}, learned with high-resolution data, consists of a set of flux limiting functions with associated probabilities, which define the frequencies of selection for their use. Using the example of Burgers' equation, we show that a machine learned, probabilistic flux limiter may be used in a shock capturing code to more accurately capture shock profiles. In particular, we show that our probabilistic flux limiter outperforms standard limiters, and can be successively improved upon (up to a point) by expanding the set of probabilistically chosen flux limiting functions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/04d9f0a92b077f68a565391c1b9980829fdf7bdd" target='_blank'>
              Probabilistic Flux Limiters
              </a>
            </td>
          <td>
            Nga Nguyen-Fotiadis, Robert Chiodi, Michael McKerns, Daniel Livescu, Andrew Sornborger
          </td>
          <td>2024-05-13</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Willems' fundamental lemma enables a trajectory-based characterization of linear systems through data-based Hankel matrices. However, in the presence of measurement noise, we ask: Is this noisy Hankel-based model expressive enough to re-identify itself? In other words, we study the output prediction accuracy from recursively applying the same persistently exciting input sequence to the model. We find an asymptotic connection to this self-consistency question in terms of the amount of data. More importantly, we also connect this question to the depth (number of rows) of the Hankel model, showing the simple act of reconfiguring a finite dataset significantly improves accuracy. We apply these insights to find a parsimonious depth for LQR problems over the trajectory space.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a5a8c3dd68d42cacef8f099fb744c61a43353a85" target='_blank'>
              Deep Hankel matrices with random elements
              </a>
            </td>
          <td>
            Nathan P. Lawrence, Philip D. Loewen, Shuyuan Wang, M. Forbes, R. B. Gopaluni
          </td>
          <td>2024-04-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>24</td>
        </tr>

        <tr id="We address online estimation of microbial growth dynamics in bioreactors from measurements of a fluorescent reporter protein synthesized along with microbial growth. We consider an extended version of standard growth models that accounts for the dynamics of reporter synthesis. We develop state estimation from sampled, noisy measurements in the cases of known and unknown growth rate functions. Leveraging conservation laws and regularized estimation techniques, we reduce these nonlinear estimation problems to linear time-varying ones, and solve them via Kalman filtering. We establish convergence results in absence of noise and show performance on noisy data in simulation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ddfcc572268069f315aeeca6f5726f89fb170cc1" target='_blank'>
              Kalman-based approaches for online estimation of bioreactor dynamics from fluorescent reporter measurements
              </a>
            </td>
          <td>
            Rand Asswad, Eugenio Cinquemani, Jean-Luc Gouz'e
          </td>
          <td>2024-04-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Mathematical Epidemiology (ME) shares with Chemical Reaction Network Theory (CRNT) the basic mathematical structure of its dynamical systems. Despite this central similarity, methods from CRNT have been seldom applied to solving problems in ME. We explore here the applicability of CRNT methods to find bifurcations at endemic equilibria of ME models. We adapt three CRNT methods to the features of ME. First, we prove that essentially all ME models admit Hopf bifurcations for certain monotone choices of the interaction functions. Second, we offer a parametrization of equilibria Jacobians of ME systems where few interactions are not in mass action form. Third, for a quite general class of models, we show that periodic oscillations in closed systems imply periodic oscillations when demography is added. Finally, we apply such results to two families of networks: a general SIR model with a nonlinear force of infection and treatment rate and a recent SIRnS model with a gradual increase in infectiousness. We give both necessary conditions and sufficient conditions for the occurrence of bifurcations at endemic equilibria of both families.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/beead2d6819176e5d23c3795cc8d5fb3ac854287" target='_blank'>
              Finding bifurcations in mathematical epidemiology via reaction network methods
              </a>
            </td>
          <td>
            Nicola Vassena, Florin Avram, Rim Adenane
          </td>
          <td>2024-05-23</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>4</td>
        </tr>

        <tr id="Predicting cancer dynamics under treatment is challenging due to high inter-patient heterogeneity, lack of predictive biomarkers, and sparse and noisy longitudinal data. Mathematical models can summarize cancer dynamics by a few interpretable parameters per patient. Machine learning methods can then be trained to predict the model parameters from baseline covariates, but do not account for uncertainty in the parameter estimates. Instead, hierarchical Bayesian modeling can model the relationship between baseline covariates to longitudinal measurements via mechanistic parameters while accounting for uncertainty in every part of the model. The mapping from baseline covariates to model parameters can be modeled in several ways. A linear mapping simplifies inference but fails to capture nonlinear covariate effects and scale poorly for interaction modeling when the number of covariates is large. In contrast, Bayesian neural networks can potentially discover interactions between covariates automatically, but at a substantial cost in computational complexity. In this work, we develop a hierarchical Bayesian model of subpopulation dynamics that uses baseline covariate information to predict cancer dynamics under treatment, inspired by cancer dynamics in multiple myeloma (MM), where serum M protein is a well-known proxy of tumor burden. As a working example, we apply the model to a simulated dataset and compare its ability to predict M protein trajectories to a model with linear covariate effects. Our results show that the Bayesian neural network covariate effect model predicts cancer dynamics more accurately than a linear covariate effect model when covariate interactions are present. The framework can also be applied to other types of cancer or other time series prediction problems that can be described with a parametric model.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/26ecd81405c7df09ef0fe2550029e319785f4a7b" target='_blank'>
              Prediction of cancer dynamics under treatment using Bayesian neural networks: A simulated study
              </a>
            </td>
          <td>
            E. M. Myklebust, A. Frigessi, Fredrik Schjesvold, J. Foo, K. Leder, Alvaro Kohn-Luque
          </td>
          <td>2024-05-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="In the framework of solid mechanics, the task of deriving material parameters from experimental data has recently re-emerged with the progress in full-field measurement capabilities and the renewed advances of machine learning. In this context, new methods such as the virtual fields method and physics-informed neural networks have been developed as alternatives to the already established least-squares and finite element-based approaches. Moreover, model discovery problems are starting to emerge and can also be addressed in a parameter estimation framework. These developments call for a new unified perspective, which is able to cover both traditional parameter estimation methods and novel approaches in which the state variables or the model structure itself are inferred as well. Adopting concepts discussed in the inverse problems community, we distinguish between all-at-once and reduced approaches. With this general framework, we are able to structure a large portion of the literature on parameter estimation in computational mechanics - and we can identify combinations that have not yet been addressed, two of which are proposed in this paper. We also discuss statistical approaches to quantify the uncertainty related to the estimated parameters, and we propose a novel two-step procedure for identification of complex material models based on both frequentist and Bayesian principles. Finally, we illustrate and compare several of the aforementioned methods with mechanical benchmarks based on synthetic and real data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ac06c8a8c3de37ac2eb5e222e458230430856d49" target='_blank'>
              Reduced and All-at-Once Approaches for Model Calibration and Discovery in Computational Solid Mechanics
              </a>
            </td>
          <td>
            Ulrich Römer, Stefan Hartmann, Jendrik-Alexander Tröger, D. Anton, Henning Wessels, Moritz Flaschel, L. Lorenzis
          </td>
          <td>2024-04-25</td>
          <td>ArXiv</td>
          <td>2</td>
          <td>50</td>
        </tr>

        <tr id="Widespread deployment of societal-scale machine learning systems necessitates a thorough understanding of the resulting long-term effects these systems have on their environment, including loss of trustworthiness, bias amplification, and violation of AI safety requirements. We introduce a repeated learning process to jointly describe several phenomena attributed to unintended hidden feedback loops, such as error amplification, induced concept drift, echo chambers and others. The process comprises the entire cycle of obtaining the data, training the predictive model, and delivering predictions to end-users within a single mathematical model. A distinctive feature of such repeated learning setting is that the state of the environment becomes causally dependent on the learner itself over time, thus violating the usual assumptions about the data distribution. We present a novel dynamical systems model of the repeated learning process and prove the limiting set of probability distributions for positive and negative feedback loop modes of the system operation. We conduct a series of computational experiments using an exemplary supervised learning problem on two synthetic data sets. The results of the experiments correspond to the theoretical predictions derived from the dynamical model. Our results demonstrate the feasibility of the proposed approach for studying the repeated learning processes in machine learning systems and open a range of opportunities for further research in the area.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bbdf526001c151c67507de963a0c683064b1f630" target='_blank'>
              A Mathematical Model of the Hidden Feedback Loop Effect in Machine Learning Systems
              </a>
            </td>
          <td>
            Andrey Veprikov, Alexander Afanasiev, Anton Khritankov
          </td>
          <td>2024-05-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Estimating parameters of dynamic models from experimental data is a challenging, and often computationally-demanding task. It requires a large number of model simulations and objective function gradient computations, if gradient-based optimization is used. The gradient depends on derivatives of the state variables with respect to parameters, also called state sensitivities, which are expensive to compute. In many cases, steady-state computation is a part of model simulation, either due to steady-state data or an assumption that the system is at steady state at the initial time point. Various methods are available for steady-state and gradient computation. Yet, the most efficient pair of methods (one for steady states, one for gradients) for a particular model is often not clear. Moreover, depending on the model and the available data, some methods may not be applicable or sufficiently robust. In order to facilitate the selection of methods, we explore six method pairs for computing the steady state and sensitivities at steady state using six real-world problems. The method pairs involve numerical integration or Newton's method to compute the steady-state, and -- for both forward and adjoint sensitivity analysis -- numerical integration or a tailored method to compute the sensitivities at steady-state. Our evaluation shows that the two method pairs that combine numerical integration for the steady-state with a tailored method for the sensitivities at steady-state were the most robust, and amongst the most computationally-efficient. We also observed that while Newton's method for steady-state computation yields a substantial speedup compared to numerical integration, it may lead to a large number of simulation failures. Overall, our study provides a concise overview across current methods for computing sensitivities at steady state, guiding modelers to choose the right methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6c47fda9f52b9ff75a0628c4bdd332f5a75382a8" target='_blank'>
              Exploration of methods for computing sensitivities in ODE models at dynamic and steady states
              </a>
            </td>
          <td>
            Polina Lakrisenko, Dilan Pathirana, Daniel Weindl, J. Hasenauer
          </td>
          <td>2024-05-26</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>36</td>
        </tr>

        <tr id="Analyzing the motion of multiple biological agents, be it cells or individual animals, is pivotal for the understanding of complex collective behaviors. With the advent of advanced microscopy, detailed images of complex tissue formations involving multiple cell types have become more accessible in recent years. However, deciphering the underlying rules that govern cell movements is far from trivial. Here, we present a novel deep learning framework to estimate the underlying equations of motion from observed trajectories, a pivotal step in decoding such complex dynamics. Our framework integrates graph neural networks with neural differential equations, enabling effective prediction of two-body interactions based on the states of the interacting entities. We demonstrate the efficacy of our approach through two numerical experiments. First, we used a simulated data from a toy model to tune the hyperparameters. Based on the obtained hyperparameters, we then applied this approach to a more complex model that describes interacting cells of cellular slime molds. Our results show that the proposed method can accurately estimate the function of two-body interactions, thereby precisely replicating both individual and collective behaviors within these systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0bbd03a34ea3ecbe6332287f4b5f0d43638d30f4" target='_blank'>
              Integrating GNN and Neural ODEs for Estimating Two-Body Interactions in Mixed-Species Collective Motion
              </a>
            </td>
          <td>
            Masahito Uwamichi, S. Schnyder, Tetsuya J. Kobayashi, Satoshi Sawai
          </td>
          <td>2024-05-26</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="It is a grand challenge to find a feasible weather modification method to mitigate the impact of extreme weather events such as tropical cyclones. Previous works have proposed potentially effective actuators and assessed their capabilities to achieve weather modification objectives through numerical simulations. However, few studies have explored efficient mathematical and computational methods to inversely determine optimal actuators from specific modification goals. Here I demonstrate the utility of the ensemble Kalman filter (EnKF)-based control method, referred to as ensemble Kalman control (EnKC). The series of numerical experiments with the Lorenz 96 model indicates that EnKC efficiently identifies local, small, and intermittent control perturbations that can mitigate extreme events. The existing techniques of EnKF, such as background error covariance localization and observation error covariance inflation, can improve the sparsity and efficiency of the control. This work paves the way toward the real-world applications of EnKC to explore the controllability of extreme atmospheric events.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/88af0541d33f91370d26b134e962314ab04859d2" target='_blank'>
              Quest for an efficient mathematical and computational method to explore optimal extreme weather modification
              </a>
            </td>
          <td>
            Yohei Sawada
          </td>
          <td>2024-05-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Global information about dynamical systems can be extracted by analysing associated infinite-dimensional transfer operators, such as Perron-Frobenius and Koopman operators as well as their infinitesimal generators. In practice, these operators typically need to be approximated from data. Popular approximation methods are extended dynamic mode decomposition (EDMD) and generator extended mode decomposition (gEDMD). We propose a unified framework that leverages Monte Carlo sampling to approximate the operator of interest on a finite-dimensional space spanned by a set of basis functions. Our framework contains EDMD and gEDMD as special cases, but can also be used to approximate more general operators. Our key contributions are proofs of the convergence of the approximating operator and its spectrum under non-restrictive conditions. Moreover, we derive explicit convergence rates and account for the presence of noise in the observations. Whilst all these results are broadly applicable, they also refine previous analyses of EDMD and gEDMD. We verify the analytical results with the aid of several numerical experiments.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a4fd97793c90e0875a903bea631c29c0d483308d" target='_blank'>
              Data-driven approximation of Koopman operators and generators: Convergence rates and error bounds
              </a>
            </td>
          <td>
            Liam Llamazares-Elias, Samir Llamazares-Elias, Jonas Latz, Stefan Klus
          </td>
          <td>2024-05-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The quality of a model resulting from (black-box) system identification is highly dependent on the quality of the data that is used during the identification procedure. Designing experiments for linear time-invariant systems is well understood and mainly focuses on the power spectrum of the input signal. Performing experiment design for nonlinear system identification on the other hand remains an open challenge as informativity of the data depends both on the frequency-domain content and on the time-domain evolution of the input signal. Furthermore, as nonlinear system identification is much more sensitive to modeling and extrapolation errors, having experiments that explore the considered operation range of interest is of high importance. Hence, this paper focuses on designing space-filling experiments i.e., experiments that cover the full operation range of interest, for nonlinear dynamical systems that can be represented in a state-space form using a broad set of input signals. The presented experiment design approach can straightforwardly be extended to a wider range of system classes (e.g., NARMAX). The effectiveness of the proposed approach is illustrated on the experiment design for a nonlinear mass-spring-damper system, using a multisine input signal.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1cf1e0c2cc26d936a2a9f4b4550d20177e396f52" target='_blank'>
              Space-Filling Input Design for Nonlinear State-Space Identification
              </a>
            </td>
          <td>
            M'at'e Kiss, Roland T'oth, M. Schoukens
          </td>
          <td>2024-05-28</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="A multifidelity method for the nonlinear propagation of uncertainties in the presence of stochastic accelerations is presented. The proposed algorithm treats the uncertainty propagation (UP) problem by separating the propagation of the initial uncertainty from that of the process noise. The initial uncertainty is propagated using an adaptive Gaussian mixture model (GMM) method which exploits a low-fidelity dynamical model to minimize the computational costs. The effects of process noise are instead computed using the PoLynomial Algebra Stochastic Moments Analysis (PLASMA) technique, which considers a high-fidelity model of the stochastic dynamics. The main focus of the paper is on the latter and on the key idea to approximate the probability density function (pdf) of the solution by a polynomial representation of its moments, which are efficiently computed using differential algebra (DA) techniques. The two estimates are finally combined to restore the accuracy of the low-fidelity surrogate and account for both sources of uncertainty. The proposed approach is applied to the problem of nonlinear orbit UP and its performance compared to that of Monte Carlo (MC) simulations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b6020c94c410d8a16935f357ca553112de7d2bde" target='_blank'>
              Efficient Multifidelity Uncertainty Propagation in the Presence of Process Noise
              </a>
            </td>
          <td>
            Alberto Fossà, Roberto Armellin, Emmanuel Delande, F. Sanfedino
          </td>
          <td>2024-05-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="We present a generative model that amortises computation for the field around e.g. gravitational or magnetic sources. Exact numerical calculation has either computational complexity $\mathcal{O}(M\times{}N)$ in the number of sources and field evaluation points, or requires a fixed evaluation grid to exploit fast Fourier transforms. Using an architecture where a hypernetwork produces an implicit representation of the field around a source collection, our model instead performs as $\mathcal{O}(M + N)$, achieves accuracy of $\sim\!4\%-6\%$, and allows evaluation at arbitrary locations for arbitrary numbers of sources, greatly increasing the speed of e.g. physics simulations. We also examine a model relating to the physical properties of the output field and develop two-dimensional examples to demonstrate its application. The code for these models and experiments is available at https://github.com/cmt-dtu-energy/hypermagnetics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/70c2a9f4249351e7bf76677c09b508db82644b76" target='_blank'>
              Scalable physical source-to-field inference with hypernetworks
              </a>
            </td>
          <td>
            Berian James, Stefan Pollok, Ignacio Peis, J. Frellsen, Rasmus Bjørk
          </td>
          <td>2024-05-07</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>20</td>
        </tr>

        <tr id="Model-based reinforcement learning is an effective approach for controlling an unknown system. It is based on a longstanding pipeline familiar to the control community in which one performs experiments on the environment to collect a dataset, uses the resulting dataset to identify a model of the system, and finally performs control synthesis using the identified model. As interacting with the system may be costly and time consuming, targeted exploration is crucial for developing an effective control-oriented model with minimal experimentation. Motivated by this challenge, recent work has begun to study finite sample data requirements and sample efficient algorithms for the problem of optimal exploration in model-based reinforcement learning. However, existing theory and algorithms are limited to model classes which are linear in the parameters. Our work instead focuses on models with nonlinear parameter dependencies, and presents the first finite sample analysis of an active learning algorithm suitable for a general class of nonlinear dynamics. In certain settings, the excess control cost of our algorithm achieves the optimal rate, up to logarithmic factors. We validate our approach in simulation, showcasing the advantage of active, control-oriented exploration for controlling nonlinear systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7cf97c150f8a0cc3bcad648019e5d858ef78b7ef" target='_blank'>
              Active Learning for Control-Oriented Identification of Nonlinear Systems
              </a>
            </td>
          <td>
            Bruce D. Lee, Ingvar M. Ziemann, George J. Pappas, Nikolai Matni
          </td>
          <td>2024-04-13</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id="State estimation of nonlinear dynamical systems has long aimed to balance accuracy, computational efficiency, robustness, and reliability. The rapid evolution of various industries has amplified the demand for estimation frameworks that satisfy all these factors. This study introduces a neuromorphic approach for robust filtering of nonlinear dynamical systems: SNN-EMSIF (spiking neural network-extended modified sliding innovation filter). SNN-EMSIF combines the computational efficiency and scalability of SNNs with the robustness of EMSIF, an estimation framework designed for nonlinear systems with zero-mean Gaussian noise. Notably, the weight matrices are designed according to the system model, eliminating the need for a learning process. The framework's efficacy is evaluated through comprehensive Monte Carlo simulations, comparing SNN-EMSIF with EKF and EMSIF. Additionally, it is compared with SNN-EKF in the presence of modeling uncertainties and neuron loss, using RMSEs as a metric. The results demonstrate the superior accuracy and robustness of SNN-EMSIF. Further analysis of runtimes and spiking patterns reveals an impressive reduction of 85% in emitted spikes compared to possible spikes, highlighting the computational efficiency of SNN-EMSIF. This framework offers a promising solution for robust estimation in nonlinear dynamical systems, opening new avenues for efficient and reliable estimation in various industries that can benefit from neuromorphic computing.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4597b269ad69fee485fb527be1df63b665e3950d" target='_blank'>
              Neuromorphic Robust Estimation of Nonlinear Dynamical Systems Applied to Satellite Rendezvous
              </a>
            </td>
          <td>
            Reza Ahmadvand, S. S. Sharif, Y. M. Banad
          </td>
          <td>2024-05-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="We consider the problem of learning the dynamics in the topology of time-evolving point clouds, the prevalent spatiotemporal model for systems exhibiting collective behavior, such as swarms of insects and birds or particles in physics. In such systems, patterns emerge from (local) interactions among self-propelled entities. While several well-understood governing equations for motion and interaction exist, they are difficult to fit to data due to the often large number of entities and missing correspondences between the observation times, which may also not be equidistant. To evade such confounding factors, we investigate collective behavior from a \textit{topological perspective}, but instead of summarizing entire observation sequences (as in prior work), we propose learning a latent dynamical model from topological features \textit{per time point}. The latter is then used to formulate a downstream regression task to predict the parametrization of some a priori specified governing equation. We implement this idea based on a latent ODE learned from vectorized (static) persistence diagrams and show that this modeling choice is justified by a combination of recent stability results for persistent homology. Various (ablation) experiments not only demonstrate the relevance of each individual model component, but provide compelling empirical evidence that our proposed model -- \textit{neural persistence dynamics} -- substantially outperforms the state-of-the-art across a diverse set of parameter regression tasks.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b49c1f339720cec5e7fa7b827d7664d093032838" target='_blank'>
              Neural Persistence Dynamics
              </a>
            </td>
          <td>
            Sebastian Zeng, Florian Graf, M. Uray, Stefan Huber, R. Kwitt
          </td>
          <td>2024-05-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>32</td>
        </tr>

        <tr id="We introduce an efficient method for learning linear models from uncertain data, where uncertainty is represented as a set of possible variations in the data, leading to predictive multiplicity. Our approach leverages abstract interpretation and zonotopes, a type of convex polytope, to compactly represent these dataset variations, enabling the symbolic execution of gradient descent on all possible worlds simultaneously. We develop techniques to ensure that this process converges to a fixed point and derive closed-form solutions for this fixed point. Our method provides sound over-approximations of all possible optimal models and viable prediction ranges. We demonstrate the effectiveness of our approach through theoretical and empirical analysis, highlighting its potential to reason about model and prediction uncertainty due to data quality issues in training data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ae6686b5127c30478d5bb06eec7601e6c915505c" target='_blank'>
              Learning from Uncertain Data: From Possible Worlds to Possible Models
              </a>
            </td>
          <td>
            Jiongli Zhu, Su Feng, Boris Glavic, Babak Salimi
          </td>
          <td>2024-05-28</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>22</td>
        </tr>

        <tr id="In the study of stochastic dynamics, the committor function describes the probability that a process starting from an initial configuration $x$ will reach set $A$ before set $B$. This paper introduces a fast and interpretable method for approximating the committor, called the"fast committor machine"(FCM). The FCM is based on simulated trajectory data, and it uses this data to train a kernel model. The FCM identifies low-dimensional subspaces that optimally describe the $A$ to $B$ transitions, and the subspaces are emphasized in the kernel model. The FCM uses randomized numerical linear algebra to train the model with runtime that scales linearly in the number of data points. This paper applies the FCM to example systems including the alanine dipeptide miniprotein: in these experiments, the FCM is generally more accurate and trains more quickly than a neural network with a similar number of parameters.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c6715c8482d3bab4d35021659cc8d135cb847116" target='_blank'>
              The fast committor machine: Interpretable prediction with kernels
              </a>
            </td>
          <td>
            D. Aristoff, M. Johnson, G. Simpson, R. J. Webber
          </td>
          <td>2024-05-16</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>0</td>
        </tr>

        <tr id="In this paper, we consider the problem of reference tracking in uncertain nonlinear systems. A neural State-Space Model (NSSM) is used to approximate the nonlinear system, where a deep encoder network learns the nonlinearity from data, and a state-space component captures the temporal relationship. This transforms the nonlinear system into a linear system in a latent space, enabling the application of model predictive control (MPC) to determine effective control actions. Our objective is to design the optimal controller using limited data from the \textit{target system} (the system of interest). To this end, we employ an implicit model-agnostic meta-learning (iMAML) framework that leverages information from \textit{source systems} (systems that share similarities with the target system) to expedite training in the target system and enhance its control performance. The framework consists of two phases: the (offine) meta-training phase learns a aggregated NSSM using data from source systems, and the (online) meta-inference phase quickly adapts this aggregated model to the target system using only a few data points and few online training iterations, based on local loss function gradients. The iMAML algorithm exploits the implicit function theorem to exactly compute the gradient during training, without relying on the entire optimization path. By focusing solely on the optimal solution, rather than the path, we can meta-train with less storage complexity and fewer approximations than other contemporary meta-learning algorithms. We demonstrate through numerical examples that our proposed method can yield accurate predictive models by adaptation, resulting in a downstream MPC that outperforms several baselines.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2140b914c25c6c89e81a3b8e30f2c87f5d4bcd5d" target='_blank'>
              MPC of Uncertain Nonlinear Systems with Meta-Learning for Fast Adaptation of Neural Predictive Models
              </a>
            </td>
          <td>
            Jiaqi Yan, Ankush Chakrabarty, Alisa Rupenyan, John Lygeros
          </td>
          <td>2024-04-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="In this work, we consider a state estimation problem for large-scale nonlinear processes in the absence of first-principles process models. By exploiting process operation data, both process modeling and state estimation design are addressed within a distributed framework. By leveraging the Koopman operator concept, a parallel subsystem modeling approach is proposed to establish interactive linear subsystem process models in higher-dimensional subspaces, each of which correlates with the original nonlinear subspace of the corresponding process subsystem via a nonlinear mapping. The data-driven linear subsystem models can be used to collaboratively characterize and predict the dynamical behaviors of the entire nonlinear process. Based on the established subsystem models, local state estimators that can explicitly handle process operation constraints are designed using moving horizon estimation. The local estimators are integrated via information exchange to form a distributed estimation scheme, which provides estimates of the unmeasured/unmeasurable state variables of the original nonlinear process in a linear manner. The proposed framework is applied to a chemical process and an agro-hydrological process to illustrate its effectiveness and applicability. Good open-loop predictability of the linear subsystem models is confirmed, and accurate estimates of the process states are obtained without requiring a first-principles process model.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/03eda988898fe86254e2029f4bc9aee75bf1c0e9" target='_blank'>
              Data-driven parallel Koopman subsystem modeling and distributed moving horizon state estimation for large-scale nonlinear processes
              </a>
            </td>
          <td>
            Xiaojie Li, Song Bo, Xuewen Zhang, Yan Qin, Xunyuan Yin
          </td>
          <td>2024-04-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="After coarse-graining a complex system, the dynamics of its macro-state may exhibit more pronounced causal effects than those of its micro-state. This phenomenon, known as causal emergence, is quantified by the indicator of effective information. However, two challenges confront this theory: the absence of well-developed frameworks in continuous stochastic dynamical systems and the reliance on coarse-graining methodologies. In this study, we introduce an exact theoretic framework for causal emergence within linear stochastic iteration systems featuring continuous state spaces and Gaussian noise. Building upon this foundation, we derive an analytical expression for effective information across general dynamics and identify optimal linear coarse-graining strategies that maximize the degree of causal emergence when the dimension averaged uncertainty eliminated by coarse-graining has an upper bound. Our investigation reveals that the maximal causal emergence and the optimal coarse-graining methods are primarily determined by the principal eigenvalues and eigenvectors of the dynamic system's parameter matrix, with the latter not being unique. To validate our propositions, we apply our analytical models to three simplified physical systems, comparing the outcomes with numerical simulations, and consistently achieve congruent results.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e8d433af638e3480730f320f680f1a07bbe2a07c" target='_blank'>
              An Exact Theory of Causal Emergence for Linear Stochastic Iteration Systems
              </a>
            </td>
          <td>
            Kaiwei Liu, Bing Yuan, Jiang Zhang
          </td>
          <td>2024-05-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Numerical continuation techniques are powerful tools that have been extensively used to identify particular solutions of nonlinear dynamical systems and enable trajectory design in chaotic astrodynamics problems such as the Circular Restricted Three-Body Problem. However, the applicability of equilibrium points and periodic orbits may be questionable in real-world applications where the uncertainties of the initial conditions of the spacecraft and dynamical parameters of the problem (e.g., mass ratio parameter) are taken into consideration. Due to uncertain parameters and initial conditions, the spacecraft might not follow the reference periodic orbit owing to growing uncertainties that cause the satellite to deviate from its nominal path. Hence, it is crucial to keep track of the probability of finding the spacecraft in a given region. Building on previous work, we extend numerical continuation to moments of the distribution (i.e., stochastic continuation) by directly continuing moments of the probability density function of the spacecraft state. Only assuming normality of the initial conditions, and leveraging moment-generating functions, Isserlis' theorem, and the algebra of truncated polynomials, we propagate the distribution of the spacecraft state at consecutive surface of section crossings while retaining a symbolic map of the final moments of the distribution that depend on the initial mean and covariance matrix only. The goal of the work is to offer a differential algebra-based general framework to continue 3D periodic orbits in the presence of uncertain dynamical systems. The proposed approach is compared against traditional Monte Carlo simulations to validate the uncertainty propagation approach and demonstrate the advantages of the proposed in terms of uncertainty propagation computational burden and access to higher-dimensional problems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/96fe155e2807e057e77249a5dd223cbc8a1b0f3d" target='_blank'>
              Stochastic Continuation of Trajectories in the Circular Restricted Three-Body Problem via Differential Algebra
              </a>
            </td>
          <td>
            Giacomo Acciarini, Nicola Baresi, David J. B. Lloyd, Dario Izzo
          </td>
          <td>2024-05-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Recurrent Neural Networks excel at predicting and generating complex high-dimensional temporal patterns. Due to their inherent nonlinear dynamics and memory, they can learn unbounded temporal dependencies from data. In a Machine Learning setting, the network's parameters are adapted during a training phase to match the requirements of a given task/problem increasing its computational capabilities. After the training, the network parameters are kept fixed to exploit the learned computations. The static parameters thereby render the network unadaptive to changing conditions, such as external or internal perturbation. In this manuscript, we demonstrate how keeping parts of the network adaptive even after the training enhances its functionality and robustness. Here, we utilize the conceptor framework and conceptualize an adaptive control loop analyzing the network's behavior continuously and adjusting its time-varying internal representation to follow a desired target. We demonstrate how the added adaptivity of the network supports the computational functionality in three distinct tasks: interpolation of temporal patterns, stabilization against partial network degradation, and robustness against input distortion. Our results highlight the potential of adaptive networks in machine learning beyond training, enabling them to not only learn complex patterns but also dynamically adjust to changing environments, ultimately broadening their applicability.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/81d77920a1f3057b33f9ab48db38a16dc2b0f292" target='_blank'>
              Adaptive control of recurrent neural networks using conceptors
              </a>
            </td>
          <td>
            Guillaume Pourcel, Mirko Goldmann, Ingo Fischer, Miguel C. Soriano
          </td>
          <td>2024-05-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Recursive Bayesian filters have been widely deployed in structural system identification where output-only filters are of higher practicality. Unfortunately, the estimation obtained by instantaneous system inversion via filters can be compromised by an ill-conditionedness of the system, which is a consequence of the architecture of the sensor network. To significantly reduce the ill-conditioning and increase the robustness to available networks, a new recursive smoothing algorithm is proposed for simultaneous input and state estimation of linear systems. Unlike the existing minimum-variance unbiased (MVU) smoothing methods that are restricted to either systems with no direct feedthrough or systems with a full-rank feedforward matrix, the proposed smoothing algorithm is universally applicable to linear systems with and without direct feedthrough as well as those with a rank-deficient feedforward matrix. The proposed smoothing method does not assume any prior knowledge of the statistical characteristics or evolutionary model pertaining to the input. A different indexing of the discrete-time input leads to a distinct linear algebra from the existing MVU smoothing methods. An eight-storey shear frame and the Taipei 101 tower in Taiwan are used as case studies, and a thorough comparison is established with the Augmented Kalman Filter, MVU filters and MVU smoothing methods. It is shown that the incorporation of singular value truncation for system inversion can result in a noticeable improvement in the estimation. Moreover, across various sensor networks and in the presence of a rank-deficient feedforward matrix, the proposed method could achieve at least 67% noise reduction compared to other filters and at least 30% improvement compared to other smoothing methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2f225782f34555f09966cc8fb16d961c3d462844" target='_blank'>
              A recursive smoothing method for input and state estimation of vibrating structures
              </a>
            </td>
          <td>
            Zihao Liu, M. E. Hassanabadi, Daniel Dias-da-Costa
          </td>
          <td>2024-04-09</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Research on stochastic differential equations (SDE) involving both additive and multiplicative noise has been extensive. In situations where the primary process is driven by a multiplicative stochastic process, additive white noise typically represents an intrinsic and unavoidable fast factor, including phenomena like thermal fluctuations, inherent uncertainties in measurement processes, or rapid wind forcing in ocean dynamics. This work focuses on a significant class of such systems, particularly those characterized by linear drift and multiplicative noise, extensively explored in the literature. Conventionally, multiplicative stochastic processes are also treated as white noise in existing studies. However, when considering colored multiplicative noise, the emphasis has been on characterizing the far tails of the probability density function (PDF), regardless of the spectral properties of the noise. In the absence of additive noise and with a general colored multiplicative SDE, standard perturbation approaches lead to a second-order PDE known as the Fokker-Planck Equation (FPE), consistent with Fick's law. This investigation unveils a notable departure from this standard behavior when introducing additive white noise. At the leading order of the stochastic process strength, perturbation approaches yield a \textit{third-order PDE}, irrespective of the white noise intensity. The breakdown of the FPE further signifies the breakdown of Fick's law. Additionally, we derive the explicit solution for the equilibrium PDF corresponding to this third-order PDE Master Equation. Through numerical simulations, we demonstrate significant deviations from outcomes derived using the FPE obtained through the application of Fick's law.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2ed3025551328020993fefce004196ea9717b6a5" target='_blank'>
              Colored Stochastic Multiplicative Processes with Additive Noise Unveil a Third-Order PDE, Defying Conventional FPE and Fick-Law Paradigms
              </a>
            </td>
          <td>
            M. Bianucci, Mauro Bologna, Riccardo Mannella
          </td>
          <td>2024-04-22</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Data assimilation refers to a set of algorithms designed to compute the optimal estimate of a system's state by refining the prior prediction (known as background states) using observed data. Variational assimilation methods rely on the maximum likelihood approach to formulate a variational cost, with the optimal state estimate derived by minimizing this cost. Although traditional variational methods have achieved great success and have been widely used in many numerical weather prediction centers, they generally assume Gaussian errors in the background states, which limits the accuracy of these algorithms due to the inherent inaccuracies of this assumption. In this paper, we introduce VAE-Var, a novel variational algorithm that leverages a variational autoencoder (VAE) to model a non-Gaussian estimate of the background error distribution. We theoretically derive the variational cost under the VAE estimation and present the general formulation of VAE-Var; we implement VAE-Var on low-dimensional chaotic systems and demonstrate through experimental results that VAE-Var consistently outperforms traditional variational assimilation methods in terms of accuracy across various observational settings.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/aff96780bad11d20091e6674a2c44fe4f05b0b20" target='_blank'>
              VAE-Var: Variational-Autoencoder-Enhanced Variational Assimilation
              </a>
            </td>
          <td>
            Yi Xiao, Qilong Jia, Wei Xue, Lei Bai
          </td>
          <td>2024-05-22</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Traffic flow modeling relies heavily on fundamental diagrams. However, deterministic fundamental diagrams, such as single or multi-regime models, cannot capture the uncertainty pattern that underlies traffic flow. To address this limitation, a sparse non-parametric regression model is proposed in this paper to formulate the stochastic fundamental diagram. Unlike parametric stochastic fundamental diagram models, a non-parametric model is insensitive to parameters, flexible, and applicable. The computation complexity and the huge memory required for training in the Gaussian process regression have been reduced by introducing the sparse Gaussian process regression. The paper also discusses how empirical knowledge influences the modeling process. The paper analyzes the influence of modeling empirical knowledge in the prior of the stochastic fundamental diagram model and whether empirical knowledge can improve the robustness and accuracy of the proposed model. By introducing several well-known single-regime fundamental diagram models as the prior and testing the model's robustness and accuracy with different sampling methods given real-world data, the authors find that empirical knowledge can only benefit the model under small inducing samples given a relatively clean and large dataset. A pure data-driven approach is sufficient to estimate and describe the pattern of the density-speed relationship.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ef31602c8919688968e647ef27a563c5c582e471" target='_blank'>
              Unraveling stochastic fundamental diagrams considering empirical knowledge: modeling, limitation and further discussion
              </a>
            </td>
          <td>
            Yuan-Zheng Lei, Yaobang Gong, X. Yang
          </td>
          <td>2024-04-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Active learning optimizes the exploration of large parameter spaces by strategically selecting which experiments or simulations to conduct, thus reducing resource consumption and potentially accelerating scientific discovery. A key component of this approach is a probabilistic surrogate model, typically a Gaussian Process (GP), which approximates an unknown functional relationship between control parameters and a target property. However, conventional GPs often struggle when applied to systems with discontinuities and non-stationarities, prompting the exploration of alternative models. This limitation becomes particularly relevant in physical science problems, which are often characterized by abrupt transitions between different system states and rapid changes in physical property behavior. Fully Bayesian Neural Networks (FBNNs) serve as a promising substitute, treating all neural network weights probabilistically and leveraging advanced Markov Chain Monte Carlo techniques for direct sampling from the posterior distribution. This approach enables FBNNs to provide reliable predictive distributions, crucial for making informed decisions under uncertainty in the active learning setting. Although traditionally considered too computationally expensive for 'big data' applications, many physical sciences problems involve small amounts of data in relatively low-dimensional parameter spaces. Here, we assess the suitability and performance of FBNNs with the No-U-Turn Sampler for active learning tasks in the 'small data' regime, highlighting their potential to enhance predictive accuracy and reliability on test functions relevant to problems in physical sciences.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ebe4e8caad7fd908989b7e37a05fb880b373a0e4" target='_blank'>
              Active Learning with Fully Bayesian Neural Networks for Discontinuous and Nonstationary Data
              </a>
            </td>
          <td>
            Maxim Ziatdinov
          </td>
          <td>2024-05-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Tuning scientific and probabilistic machine learning models -- for example, partial differential equations, Gaussian processes, or Bayesian neural networks -- often relies on evaluating functions of matrices whose size grows with the data set or the number of parameters. While the state-of-the-art for evaluating these quantities is almost always based on Lanczos and Arnoldi iterations, the present work is the first to explain how to differentiate these workhorses of numerical linear algebra efficiently. To get there, we derive previously unknown adjoint systems for Lanczos and Arnoldi iterations, implement them in JAX, and show that the resulting code can compete with Diffrax when it comes to differentiating PDEs, GPyTorch for selecting Gaussian process models and beats standard factorisation methods for calibrating Bayesian neural networks. All this is achieved without any problem-specific code optimisation. Find the code at https://github.com/pnkraemer/experiments-lanczos-adjoints and install the library with pip install matfree.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c9b4877fbbde0a35c3b7f714c4cefa28d519d470" target='_blank'>
              Gradients of Functions of Large Matrices
              </a>
            </td>
          <td>
            Nicholas Kramer, Pablo Moreno-Munoz, Hrittik Roy, Søren Hauberg
          </td>
          <td>2024-05-27</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Neural networks are lately more and more often being used in the context of data-driven control, as an approximate model of the true system dynamics. Model Predictive Control (MPC) adopts this practise leading to neural MPC strategies. This raises a question of whether the trained neural network has converged and generalized in a way that the learned model encapsulates an accurate approximation of the true dynamic model of the system, thus making it a reliable choice for model-based control, especially for disturbed and uncertain systems. To tackle that, we propose Dropout MPC, a novel sampling-based ensemble neural MPC algorithm that employs the Monte-Carlo dropout technique on the learned system model. The closed loop is based on an ensemble of predictive controllers, that are used simultaneously at each time-step for trajectory optimization. Each member of the ensemble influences the control input, based on a weighted voting scheme, thus by employing different realizations of the learned system dynamics, neural control becomes more reliable by design. An additional strength of the method is that it offers by design a way to estimate future uncertainty, leading to cautious control. While the method aims in general at uncertain systems with complex dynamics, where models derived from first principles are hard to infer, to showcase the application we utilize data gathered in the laboratory from a real mobile manipulator and employ the proposed algorithm for the navigation of the robot in simulation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ffb5110c1249088154b163fffe6b0fa9097287fd" target='_blank'>
              Dropout MPC: An Ensemble Neural MPC Approach for Systems with Learned Dynamics
              </a>
            </td>
          <td>
            Spyridon Syntakas, K. Vlachos
          </td>
          <td>2024-06-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="The precision motion control problem is investigated in this paper for microstages with cross‐axial coupling and hysteresis. Cross‐axis coupling generally results in stress‐stiffening effects, thereby causing time‐varying dynamics in the microstages. Additionally, when a microstage is driven by piezoelectric actuators (PEAs), the hysteresis effect of the actuator itself must also be considered. Modeling the microstages becomes complicated when both nonlinear characteristics, coupling and hysteresis, coexist. To address this challenge without the need for modeling, a novel data‐driven model‐free predictive control scheme called first‐order tensor‐vector product polynomial approximation based model‐free predictive control (TPPA
‐MFPC is proposed. TPPA
‐MFPC solely relies on the sampling input/output (I/O) data of the systems. The main concept behind TPPA
‐MFPC is to derive a linear approximation model using the I/O data collected during operation. This linear approximation model then serves as a nominal model in a predictive controller, enabling the control of the microstages. Finally, the effectiveness of the proposed TPPA
‐MFPC scheme and the performance improvement over existing model‐free schemes, for example, proportion integration differentiation control (PID), model‐free adaptive control (MFAC), model‐free adaptive predictive control (MFAPC), data‐dependent LMI (DDLMI), and data‐enabled predictive control (DeePC) are demonstrated in the simulation examples with a 2‐degree of freedom (DOF) multileaf spring‐based microstage driven by PEA.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/16c81cf8fb6d8051ac301cce3649854190427ef8" target='_blank'>
              Data‐driven model‐free predictive control for microstage with coupling and hysteresis nonlinearities
              </a>
            </td>
          <td>
            Shiqi Lin, Xuesong Chen
          </td>
          <td>2024-04-14</td>
          <td>Asian Journal of Control</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Semi-Lagrangian (SL) schemes are highly efficient for simulating transport equations and are widely used across various applications. Despite their success, designing genuinely multi-dimensional and conservative SL schemes remains a significant challenge. Building on our previous work [Chen et al., J. Comput. Phys., V490 112329, (2023)], we introduce a conservative machine-learning-based SL finite difference (FD) method that allows for extra-large time step evolution. At the core of our approach is a novel dynamical graph neural network designed to handle the complexities associated with tracking accurately upstream points along characteristics. This proposed neural transport solver learns the conservative SL FD discretization directly from data, improving accuracy and efficiency compared to traditional numerical schemes, while significantly simplifying algorithm implementation. We validate the method' s effectiveness and efficiency through numerical tests on benchmark transport equations in both one and two dimensions, as well as the nonlinear Vlasov-Poisson system.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/cee2cc76a668b9e93d93f4d17468c991f33508bf" target='_blank'>
              Conservative semi-lagrangian finite difference scheme for transport simulations using graph neural networks
              </a>
            </td>
          <td>
            Yongsheng Chen, Wei Guo, Xinghui Zhong
          </td>
          <td>2024-05-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="To analyze and study the behaviour of the shallow water waves, the perturbed Boussinesq equation has acquired fundamental importance. The principal objective of this paper is to manifest the exact traveling wave solution of the perturbed Boussinesq equation by two well known techniques named as, two variables (G′G,1G) expansion method and generalized projective Riccati equations method. A diverse array of soliton solutions, encompassing periodic, bright solitons, singular solitons and bright singular solitons are obtained by the applications of proposed techniques. The constraint conditions for newly constructed solutions are also specified. To enhance comprehension, the numerical illustrations of constructed solutions have been represented using surface plots, 2D plots and density plots. The results delineated in this paper transcend existing analysis, offering a novel, well-structured, and modern perspective. The solutions obtained not only enrich understanding of shallow water wave models but also exhibit efficacy in providing detailed descriptions of their dynamics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bd1b63c32586d07adda6ef3a7e2810ba02ab9dfc" target='_blank'>
              Analysis of perturbed Boussinesq equation via novel integrating schemes
              </a>
            </td>
          <td>
            Miguel Vivas-Cortez, Saima Arshed, Zahida Perveen, Maasoomah Sadaf, G. Akram, Kashif Rehan, Komal Saeed
          </td>
          <td>2024-05-17</td>
          <td>PLOS ONE</td>
          <td>0</td>
          <td>28</td>
        </tr>

        <tr id="Physics-informed neural networks (PINN) is a extremely powerful paradigm used to solve equations encountered in scientific computing applications. An important part of the procedure is the minimization of the equation residual which includes, when the equation is time-dependent, a time sampling. It was argued in the literature that the sampling need not be uniform but should overweight initial time instants, but no rigorous explanation was provided for these choice. In this paper we take some prototypical examples and, under standard hypothesis concerning the neural network convergence, we show that the optimal time sampling follows a truncated exponential distribution. In particular we explain when the time sampling is best to be uniform and when it should not be. The findings are illustrated with numerical examples on linear equation, Burgers' equation and the Lorenz system.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/19e471fad028cba1fe70f47767cf3a6ba2043b8d" target='_blank'>
              Optimal time sampling in physics-informed neural networks
              </a>
            </td>
          <td>
            Gabriel Turinici
          </td>
          <td>2024-04-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Dynamical systems are crucial for defining our comprehension of the physical world, offering a robust structure for examining and representing intricate occurrences. The exploration of dynamical systems in physics traces back to the initial developments of classical mechanics by Newton and Lagrange. Over time, this framework has developed and grown to encompass a broad array of physical phenomena, ranging from the movement of astronomical objects to the actions of subatomic particles. The close relationship between dynamical systems and physical principles has inspired the study and improvement of this mathematical field. This paper delves into the diverse applications of dynamical systems in physics, emphasizing the research background, methodology, main discoveries, and wider ramifications. This study tries to offer a thorough summary of the diverse impacts of dynamical systems on the area of physics by combining several research papers. By utilizing dynamical systems, researchers have gained a deeper understanding of the fundamental order that governs complex dynamics, paving the way for improved predictions, innovative technologies, and a deeper understanding of the underlying principles that govern the universe.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7c134f16023991304478455daa760238413e5a02" target='_blank'>
              Applications of dynamical systems in physics
              </a>
            </td>
          <td>
            Zhengran Liu
          </td>
          <td>2024-05-28</td>
          <td>Theoretical and Natural Science</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="We introduce a novel neural architecture termed thermoNET, designed to represent thermospheric density in satellite orbital propagation using a reduced amount of differentiable computations. Due to the appearance of a neural network on the right-hand side of the equations of motion, the resulting satellite dynamics is governed by a NeuralODE, a neural Ordinary Differential Equation, characterized by its fully differentiable nature, allowing the derivation of variational equations (hence of the state transition matrix) and facilitating its use in connection to advanced numerical techniques such as Taylor-based numerical propagation and differential algebraic techniques. Efficient training of the network parameters occurs through two distinct approaches. In the first approach, the network undergoes training independently of spacecraft dynamics, engaging in a pure regression task against ground truth models, including JB-08 and NRLMSISE-00. In the second paradigm, network parameters are learned based on observed dynamics, adapting through ODE sensitivities. In both cases, the outcome is a flexible, compact model of the thermosphere density greatly enhancing numerical propagation efficiency while maintaining accuracy in the orbital predictions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3b57fe3207d805375328ba41dd921c7ce36e2d23" target='_blank'>
              NeuralODEs for VLEO simulations: Introducing thermoNET for Thermosphere Modeling
              </a>
            </td>
          <td>
            Dario Izzo, Giacomo Acciarini, F. Biscani
          </td>
          <td>2024-05-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>13</td>
        </tr>

        <tr id="In this paper, we investigate the (2+1)-dimensional Kadomtsev-Petviashvili-Benjamin-Bona Mahony equation using two effective methods: the unified scheme and the advanced auxiliary equation scheme, aiming to derive precise wave solutions. These solutions are expressed as combinations of trigonometric, rational, hyperbolic, and exponential functions. Visual representations, including three-dimensional (3D) and two-dimensional (2D) combined charts, are provided for some of these solutions. The influence of the nonlinear parameter p on the wave type is thoroughly examined through diverse figures, illustrating the profound impact of nonlinearity. Additionally, we briefly investigate the Hamiltonian function and the stability of the model using a planar dynamical system approach. This involves examining trajectories, isoclines, and nullclines to illustrate stable solution paths for the wave variables. Numerical results demonstrate that these methods are reliable, straightforward, and potent tools for analyzing various nonlinear evolution equations found in physics, applied mathematics, and engineering.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a1e87c65b95cae55259c3ae3028178a26e5c1a70" target='_blank'>
              Investigating wave solutions and impact of nonlinearity: Comprehensive study of the KP-BBM model with bifurcation analysis
              </a>
            </td>
          <td>
            S. M. Rayhanul Islam, K. Khan
          </td>
          <td>2024-05-02</td>
          <td>PLOS ONE</td>
          <td>0</td>
          <td>21</td>
        </tr>

        <tr id="We study online policy optimization in nonlinear time-varying dynamical systems where the true dynamical models are unknown to the controller. This problem is challenging because, unlike in linear systems, the controller cannot obtain globally accurate estimations of the ground-truth dynamics using local exploration. We propose a meta-framework that combines a general online policy optimization algorithm ($\texttt{ALG}$) with a general online estimator of the dynamical system's model parameters ($\texttt{EST}$). We show that if the hypothetical joint dynamics induced by $\texttt{ALG}$ with known parameters satisfies several desired properties, the joint dynamics under inexact parameters from $\texttt{EST}$ will be robust to errors. Importantly, the final policy regret only depends on $\texttt{EST}$'s predictions on the visited trajectory, which relaxes a bottleneck on identifying the true parameters globally. To demonstrate our framework, we develop a computationally efficient variant of Gradient-based Adaptive Policy Selection, called Memoryless GAPS (M-GAPS), and use it to instantiate $\texttt{ALG}$. Combining M-GAPS with online gradient descent to instantiate $\texttt{EST}$ yields (to our knowledge) the first local regret bound for online policy optimization in nonlinear time-varying systems with unknown dynamics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6decacac529e3c0f4124d4de7e19984f8b0f0175" target='_blank'>
              Online Policy Optimization in Unknown Nonlinear Systems
              </a>
            </td>
          <td>
            Yiheng Lin, James A. Preiss, Fengze Xie, Emile Anand, Soon-Jo Chung, Yisong Yue, Adam Wierman
          </td>
          <td>2024-04-19</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>9</td>
        </tr>

        <tr id="Developing physical closure models with explicit expressions based on a given dataset is essential to science and engineering. For such symbolic regression tasks, biology-inspired evolutionary algorithms are most widely used. However, typical evolutionary algorithms do not utilize any structural information inherent in training data, which limits their performance in finding accurate model structures and coefficients. By combining one evolutionary algorithm, gene expression programing (GEP), with an artificial neural network (ANN) for symbolic regression, we propose a novel evolutionary neural network method, in which candidate expressions are specifically designed so that they can be transformed between the GEP and ANN structures during training iterations. By combining the GEP's global searching and the ANN's gradient optimization capabilities, efficient and robust convergence to accurate models can be achieved. In addition, sparsity-enhancing strategies have been introduced to improve the interpretability of the trained models. The present method has been tested for finding different physical laws and then applied to turbulence modeling problems with different configurations, showing advantages compared to the existing GEP and ANN methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5f6b8aac20c06c4c72f3e37eb3aed6566c0c27f0" target='_blank'>
              Evolutionary neural networks for learning turbulence closure models with explicit expressions
              </a>
            </td>
          <td>
            Haochen Li, Yaomin Zhao, F. Waschkowski, R. D. Sandberg
          </td>
          <td>2024-05-01</td>
          <td>Physics of Fluids</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a9140074d19390b19afab2f261d441314a2bef0f" target='_blank'>
              Koopman operator-based multi-model for predictive control
              </a>
            </td>
          <td>
            M. Ławryńczuk
          </td>
          <td>2024-04-27</td>
          <td>Nonlinear Dynamics</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="Reservoir computing, a machine learning framework used for modeling the brain, can predict temporal data with little observations and minimal computational resources. However, it is difficult to accurately reproduce the long-term target time series because the reservoir system becomes unstable. This predictive capability is required for a wide variety of time-series processing, including predictions of motor timing and chaotic dynamical systems. This study proposes oscillation-driven reservoir computing (ODRC) with feedback, where oscillatory signals are fed into a reservoir network to stabilize the network activity and induce complex reservoir dynamics. The ODRC can reproduce long-term target time series more accurately than conventional reservoir computing methods in a motor timing and chaotic time-series prediction tasks. Furthermore, it generates a time series similar to the target in the unexperienced period, that is, it can learn the abstract generative rules from limited observations. Given these significant improvements made by the simple and computationally inexpensive implementation, the ODRC would serve as a practical model of various time series data. Moreover, we will discuss biological implications of the ODRC, considering it as a model of neural oscillations and their cerebellar processors.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/be6e6176cecfe11f59814a81dd7ff34c2eada2b4" target='_blank'>
              Oscillations enhance time-series prediction in reservoir computing with feedback
              </a>
            </td>
          <td>
            Yuji Kawai, Takashi Morita, Jihoon Park, Minoru Asada
          </td>
          <td>2024-06-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Subspace predictive control (SPC) is a widely utilized data-driven control technique in various industrial applications. However, its static nature restricts its ability to effectively track nonlinear dynamic systems, resulting in diminished performance. To address this problem, an adaptive subspace predictive control approach is proposed, incorporating an adaptive mechanism to continuously update the subspace predictor. The designed adaptive mechanism mitigates the negative impact of historical data by sliding the data window. It simultaneously employs the addition and deletion of data vectors in the data matrix through recursive matrix transformation, simplifying computational complexity while maintaining accuracy. In addition, the developed subspace predictor enables online learning and effectively handles the dynamic nature of industrial processes, requiring little prior knowledge. The theoretical analysis of the proposed control approach includes recursive feasibility and stability, along with a discussion on determining relevant parameters. The effectiveness of the proposed control approach is demonstrated through its application to a continuous stirred tank heater benchmark. The results exhibit significant improvements in tracking control performance, leading to enhanced efficiency and cost reduction. Overall, this research presents a promising solution for addressing the challenges of predictive control in industrial processes.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ff6b217cb35ea3c09e7f6f8e5be806b71f5cf6ef" target='_blank'>
              A Novel Adaptive Subspace Predictive Control Approach With Application to Continuous Stirred Tank Heater
              </a>
            </td>
          <td>
            Xinwei Wu, Xuebo Yang, Jianbin Qiu
          </td>
          <td>2024-06-01</td>
          <td>IEEE Transactions on Industrial Informatics</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="This study introduces a computational approach leveraging Physics-Informed Neural Networks (PINNs) for the efficient computation of arterial blood flows, particularly focusing on solving the incompressible Navier-Stokes equations by using the domain decomposition technique. Unlike conventional computational fluid dynamics methods, PINNs offer advantages by eliminating the need for discretized meshes and enabling the direct solution of partial differential equations (PDEs). In this paper, we propose the weighted Extended Physics-Informed Neural Networks (WXPINNs) and weighted Conservative Physics-Informed Neural Networks (WCPINNs), tailored for detailed hemodynamic simulations based on generalized space-time domain decomposition techniques. The inclusion of multiple neural networks enhances the representation capacity of the weighted PINN methods. Furthermore, the weighted PINNs can be efficiently trained in parallel computing frameworks by employing separate neural networks for each sub-domain. We show that PINNs simulation results circumvent backflow instabilities, underscoring a notable advantage of employing PINNs over traditional numerical methods to solve such complex blood flow models. They naturally address such challenges within their formulations. The presented numerical results demonstrate that the proposed weighted PINNs outperform traditional PINNs settings, where sub-PINNs are applied to each subdomain separately. This study contributes to the integration of deep learning methodologies with fluid mechanics, paving the way for accurate and efficient high-fidelity simulations in biomedical applications, particularly in modeling arterial blood flow.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/12cdb7499810597d8960adf74360b4aee67e77d0" target='_blank'>
              Enhancing Arterial Blood Flow Simulations through Physics-Informed Neural Networks
              </a>
            </td>
          <td>
            Shivam Bhargava, Nagaiah Chamakuri
          </td>
          <td>2024-04-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Learning complex trajectories from demonstrations in robotic tasks has been effectively addressed through the utilization of Dynamical Systems (DS). State-of-the-art DS learning methods ensure stability of the generated trajectories; however, they have three shortcomings: a) the DS is assumed to have a single attractor, which limits the diversity of tasks it can achieve, b) state derivative information is assumed to be available in the learning process and c) the state of the DS is assumed to be measurable at inference time. We propose a class of provably stable latent DS with possibly multiple attractors, that inherit the training methods of Neural Ordinary Differential Equations, thus, dropping the dependency on state derivative information. A diffeomorphic mapping for the output and a loss that captures time-invariant trajectory similarity are proposed. We validate the efficacy of our approach through experiments conducted on a public dataset of handwritten shapes and within a simulated object manipulation task.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/cc227c83d593a317b47926de7d4a6905d2fc78a4" target='_blank'>
              Learning Deep Dynamical Systems using Stable Neural ODEs
              </a>
            </td>
          <td>
            Andreas Sochopoulos, M. Gienger, S. Vijayakumar
          </td>
          <td>2024-04-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>45</td>
        </tr>

        <tr id="A reservoir computer (RC) is a recurrent neural network (RNN) framework that achieves computational efficiency where only readout layer training is required. Additionally, it effectively predicts nonlinear dynamical system tasks and has various applications. RC is effective for forecasting nonautonomous dynamical systems with gradual changes to the external drive amplitude. This study investigates the predictability of nonautonomous dynamical systems with rapid changes to the phase of the external drive. The forced Van der Pol equation was employed for the base model, implementing forecasting tasks with the RC. The study findings suggest that, despite hidden variables, a nonautonomous dynamical system with rapid changes to the phase of the external drive is predictable. Therefore, RC can offer better schedules for individual shift workers.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c287992af2ce64be6c79397ffdf3d5bcc326f821" target='_blank'>
              Forecasting the Forced Van der Pol Equation with Frequent Phase Shifts Using a Reservoir Computer
              </a>
            </td>
          <td>
            Sho Kuno, Hiroshi Kori
          </td>
          <td>2024-04-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="This paper presents a new boundary-value problem formulation for quantifying uncertainty induced by the presence of small Brownian noise near transversally stable periodic orbits (limit cycles) and quasiperiodic invariant tori of the deterministic dynamical systems obtained in the absence of noise. The formulation uses adjoints to construct a continuous family of transversal hyperplanes that are invariant under the linearized deterministic flow near the limit cycle or quasiperiodic invariant torus. The intersections with each hyperplane of stochastic trajectories that remain near the deterministic cycle or torus over intermediate times may be approximated by a Gaussian distribution whose covariance matrix can be obtained from the solution to the corresponding boundary-value problem. In the case of limit cycles, the analysis improves upon results in the literature through the explicit use of state-space projections, transversality constraints, and symmetry-breaking parameters that ensure uniqueness of the solution despite the lack of hyperbolicity along the limit cycle. These same innovations are then generalized to the case of a quasiperiodic invariant torus of arbitrary dimension. In each case, a closed-form solution to the covariance boundary-value problem is found in terms of a convergent series. The methodology is validated against the results of numerical integration for two examples of stochastically perturbed limit cycles and one example of a stochastically perturbed two-dimensional quasiperiodic invariant torus. Finally, an implementation of the covariance boundary-value problem in the numerical continuation package coco is applied to analyze the small-noise limit near a two-dimensional quasiperiodic invariant torus in a nonlinear deterministic dynamical system in $\mathbb{R}^4$ that does not support closed-form analysis.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3301de8fe4477b187bf60eaf9e1b46e7eb66f04f" target='_blank'>
              Adjoint-Based Projections for Uncertainty Quantification near Stochastically Perturbed Limit Cycles and Tori
              </a>
            </td>
          <td>
            Zaid Ahsan, Harry Dankowicz, Christian Kuehn
          </td>
          <td>2024-04-20</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>5</td>
        </tr>

        <tr id="Abstract Motivation Systems biology aims to better understand living systems through mathematical modelling of experimental and clinical data. A pervasive challenge in quantitative dynamical modelling is the integration of time series measurements, which often have high variability and low sampling resolution. Approaches are required to utilize such information while consistently handling uncertainties. Results We present BayModTS (Bayesian modelling of time series data), a new FAIR (findable, accessible, interoperable, and reusable) workflow for processing and analysing sparse and highly variable time series data. BayModTS consistently transfers uncertainties from data to model predictions, including process knowledge via parameterized models. Further, credible differences in the dynamics of different conditions can be identified by filtering noise. To demonstrate the power and versatility of BayModTS, we applied it to three hepatic datasets gathered from three different species and with different measurement techniques: (i) blood perfusion measurements by magnetic resonance imaging in rat livers after portal vein ligation, (ii) pharmacokinetic time series of different drugs in normal and steatotic mice, and (iii) CT-based volumetric assessment of human liver remnants after clinical liver resection. Availability and implementation The BayModTS codebase is available on GitHub at https://github.com/Systems-Theory-in-Systems-Biology/BayModTS. The repository contains a Python script for the executable BayModTS workflow and a widely applicable SBML (systems biology markup language) model for retarded transient functions. In addition, all examples from the paper are included in the repository. Data and code of the application examples are stored on DaRUS: https://doi.org/10.18419/darus-3876. The raw MRI ROI voxel data were uploaded to DaRUS: https://doi.org/10.18419/darus-3878. The steatosis metabolite data are published on FairdomHub: 10.15490/fairdomhub.1.study.1070.1.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/483f129e077df807f3f25aef2dde774505aa52b2" target='_blank'>
              Bayesian modelling of time series data (BayModTS)—a FAIR workflow to process sparse and highly variable data
              </a>
            </td>
          <td>
            Sebastian Höpfl, Mohamed Albadry, U. Dahmen, Karl-Heinz Herrmann, E. Kindler, Matthias König, Jürgen Rainer Reichenbach, Hans-Michael Tautenhahn, Weiwei Wei, Wan-Ting Zhao, Nicole Erika Radde
          </td>
          <td>2024-05-01</td>
          <td>Bioinformatics</td>
          <td>0</td>
          <td>36</td>
        </tr>

        <tr id="Ensemble systems appear frequently in many engineering applications and, as a result, they have become an important research topic in control theory. These systems are best characterized by the evolution of their underlying state distribution. Despite the work to date, few results exist dealing with the problem of directly modifying (i.e.,"steering") the distribution of an ensemble system. In addition, in most of the existing results, the distribution of the states of an ensemble of discrete-time systems is assumed to be Gaussian. However, in case the system parameters are uncertain, it is not always realistic to assume that the distribution of the system follows a Gaussian distribution, thus complicating the solution of the overall problem. In this paper, we address the general distribution steering problem for first-order discrete-time ensemble systems, where the distributions of the system parameters and the states are arbitrary with finite first few moments. Both linear and nonlinear system dynamics are considered using the method of power moments to transform the original infinite-dimensional problem into a finite-dimensional one. We also propose a control law for the ensuing moment system, which allows us to obtain the power moments of the desired control inputs. Finally, we solve the inverse problem to obtain the feasible control inputs from their corresponding power moments. We provide numerical results to validate our theoretical developments. These include cases where the parameter distribution is uniform, Gaussian, non-Gaussian, and multi-modal, respectively.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/48fbd518d7f9fd0527962e3a3cff63f12ae709a4" target='_blank'>
              Distribution Steering for Discrete-Time Uncertain Ensemble Systems
              </a>
            </td>
          <td>
            Guangyu Wu, Panagiotis Tsiotras, Anders Lindquist
          </td>
          <td>2024-05-20</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2d72fbac501c75d7e3eae527a5d016165360cba5" target='_blank'>
              Tutorial: a beginner’s guide to building a representative model of dynamical systems using the adjoint method
              </a>
            </td>
          <td>
            Leon Lettermann, Alejandro Jurado, Timo Betz, F. Wörgötter, S. Herzog
          </td>
          <td>2024-04-15</td>
          <td>Communications Physics</td>
          <td>0</td>
          <td>49</td>
        </tr>

        <tr id="
 This paper deals into the complexities of nonlinear dynamics within the nonlinear generalized advection- diffusion-reaction equation, which describes intricate transport phenomena involving advection, diffusion, and reaction processes occurring simultaneously. Through the utilization of the Lie symmetry approach, we thoroughly examine this proposed model, transforming the partial differential equation into an ordinary differential equation using similarity reduction techniques to facilitate a more comprehensive analysis. Ex- act solutions for this transformed equation are derived employing the extended simplest equation method and the new extended direct algebraic method. To enhance understanding, contour plots along with 2D and 3D visualizations of solutions are employed. Additionally, we explore bifurcation and chaotic be- haviours through a qualitative analysis of the model. Phase portraits are meticulously scrutinized across various parameter values, offering insights into system behavior. Introduction of an external periodic strength allows us to utilize various tools including time series, 3D, and 2D phase patterns to discern chaotic and quasi-periodic behaviors. Furthermore, a multistability analysis is conducted to examine the impacts of diverse initial conditions. These findings underscore the efficacy and practicality of the pro- posed methodologies in evaluating soliton solutions and elucidating phase dynamics across a spectrum of nonlinear models, offering novel perspectives on intricate physical phenomena.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/508ebc06c56bbbb75a7f16d2ee1353ff5f26d235" target='_blank'>
              Symmetry and complexity: A Lie symmetry method tobifurcation, chaos, multistability and soliton solutions of thenonlinear generalized advection-diffusion-reaction equation
              </a>
            </td>
          <td>
            Samina Samina, Adil Jhangeer, Zili Chen
          </td>
          <td>2024-05-23</td>
          <td>Physica Scripta</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Abstract Small data learning problems are characterized by a significant discrepancy between the limited number of response variable observations and the large feature space dimension. In this setting, the common learning tools struggle to identify the features important for the classification task from those that bear no relevant information and cannot derive an appropriate learning rule that allows discriminating among different classes. As a potential solution to this problem, here we exploit the idea of reducing and rotating the feature space in a lower-dimensional gauge and propose the gauge-optimal approximate learning (GOAL) algorithm, which provides an analytically tractable joint solution to the dimension reduction, feature segmentation, and classification problems for small data learning problems. We prove that the optimal solution of the GOAL algorithm consists in piecewise-linear functions in the Euclidean space and that it can be approximated through a monotonically convergent algorithm that presents—under the assumption of a discrete segmentation of the feature space—a closed-form solution for each optimization substep and an overall linear iteration cost scaling. The GOAL algorithm has been compared to other state-of-the-art machine learning tools on both synthetic data and challenging real-world applications from climate science and bioinformatics (i.e., prediction of the El Niño Southern Oscillation and inference of epigenetically induced gene-activity networks from limited experimental data). The experimental results show that the proposed algorithm outperforms the reported best competitors for these problems in both learning performance and computational cost.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/65b75fd640587625519581accb1de4f7b024e14f" target='_blank'>
              Gauge-Optimal Approximate Learning for Small Data Classification
              </a>
            </td>
          <td>
            Edoardo Vecchi, Davide Bassetti, Fabio Graziato, Lukáš Pospíšil, I. Horenko
          </td>
          <td>2023-10-29</td>
          <td>Neural Computation</td>
          <td>0</td>
          <td>26</td>
        </tr>

        <tr id="We consider the problem of optimizing initial conditions and timing in dynamical systems governed by unknown ordinary differential equations (ODEs), where evaluating different initial conditions is costly and there are constraints on observation times. To identify the optimal conditions within several trials, we introduce a few-shot Bayesian Optimization (BO) framework based on the system's prior information. At the core of our approach is the System-Aware Neural ODE Processes (SANODEP), an extension of Neural ODE Processes (NODEP) designed to meta-learn ODE systems from multiple trajectories using a novel context embedding block. Additionally, we propose a multi-scenario loss function specifically for optimization purposes. Our two-stage BO framework effectively incorporates search space constraints, enabling efficient optimization of both initial conditions and observation timings. We conduct extensive experiments showcasing SANODEP's potential for few-shot BO. We also explore SANODEP's adaptability to varying levels of prior information, highlighting the trade-off between prior flexibility and model fitting accuracy.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/fcc3aee3d63369b46495f52c938226e7f6a37977" target='_blank'>
              System-Aware Neural ODE Processes for Few-Shot Bayesian Optimization
              </a>
            </td>
          <td>
            Jixiang Qing, Becky D Langdon, Robert M. Lee, B. Shafei, Mark van der Wilk, Calvin Tsay, Ruth Misener
          </td>
          <td>2024-06-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>22</td>
        </tr>

        <tr id="Many problems in statistics and machine learning can be formulated as model selection problems, where the goal is to choose an optimal parsimonious model among a set of candidate models. It is typical to conduct model selection by penalizing the objective function via information criteria (IC), as with the pioneering work by Akaike and Schwarz. Via recent work, we propose a generalized IC framework to consistently estimate general loss-based learning problems. In this work, we propose a consistent estimation method for Generalized Linear Model (GLM) regressions by utilizing the recent IC developments. We advance the generalized IC framework by proposing model selection problems, where the model set consists of a potentially uncountable set of models. In addition to theoretical expositions, our proposal introduces a computational procedure for the implementation of our methods in the finite sample setting, which we demonstrate via an extensive simulation study.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/37f94925196e52833177e5483399fad3bcdac36c" target='_blank'>
              Consistent information criteria for regularized regression and loss-based learning problems
              </a>
            </td>
          <td>
            Qingyuan Zhang, Hien Duy Nguyen
          </td>
          <td>2024-04-26</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The estimation of relative motion between spacecraft increasingly relies on feature-matching computer vision, which feeds data into a recursive filtering algorithm. Kalman filters, although efficient in noise compensation, demand extensive tuning of system and noise models. This paper introduces FlexKalmanNet, a novel modular framework that bridges this gap by integrating a deep fully connected neural network with Kalman filter-based motion estimation algorithms. FlexKalmanNet's core innovation is its ability to learn any Kalman filter parameter directly from measurement data, coupled with the flexibility to utilize various Kalman filter variants. This is achieved through a notable design decision to outsource the sequential computation from the neural network to the Kalman filter variant, enabling a purely feedforward neural network architecture. This architecture, proficient at handling complex, nonlinear features without the dependency on recurrent network modules, captures global data patterns more effectively. Empirical evaluation using data from NASA's Astrobee simulation environment focuses on learning unknown parameters of an Extended Kalman filter for spacecraft pose and twist estimation. The results demonstrate FlexKalmanNet's rapid training convergence, high accuracy, and superior performance against manually tuned Extended Kalman filters.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/cd57ff30be7442165f7f8621c7a884d777cfdc60" target='_blank'>
              FlexKalmanNet: A Modular AI-Enhanced Kalman Filter Framework Applied to Spacecraft Motion Estimation
              </a>
            </td>
          <td>
            Moritz D. Pinheiro-Torres Vogt, Markus Huwald, rd M. Khalil, Enrico Stoll
          </td>
          <td>2024-05-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The growing scale and complexity of safety-critical control systems underscore the need to evolve current control architectures aiming for the unparalleled performances achievable through state-of-the-art optimization and machine learning algorithms. However, maintaining closed-loop stability while boosting the performance of nonlinear control systems using data-driven and deep-learning approaches stands as an important unsolved challenge. In this paper, we tackle the performance-boosting problem with closed-loop stability guarantees. Specifically, we establish a synergy between the Internal Model Control (IMC) principle for nonlinear systems and state-of-the-art unconstrained optimization approaches for learning stable dynamics. Our methods enable learning over arbitrarily deep neural network classes of performance-boosting controllers for stable nonlinear systems; crucially, we guarantee Lp closed-loop stability even if optimization is halted prematurely, and even when the ground-truth dynamics are unknown, with vanishing conservatism in the class of stabilizing policies as the model uncertainty is reduced to zero. We discuss the implementation details of the proposed control schemes, including distributed ones, along with the corresponding optimization procedures, demonstrating the potential of freely shaping the cost functions through several numerical experiments.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e51cb2795804c20221e3c822bebda0752242996d" target='_blank'>
              Learning to Boost the Performance of Stable Nonlinear Systems
              </a>
            </td>
          <td>
            Luca Furieri, C. Galimberti, Giancarlo Ferrari-Trecate
          </td>
          <td>2024-05-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="Neural networks have become a widely adopted tool for tackling a variety of problems in machine learning and artificial intelligence. In this contribution we use the mathematical framework of local stability analysis to gain a deeper understanding of the learning dynamics of feed forward neural networks. Therefore, we derive equations for the tangent operator of the learning dynamics of three-layer networks learning regression tasks. The results are valid for an arbitrary numbers of nodes and arbitrary choices of activation functions. Applying the results to a network learning a regression task, we investigate numerically, how stability indicators relate to the final training-loss. Although the specific results vary with different choices of initial conditions and activation functions, we demonstrate that it is possible to predict the final training loss, by monitoring finite-time Lyapunov exponents or covariant Lyapunov vectors during the training process.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/870465bd2bfb984efc8bc1293ffbd4dda5049468" target='_blank'>
              On the weight dynamics of learning networks
              </a>
            </td>
          <td>
            Nahal Sharafi, Christoph Martin, Sarah Hallerberg
          </td>
          <td>2024-04-30</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="This study provides an innovative and attractive analytical strategy to examine the numerical solution for the time-fractional Schrödinger equation (SE) in the sense of Caputo fractional operator. In this research, we present the Elzaki transform residual power series method (ET-RPSM), which combines the Elzaki transform (ET) with the residual power series method (RPSM). This strategy has the advantage of requiring only the premise of limiting at zero for determining the coefficients of the series, and it uses symbolic computation software to perform the least number of calculations. The results obtained through the considered method are in the form of a series solution and converge rapidly. These outcomes closely match the precise results and are discussed through graphical structures to express the physical representation of the considered equation. The results showed that the suggested strategy is a straightforward, suitable, and practical tool for solving and comprehending a wide range of nonlinear physical models.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b9fe64f8fe4a8c55f8a71223f834df8690b5233d" target='_blank'>
              Numerical Study of Time-Fractional Schrödinger Model in One-Dimensional Space Arising in Mathematical Physics
              </a>
            </td>
          <td>
            Muhammad Nadeem, LOREDANA-FLORENTINA Iambor
          </td>
          <td>2024-05-07</td>
          <td>Fractal and Fractional</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="In complex and unknown processes, global models are initially generated over the entire experimental space, but they often fail to provide accurate predictions in local areas. Recognizing this limitation, this study addresses the need for models that effectively represent both global and local experimental spaces. It introduces a novel machine learning (ML) approach: Polynomial Chaos Expanded Gaussian Process (PCEGP), leveraging polynomial chaos expansion (PCE) to calculate input-dependent hyperparameters of the Gaussian process (GP). This approach provides a mathematically interpretable method that incorporates non-stationary covariance functions and heteroscedastic noise estimation to generate locally adapted models. The model performance is compared to different algorithms in benchmark tests for regression tasks. The results demonstrate low prediction errors of the PCEGP in these benchmark applications, highlighting model performance that is often competitive with or superior to previous methods. A key advantage of the presented model is the transparency and traceability in the calculation of hyperparameters and model predictions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/79fcfc9d7d191364d7c1f0e349ea576035887a86" target='_blank'>
              Polynomial Chaos Expanded Gaussian Process
              </a>
            </td>
          <td>
            Dominik Polke, Tim Kosters, Elmar Ahle, Dirk Soffker
          </td>
          <td>2024-05-02</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="
 This paper introduces a methodology for updating the nonlinear stochastic dynamics of a nozzle with uncertain computational model. The approach focuses on a high-dimensional nonlinear computational model constrained by a small target dataset. Challenges include the large number of degrees-of-freedom, geometric nonlinearities, material uncertainties, stochastic external loads, under-observability, and high computational costs. A detailed dynamic analysis of the nozzle is presented. An updated statistical surrogate model relating the observations of interest to the control parameters is constructed. Despite small training and target datasets, and partial observability, the study successfully applies Probabilistic Learning on Manifolds (PLoM) to address these challenges. PLoM captures geometric nonlinear effects and uncertainty propagation, improving conditional mean statistics compared to training data. The conditional confidence region demonstrates the ability of the methodology to accurately represent both observed and unobserved output variables, contributing to advancements in modeling complex systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/47ba81770bbd1dbf667d111d3293f5a512dfd8a5" target='_blank'>
              Updating Nonlinear Stochastic Dynamics of an Uncertain Nozzle Model using Probabilistic Learning with Partial Observability and Incomplete dataset
              </a>
            </td>
          <td>
            E. Capiez-Lernout, O. Ezvan, Christian Soize
          </td>
          <td>2024-04-15</td>
          <td>Journal of Computing and Information Science in Engineering</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3a55eaca89003e36b7cc1e7255b5a0a0b78a25e1" target='_blank'>
              Fractional dynamics study: analytical solutions of modified Kordeweg-de Vries equation and coupled Burger’s equations using Aboodh transform
              </a>
            </td>
          <td>
            Naveed Iqbal, Shah Hussain, A. Hamza, Ali Abdullah, Wael W. Mohammed, Mohammad Yar
          </td>
          <td>2024-06-03</td>
          <td>Scientific Reports</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="Neural network-based approaches have recently shown significant promise in solving partial differential equations (PDEs) in science and engineering, especially in scenarios featuring complex domains or the incorporation of empirical data. One advantage of the neural network method for PDEs lies in its automatic differentiation (AD), which necessitates only the sample points themselves, unlike traditional finite difference (FD) approximations that require nearby local points to compute derivatives. In this paper, we quantitatively demonstrate the advantage of AD in training neural networks. The concept of truncated entropy is introduced to characterize the training property. Specifically, through comprehensive experimental and theoretical analyses conducted on random feature models and two-layer neural networks, we discover that the defined truncated entropy serves as a reliable metric for quantifying the residual loss of random feature models and the training speed of neural networks for both AD and FD methods. Our experimental and theoretical analyses demonstrate that, from a training perspective, AD outperforms FD in solving partial differential equations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/dab74a78b1102fae26f5c81587f815591116d925" target='_blank'>
              Automatic Differentiation is Essential in Training Neural Networks for Solving Differential Equations
              </a>
            </td>
          <td>
            Chuqi Chen, Yahong Yang, Yang Xiang, Wenrui Hao
          </td>
          <td>2024-05-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="We present ElastoGen, a knowledge-driven model that generates physically accurate and coherent 4D elastodynamics. Instead of relying on petabyte-scale data-driven learning, ElastoGen leverages the principles of physics-in-the-loop and learns from established physical knowledge, such as partial differential equations and their numerical solutions. The core idea of ElastoGen is converting the global differential operator, corresponding to the nonlinear elastodynamic equations, into iterative local convolution-like operations, which naturally fit modern neural networks. Each network module is specifically designed to support this goal rather than functioning as a black box. As a result, ElastoGen is exceptionally lightweight in terms of both training requirements and network scale. Additionally, due to its alignment with physical procedures, ElastoGen efficiently generates accurate dynamics for a wide range of hyperelastic materials and can be easily integrated with upstream and downstream deep modules to enable end-to-end 4D generation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c4060213d522f399e2e12d94169c6f983895e9af" target='_blank'>
              ElastoGen: 4D Generative Elastodynamics
              </a>
            </td>
          <td>
            Yutao Feng, Yintong Shang, Xiang Feng, Lei Lan, Shandian Zhe, Tianjia Shao, Hongzhi Wu, Kun Zhou, Hao Su, Chenfanfu Jiang, Yin Yang
          </td>
          <td>2024-05-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>21</td>
        </tr>

        <tr id="Biochemical reaction networks perform a variety of signal processing functions, one of which is computing the integrals of signal values. This is often used in integral feedback control, where it enables a system’s output to respond to changing inputs, but to then return exactly back to some pre-determined setpoint value afterward. To gain a deeper understanding of how biochemical networks are able to both integrate signals and perform integral feedback control, we investigated these abilities for several simple reaction networks. We found imperfect overlap between these categories, with some networks able to perform both tasks, some able to perform integration but not integral feedback control, and some the other way around. Nevertheless, networks that could either integrate or perform integral feedback control shared key elements. In particular, they included a chemical species that was neutrally stable in the open loop system (no feedback), meaning that this species does not have a unique stable steady-state concentration. Neutral stability could arise from zeroth order decay reactions, binding to a partner that was produced at a constant rate (which occurs in antithetic control), or through a long chain of covalent cycles. Mathematically, it arose from rate equations for the reaction network that were underdetermined when evaluated at steady-state.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a909d1d990b5de2bed45db0e78f5863b1dccd2fb" target='_blank'>
              Signal integration and integral feedback control with biochemical reaction networks
              </a>
            </td>
          <td>
            Steven S. Andrews, Michael A. Kochen, Lucian P. Smith, Song-Jiang Feng, H. S. Wiley, Herbert M. Sauro
          </td>
          <td>2024-04-29</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Learning dynamical systems from sparse observations is critical in numerous fields, including biology, finance, and physics. Even if tackling such problems is standard in general information fusion, it remains challenging for contemporary machine learning models, such as diffusion models. We introduce a method that integrates conditional particle filtering with ancestral sampling and diffusion models, enabling the generation of realistic trajectories that align with observed data. Our approach uses a smoother based on iterating a conditional particle filter with ancestral sampling to first generate plausible trajectories matching observed marginals, and learns the corresponding diffusion model. This approach provides both a generative method for high-quality, smoothed trajectories under complex constraints, and an efficient approximation of the particle smoothing distribution for classical tracking problems. We demonstrate the approach in time-series generation and interpolation tasks, including vehicle tracking and single-cell RNA sequencing data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/259c6de89cac71f6f0a9faf860c8cdb8339a4240" target='_blank'>
              Learning to Approximate Particle Smoothing Trajectories via Diffusion Generative Models
              </a>
            </td>
          <td>
            Ella Tamir, Arno Solin
          </td>
          <td>2024-06-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Bistable autonomous systems can be found inmany areas of science. When the intrinsic noise intensity is large, these systems exhibits stochastic transitions from onemetastable steady state to another. In electronic bistable memories, these transitions are failures, usually simulated in a Monte-Carlo fashion at a high CPU-time price. Existing closed-form formulas, relying on near-stable-steady-state approximations of the nonlinear system dynamics to estimate the mean transition time, have turned out inaccurate. Our contribution is twofold. From a unidimensional stochastic model of overdamped autonomous systems, we propose an extended Eyring-Kramers analytical formula accounting for both nonlinear drift and state-dependent white noise variance, rigorously derived from It\^o stochastic calculus. We also adapt it to practical system engineering situations where the intrinsic noise sources are hidden and can only be inferred from the fluctuations of observables measured in steady states. First numerical trials on an industrial electronic case study suggest that our approximate prediction formula achieve remarkable accuracy, outperforming previous non-Monte-Carlo approaches.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/225568d587ca00a55e72291cfa248b1a5edae4b1" target='_blank'>
              Predicting State Transitions in Autonomous Nonlinear Bistable Systems With Hidden Stochasticity
              </a>
            </td>
          <td>
            Léopold Van Brandt, Jean-Charles Delvenne
          </td>
          <td>2024-05-13</td>
          <td>IEEE Control Systems Letters</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="In areas such as finance, engineering, and science, we often face situations that change quickly and unpredictably. These situations are tough to handle and require special tools and methods capable of understanding and predicting what might happen next. Stochastic Differential Equations (SDEs) are renowned for modeling and analyzing real-world dynamical systems. However, obtaining the parameters, boundary conditions, and closed-form solutions of SDEs can often be challenging. In this paper, we will discuss the application of Kalman filtering theory to SDEs, including Extended Kalman filtering and Particle Extended Kalman filtering. We will explore how to fit existing SDE systems through filtering and track the original SDEs by fitting the obtained closed-form solutions. This approach aims to gather more information about these SDEs, which could be used in various ways, such as incorporating them into parameters of data-based SDE models.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9bfa59651ac97a2cc65f505e0e6450df46852322" target='_blank'>
              Application of Kalman Filter in Stochastic Differential Equations
              </a>
            </td>
          <td>
            Wencheng Bao, Shi Feng, Kaiwen Zhang
          </td>
          <td>2024-04-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Controlling the false discovery rate (FDR) is a popular approach to multiple testing, variable selection, and related problems of simultaneous inference. In many contemporary applications, models are not specified by discrete variables, which necessitates a broadening of the scope of the FDR control paradigm. Motivated by the ubiquity of low-rank models for high-dimensional matrices, we present methods for subspace selection in principal components analysis that provide control on a geometric analog of FDR that is adapted to subspace selection. Our methods crucially rely on recently-developed tools from random matrix theory, in particular on a characterization of the limiting behavior of eigenvectors and the gaps between successive eigenvalues of large random matrices. Our procedure is parameter-free, and we show that it provides FDR control in subspace selection for common noise models considered in the literature. We demonstrate the utility of our algorithm with numerical experiments on synthetic data and on problems arising in single-cell RNA sequencing and hyperspectral imaging.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/126cb5494272623b107924e2ccd4b301462bd272" target='_blank'>
              Controlling the False Discovery Rate in Subspace Selection
              </a>
            </td>
          <td>
            M. D'iaz, Venkat Chandrasekaran
          </td>
          <td>2024-04-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Nonlinear system identification remains an important open challenge across research and academia. Large numbers of novel approaches are seen published each year, each presenting improvements or extensions to existing methods. It is natural, therefore, to consider how one might choose between these competing models. Benchmark datasets provide one clear way to approach this question. However, to make meaningful inference based on benchmark performance it is important to understand how well a new method performs comparatively to results available with well-established methods. This paper presents a set of ten baseline techniques and their relative performances on five popular benchmarks. The aim of this contribution is to stimulate thought and discussion regarding objective comparison of identification methodologies.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f6779b8b9b26a6331757a4f88774427a41eb0cc3" target='_blank'>
              Baseline Results for Selected Nonlinear System Identification Benchmarks
              </a>
            </td>
          <td>
            M.D. Champneys, G. Beintema, Roland T'oth, M. Schoukens, T. J. Rogers
          </td>
          <td>2024-05-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="The probabilistic characterization of non-Markovian responses to nonlinear dynamical systems under colored excitation is an important issue, arising in many applications. Extending the Fokker-Planck-Kolmogorov equation, governing the first-order response probability density function (pdf), to this case is a complicated task calling for special treatment. In this work, a new pdf-evolution equation is derived for the response of nonlinear dynamical systems under additive colored Gaussian noise. The derivation is based on the Stochastic Liouville equation (SLE), transformed, by means of an extended version of the Novikov-Furutsu theorem, to an exact yet non-closed equation, involving averages over the history of the functional derivatives of the non-Markovian response with respect to the excitation. The latter are calculated exactly by means of the state-transition matrix of variational, time-varying systems. Subsequently, an approximation scheme is implemented, relying on a decomposition of the state-transition matrix in its instantaneous mean value and its fluctuation around it. By a current-time approximation to the latter, we obtain our final equation, in which the effect of the instantaneous mean value of the response is maintained, rendering it nonlinear and non-local in time. Numerical results for the response pdf are provided for a bistable Duffing oscillator, under Gaussian excitation. The pdfs obtained from the solution of the novel equation and a simpler small correlation time (SCT) pdf-evolution equation are compared to Monde Carlo (MC) simulations. The novel equation outperforms the SCT equation as the excitation correlation time increases, keeping good agreement with the MC simulations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d0b6f6c03b839a52815976d672739470954a8602" target='_blank'>
              A systematic path to non-Markovian dynamics II: Probabilistic response of nonlinear multidimensional systems to Gaussian colored noise excitation
              </a>
            </td>
          <td>
            G. Athanassoulis, Nikolaos P. Nikoletatos-Kekatos, K. Mamis
          </td>
          <td>2024-05-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>22</td>
        </tr>

        <tr id="Thanks to their simple architecture, Restricted Boltzmann Machines (RBMs) are powerful tools for modeling complex systems and extracting interpretable insights from data. However, training RBMs, as other energy-based models, on highly structured data poses a major challenge, as effective training relies on mixing the Markov chain Monte Carlo simulations used to estimate the gradient. This process is often hindered by multiple second-order phase transitions and the associated critical slowdown. In this paper, we present an innovative method in which the principal directions of the dataset are integrated into a low-rank RBM through a convex optimization procedure. This approach enables efficient sampling of the equilibrium measure via a static Monte Carlo process. By starting the standard training process with a model that already accurately represents the main modes of the data, we bypass the initial phase transitions. Our results show that this strategy successfully trains RBMs to capture the full diversity of data in datasets where previous methods fail. Furthermore, we use the training trajectories to propose a new sampling method, {\em parallel trajectory tempering}, which allows us to sample the equilibrium measure of the trained model much faster than previous optimized MCMC approaches and a better estimation of the log-likelihood. We illustrate the success of the training method on several highly structured datasets.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f812e8deb29218543b1d81075e5fe86e2a201997" target='_blank'>
              Fast, accurate training and sampling of Restricted Boltzmann Machines
              </a>
            </td>
          <td>
            Nicolas B'ereux, A. Decelle, Cyril Furtlehner, Lorenzo Rosset, Beatriz Seoane
          </td>
          <td>2024-05-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>14</td>
        </tr>

        <tr id="Bayesian inversion is central to the quantification of uncertainty within problems arising from numerous applications in science and engineering. To formulate the approach, four ingredients are required: a forward model mapping the unknown parameter to an element of a solution space, often the solution space for a differential equation; an observation operator mapping an element of the solution space to the data space; a noise model describing how noise pollutes the observations; and a prior model describing knowledge about the unknown parameter before the data is acquired. This paper is concerned with learning the prior model from data; in particular, learning the prior from multiple realizations of indirect data obtained through the noisy observation process. The prior is represented, using a generative model, as the pushforward of a Gaussian in a latent space; the pushforward map is learned by minimizing an appropriate loss function. A metric that is well-defined under empirical approximation is used to define the loss function for the pushforward map to make an implementable methodology. Furthermore, an efficient residual-based neural operator approximation of the forward model is proposed and it is shown that this may be learned concurrently with the pushforward map, using a bilevel optimization formulation of the problem; this use of neural operator approximation has the potential to make prior learning from indirect data more computationally efficient, especially when the observation process is expensive, non-smooth or not known. The ideas are illustrated with the Darcy flow inverse problem of finding permeability from piezometric head measurements.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/878c6d062447c0bb1afc981337901f25d0c3f9fb" target='_blank'>
              Efficient Prior Calibration From Indirect Data
              </a>
            </td>
          <td>
            O. D. Akyildiz, M. Girolami, Andrew M. Stuart, A. Vadeboncoeur
          </td>
          <td>2024-05-28</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="Determining the reachable set for a given nonlinear system is critically important for autonomous trajectory planning for reach-avoid applications and safety critical scenarios. Providing the reachable set is generally impossible when the dynamics are unknown, so we calculate underapproximations of such sets using local dynamics at a single point and bounds on the rate of change of the dynamics determined from known physical laws. Motivated by scenarios where an adverse event causes an abrupt change in the dynamics, we attempt to determine a provably reachable set of states without knowledge of the dynamics. This paper considers systems which are known to operate on a manifold. Underapproximations are calculated by utilizing the aforementioned knowledge to derive a guaranteed set of velocities on the tangent bundle of a complete Riemannian manifold that can be reached within a finite time horizon. We then interpret said set as a control system; the trajectories of this control system provide us with a guaranteed set of reachable states the unknown system can reach within a given time. The results are general enough to apply on systems that operate on any complete Riemannian manifold. To illustrate the practical implementation of our results, we apply our algorithm to a model of a pendulum operating on a sphere and a three-dimensional rotational system which lives on the abstract set of special orthogonal matrices.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0b3a55a1c426bab2020f30a6080fdbb60707a360" target='_blank'>
              Guaranteed Reachability on Riemannian Manifolds for Unknown Nonlinear Systems
              </a>
            </td>
          <td>
            Taha Shafa, Melkior Ornik
          </td>
          <td>2024-04-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="Dimensionality reduction represents the process of generating a low dimensional representation of high dimensional data. Motivated by the formation control of mobile agents, we propose a nonlinear dynamical system for dimensionality reduction. The system consists of two parts; the control of neighbor points, addressing local structures, and the control of remote points, accounting for global structures. We also include a brief mathematical observation of the model and its numerical procedure. Numerical experiments are performed on both synthetic and real datasets and comparisons with existing models demonstrate the soundness and effectiveness of the proposed model.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/87e532abe1f2979ea704245ce80a94b7769a0406" target='_blank'>
              Formation-Controlled Dimensionality Reduction
              </a>
            </td>
          <td>
            Taeuk Jeong, Yoon Mo Jung
          </td>
          <td>2024-04-10</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Time delays are ubiquitous in industry and nature, and they significantly affect both transient dynamics and stability properties. Consequently, it is often necessary to identify and account for the delays when, e.g., designing a model-based control strategy. However, identifying delays in differential equations is not straightforward and requires specialized methods. Therefore, we propose an algorithm for identifying distributed delays in delay differential equations (DDEs) that only involves simulation of ordinary differential equations (ODEs). Specifically, we 1) approximate the kernel in the DDEs (also called the memory function) by the probability density function of a mixed Erlang distribution and 2) use the linear chain trick (LCT) to transform the resulting DDEs into ODEs. Finally, the parameters in the kernel approximation are estimated as the solution to a dynamical least-squares problem, and we use a single-shooting approach to approximate this solution. We demonstrate the efficacy of the algorithm using numerical examples that involve the logistic equation and a point reactor kinetics model of a molten salt nuclear fission reactor.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ab5bd3dbfedbb0ecfa51468024e055f509d69dc3" target='_blank'>
              An algorithm for distributed time delay identification based on a mixed Erlang kernel approximation and the linear chain trick
              </a>
            </td>
          <td>
            T. K. Ritschel, J. Wyller
          </td>
          <td>2024-05-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="
 Model Predictive Control (MPC) is a prominent control paradigm providing accurate state prediction and subsequent control actions for intricate dynamical systems with applications ranging from autonomous driving to star tracking. However, there is an apparent discrepancy between the model’s mathematical description and its behavior in real-world conditions, affecting its performance in real-time. In this work, we propose a novel neuromorphic spiking neural network for continuous adaptive non-linear MPC. By using real-time learning, our design significantly reduces dynamic error and augments model accuracy, while simultaneously addressing unforeseen situations. We evaluated our framework using real-world scenarios in autonomous driving, implemented in a physics-driven simulation. We tested our design with various vehicles (from a Tesla Model 3 to an Ambulance) experiencing malfunctioning and swift steering scenarios. We demonstrate significant improvements in dynamic error rate compared with traditional MPC implementation with up to 89.87% median prediction error reduction with 5 spiking neurons and up to 96.95% with 5000 neurons. Our results may pave the way for novel applications in real-time control and stimulate further studies in the adaptive control realm with spiking neural networks.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7f8f1659532465ab69d1e5ebec65f1856bc20b23" target='_blank'>
              Continuous adaptive nonlinear model predictive control using spiking neural networks and real-time learning
              </a>
            </td>
          <td>
            Raz Halaly, Elishai Ezra Tsur
          </td>
          <td>2024-04-23</td>
          <td>Neuromorphic Computing and Engineering</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="This paper introduces a method of identifying a maximal set of safe strategies from data for stochastic systems with unknown dynamics using barrier certificates. The first step is learning the dynamics of the system via Gaussian process (GP) regression and obtaining probabilistic errors for this estimate. Then, we develop an algorithm for constructing piecewise stochastic barrier functions to find a maximal permissible strategy set using the learned GP model, which is based on sequentially pruning the worst controls until a maximal set is identified. The permissible strategies are guaranteed to maintain probabilistic safety for the true system. This is especially important for learning-enabled systems, because a rich strategy space enables additional data collection and complex behaviors while remaining safe. Case studies on linear and nonlinear systems demonstrate that increasing the size of the dataset for learning the system grows the permissible strategy set.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/90d73cf3b757df2be3550f3c91f028c513c7971f" target='_blank'>
              Data-Driven Permissible Safe Control with Barrier Certificates
              </a>
            </td>
          <td>
            Rayan Mazouz, John Skovbekk, Frederik Baymler Mathiesen, Eric Frew, Luca Laurenti, Morteza Lahijanian
          </td>
          <td>2024-04-30</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="Differential equations are pivotal in modeling and understanding the dynamics of various systems, offering insights into their future states through parameter estimation fitted to time series data. In fields such as economy, politics, and biology, the observation data points in the time series are often independently obtained (i.e., Repeated Cross-Sectional (RCS) data). With RCS data, we found that traditional methods for parameter estimation in differential equations, such as using mean values of time trajectories or Gaussian Process-based trajectory generation, have limitations in estimating the shape of parameter distributions, often leading to a significant loss of data information. To address this issue, we introduce a novel method, Estimation of Parameter Distribution (EPD), providing accurate distribution of parameters without loss of data information. EPD operates in three main steps: generating synthetic time trajectories by randomly selecting observed values at each time point, estimating parameters of a differential equation that minimize the discrepancy between these trajectories and the true solution of the equation, and selecting the parameters depending on the scale of discrepancy. We then evaluated the performance of EPD across several models, including exponential growth, logistic population models, and target cell-limited models with delayed virus production, demonstrating its superiority in capturing the shape of parameter distributions. Furthermore, we applied EPD to real-world datasets, capturing various shapes of parameter distributions rather than a normal distribution. These results effectively address the heterogeneity within systems, marking a substantial progression in accurately modeling systems using RCS data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4958ae9d906d555cc687a6830d10e86665c3091e" target='_blank'>
              Estimating the Distribution of Parameters in Differential Equations with Repeated Cross-Sectional Data
              </a>
            </td>
          <td>
            Hyeontae Jo, S. Cho, Hyung Ju Hwang
          </td>
          <td>2024-04-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="An iterated multistep forecasting scheme based on recurrent neural networks (RNN) is proposed for the time series generated by causal chains with infinite memory. This forecasting strategy contains, as a particular case, the iterative prediction strategies for dynamical systems that are customary in reservoir computing. Readily computable error bounds are obtained as a function of the forecasting horizon, functional and dynamical features of the specific RNN used, and the approximation error committed by it. The framework in the paper circumvents difficult-to-verify embedding hypotheses that appear in previous references in the literature and applies to new situations like the finite-dimensional observations of functional differential equations or the deterministic parts of stochastic processes to which standard embedding techniques do not necessarily apply.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/08c01d5b50fd31d1eec0663fad8a6c82d4655e41" target='_blank'>
              Forecasting causal dynamics with universal reservoirs
              </a>
            </td>
          <td>
            Lyudmila Grigoryeva, James Louw, Juan-Pablo Ortega
          </td>
          <td>2024-05-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>14</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/80417027eb02c814f8e81639544376b300c98336" target='_blank'>
              A novel method for response probability density of nonlinear stochastic dynamic systems
              </a>
            </td>
          <td>
            Xi Wang, Junchao Jiang, L. Hong, Jiandong Sun
          </td>
          <td>2024-05-17</td>
          <td>Nonlinear Dynamics</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="We introduce a machine learning (ML) supervised model function that is inspired by the variational principle of physics. This ML hypothesis evolutionary method, termed ML-Omega, allows us to go from data to differential equation(s) underlying the physical (chemical, engineering, etc.) phenomena the data are derived from. The fundamental equations of physics can be derived from this ML-Omega evolutionary method when provided the proper training data. By training the ML-Omega model function with only three hydrogen-like atom energies, the method can find Schr\"odinger's exact functional and, from it, Schr\"odinger's fundamental equation. Then, in the field of density functional theory (DFT), when the model function is trained with the energies from the known Thomas-Fermi (TF) formula E = -0.7687Z^7/3, it correctly finds the exact TF functional. Finally, the method is applied to find a local orbital-free (OF) functional expression of the independent electron kinetic energy functional Ts based on the gamma-TF-lambda-vW model. By considering the theoretical energies of only 5 atoms (He, Be, Ne, Mg, Ar) as the training set, the evolutionary ML-Omega method finds an ML-Omega-OF-DFT local Ts functional (gamma-TF-lambda-vW (0.964, 1/4)) that outperforms all the OF- DFT functionals of a representative group. Moreover, our ML-Omega-OF functional overcomes the LDA's and some local GGA-DFT's functionals' difficulty to describe the stretched bond region at the correct spin configuration of diatomic molecules. Although our evolutionary ML-Omega model function can work without an explicit prior-form functional, by using the techniques of symbolic regression, in this work we exploit prior-form functional expressions to make the training process faster in the example problems presented here.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0d1ca8ca86c43ac9d95b74b840dc00a04c296885" target='_blank'>
              A physics-inspired evolutionary machine learning method: from the Schr\"odinger equation to an orbital-free-DFT kinetic energy functional
              </a>
            </td>
          <td>
            Juan I Rodríguez, Ulises A Vergara-Beltran
          </td>
          <td>2024-05-28</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3ab1e6fdd43f83a3f8f915944f8d75b2313b7181" target='_blank'>
              A mathematical model with uncertainty quantification for allelopathy with applications to real-world data
              </a>
            </td>
          <td>
            V. Bevia, Juan-Carlos Cortés, Ana Moscardó, Cristina-Luisovna Pérez, Rafael-Jacinto Villanueva
          </td>
          <td>2024-04-17</td>
          <td>Environmental and Ecological Statistics</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Multi-factor screenings are commonly used in diverse applications in medicine and bioengineering, including optimizing combination drug treatments and microbiome engineering. Despite the advances in high-throughput technologies, large-scale experiments typically remain prohibitively expensive. Here we introduce a machine learning platform, structure-augmented regression (SAR), that exploits the intrinsic structure of each biological system to learn a high-accuracy model with minimal data requirement. Under different environmental perturbations, each biological system exhibits a unique, structured phenotypic response. This structure can be learned based on limited data and once learned, can constrain subsequent quantitative predictions. We demonstrate that SAR requires significantly fewer data comparing to other existing machine-learning methods to achieve a high prediction accuracy, first on simulated data, then on experimental data of various systems and input dimensions. We then show how a learned structure can guide effective design of new experiments. Our approach has implications for predictive control of biological systems and an integration of machine learning prediction and experimental design.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c960a00bc91e7ef861762c26cbaf5fb088878ab0" target='_blank'>
              Data-driven learning of structure augments quantitative prediction of biological responses.
              </a>
            </td>
          <td>
            Yuanchi Ha, Helena R. Ma, Feilun Wu, Andrea Weiss, Katherine Duncker, Helen Xu, Jia Lu, Max Golovsky, Daniel Reker, Lingchong You
          </td>
          <td>2024-06-03</td>
          <td>PLoS computational biology</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Functional time series data frequently appears in economic applications, where the functions of interest are subject to some shape constraints, including monotonicity and convexity, as typical of the estimation of the Lorenz curve. This paper proposes a state-space model for time-varying functions to extract trends and serial dependence from functional time series while imposing the shape constraints on the estimated functions. The function of interest is modeled by a convex combination of selected basis functions to satisfy the shape constraints, where the time-varying convex weights on simplex follow the dynamic multi-logit models. For the complicated likelihood of this model, a novel data augmentation technique is devised to enable posterior computation by an efficient Markov chain Monte Carlo method. The proposed method is applied to the estimation of time-varying Lorenz curves, and its utility is illustrated through numerical experiments and analysis of panel data of household incomes in Japan.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/07b83124e1120b0096933ab8154256596b013bc5" target='_blank'>
              State-Space Modeling of Shape-constrained Functional Time Series
              </a>
            </td>
          <td>
            Daichi Hiraki, Y. Hamura, Kaoru Irie, S. Sugasawa
          </td>
          <td>2024-04-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>11</td>
        </tr>

        <tr id="Practical Bayesian learning often requires (1) online inference, (2) dynamic models, and (3) ensembling over multiple different models. Recent advances have shown how to use random feature approximations to achieve scalable, online ensembling of Gaussian processes with desirable theoretical properties and fruitful applications. One key to these methods' success is the inclusion of a random walk on the model parameters, which makes models dynamic. We show that these methods can be generalized easily to any basis expansion model and that using alternative basis expansions, such as Hilbert space Gaussian processes, often results in better performance. To simplify the process of choosing a specific basis expansion, our method's generality also allows the ensembling of several entirely different models, for example, a Gaussian process and polynomial regression. Finally, we propose a novel method to ensemble static and dynamic models together.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/061122b4dbb461f2f6e32a8c499ba190d5f0b72a" target='_blank'>
              Dynamic Online Ensembles of Basis Expansions
              </a>
            </td>
          <td>
            Daniel Waxman, Petar M. Djuri'c
          </td>
          <td>2024-05-02</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>0</td>
        </tr>

        <tr id="The $L^2$ gradient flow of the Ginzburg-Landau free energy functional leads to the Allen Cahn equation that is widely used for modeling phase separation. Machine learning methods for solving the Allen-Cahn equation in its strong form suffer from inaccuracies in collocation techniques, errors in computing higher-order spatial derivatives through automatic differentiation, and the large system size required by the space-time approach. To overcome these limitations, we propose a separable neural network-based approximation of the phase field in a minimizing movement scheme to solve the aforementioned gradient flow problem. At each time step, the separable neural network is used to approximate the phase field in space through a low-rank tensor decomposition thereby accelerating the derivative calculations. The minimizing movement scheme naturally allows for the use of Gauss quadrature technique to compute the functional. A `$tanh$' transformation is applied on the neural network-predicted phase field to strictly bounds the solutions within the values of the two phases. For this transformation, a theoretical guarantee for energy stability of the minimizing movement scheme is established. Our results suggest that bounding the solution through this transformation is the key to effectively model sharp interfaces through separable neural network. The proposed method outperforms the state-of-the-art machine learning methods for phase separation problems and is an order of magnitude faster than the finite element method.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b9587ef56ec1c5bcfe5410cb08c0d1d13eebeee3" target='_blank'>
              Gradient Flow Based Phase-Field Modeling Using Separable Neural Networks
              </a>
            </td>
          <td>
            R. Mattey, Susanta Ghosh
          </td>
          <td>2024-05-09</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="This article delves into examining exact soliton solutions within the context of the generalized nonlinear Schrödinger equation. It covers higher-order dispersion with higher order nonlinearity and a parameter associated with weak nonlocality. To tackle this equation, two reputable methods are harnessed: the sine-Gordon expansion method and the G′/(bG′+G+a)-expansion method. These methods are employed alongside suitable traveling wave transformation to yield novel, efficient single-wave soliton solutions for the governing model. To deepen our grasp of the equation’s physical significance, we utilize Wolfram Mathematica 12, a computational tool, to produce both 3D and 2D visual depictions. These graphical representations shed light on diverse facets of the equation’s dynamics, offering invaluable insights. Through the manipulation of parameter values, we achieve an array of solutions, encompassing kink-type, dark soliton, and solitary wave solutions. Our computational analysis affirms the effectiveness and versatility of our methods in tackling a wide spectrum of nonlinear challenges within the domains of mathematical science and engineering.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b2cd6b7716ecc06614834c0ea2c5f59906b3cb43" target='_blank'>
              Extraction of new solitary wave solutions in a generalized nonlinear Schrödinger equation comprising weak nonlocality
              </a>
            </td>
          <td>
            Miguel Vivas-Cortez, Ghada Ali Basendwah, Beenish Rani, Nauman Raza, Mohammed Kbiri Alaoui
          </td>
          <td>2024-05-14</td>
          <td>PLOS ONE</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="One of the main challenges in surrogate modeling is the limited availability of data due to resource constraints associated with computationally expensive simulations. Multi-fidelity methods provide a solution by chaining models in a hierarchy with increasing fidelity, associated with lower error, but increasing cost. In this paper, we compare different multi-fidelity methods employed in constructing Gaussian process surrogates for regression. Non-linear autoregressive methods in the existing literature are primarily confined to two-fidelity models, and we extend these methods to handle more than two levels of fidelity. Additionally, we propose enhancements for an existing method incorporating delay terms by introducing a structured kernel. We demonstrate the performance of these methods across various academic and real-world scenarios. Our findings reveal that multi-fidelity methods generally have a smaller prediction error for the same computational cost as compared to the single-fidelity method, although their effectiveness varies across different scenarios.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1bac31304955df9b184f5ecf63b64c195fca9e0c" target='_blank'>
              Multi-fidelity Gaussian process surrogate modeling for regression problems in physics
              </a>
            </td>
          <td>
            Kislaya Ravi, Vladyslav Fediukov, Felix Dietrich, T. Neckel, Fabian Buse, Michael Bergmann, H. Bungartz
          </td>
          <td>2024-04-18</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>35</td>
        </tr>

        <tr id="Soft actuators, distinguished by their complex nonlinear behavior, are difficult to model analytically and cumbersome to prototype. Finite element (FE) models allow for more efficient behavioral prediction, but often require onerous setup, especially for large systems. We present a physics-informed neural network model formed by combining a low fidelity analytical model and input-convex neural networks to learn an underlying energy potential for the actuator from experimental and finite element simulation data. In doing this, the neural network can provide sufficiently accurate predictions about systems made up of multiple units, essentially scaling the model from a single unit to an assembly of many. To test this concept, we compare predictions of the deformation of a 5-actuator system from an FE model and from the physics-informed neural network. The neural network, which provides a prediction similar in accuracy to the FE equivalent, can more easily be adjusted to execute systems of greater quantities of units without drastic increases in computational consumption. In this way, we can scale our predictive understanding with adequate accuracy without compounding resources.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/97898a8ef39e378f477e3b2603114c706798ea97" target='_blank'>
              Physics-Informed Neural Network for Scalable Soft Multi-Actuator Systems
              </a>
            </td>
          <td>
            Carly Mendenhall, Jonathan Hardan, Trysta D. Chiang, Laura H. Blumenschein, A. B. Tepole
          </td>
          <td>2024-04-14</td>
          <td>2024 IEEE 7th International Conference on Soft Robotics (RoboSoft)</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="Data assimilation algorithms integrate prior information from numerical model simulations with observed data. Ensemble-based filters, regarded as state-of-the-art, are widely employed for large-scale estimation tasks in disciplines such as geoscience and meteorology. Despite their inability to produce the true posterior distribution for nonlinear systems, their robustness and capacity for state tracking are noteworthy. In contrast, Particle filters yield the correct distribution in the ensemble limit but require substantially larger ensemble sizes than ensemble-based filters to maintain stability in higher-dimensional spaces. It is essential to transcend traditional Gaussian assumptions to achieve realistic quantification of uncertainties. One approach involves the hybridisation of filters, facilitated by tempering, to harness the complementary strengths of different filters. A new adaptive tempering method is proposed to tune the underlying schedule, aiming to systematically surpass the performance previously achieved. Although promising numerical results for certain filter combinations in toy examples exist in the literature, the tuning of hyperparameters presents a considerable challenge. A deeper understanding of these interactions is crucial for practical applications.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4a500974f4c0c869f60d3828de42111041646802" target='_blank'>
              Adaptive tempering schedules with approximative intermediate measures for filtering problems
              </a>
            </td>
          <td>
            Iris Rammelmuller, Gottfried Hastermann, Jana de Wiljes
          </td>
          <td>2024-05-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Many complex systems can be accurately modeled as a set of coupled time-dependent partial differential equations (PDEs). However, solving such equations can be prohibitively expensive, easily taxing the world's largest supercomputers. One pragmatic strategy for attacking such problems is to split the PDEs into components that can more easily be solved in isolation. This operator splitting approach is used ubiquitously across scientific domains, and in many cases leads to a set of ordinary differential equations (ODEs) that need to be solved as part of a larger"outer-loop"time-stepping approach. The SUNDIALS library provides a plethora of robust time integration algorithms for solving ODEs, and the U.S. Department of Energy Exascale Computing Project (ECP) has supported its extension to applications on exascale-capable computing hardware. In this paper, we highlight some SUNDIALS capabilities and its deployment in combustion and cosmology application codes (Pele and Nyx, respectively) where operator splitting gives rise to numerous, small ODE systems that must be solved concurrently.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/def3705a70bcd2236554241dd23bf81546620191" target='_blank'>
              SUNDIALS Time Integrators for Exascale Applications with Many Independent ODE Systems
              </a>
            </td>
          <td>
            C. Balos, Marc Day, Lucas Esclapez, A. Felden, D. J. Gardner, Malik Hassanaly, Daniel R. Reynolds, Jon Rood, Jean M. Sexton, N. Wimer, Carol S. Woodward
          </td>
          <td>2024-05-02</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>8</td>
        </tr>

        <tr id="For complex nonlinear systems, it is challenging to design algorithms that are fast, scalable, and give an accurate approximation of the stability region. This paper proposes a sampling-based approach to address these challenges. By extending the parametrization of quadratic Lyapunov functions with the system dynamics and formulating an $\ell_1$ optimization to maximize the invariant set over a grid of the state space, we arrive at a computationally efficient algorithm that estimates the domain of attraction (DOA) of nonlinear systems accurately by using only linear programming. The scalability of the Lyapunov function synthesis is further improved by combining the algorithm with ADMM-based parallelization. To resolve the inherent approximative nature of grid-based techniques, a small-scale nonlinear optimization is proposed. The performance of the algorithm is evaluated and compared to state-of-the-art solutions on several numerical examples.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0acaee5189452cb7a7c65946c5c7af1ad55613f4" target='_blank'>
              Computationally Efficient Sampling-Based Algorithm for Stability Analysis of Nonlinear Systems
              </a>
            </td>
          <td>
            P'eter Antal, , Roland T'oth
          </td>
          <td>2024-05-22</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Irregularly sampled time series with missing values are often observed in multiple real-world applications such as healthcare, climate and astronomy. They pose a significant challenge to standard deep learn- ing models that operate only on fully observed and regularly sampled time series. In order to capture the continuous dynamics of the irreg- ular time series, many models rely on solving an Ordinary Differential Equation (ODE) in the hidden state. These ODE-based models tend to perform slow and require large memory due to sequential operations and a complex ODE solver. As an alternative to complex ODE-based mod- els, we propose a family of models called Functional Latent Dynamics (FLD). Instead of solving the ODE, we use simple curves which exist at all time points to specify the continuous latent state in the model. The coefficients of these curves are learned only from the observed values in the time series ignoring the missing values. Through extensive experi- ments, we demonstrate that FLD achieves better performance compared to the best ODE-based model while reducing the runtime and memory overhead. Specifically, FLD requires an order of magnitude less time to infer the forecasts compared to the best performing forecasting model.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f2a5b8158db29854109275cb5c3fbcf47c080c1c" target='_blank'>
              Functional Latent Dynamics for Irregularly Sampled Time Series Forecasting
              </a>
            </td>
          <td>
            Christian Klotergens, Vijaya Krishna Yalavarthi, Maximilian Stubbemann, Lars Schmidt-Thieme
          </td>
          <td>2024-05-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="A major problem in system identification is the incorporation of prior knowledge about the physical properties of the given system, such as stability, positivity and passivity. In this paper, we present first steps towards tackling this problem for passive systems. In particular, using ideas from the theory of reproducing kernel Hilbert spaces, we solve the problem of identifying a nonnegative input-output operator from data consisting of input-output trajectories of the system. We prove a representer theorem for this problem in the case where the input space is finite-dimensional. This provides a computationally tractable solution, which we show can be obtained by solving an associated semidefinite program.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4b397889058083a5f9ab3356b42fdc13a64538d0" target='_blank'>
              Towards a representer theorem for identification of passive systems
              </a>
            </td>
          <td>
            B. Shali, H. V. Waarde
          </td>
          <td>2024-04-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>11</td>
        </tr>

        <tr id="Controllability is a fundamental property of control systems, serving as the prerequisite for controller design. While controllability test is well established in modelic (i.e., model-driven) control systems, extending it to datatic (i.e., data-driven) control systems is still a challenging task due to the absence of system models. In this study, we propose a general controllability test method for nonlinear systems with datatic description, where the system behaviors are merely described by data. In this situation, the state transition information of a dynamic system is available only at a limited number of data points, leaving the behaviors beyond these points unknown. Different from traditional exact controllability, we introduce a new concept called $\epsilon$-controllability, which extends the definition from point-to-point form to point-to-region form. Accordingly, our focus shifts to checking whether the system state can be steered to a closed state ball centered on the target state, rather than exactly at that target state. On its basis, we propose a tree search algorithm called maximum expansion of controllable subset (MECS) to identify controllable states in the dataset. Starting with a specific target state, our algorithm can iteratively propagate controllability from a known state ball to a new one. This iterative process gradually enlarges the $\epsilon$-controllable subset by incorporating new controllable balls until all $\epsilon$-controllable states are searched. Besides, a simplified version of MECS is proposed by solving a special shortest path problem, called Floyd expansion with radius fixed (FERF). FERF maintains a fixed radius of all controllable balls based on a mutual controllability assumption of neighboring states. The effectiveness of our method is validated in three datatic control systems whose dynamic behaviors are described by sampled data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5032dbd5a9a4ad499d8a2959e1ea1ececcf3f3ca" target='_blank'>
              Controllability Test for Nonlinear Datatic Systems
              </a>
            </td>
          <td>
            Yujie Yang, Letian Tao, Likun Wang, Shengbo Eben Li
          </td>
          <td>2024-05-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Simulating stochastic systems with feedback control is challenging due to the complex interplay between the system's dynamics and the feedback-dependent control protocols. We present a single-step-trajectory probability analysis to time-dependent stochastic systems. Based on this analysis, we revisit several time-dependent kinetic Monte Carlo (KMC) algorithms designed for systems under open-loop-control protocols. Our analysis provides an unified alternative proof to these algorithms, summarized into a pedagogical tutorial. Moreover, with the trajectory probability analysis, we present a novel feedback-controlled KMC algorithm that accurately captures the dynamics systems controlled by external signal based on measurements of the system's state. Our method correctly captures the system dynamics and avoids the artificial Zeno effect that arises from incorrectly applying the direct Gillespie algorithm to feedback-controlled systems. This work provides a unified perspective on existing open-loop-control KMC algorithms and also offers a powerful and accurate tool for simulating stochastic systems with feedback control.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/6b033d24d2e88c7881fe1d6e0b2fd373c3b2fe38" target='_blank'>
              Revisiting Kinetic Monte Carlo Algorithms for Time-dependent Processes: from open-loop control to feedback control
              </a>
            </td>
          <td>
            Supraja S Chittari, Zhiyue Lu
          </td>
          <td>2024-05-07</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="A persistent challenge in tasks involving large-scale dynamical systems, such as state estimation and error reduction, revolves around processing the collected measurements. Frequently, these data suffer from the curse of dimensionality, leading to increased computational demands in data processing methodologies. Recent scholarly investigations have underscored the utility of delineating collective states and dynamics via moment-based representations. These representations serve as a form of sufficient statistics for encapsulating collective characteristics, while simultaneously permitting the retrieval of individual data points. In this paper, we reshape the Kalman filter methodology, aiming its application in the moment domain of an ensemble system and developing the basis for moment ensemble noise filtering. The moment system is defined with respect to the normalized Legendre polynomials, and it is shown that its orthogonal basis structure introduces unique benefits for the application of Kalman filter for both i.i.d. and universal Gaussian disturbances. The proposed method thrives from the reduction in problem dimension, which is unbounded within the state-space representation, and can achieve significantly smaller values when converted to the truncated moment-space. Furthermore, the robustness of moment data toward outliers and localized inaccuracies is an additional positive aspect of this approach. The methodology is applied for an ensemble of harmonic oscillators and units following aircraft dynamics, with results showcasing a reduction in both cumulative absolute error and covariance with reduced calculation cost due to the realization of operations within the moment framework conceived.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4376ba42b9f71e5cb461ae363957cc3187611dbf" target='_blank'>
              A moment-based Kalman filtering approach for estimation in ensemble systems.
              </a>
            </td>
          <td>
            A. L. P. de Lima, Jr-Shin Li
          </td>
          <td>2024-06-01</td>
          <td>Chaos</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Learning from expert demonstrations to flexibly program an autonomous system with complex behaviors or to predict an agent's behavior is a powerful tool, especially in collaborative control settings. A common method to solve this problem is inverse reinforcement learning (IRL), where the observed agent, e.g., a human demonstrator, is assumed to behave according to the optimization of an intrinsic cost function that reflects its intent and informs its control actions. While the framework is expressive, it is also computationally demanding and generally lacks convergence guarantees. We therefore propose a novel, stability-certified IRL approach by reformulating the cost function inference problem to learning control Lyapunov functions (CLF) from demonstrations data. By additionally exploiting closed-form expressions for associated control policies, we are able to efficiently search the space of CLFs by observing the attractor landscape of the induced dynamics. For the construction of the inverse optimal CLFs, we use a Sum of Squares and formulate a convex optimization problem. We present a theoretical analysis of the optimality properties provided by the CLF and evaluate our approach using both simulated and real-world data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/31a87861d2005c9eeac675e6e65ef03477903336" target='_blank'>
              Stable Inverse Reinforcement Learning: Policies from Control Lyapunov Landscapes
              </a>
            </td>
          <td>
            Samuel Tesfazgi, Leonhard Sprandl, Armin Lederer, Sandra Hirche
          </td>
          <td>2024-05-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="In general, the extended Kalman filter (EKF) has a wide range of applications, aiming to minimize symmetric loss function (mean square error) and improve the accuracy and efficiency of state estimation. As the nonlinear model complexity increases, rounding errors gradually amplify, leading to performance degradation. After multiple iterations, divergence may occur. The traditional extended Kalman filter cannot accurately estimate the nonlinear model, and these errors still have an impact on the accuracy. To improve the filtering performance of the extended Kalman filter (EKF), this paper proposes a new extended Kalman filter (REKF) method that utilizes the statistical properties of the rounding error to enhance the estimation accuracy. After establishing the state model and measurement model, the residual term is used to replace the higher-order term in the Taylor expansion, and the least squares method is applied to identify the residual term step by step. Then, the iterative process of updating the extended Kalman filter is carried out. Within the Kalman filter framework, a higher-order rounding error-based extended Kalman filter (REKF) is designed for the joint estimation of rounding error and random variables, and the solution method for the rounding error is considered for the multilevel approximation of the original function. Through numerical simulations on a general nonlinear model, the higher-order rounding error-based extended Kalman filter (REKF) achieves better estimation results than the extended Kalman filter (EKF) and improves the filtering accuracy by utilizing the higher-order rounding error information, which also proves the effectiveness of the proposed method.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/92c33fc8739fa3f2864678e080981473c36655e6" target='_blank'>
              High-Order Extended Kalman Filter for State Estimation of Nonlinear Systems
              </a>
            </td>
          <td>
            Linwang Ding, Chenglin Wen
          </td>
          <td>2024-05-16</td>
          <td>Symmetry</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="This work addresses data-driven inverse optimization (IO), where the goal is to estimate unknown parameters in an optimization model from observed decisions that can be assumed to be optimal or near-optimal solutions to the optimization problem. The IO problem is commonly formulated as a large-scale bilevel program that is notoriously difficult to solve. Deviating from traditional exact solution methods, we propose a derivative-free optimization approach based on Bayesian optimization, which we call BO4IO, to solve general IO problems. We treat the IO loss function as a black box and approximate it with a Gaussian process model. Using the predicted posterior function, an acquisition function is minimized at each iteration to query new candidate solutions and sequentially converge to the optimal parameter estimates. The main advantages of using Bayesian optimization for IO are two-fold: (i) it circumvents the need of complex reformulations of the bilevel program or specialized algorithms and can hence enable computational tractability even when the underlying optimization problem is nonconvex or involves discrete variables, and (ii) it allows approximations of the profile likelihood, which provide uncertainty quantification on the IO parameter estimates. We apply the proposed method to three computational case studies, covering different classes of forward optimization problems ranging from convex nonlinear to nonconvex mixed-integer nonlinear programs. Our extensive computational results demonstrate the efficacy and robustness of BO4IO to accurately estimate unknown model parameters from small and noisy datasets. In addition, the proposed profile likelihood analysis has proven to be effective in providing good approximations of the confidence intervals on the parameter estimates and assessing the identifiability of the unknown parameters.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4db6578624c494887002f97488387665b880c562" target='_blank'>
              BO4IO: A Bayesian optimization approach to inverse optimization with uncertainty quantification
              </a>
            </td>
          <td>
            Yen-An Lu, Wei-Shou Hu, J. Paulson, Qi Zhang
          </td>
          <td>2024-05-28</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>21</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b6b486d68689dbfa46c6a123301df2da0ae04088" target='_blank'>
              New graphical models for sequential data and the improved state estimations by data-conditioned driving noises
              </a>
            </td>
          <td>
            Wonjung Lee
          </td>
          <td>2024-04-10</td>
          <td>EURASIP Journal on Advances in Signal Processing</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="When design engineers are creating new design methods, it is important for them to have analytical dependencies to assess the impact of the parameters and external loads of the system under study on its stability and dynamic behaviour. This is used to create heterogeneous structures for aerospace engineering, the construction industry, and mechanical engineering. The solution of a large number of mathematical physics problems that boil down to the necessity of solving singular differential equations with variable discontinuity coefficients is often based on the use of numerical methods that do not allow for a qualitative analysis of the dependencies obtained. A feature of this work is the development of a hybrid WKB-Galyorkin asymptotic approach to the solution of nonlinear singular (with a “small” parameter at the older derivative) differential equations with variable discontinuous coefficients in the presence of a δ-function in the right-hand side. An approximate algorithm of analytical solution suitable for solving of mathematical physics applied problems using the perturbation method, which allows estimating the influence of the nonlinear component of the equation and computer algebra. is proposed. As an example, a nonlinear Duffing type differential equation with variable coefficients is considered. Particular attention is paid to the influence of the nature of the change in the coefficients of the main singular differential equation on the effect of the presence of a δ-function in the first derivative. Numerical results of analytical solutions (depending on the value of the parameters of the asymptotic development in two approximations) and comparison of the approximate analytical solution with the direct numerical solution of the problem under study are provided. Using computer algebra software package “Mathematica”, graphs of the results of calculations of the main equation of the problem are constructed by the direct numerical integration and the hybrid asymptotic method.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5b077b42be0eddabde67a7a51c2cdea1ec8598e2" target='_blank'>
              HYBRID ASYMPTOTIC APPROACH TO SOLVING NONLINEAR DIFFERENTIAL EQUATIONS WITH VARIABLE COEFFICIENTS IN THE PRESENCE OF THE δ-FUNCTION
              </a>
            </td>
          <td>
            В. З. Грищак, Д. О. Руденко
          </td>
          <td>2024-05-30</td>
          <td>Visnyk of Zaporizhzhya National University Physical and Mathematical Sciences</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="As one kind important phase field equations, Cahn-Hilliard equations contain spatial high order derivatives, strong nonlinearities, and even singularities. When using the physics informed neural network (PINN) to simulate the long time evolution, it is necessary to decompose the time domain to capture the transition of solutions in different time. Moreover, the baseline PINN can't maintain the mass conservation property for the equations. We propose a mass-preserving spatio-temporal adaptive PINN. This method adaptively dividing the time domain according to the rate of energy decrease, and solves the Cahn-Hilliard equation in each time step using an independent neural network. To improve the prediction accuracy, spatial adaptive sampling is employed in the subdomain to select points with large residual value and add them to the training samples. Additionally, a mass constraint is added to the loss function to compensate the mass degradation problem of the PINN method in solving the Cahn-Hilliard equations. The mass-preserving spatio-temporal adaptive PINN is employed to solve a series of numerical examples. These include the Cahn-Hilliard equations with different bulk potentials, the three dimensional Cahn-Hilliard equation with singularities, and the set of Cahn-Hilliard equations. The numerical results demonstrate the effectiveness of the proposed algorithm.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c3067a09d2763478dfa3a700261e63c35c97eb92" target='_blank'>
              Mass-preserving Spatio-temporal adaptive PINN for Cahn-Hilliard equations with strong nonlinearity and singularity
              </a>
            </td>
          <td>
            Qiumei Huang, Jiaxuan Ma, Zhen Xu
          </td>
          <td>2024-04-28</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Solving high-dimensional dynamical systems in multi-query or real-time applications requires efficient surrogate modelling techniques, as e.g., achieved via model order reduction (MOR). If these systems are Hamiltonian systems their physical structure should be preserved during the reduction, which can be ensured by applying symplectic basis generation techniques such as the complex SVD (cSVD). Recently, randomized symplectic methods such as the randomized complex singular value decomposition (rcSVD) have been developed for a more efficient computation of symplectic bases that preserve the Hamiltonian structure during MOR. In the current paper, we present two error bounds for the rcSVD basis depending on the choice of hyperparameters and show that with a proper choice of hyperparameters, the projection error of rcSVD is at most a constant factor worse than the projection error of cSVD. We provide numerical experiments that demonstrate the efficiency of randomized symplectic basis generation and compare the bounds numerically.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/784185a6757f45f1fb6a75360f444570984fe1d6" target='_blank'>
              Error Analysis of Randomized Symplectic Model Order Reduction for Hamiltonian systems
              </a>
            </td>
          <td>
            Robin Herkert, Patrick Buchfink, B. Haasdonk, Johannes Rettberg, Jorg Fehr
          </td>
          <td>2024-05-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>32</td>
        </tr>

        <tr id="Model predictive control (MPC) for linear systems with quadratic costs and linear constraints is shown to admit an exact representation as an implicit neural network. A method to"unravel"the implicit neural network of MPC into an explicit one is also introduced. As well as building links between model-based and data-driven control, these results emphasize the capability of implicit neural networks for representing solutions of optimisation problems, as such problems are themselves implicitly defined functions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/dc3b642b6f39332a0a65d26c370754cf642847ba" target='_blank'>
              Mapping back and forth between model predictive control and neural networks
              </a>
            </td>
          <td>
            Ross Drummond, P. R. B. Monasterios, Giorgio Valmorbida
          </td>
          <td>2024-04-18</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>5</td>
        </tr>

        <tr id="Continuous time recurrent neural networks (CTRNNs) are systems of coupled ordinary differential equations (ODEs) inspired by the structure of neural networks in the brain. CTRNNs are known to be universal dynamical approximators: given a large enough system, the parameters of a CTRNN can be tuned to produce output that is arbitrarily close to that of any other dynamical system. However, in practice, both designing systems of CTRNN to have a certain output, and the reverse-understanding the dynamics of a given system of CTRNN-can be nontrivial. In this article, we describe a method for embedding any specified Turing machine in its entirety into a CTRNN. As such, we describe in detail a continuous time dynamical system that performs arbitrary discrete-state computations. We suggest that in acting as both a continuous time dynamical system and as a computer, the study of such systems can help refine and advance the debate concerning the Computational Hypothesis that cognition is a form of computation and the Dynamical Hypothesis that cognitive systems are dynamical systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a4c18d67633c17f70ffc53a4f2853ff51348378c" target='_blank'>
              A Continuous Time Dynamical Turing Machine.
              </a>
            </td>
          <td>
            C. Postlethwaite, Peter Ashwin, Matthew Egbert
          </td>
          <td>2024-05-16</td>
          <td>IEEE transactions on neural networks and learning systems</td>
          <td>0</td>
          <td>18</td>
        </tr>

        <tr id="We consider a robust dynamic event-driven control (EDC) problem of nonlinear systems having both unmatched perturbations and unknown styles of constraints. Specifically, the constraints imposed on the nonlinear systems' input could be symmetric or asymmetric. Initially, to tackle such constraints, we construct a novel nonquadratic cost function for the constrained auxiliary system. Then, we propose a dynamic event-triggering mechanism relied on the time-based variable and the system states simultaneously for cutting down the computational load. Meanwhile, we show that the robust dynamic EDC of original nonlinear-constrained systems could be acquired by solving the event-driven optimal control problem of the constrained auxiliary system. After that, we develop the corresponding event-driven Hamilton-Jacobi-Bellman equation, and then solve it through a unique critic neural network (CNN) in the reinforcement learning framework. To relax the persistence of excitation condition in tuning CNN's weights, we incorporate experience replay into the gradient descent method. With the aid of Lyapunov's approach, we prove that the closed-loop auxiliary system and the weight estimation error are uniformly ultimately bounded stable. Finally, two examples, including a nonlinear plant and the pendulum system, are utilized to validate the theoretical claims.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/96bf2c389a5101fc7c633266bc2217a647f303d2" target='_blank'>
              Reinforcement Learning for Robust Dynamic Event-Driven Constrained Control.
              </a>
            </td>
          <td>
            Xiong Yang, Ding Wang
          </td>
          <td>2024-05-03</td>
          <td>IEEE transactions on neural networks and learning systems</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="Digital twin (DT) technology integrates the physical world with its digitalized counterpart and suggests significant potential for intelligent transportation system development, such as CAV test and development. In the foreseeable near future, human-driven vehicles (HDVs) will continue to predominate, and a digital replica of the transportation system should reflect their behavioral patterns for enhanced simulation realism purposes. As such, stochastic driver behavior and vehicle dynamics should be respected. The observations serving as DT input, often captured at discrete moments (e.g., the roadside units and cameras are only installed at certain locations), result in discontinuously captured vehicle trajectories. The stochastic generation of behaviorally consistent vehicle trajectories conditional on such incomplete information becomes important. Current conditional approaches include modified Brownian bridge (MBB) and guided proposal bridge (GPB) may not be able to output realistic results. To fill this gap, we propose conditional generation methods of behaviorally consistent trajectories, employing the stochastic bridge approach for the first time. First, a vehicular dynamics model that encapsulates the stochasticity of the human–vehicle system is employed, and then we prove that MBB and GPB fail to generate satisfactory results. Then, a forward–backward method is proposed based on the backward Markov process, which takes the vehicular dynamics model as behavioral input. The proposed method is validated against real-world data and mainstream simulation platforms, showing that the forward–backward generation method provides consistent and realistic results. Its time consumption has also been proven to be promising for real-time DT applications.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/617320528d7303dced637cb2d74aab9dee7196fb" target='_blank'>
              Bridging Specified States With Stochastic Behavioral-Consistent Vehicle Trajectories for Enhanced Digital Twin Simulation Realism
              </a>
            </td>
          <td>
            Hongsheng Qi, Chenxi Chen, Xianbiao Hu
          </td>
          <td>2024-05-15</td>
          <td>IEEE Internet of Things Journal</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="We address data-driven learning of the infinitesimal generator of stochastic diffusion processes, essential for understanding numerical simulations of natural and physical systems. The unbounded nature of the generator poses significant challenges, rendering conventional analysis techniques for Hilbert-Schmidt operators ineffective. To overcome this, we introduce a novel framework based on the energy functional for these stochastic processes. Our approach integrates physical priors through an energy-based risk metric in both full and partial knowledge settings. We evaluate the statistical performance of a reduced-rank estimator in reproducing kernel Hilbert spaces (RKHS) in the partial knowledge setting. Notably, our approach provides learning bounds independent of the state space dimension and ensures non-spurious spectral estimation. Additionally, we elucidate how the distortion between the intrinsic energy-induced metric of the stochastic diffusion and the RKHS metric used for generator estimation impacts the spectral learning bounds.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/810eaf286a745319d778b46fae72d2d33882824b" target='_blank'>
              Learning the Infinitesimal Generator of Stochastic Diffusion Processes
              </a>
            </td>
          <td>
            Vladimir Kostic, Karim Lounici, Helene Halconruy, Timothee Devergne, M. Pontil
          </td>
          <td>2024-05-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>70</td>
        </tr>

        <tr id="Duality between estimation and control is a foundational concept in Control Theory. Most students learn about the elementary duality -- between observability and controllability -- in their first graduate course in linear systems theory. Therefore, it comes as a surprise that for a more general class of nonlinear stochastic systems (hidden Markov models or HMMs), duality is incomplete. Our objective in writing this article is two-fold: (i) To describe the difficulty in extending duality to HMMs; and (ii) To discuss its recent resolution by the authors. A key message is that the main difficulty in extending duality comes from time reversal in going from estimation to control. The reason for time reversal is explained with the aid of the familiar linear deterministic and linear Gaussian models. The explanation is used to motivate the difference between the linear and the nonlinear models. Once the difference is understood, duality for HMMs is described based on our recent work. The article also includes a comparison and discussion of the different types of duality considered in literature.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/cff50920a2cdf0632a55e8e52a013a32a3926e8a" target='_blank'>
              Arrow of Time in Estimation and Control: Duality Theory Beyond the Linear Gaussian Model
              </a>
            </td>
          <td>
            J. W. Kim, Prashant G. Mehta
          </td>
          <td>2024-05-13</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="This article develops mathematical formalisms and provides numerical methods for studying the evolution of measures in nonsmooth dynamical systems using the continuity equation. The nonsmooth dynamical system is described by an evolution variational inequality and we derive the continuity equation associated with this system class using three different formalisms. The first formalism consists of using the {superposition principle} to describe the continuity equation for a measure that disintegrates into a probability measure supported on the set of vector fields and another measure representing the distribution of system trajectories at each time instant. The second formalism is based on the regularization of the nonsmooth vector field and describing the measure as the limit of a sequence of measures associated with the regularization parameter. In doing so, we obtain quantitative bounds on the Wasserstein metric between measure solutions of the regularized vector field and the limiting measure associated with the nonsmooth vector field. The third formalism uses a time-stepping algorithm to model a time-discretized evolution of the measures and show that the absolutely continuous trajectories associated with the continuity equation are recovered in the limit as the sampling time goes to zero. We also validate each formalism with numerical examples. For the first formalism, we use polynomial optimization techniques and the moment-SOS hierarchy to obtain approximate moments of the measures. For the second formalism, we illustrate the bounds on the Wasserstein metric for an academic example for which the closed-form expression of the Wasserstein metric can be calculated. For the third formalism, we illustrate the time-stepping based algorithm for measure evolution on an example that shows the effect of the concentration of measures.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3e9e4499422a19e67ffdc1502cf5b778af6e4bb7" target='_blank'>
              Evolution of Measures in Nonsmooth Dynamical Systems: Formalisms and Computation
              </a>
            </td>
          <td>
            S. Chhatoi, A. Tanwani, Didier Henrion
          </td>
          <td>2024-05-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="Neural Cellular Automata (NCA) is a class of Cellular Automata where the update rule is parameterized by a neural network that can be trained using gradient descent. In this paper, we focus on NCA models used for texture synthesis, where the update rule is inspired by partial differential equations (PDEs) describing reaction-diffusion systems. To train the NCA model, the spatio-termporal domain is discretized, and Euler integration is used to numerically simulate the PDE. However, whether a trained NCA truly learns the continuous dynamic described by the corresponding PDE or merely overfits the discretization used in training remains an open question. We study NCA models at the limit where space-time discretization approaches continuity. We find that existing NCA models tend to overfit the training discretization, especially in the proximity of the initial condition, also called"seed". To address this, we propose a solution that utilizes uniform noise as the initial condition. We demonstrate the effectiveness of our approach in preserving the consistency of NCA dynamics across a wide range of spatio-temporal granularities. Our improved NCA model enables two new test-time interactions by allowing continuous control over the speed of pattern formation and the scale of the synthesized patterns. We demonstrate this new NCA feature in our interactive online demo. Our work reveals that NCA models can learn continuous dynamics and opens new venues for NCA research from a dynamical systems' perspective.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/76298dc594d0dec3c5ef61fbe6cde4325b9051b7" target='_blank'>
              NoiseNCA: Noisy Seed Improves Spatio-Temporal Continuity of Neural Cellular Automata
              </a>
            </td>
          <td>
            Ehsan Pajouheshgar, Yitao Xu, Sabine Süsstrunk
          </td>
          <td>2024-04-09</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="
 In this article, we investigate a couple of nonlinear fractional models of eminent interests subsequently the conformable derivative sense is used to designate the fractional order derivatives. The given structures are transformed into nonlinear ordinary differential equations of integer order, and the extended simple equation technique is then employed to solve the resulting equations. Initially, the nonlinear space time fractional Klein–Gordon equation is considered emerging from quantum and classical relativistic mechanics, which have application in plasma physics, dispersive wave phenomena, quantum field theory, and optical fibres. Later, the (2 + 1)-dimensional time fractional Zoomeron equation is analysed which is convenient to explore the innovative phenomena related to boomerons and trappons. As a result, various new soliton solutions are successfully established. The reported results offer a key implementation for analysing the soliton solutions of nonlinear fractional models which are extremely encouraging arising in the recent era of science and engineering. The 3D simulations have been carried out to demonstrate dynamics of the various soliton solutions for a given set of parameters.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7c4f0a15bf8f4cd39a1dd0697b2290f25f3a8942" target='_blank'>
              On the construction of various soliton solutions of two space-time fractional nonlinear models
              </a>
            </td>
          <td>
            K. U. Tariq, Jian-Guo Liu
          </td>
          <td>2024-05-09</td>
          <td>Journal of Nonlinear, Complex and Data Science</td>
          <td>0</td>
          <td>18</td>
        </tr>

        <tr id="Gaussian processes are flexible probabilistic regression models which are widely used in statistics and machine learning. However, a drawback is their limited scalability to large data sets. To alleviate this, we consider full-scale approximations (FSAs) that combine predictive process methods and covariance tapering, thus approximating both global and local structures. We show how iterative methods can be used to reduce the computational costs for calculating likelihoods, gradients, and predictive distributions with FSAs. We introduce a novel preconditioner and show that it accelerates the conjugate gradient method's convergence speed and mitigates its sensitivity with respect to the FSA parameters and the eigenvalue structure of the original covariance matrix, and we demonstrate empirically that it outperforms a state-of-the-art pivoted Cholesky preconditioner. Further, we present a novel, accurate, and fast way to calculate predictive variances relying on stochastic estimations and iterative methods. In both simulated and real-world data experiments, we find that our proposed methodology achieves the same accuracy as Cholesky-based computations with a substantial reduction in computational time. Finally, we also compare different approaches for determining inducing points in predictive process and FSA models. All methods are implemented in a free C++ software library with high-level Python and R packages.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d90e91613853eaa5a79241f1fa73bca170e38dd6" target='_blank'>
              Iterative Methods for Full-Scale Gaussian Process Approximations for Large Spatial Data
              </a>
            </td>
          <td>
            Tim Gyger, Reinhard Furrer, Fabio Sigrist
          </td>
          <td>2024-05-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/aa8792193af72763738332e877e05b56e9196bb5" target='_blank'>
              Bifurcation analysis and soliton solutions to the doubly dispersive equation in elastic inhomogeneous Murnaghan’s rod
              </a>
            </td>
          <td>
            S. M. R. Islam
          </td>
          <td>2024-05-19</td>
          <td>Scientific Reports</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Developing and optimizing models for complex systems poses challenges due to the inherent complexity introduced by multiple types of input information and sources of uncertainty. In this study, we utilize Bayesian formalism to analytically examine the propagation of probability in the modeling process and propose quantitative assessments for it. Upon which, we develop a method for optimizing models for complex systems by (i) minimizing model uncertainty; (ii) maximizing model consistency; and (iii) minimizing model complexity, following the Bayesian Occam’s razor rationale. We showcase the benefits of this method by optimizing the modeling of the dynamic system of glucose-stimulated insulin secretion in pancreatic β-cells, leading to an optimized model that demonstrates better alignment with experimental observations compared to the non-optimized one. We anticipate that this method will facilitate the construction of accurate, precise, and sufficiently simple models for diverse complex systems. It is implemented in our open-source software Integrative Modeling Platform (IMP), ensuring its broad applicability.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2852aa1c64c573614d3968195a3e4de98331119b" target='_blank'>
              Bayesian Occam’s Razor to Optimize Models for Complex Systems
              </a>
            </td>
          <td>
            Chenxi Wang, Jihui Zhao, Jingjing Zheng, Barak Raveh, Xuming He, Liping Sun
          </td>
          <td>2024-06-02</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="Accurate parameter dependent electro-chemical numerical models for lithium-ion batteries are essential in industrial application. The exact parameters of each battery cell are unknown and a process of estimation is necessary to infer them. The parameter estimation generates an accurate model able to reproduce real cell data. The field of optimal input/experimental design deals with creating the experimental settings facilitating the estimation problem. Here we apply two different input design algorithms that aim at maximizing the observability of the true, unknown parameters: in the first algorithm, we design the applied current and the starting voltage. This lets the algorithm collect information on different states of charge, but requires long experimental times (60 000 s). In the second algorithm, we generate a continuous current, composed of concatenated optimal intervals. In this case, the experimental time is shorter (7000 s) and numerical experiments with virtual data give an even better accuracy results, but experiments with real battery data reveal that the accuracy could decrease hundredfold. As the design algorithms are built independent of the model, the same results and motivation are applicable to more complex battery cell models and, moreover, to other applications.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3ac7d9fcc02c606c988d433a1e3e9e1ffe6dbabd" target='_blank'>
              Optimal Experimental Design for Large-Scale Inverse Problems via Multi-PDE-constrained Optimization
              </a>
            </td>
          <td>
            A. Petrocchi, Matthias K. Scharrer, Franz Pichler, Stefan Volkwein
          </td>
          <td>2024-04-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="In this work, we explore the efficacy of rectified linear unit artificial neural networks in addressing the intricate challenges of convoluted constraints arising from feedback linearization mapping. Our approach involves a comprehensive procedure, encompassing the approximation of constraints through a regression process. Subsequently, we transform these constraints into an equivalent representation of mixed-integer linear constraints, seamlessly integrating them into other stabilizing control architectures. The advantage resides in the compatibility with the linear control design and the constraint satisfaction in the model predictive control setup, even for forecasted trajectories. Simulations are provided to validate the proposed constraint reformulation.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/44561ac2679a3a53ec0189a4e0674ed2a4c1f727" target='_blank'>
              On the constrained feedback linearization control based on the MILP representation of a ReLU-ANN
              </a>
            </td>
          <td>
            H. Do, I. Prodan
          </td>
          <td>2024-05-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="Dynamic models generating time‐dependent model predictions are typically associated with high‐dimensional input spaces and high‐dimensional output spaces, in particular if time is discretized. It is computationally prohibitive to apply traditional global sensitivity analysis (SA) separately on each time output, as is common in the literature on multivariate SA. As an alternative, we propose a novel method for efficient global SA of dynamic models with high‐dimensional inputs by combining a new polynomial chaos expansion (PCE)‐driven partial least squares (PLS) algorithm with the analysis of variance. PLS is used to simultaneously reduce the dimensionality of the input and output variables spaces, by identifying the input and output latent variables that account for most of their joint variability. PCE is incorporated into the PLS algorithm to capture the non‐linear behavior of the physical system. We derive the sensitivity indices associated with each output latent variable, based on which we propose generalized sensitivity indices that synthesize the influence of each input on the variance of entire output time series. All sensitivities can be computed analytically by post‐processing the coefficients of the PLS‐PCE representation. Hence, the computational cost of global SA for dynamic models essentially reduces to the cost for estimating these coefficients. We numerically compare the proposed method with existing methods by several dynamic models with high‐dimensional inputs. The results show that the PLS‐PCE method can obtain accurate sensitivity indices at low computational cost, even for models with strong interaction among the inputs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/97aab73b4dc853e42f210580fa16e0d7aafa3d57" target='_blank'>
              Efficient global sensitivity analysis method for dynamic models in high dimensions
              </a>
            </td>
          <td>
            Luyi Li, I. Papaioannou, Daniel Straub
          </td>
          <td>2024-05-07</td>
          <td>International Journal for Numerical Methods in Engineering</td>
          <td>0</td>
          <td>24</td>
        </tr>

        <tr id="One of the main theoretical challenges in learning dynamical systems from data is providing upper bounds on the generalization error, that is, the difference between the expected prediction error and the empirical prediction error measured on some finite sample. In machine learning, a popular class of such bounds are the so-called Probably Approximately Correct (PAC) bounds. In this paper, we derive a PAC bound for stable continuous-time linear parameter-varying (LPV) systems. Our bound depends on the H2 norm of the chosen class of the LPV systems, but does not depend on the time interval for which the signals are considered.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/06ee4d9bca15b8e5ff46993fc4598f015c786bb2" target='_blank'>
              A finite-sample generalization bound for stable LPV systems
              </a>
            </td>
          <td>
            Daniel Racz, Martin Gonzalez, M. Petreczky, A. Benczúr, B. Daróczy
          </td>
          <td>2024-05-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>26</td>
        </tr>

        <tr id="Symbolic regression has excelled in uncovering equations from physics, chemistry, biology, and related disciplines. However, its effectiveness becomes less certain when applied to experimental data lacking inherent closed-form expressions. Empirically derived relationships, such as entire stress-strain curves, may defy concise closed-form representation, compelling us to explore more adaptive modeling approaches that balance flexibility with interpretability. In our pursuit, we turn to Generalized Additive Models (GAMs), a widely used class of models known for their versatility across various domains. Although GAMs can capture non-linear relationships between variables and targets, they cannot capture intricate feature interactions. In this work, we investigate both of these challenges and propose a novel class of models, Shape Arithmetic Expressions (SHAREs), that fuses GAM's flexible shape functions with the complex feature interactions found in mathematical expressions. SHAREs also provide a unifying framework for both of these approaches. We also design a set of rules for constructing SHAREs that guarantee transparency of the found expressions beyond the standard constraints based on the model's size.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/299a08060c18ae6be4dab3cb0f9bb0b08240688f" target='_blank'>
              Shape Arithmetic Expressions: Advancing Scientific Discovery Beyond Closed-Form Equations
              </a>
            </td>
          <td>
            Krzysztof Kacprzyk, M. Schaar
          </td>
          <td>2024-04-15</td>
          <td>DBLP, ArXiv</td>
          <td>0</td>
          <td>64</td>
        </tr>

        <tr id="
 In this paper, the extended (3 + 1)-dimensional Zakharov-Kuznetsov equation, which describes the propagation of ion-acoustic waves in a magnetic environment, is investigated. Due to the exposure of the propagation to unpredictable factors, the stochastic model is assessed including the Brownian process, in addition to including the recent concept of truncated M-fractional derivative. A fractional stochastic transformation is applied to transform the model into an integer-order ordinary differential equation which in turn is equivalent to a conservative Hamiltonian model. Novel solutions, such as hyperbolic, trigonometric, and Jacobian elliptic functions, are established by employing both of the qualitative analysis of dynamical systems and the first integral of the Hamiltonian model. We explore and graphically display the effects of the fractional derivative order and noise intensity on the solutions structures. In the deterministic instance, i.e., in the absence of noise, solitary and cnoidal solutions among other traveling wave solutions of the Zakharov-Kuznetsov equation, are derived. Further, it is found that the curvature of the wave disturbs and the surface turns substantially flat by increasing the value of noise. While the curve in all cases loses its characteristic shape and degenerates into another deterministic shape by changing the fractional derivative order.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/70509cd94315ba14c730ae366d6ca5da730b999a" target='_blank'>
              Qualitative analysis and new exact solutions for the extended space-fractional stochastic (3 + 1)-dimensional Zakharov-Kuznetsov equation
              </a>
            </td>
          <td>
            M. Elbrolosy
          </td>
          <td>2024-05-22</td>
          <td>Physica Scripta</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="In a nutshell, unscented trajectory optimization is the generation of optimal trajectories through the use of an unscented transform. Although unscented trajectory optimization was introduced by the authors about a decade ago, it is reintroduced in this paper as a special instantiation of tychastic optimal control theory. Tychastic optimal control theory (from \textit{Tyche}, the Greek goddess of chance) avoids the use of a Brownian motion and the resulting It\^{o} calculus even though it uses random variables across the entire spectrum of a problem formulation. This approach circumvents the enormous technical and numerical challenges associated with stochastic trajectory optimization. Furthermore, it is shown how a tychastic optimal control problem that involves nonlinear transformations of the expectation operator can be quickly instantiated using an unscented transform. These nonlinear transformations are particularly useful in managing trajectory dispersions be it associated with path constraints or targeted values of final-time conditions. This paper also presents a systematic and rapid process for formulating and computing the most desirable tychastic trajectory using an unscented transform. Numerical examples are used to illustrate how unscented trajectory optimization may be used for risk reduction and mission recovery caused by uncertainties and failures.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d5a182338afafe89052cfc5cf13db0c5c18cf54d" target='_blank'>
              Unscented Trajectory Optimization
              </a>
            </td>
          <td>
            I. M. Ross, R. Proulx, M. Karpenko
          </td>
          <td>2024-05-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>11</td>
        </tr>

        <tr id="We present a subspace method based on neural networks (SNN) for solving the partial differential equation with high accuracy. The basic idea of our method is to use some functions based on neural networks as base functions to span a subspace, then find an approximate solution in this subspace. We design two special algorithms in the strong form of partial differential equation. One algorithm enforces the equation and initial boundary conditions to hold on some collocation points, and another algorithm enforces $L^2$-norm of the residual of the equation and initial boundary conditions to be $0$. Our method can achieve high accuracy with low cost of training. Moreover, our method is free of parameters that need to be artificially adjusted. Numerical examples show that the cost of training these base functions of subspace is low, and only one hundred to two thousand epochs are needed for most tests. The error of our method can even fall below the level of $10^{-10}$ for some tests. The performance of our method significantly surpasses the performance of PINN and DGM in terms of the accuracy and computational cost.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bd756a3c78496f109b832163bd37e70bc7e96e3c" target='_blank'>
              Subspace method based on neural networks for solving the partial differential equation
              </a>
            </td>
          <td>
            Zhaodong Xu, Zhiqiang Sheng
          </td>
          <td>2024-04-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Time-domain simulations in power systems are crucial for ensuring power system stability and avoiding critical scenarios that could lead to blackouts. The proliferation of converter-connected resources, however, adds significant additional degrees of non-linearity and complexity to these simulations. This drastically increases the computational time and the number of critical scenarios to be considered. Physics-Informed Neural Networks (PINN) have been shown to accelerate these simulations by several orders of magnitude. This paper introduces the first natural step to remove the barriers for using PINNs in time-domain simulations: it proposes the first method to integrate PINNs in conventional numerical solvers. Integrating PINNs into conventional solvers unlocks a wide range of opportunities. First, PINNs can substantially accelerate simulation time, second, the modeling of components with PINNs allows new ways to reduce privacy concerns when sharing models, and last, enhance the applicability of PINN-based surrogate modeling. We demonstrate the training, integration, and simulation framework for several combinations of PINNs and numerical solution methods, using the IEEE 9-bus system.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b0d7fafc766593385db83ccc98dd3fe2596df6f4" target='_blank'>
              Integrating Physics-Informed Neural Networks into Power System Dynamic Simulations
              </a>
            </td>
          <td>
            Ignasi Ventura Nadal, Jochen Stiasny, Spyros Chatzivasileiadis
          </td>
          <td>2024-04-20</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>27</td>
        </tr>

        <tr id="The stochastic FitzHugh-Nagumo (FHN) model considered here is a two-dimensional nonlinear stochastic differential equation with additive degenerate noise, whose first component, the only one observed, describes the membrane voltage evolution of a single neuron. Due to its low dimensionality, its analytical and numerical tractability, and its neuronal interpretation, it has been used as a case study to test the performance of different statistical methods in estimating the underlying model parameters. Existing methods, however, often require complete observations, non-degeneracy of the noise or a complex architecture (e.g., to estimate the transition density of the process,"recovering"the unobserved second component), and they may not (satisfactorily) estimate all model parameters simultaneously. Moreover, these studies lack real data applications for the stochastic FHN model. Here, we tackle all challenges (non-globally Lipschitz drift, non-explicit solution, lack of available transition density, degeneracy of the noise, and partial observations) via an intuitive and easy-to-implement sequential Monte Carlo approximate Bayesian computation algorithm. The proposed method relies on a recent computationally efficient and structure-preserving numerical splitting scheme for synthetic data generation, and on summary statistics exploiting the structural properties of the process. We succeed in estimating all model parameters from simulated data and, more remarkably, real action potential data of rats. The presented novel real-data fit may broaden the scope and credibility of this classic and widely used neuronal model.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4d8970578d506e7d7e0e7b819bb6efcd7a6460b8" target='_blank'>
              Inference for the stochastic FitzHugh-Nagumo model from real action potential data via approximate Bayesian computation
              </a>
            </td>
          <td>
            Adeline Samson, M. Tamborrino, I. Tubikanec
          </td>
          <td>2024-05-28</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>11</td>
        </tr>

        <tr id="In this paper we present an efficient active-set method for the solution of convex quadratic programming problems with general piecewise-linear terms in the objective, with applications to sparse approximations and risk-minimization. The algorithm is derived by combining a proximal method of multipliers (PMM) with a standard semismooth Newton method (SSN), and is shown to be globally convergent under minimal assumptions. Further local linear (and potentially superlinear) convergence is shown under standard additional conditions. The major computational bottleneck of the proposed approach arises from the solution of the associated SSN linear systems. These are solved using a Krylov-subspace method, accelerated by certain novel general-purpose preconditioners which are shown to be optimal with respect to the proximal penalty parameters. The preconditioners are easy to store and invert, since they exploit the structure of the nonsmooth terms appearing in the problem's objective to significantly reduce their memory requirements. We showcase the efficiency, robustness, and scalability of the proposed solver on a variety of problems arising in risk-averse portfolio selection, $L^1$-regularized partial differential equation constrained optimization, quantile regression, and binary classification via linear support vector machines. We provide computational evidence, on real-world datasets, to demonstrate the ability of the solver to efficiently and competitively handle a diverse set of medium- and large-scale optimization instances.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/695ed3de01e391e3338f9c30f41c35390429161d" target='_blank'>
              An efficient active-set method with applications to sparse approximations and risk minimization
              </a>
            </td>
          <td>
            Spyridon Pougkakiotis, J. Gondzio, Dionysis Kalogerias
          </td>
          <td>2024-05-07</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>39</td>
        </tr>

        <tr id="Frequency response function (FRF) estimation is a classical subject in system identification. In the past two decades, there have been remarkable advances in developing local methods for this subject, e.g., the local polynomial method, local rational method, and iterative local rational method. The recent concentrations for local methods are two issues: the model order selection and the identification of lightly damped systems. To address these two issues, we propose a new local method called local Gaussian process regression (LGPR). We show that the frequency response function locally is either analytic or resonant, and this prior knowledge can be embedded into a kernel-based regularized estimate through a dot-product kernel plus a resonance kernel induced by a second-order resonant system. The LGPR provides a new route to tackle the aforementioned issues. In the numerical simulations, the LGPR shows the best FRF estimation accuracy compared with the existing local methods, and moreover, the LGPR is more robust with respect to sample size and noise level.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3c5b2ba957ae62bfcf3fd64f58eb3b62df789e27" target='_blank'>
              A Local Gaussian Process Regression Approach to Frequency Response Function Estimation
              </a>
            </td>
          <td>
            Xiaozhu Fang, Yu Xu, Tianshi Chen
          </td>
          <td>2024-05-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Classic Bayesian methods with complex models are frequently infeasible due to an intractable likelihood. Simulation-based inference methods, such as Approximate Bayesian Computing (ABC), calculate posteriors without accessing a likelihood function by leveraging the fact that data can be quickly simulated from the model, but converge slowly and/or poorly in high-dimensional settings. In this paper, we propose a framework for Bayesian posterior estimation by mapping data to posteriors of parameters using a neural network trained on data simulated from the complex model. Posterior distributions of model parameters are efficiently obtained by feeding observed data into the trained neural network. We show theoretically that our posteriors converge to the true posteriors in Kullback-Leibler divergence. Our approach yields computationally efficient and theoretically justified uncertainty quantification, which is lacking in existing simulation-based neural network approaches. Comprehensive simulation studies highlight our method's robustness and accuracy.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a1714b4117591164cd7ee026259d5908c497386f" target='_blank'>
              A variational neural Bayes framework for inference on intractable posterior distributions
              </a>
            </td>
          <td>
            Elliot Maceda, Emily C. Hector, Amanda Lenzi, Brian J. Reich
          </td>
          <td>2024-04-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The diffusion bridge is a type of diffusion process that conditions on hitting a specific state within a finite time period. It has broad applications in fields such as Bayesian inference, financial mathematics, control theory, and shape analysis. However, simulating the diffusion bridge for natural data can be challenging due to both the intractability of the drift term and continuous representations of the data. Although several methods are available to simulate finite-dimensional diffusion bridges, infinite-dimensional cases remain unresolved. In the paper, we present a solution to this problem by merging score-matching techniques with operator learning, enabling a direct approach to score-matching for the infinite-dimensional bridge. We construct the score to be discretization invariant, which is natural given the underlying spatially continuous process. We conduct a series of experiments, ranging from synthetic examples with closed-form solutions to the stochastic nonlinear evolution of real-world biological shape data, and our method demonstrates high efficacy, particularly due to its ability to adapt to any resolution without extra training.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2a2ce647eed223b2dcdd8f97c0c41008d612d912" target='_blank'>
              Simulating infinite-dimensional nonlinear diffusion bridges
              </a>
            </td>
          <td>
            Gefan Yang, E. Baker, Michael L. Severinsen, C. Hipsley, Stefan Sommer
          </td>
          <td>2024-05-28</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="
 In this study, we use the Khater Method (KM) as an efficient analytical tool to solve (3+1)-dimensional fractional extended shallow water wave equations (FESWWEs) with conformable derivatives. The KM transforms fractional partial differential equations to ordinary differential equations (ODEs) via strategic variable transformation. Then, series-form solutions to these ODEs are proposed, which turn them into nonlinear algebraic systems. The solution to this set of algebraic equations yields shock travelling wave solutions expressed in hyperbolic, trigonometric, exponential, and rational functions. The study's findings are corroborated by 2D, 3D, and contour graphs that show the changing patterns of the detected shock travelling waves. These findings have important significance for the discipline, offering vital insights into the intricate dynamics of FESWWEs. The effectiveness of KM is demonstrated by its capacity to produce varied solutions and contribute to a thorough knowledge of such complex phenomena.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/99ea9edf26ccae64cbeea30f2a66a6700ddf2776" target='_blank'>
              Analytical study of soliton dynamics in the realm of fractional extended shallow water wave equations
              </a>
            </td>
          <td>
            Rashid Ali, Shoaib Barak, Ali A. Altalbe
          </td>
          <td>2024-05-03</td>
          <td>Physica Scripta</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="In this paper we consider adaptive deep neural network approximation for stochastic dynamical systems. Based on the Liouville equation associated with the stochastic dynamical systems, a new temporal KRnet (tKRnet) is proposed to approximate the probability density functions (PDFs) of the state variables. The tKRnet gives an explicit density model for the solution of the Liouville equation, which alleviates the curse of dimensionality issue that limits the application of traditional grid based numerical methods. To efficiently train the tKRnet, an adaptive procedure is developed to generate collocation points for the corresponding residual loss function, where samples are generated iteratively using the approximate density function at each iteration. A temporal decomposition technique is also employed to improve the long-time integration. Theoretical analysis of our proposed method is provided, and numerical examples are presented to demonstrate its performance.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/827723bda19209701daa5c4d36f6625034285087" target='_blank'>
              Adaptive deep density approximation for stochastic dynamical systems
              </a>
            </td>
          <td>
            Junjie He, Qifeng Liao, Xiaoliang Wan
          </td>
          <td>2024-05-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Optimal transport has been an essential tool for reconstructing dynamics from complex data. With the increasingly available multifaceted data, a system can often be characterized across multiple spaces. Therefore, it is crucial to maintain coherence in the dynamics across these diverse spaces. To address this challenge, we introduce Synchronized Optimal Transport (SyncOT), a novel approach to jointly model dynamics that represent the same system through multiple spaces. With given correspondence between the spaces, SyncOT minimizes the aggregated cost of the dynamics induced across all considered spaces. The problem is discretized into a finite-dimensional convex problem using a staggered grid. Primal-dual algorithm-based approaches are then developed to solve the discretized problem. Various numerical experiments demonstrate the capabilities and properties of SyncOT and validate the effectiveness of the proposed algorithms.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bafa108eb9b78b8523cef21c7af52ee299aa0fd1" target='_blank'>
              Synchronized Optimal Transport for Joint Modeling of Dynamics Across Multiple Spaces
              </a>
            </td>
          <td>
            Zixuan Cang, Yanxiang Zhao
          </td>
          <td>2024-06-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="In this study, we investigate trajectories involving multiple impulses within the framework of a generic spacecraft dynamics. Revisiting the age-old query of"How many impulses?", we present novel manipulations heavily leveraging on the properties ofthe state transition matrix. Surprisingly, we are able to rediscover classical results leading to the introduction of a primer vector, albeit not making use of Pontryagin Maximum Principle as in the original developments by Lawden. Furthermore, our mathematical framework exhibits great flexibility and enables the introduction of what we term a"surrogate primer vector"extending a well known concept widely used in mission design. This enhancement allows to derive new simple optimality conditions that provide insights into the possibility to add and/or move multiple impulsive manoeuvres and improve the overall mass budget. This proves especially valuable in scenarios where a baseline trajectory arc is, for example, limited to a single impulse-an instance where traditional primer vector developments become singular and hinder conclusive outcomes. In demonstrating the practical application of the surrogate primer vector, we examine a specific case involving the four-body dynamics of a spacecraft within an Earth-Moon-Sun system. The system is characterized by the high-precision and differentiable VSOP2013 and ELP2000 ephemerides models. The focal point of our investigation is a reference trajectory representing a return from Mars, utilizing the weak stability boundary (WSB) of the Sun-Earth-Moon system. The trajectory incorporates two consecutive lunar flybys to insert the spacecraft into a lunar distant retrograde orbit (DRO). Conventionally, this trajectory necessitates a single maneuver at the DRO injection point.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1331d56e1174ea0b8649a916de13d0f148db55ab" target='_blank'>
              Breaking traditions: introducing a surrogate Primer Vector in non Keplerian dynamics
              </a>
            </td>
          <td>
            Laurent Beauregard, Dario Izzo, Giacomo Acciarini
          </td>
          <td>2024-05-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Modeling and forecasting the dynamics of complex systems, such as moderate pressure capacitively coupled plasma (CCP) systems, remains a challenge due to the interactions of physical and chemical processes across multiple scales. Historically, optimization for a given application would be accomplished via a design of experiment (DOE) study across the various external control parameters. Machine learning (ML) techniques show the potential to “forecast” process conditions not tested in a traditional DOE study and thereby allow better optimization and control of a plasma tool. In this article, we have used standard DOE as well as ML predictions to analyze I-V data in a moderate-pressure CCP system. We have demonstrated that supervised regression ML techniques can be a useful tool for extrapolating data even when a plasma system is undergoing a transition in the heating mode, in this case from the alpha to gamma mode. Classification analysis of control parameters is another possible application of ML techniques that can be deployed for system control. Here, we show that given a large set of measured data, the models can identify the gas ratio in the feed gas as well as correctly identify the operating pressure and electrode gap in almost all the cases.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f5d56bdf2c513202454ebc1099849bb24098757b" target='_blank'>
              Case study in machine learning for predicting moderate pressure plasma behavior
              </a>
            </td>
          <td>
            S. Hussain, David J. Lary, K. Hara, K. Bera, Shahid Rauf, M. Goeckner
          </td>
          <td>2024-05-14</td>
          <td>Journal of Vacuum Science &amp; Technology A</td>
          <td>0</td>
          <td>16</td>
        </tr>

        <tr id="In complex systems with multiple variables monitored at high‐frequency, variables are not only temporally autocorrelated, but they may also be nonlinearly related or exhibit nonstationarity as the inputs or operation changes. One approach to handling such variables is to detrend them prior to monitoring and then apply control charts that assume independence and stationarity to the residuals. Monitoring controlled systems is even more challenging because the control strategy seeks to maintain variables at prespecified mean levels, and to compensate, correlations among variables may change, making monitoring the covariance essential. In this paper, a vector autoregressive model (VAR) is compared with a multivariate random forest (MRF) and a neural network (NN) for detrending multivariate time series prior to monitoring the covariance of the residuals using a multivariate exponentially weighted moving average (MEWMA) control chart. Machine learning models have an advantage when the data's structure is unknown or may change. We design a novel simulation study with nonlinear, nonstationary, and autocorrelated data to compare the different detrending models and subsequent covariance monitoring. The machine learning models have superior performance for nonlinear and strongly autocorrelated data and similar performance for linear data. An illustration with data from a reverse osmosis process is given.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/51a2f660fc5b36962a4d62c61c181a9c79c41977" target='_blank'>
              Monitoring covariance in multivariate time series: Comparing machine learning and statistical approaches
              </a>
            </td>
          <td>
            Derek Weix, T. Cath, A. Hering
          </td>
          <td>2024-04-09</td>
          <td>Quality and Reliability Engineering International</td>
          <td>0</td>
          <td>58</td>
        </tr>

        <tr id="Scientific advancement is universally based on the dynamic interplay between theoretical insights, modelling, and experimental discoveries. However, this feedback loop is often slow, including delayed community interactions and the gradual integration of experimental data into theoretical frameworks. This challenge is particularly exacerbated in domains dealing with high-dimensional object spaces, such as molecules and complex microstructures. Hence, the integration of theory within automated and autonomous experimental setups, or theory in the loop automated experiment, is emerging as a crucial objective for accelerating scientific research. The critical aspect is not only to use theory but also on-the-fly theory updates during the experiment. Here, we introduce a method for integrating theory into the loop through Bayesian co-navigation of theoretical model space and experimentation. Our approach leverages the concurrent development of surrogate models for both simulation and experimental domains at the rates determined by latencies and costs of experiments and computation, alongside the adjustment of control parameters within theoretical models to minimize epistemic uncertainty over the experimental object spaces. This methodology facilitates the creation of digital twins of material structures, encompassing both the surrogate model of behavior that includes the correlative part and the theoretical model itself. While demonstrated here within the context of functional responses in ferroelectric materials, our approach holds promise for broader applications, the exploration of optical properties in nanoclusters, microstructure-dependent properties in complex materials, and properties of molecular systems. The analysis code that supports the funding is publicly available at https://github.com/Slautin/2024_Co-navigation/tree/main">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/384c4b49d3ff96efb0b7bc35a8887e3db4b7779e" target='_blank'>
              Bayesian Co-navigation: Dynamic Designing of the Materials Digital Twins via Active Learning
              </a>
            </td>
          <td>
            B. Slautin, Yongtao Liu, Hiroshi Funakubo, R. Vasudevan, M. Ziatdinov, Sergei V. Kalinin
          </td>
          <td>2024-04-19</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>38</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/76a0255c39dd8ed49f328265256b4cf79a343423" target='_blank'>
              Exploiting residual errors in nonlinear online prediction
              </a>
            </td>
          <td>
            Emirhan Ilhan, Ahmet B. Koc, S. Kozat
          </td>
          <td>2024-05-29</td>
          <td>Machine Learning</td>
          <td>0</td>
          <td>25</td>
        </tr>

        <tr id="The data-informativity approach in data-driven control focuses on data and their matching model sets for system design and analysis. The approach offers a new mathematical formulation different from model-based control and is expected to progress. In model-based control, the introduction of equivalent transformations has made system analysis and design easier and facilitated theoretical development. In this study, we focus on data transformations and their transformation of matching model sets. We first introduce an algebraic sequence representing the relationship between the data and model set, and using this algebraic approach, we utilize propositions from homology theory, such as kernel universality, to analyze data and model transformations. This technique is significant not only mathematically but also in engineering. Further, we demonstrate how this technique can be applied to derive controllability judgments for data informativity-based analysis. Finally, we prove that design problems can be reduced to analysis problems involving controller inclusion.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4e88d17edecdb39191fd1626364d96fe62747d4a" target='_blank'>
              Data transformation technique in the data informativity approach via algebraic sequences
              </a>
            </td>
          <td>
            Yuki Tanaka, Osamu Kaneko
          </td>
          <td>2024-05-25</td>
          <td>Kybernetika</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Learning and understanding car-following (CF) behaviors are crucial for microscopic traffic simulation. Traditional CF models, though simple, often lack generalization capabilities, while many data-driven methods, despite their robustness, operate as"black boxes"with limited interpretability. To bridge this gap, this work introduces a Bayesian Matrix Normal Mixture Regression (MNMR) model that simultaneously captures feature correlations and temporal dynamics inherent in CF behaviors. This approach is distinguished by its separate learning of row and column covariance matrices within the model framework, offering an insightful perspective into the human driver decision-making processes. Through extensive experiments, we assess the model's performance across various historical steps of inputs, predictive steps of outputs, and model complexities. The results consistently demonstrate our model's adeptness in effectively capturing the intricate correlations and temporal dynamics present during CF. A focused case study further illustrates the model's outperforming interpretability of identifying distinct operational conditions through the learned mean and covariance matrices. This not only underlines our model's effectiveness in understanding complex human driving behaviors in CF scenarios but also highlights its potential as a tool for enhancing the interpretability of CF behaviors in traffic simulations and autonomous driving systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2a10e42108a37b19274f38a584e7be2d0ddebf44" target='_blank'>
              Learning Car-Following Behaviors Using Bayesian Matrix Normal Mixture Regression
              </a>
            </td>
          <td>
            Chengyuan Zhang, Kehua Chen, Meixin Zhu, Hai Yang, Lijun Sun
          </td>
          <td>2024-04-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="This article concerns the investigation on the consensus problem for the joint state-uncertainty estimation of a class of parabolic partial differential equation (PDE) systems with parametric and nonparametric uncertainties. We propose a two-layer network consisting of informed and uninformed boundary observers where novel adaptation laws are developed for the identification of uncertainties. Particularly, all observer agents in the network transmit their information with each other across the entire network. The proposed adaptation laws include a penalty term of the mismatch between the parameter estimates generated by the other observer agents. Moreover, for the nonparametric uncertainties, radial basis function (RBF) neural networks are employed for the universal approximation of unknown nonlinear functions. Given the persistently exciting condition, it is shown that the proposed network of adaptive observers can achieve exponential joint state-uncertainty estimation in the presence of parametric uncertainties and ultimate bounded estimation in the presence of nonparametric uncertainties based on the Lyapunov stability theory. The effects of the proposed consensus method are demonstrated through a typical reaction-diffusion system example, which implies convincing numerical findings.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a852e770841036b38d3e8adaf0e0eed8355635c9" target='_blank'>
              Adaptive Neural Consensus Observer Networks Design for a Class of Semilinear Parabolic PDE Systems.
              </a>
            </td>
          <td>
            Mingxing Cai, Yuan Yuan, Biao Luo, Fanbiao Li, Xiaodong Xu, Chunhua Yang, Weihua Gui
          </td>
          <td>2024-04-10</td>
          <td>IEEE transactions on neural networks and learning systems</td>
          <td>0</td>
          <td>23</td>
        </tr>

        <tr id="
 This article investigates the non-linear generalized geophysical KdV equation, which describes shallow water waves in an ocean. The proposed generalized projective Riccati equation method and modified auxiliary equation method extract a more efficient and broad range of soliton solutions. These include U-shaped, W-shaped, singular, periodic, bright, dark, kink-type, breather soliton, multi-singular soliton, singular soliton with high amplitude, multiple periodic, multiple lump wave soliton, and flat kink-type soliton solutions. The travelling wave patterns of the model are graphically presented with suitable parameter values using the modern software Maple and Wolfram Mathematica. The visual representation of the solutions in 3D, 2D, and contour surfaces enhances understanding of parameter impact. Sensitivity and modulation instability analyses were performed to offer insights into the dynamics of the examined model. The observed dynamics of the proposed model were presented, revealing quasi-periodic chaotic, periodic systems, and quasi-periodic behaviour. This analysis confirms the effectiveness and reliability of the method employed, demonstrating its applicability in discovering travelling wave solitons for a wide range of nonlinear evolution equations.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/692adfe4f5251d2708ba7f1d351e662f5a0a9e7e" target='_blank'>
              Formation of Solitary Waves Solutions and Dynamic Visualization of the Nonlinear Schrödinger Equation with Efficient Techniques
              </a>
            </td>
          <td>
            Sheikh Zain Majid, M. Asjad, W. Faridi
          </td>
          <td>2024-05-14</td>
          <td>Physica Scripta</td>
          <td>0</td>
          <td>14</td>
        </tr>

        <tr id="
 This paper explores the use of Gaussian Process Regression (GPR) for system iden- tification in control engineering. It introduces two novel approaches that utilize the data from a measured global system error. The paper demonstrates these approaches by identifying a simulated system with three subsystems, a one degree of freedom mass with two antagonist muscles. The first approach uses this whole-system error data alone, achieving accuracy on the same order of magnitude as subsystem-specific data (9.28 ± 0.87 N vs. 6.96 ± 0.32 N of total model errors). This is significant, as it shows that the same data set can be used to identify unique subsystems, as op- posed to requiring a set of data descriptive of only a single subsystem. The second approach demonstrated in this paper mixes traditional subsystem-specific data with the whole system error data, achieving up to 98.71% model improvement.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8f245766e2e48a6c115dbc2c6bc632482a91928d" target='_blank'>
              Global System Errors to Simultaneously Improve the Identification of Subsystems with Mixed Data Gaussian Process Regression
              </a>
            </td>
          <td>
            Cameron J LaMack, Eric M. Schearer
          </td>
          <td>2024-05-20</td>
          <td>Machine Learning: Science and Technology</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id="Kolmogorov-Arnold Networks (KAN) is a groundbreaking model recently proposed by the MIT team, representing a revolutionary approach with the potential to be a game-changer in the field. This innovative concept has rapidly garnered worldwide interest within the AI community. Inspired by the Kolmogorov-Arnold representation theorem, KAN utilizes spline-parametrized univariate functions in place of traditional linear weights, enabling them to dynamically learn activation patterns and significantly enhancing interpretability. In this paper, we explore the application of KAN to time series forecasting and propose two variants: T-KAN and MT-KAN. T-KAN is designed to detect concept drift within time series and can explain the nonlinear relationships between predictions and previous time steps through symbolic regression, making it highly interpretable in dynamically changing environments. MT-KAN, on the other hand, improves predictive performance by effectively uncovering and leveraging the complex relationships among variables in multivariate time series. Experiments validate the effectiveness of these approaches, demonstrating that T-KAN and MT-KAN significantly outperform traditional methods in time series forecasting tasks, not only enhancing predictive accuracy but also improving model interpretability. This research opens new avenues for adaptive forecasting models, highlighting the potential of KAN as a powerful and interpretable tool in predictive analytics.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/10145b2238569436754c4d9be3f9c7db501cc65c" target='_blank'>
              Kolmogorov-Arnold Networks for Time Series: Bridging Predictive Power and Interpretability
              </a>
            </td>
          <td>
            Kunpeng Xu, Lifei Chen, Shengrui Wang
          </td>
          <td>2024-06-04</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="This paper is concerned with collective variables, or reaction coordinates, that map a discrete-in-time Markov process $X_n$ in $\mathbb{R}^d$ to a (much) smaller dimension $k \ll d$. We define the effective dynamics under a given collective variable map $\xi$ as the best Markovian representation of $X_n$ under $\xi$. The novelty of the paper is that it gives strict criteria for selecting optimal collective variables via the properties of the effective dynamics. In particular, we show that the transition density of the effective dynamics of the optimal collective variable solves a relative entropy minimization problem from certain family of densities to the transition density of $X_n$. We also show that many transfer operator-based data-driven numerical approaches essentially learn quantities of the effective dynamics. Furthermore, we obtain various error estimates for the effective dynamics in approximating dominant timescales / eigenvalues and transition rates of the original process $X_n$ and how optimal collective variables minimize these errors. Our results contribute to the development of theoretical tools for the understanding of complex dynamical systems, e.g. molecular kinetics, on large timescales. These results shed light on the relations among existing data-driven numerical approaches for identifying good collective variables, and they also motivate the development of new methods.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/000831a8effc8d5eba43ba65cb8b22d1d5706ebb" target='_blank'>
              On finding optimal collective variables for complex systems by minimizing the deviation between effective and full dynamics
              </a>
            </td>
          <td>
            Wei Zhang, Christof Schutte
          </td>
          <td>2024-05-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="This paper introduces and analyses a continuous optimization approach to solve optimal control problems involving ordinary differential equations (ODEs) and tracking type objectives. Our aim is to determine control or input functions, and potentially uncertain model parameters, for a dynamical system described by an ODE. We establish the mathematical framework and define the optimal control problem with a tracking functional, incorporating regularization terms and box-constraints for model parameters and input functions. Treating the problem as an infinite-dimensional optimization problem, we employ a Gauss-Newton method within a suitable function space framework. This leads to an iterative process where, at each step, we solve a linearization of the problem by considering a linear surrogate model around the current solution estimate. The resulting linear auxiliary problem resembles a linear-quadratic ODE optimal tracking control problem, which we tackle using either a gradient descent method in function spaces or a Riccati-based approach. Finally, we present and analyze the efficacy of our method through numerical experiments.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/df6b6964f9ff6a8bf025cd417a17240bab28a435" target='_blank'>
              A Gauss-Newton Method for ODE Optimal Tracking Control
              </a>
            </td>
          <td>
            Vicky Holfeld, Michael Burger, C. Schillings
          </td>
          <td>2024-05-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>19</td>
        </tr>

        <tr id="
 The current investigation examines the fractional forced Korteweg-de Vries (FF-KdV) equation, a critically significant evolution equation in various nonlinear branches of science. The equation in question and other associated equations are widely acknowledged for their broad applicability and potential for simulating a wide range of nonlinear phenomena in fluid physics, plasma physics, and various scientific domains. Consequently, the main goal of this study is to use the Yang homotopy perturbation method (YHPM) and the Yang transform decomposition method (YTDM), along with the Caputo operator, for analyzing the FF-KdV equation. The derived approximations are numerically examined and discussed. Our study will show that the two suggested methods are helpful, easy to use, and essential for looking at different nonlinear models that affect complex processes.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/901f7cb48bf6b0fda224ba5abb6ea57275727eb4" target='_blank'>
              On the analytical soliton approximations to fractional forced Korteweg-de Vries equation arising in fluids and Plasmas using two novel techniques
              </a>
            </td>
          <td>
            Weeam Alhejaili, Emad Az-Zo'bi, Rasool Shah, S. A. El-Tantawy
          </td>
          <td>2024-06-04</td>
          <td>Communications in Theoretical Physics</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Understanding how genetically encoded rules drive and guide complex neuronal growth processes is essential to comprehending the brain's architecture, and agent-based models (ABMs) offer a powerful simulation approach to further develop this understanding. However, accurately calibrating these models remains a challenge. Here, we present a novel application of Approximate Bayesian Computation (ABC) to address this issue. ABMs are based on parametrized stochastic rules that describe the time evolution of small components -- the so-called agents -- discretizing the system, leading to stochastic simulations that require appropriate treatment. Mathematically, the calibration defines a stochastic inverse problem. We propose to address it in a Bayesian setting using ABC. We facilitate the repeated comparison between data and simulations by quantifying the morphological information of single neurons with so-called morphometrics and resort to statistical distances to measure discrepancies between populations thereof. We conduct experiments on synthetic as well as experimental data. We find that ABC utilizing Sequential Monte Carlo sampling and the Wasserstein distance finds accurate posterior parameter distributions for representative ABMs. We further demonstrate that these ABMs capture specific features of pyramidal cells of the hippocampus (CA1). Overall, this work establishes a robust framework for calibrating agent-based neuronal growth models and opens the door for future investigations using Bayesian techniques for model building, verification, and adequacy assessment.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/602e562a638c303ab6aec9bc84d3da8073b4fa39" target='_blank'>
              Calibration of stochastic, agent-based neuron growth models with Approximate Bayesian Computation
              </a>
            </td>
          <td>
            Tobias Duswald, Lukas Breitwieser, Thomas Thorne, Barbara Wohlmuth, Roman Bauer
          </td>
          <td>2024-05-22</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d63afa9ac9d835d94e1d88390467934811db53a5" target='_blank'>
              Task-oriented machine learning surrogates for tipping points of agent-based models
              </a>
            </td>
          <td>
            Gianluca Fabiani, N. Evangelou, Tianqi Cui, J. M. Bello-Rivas, Cristina P. Martin-Linares, Constantinos Siettos, I. Kevrekidis
          </td>
          <td>2024-05-15</td>
          <td>Nature Communications</td>
          <td>0</td>
          <td>8</td>
        </tr>

        <tr id="In the present study, we consider continuous-time modeling of dynamics using observed data and formulate the modeling error caused by the discretization method used in the process. In the formulation, a class of linearized dynamics called Dahlquist’s test equations is used as representative of the target dynamics, and the characteristics of each discretization method for various dynamics are taken into account. The family of explicit Runge–Kutta methods is analyzed as a specific discretization method using the proposed framework. As a result, equations for predicting the modeling error are derived, and it is found that there can be multiple possible models obtained when using these methods. Several learning experiments using a simple neural network exhibited consistent results with theoretical predictions, including the nonuniqueness of the resulting model.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2e45ec76c34a9a0b68cd5d63cae0eab15390374b" target='_blank'>
              Modeling Error and Nonuniqueness of the Continuous-Time Models Learned via Runge–Kutta Methods
              </a>
            </td>
          <td>
            Shunpei Terakawa, Takaharu Yaguchi
          </td>
          <td>2024-04-16</td>
          <td>Mathematics</td>
          <td>0</td>
          <td>11</td>
        </tr>

        <tr id="Dynamic feedback linearization-based methods allow us to design control algorithms for a fairly large class of nonlinear systems in continuous time. However, this feature does not extend to their sampled counterparts, i.e., for a given dynamically feedback linearizable continuous time system, its numerical discretization may fail to be so. In this article, we present a way to construct discretization schemes (accurate up to first order) that result in schemes that are feedback linearizable. This result is an extension of our previous work, where we had considered only static feedback linearizable systems. The result presented here applies to a fairly general class of nonlinear systems, in particular, our analysis applies to both endogenous and exogenous types of feedback. While the results in this article are presented on a control affine form of nonlinear systems, they can be readily modified to general nonlinear systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b609aecb1185e7fa992cd1368ae0f0432080315a" target='_blank'>
              Constructing Dynamic Feedback Linearizable Discretizations
              </a>
            </td>
          <td>
            Ashutosh Jindal, Florentina Nicolau, David Martin Diego, Ravi Banavar
          </td>
          <td>2024-06-03</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="We have developed an advanced workflow for reservoir characterization, effectively addressing the challenges of reservoir history matching through a novel approach. This method integrates a Physics Informed Neural Operator (PINO) as a forward model within a sophisticated Cluster Classify Regress (CCR) framework. The process is enhanced by an adaptive Regularized Ensemble Kalman Inversion (aREKI), optimized for rapid uncertainty quantification in reservoir history matching. This innovative workflow parameterizes unknown permeability and porosity fields, capturing non-Gaussian posterior measures with techniques such as a variational convolution autoencoder and the CCR. Serving as exotic priors and a supervised model, the CCR synergizes with the PINO surrogate to accurately simulate the nonlinear dynamics of Peaceman well equations. The CCR approach allows for flexibility in applying distinct machine learning algorithms across its stages. Updates to the PINO reservoir surrogate are driven by a loss function derived from supervised data, initial conditions, and residuals of governing black oil PDEs. Our integrated model, termed PINO-Res-Sim, outputs crucial parameters including pressures, saturations, and production rates for oil, water, and gas. Validated against traditional simulators through controlled experiments on synthetic reservoirs and the Norne field, the methodology showed remarkable accuracy. Additionally, the PINO-Res-Sim in the aREKI workflow efficiently recovered unknown fields with a computational speedup of 100 to 6000 times faster than conventional methods. The learning phase for PINO-Res-Sim, conducted on an NVIDIA H100, was impressively efficient, compatible with ensemble-based methods for complex computational tasks.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e59d2ee6ed5f470d3264bb80857458ab28e6b078" target='_blank'>
              A Novel A.I Enhanced Reservoir Characterization with a Combined Mixture of Experts - NVIDIA Modulus based Physics Informed Neural Operator Forward Model
              </a>
            </td>
          <td>
            C. Etienam, Juntao Yang, Issam Said, O. Ovcharenko, Kaustubh Tangsali, Pavel Dimitrov, Ken Hester
          </td>
          <td>2024-04-20</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>4</td>
        </tr>

    </tbody>
    <tfoot>
      <tr>
          <th>Abstract</th>
          <th>Title</th>
          <th>Authors</th>
          <th>Publication Date</th>
          <th>Journal/Conference</th>
          <th>Citation count</th>
          <th>Highest h-index</th>
      </tr>
    </tfoot>
    </table>
    </p>
  </div>

</body>

<script>

  function create_author_list(author_list) {
    let td_author_element = document.getElementById();
    for (let i = 0; i < author_list.length; i++) {
          // tdElements[i].innerHTML = greet(tdElements[i].innerHTML);
          alert (author_list[i]);
      }
  }

  var trace1 = {
    x: ['2023', '2024'],
    y: [0, 27],
    name: 'Num of citations',
    yaxis: 'y1',
    type: 'scatter'
  };

  var data = [trace1];

  var layout = {
    yaxis: {
      title: 'Num of citations',
      }
  };
  Plotly.newPlot('myDiv1', data, layout);
</script>
<script>
var dataTableOptions = {
        initComplete: function () {
        this.api()
            .columns()
            .every(function () {
                let column = this;

                // Create select element
                let select = document.createElement('select');
                select.add(new Option(''));
                column.footer().replaceChildren(select);

                // Apply listener for user change in value
                select.addEventListener('change', function () {
                    column
                        .search(select.value, {exact: true})
                        .draw();
                });

                // keep the width of the select element same as the column
                select.style.width = '100%';

                // Add list of options
                column
                    .data()
                    .unique()
                    .sort()
                    .each(function (d, j) {
                        select.add(new Option(d));
                    });
            });
    },
    scrollX: true,
    scrollCollapse: true,
    paging: true,
    fixedColumns: true,
    columnDefs: [
        {"className": "dt-center", "targets": "_all"},
        // set width for both columns 0 and 1 as 25%
        { width: '7%', targets: 0 },
        { width: '30%', targets: 1 },
        { width: '25%', targets: 2 },
        { width: '15%', targets: 4 }

      ],
    pageLength: 10,
    layout: {
        topStart: {
            buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
        }
    }
  }
  new DataTable('#table1', dataTableOptions);
  new DataTable('#table2', dataTableOptions);

  var table1 = $('#table1').DataTable();
  $('#table1 tbody').on('click', 'td:first-child', function () {
    var tr = $(this).closest('tr');
    var row = table1.row( tr );

    var rowId = tr.attr('id');
    // alert(rowId);

    if (row.child.isShown()) {
      // This row is already open - close it.
      row.child.hide();
      tr.removeClass('shown');
      tr.find('td:first-child').html('<i class="material-icons">visibility_off</i>');
    } else {
      // Open row.
      // row.child('foo').show();
      tr.find('td:first-child').html('<i class="material-icons">visibility</i>');
      var content = '<div class="child-row-content"><strong>Abstract:</strong> ' + rowId + '</div>';
      row.child(content).show();
      tr.addClass('shown');
    }
  });
  var table2 = $('#table2').DataTable();
  $('#table2 tbody').on('click', 'td:first-child', function () {
    var tr = $(this).closest('tr');
    var row = table2.row( tr );

    var rowId = tr.attr('id');
    // alert(rowId);

    if (row.child.isShown()) {
      // This row is already open - close it.
      row.child.hide();
      tr.removeClass('shown');
      tr.find('td:first-child').html('<i class="material-icons">visibility_off</i>');
    } else {
      // Open row.
      // row.child('foo').show();
      var content = '<div class="child-row-content"><strong>Abstract:</strong> ' + rowId + '</div>';
      row.child(content).show();
      tr.addClass('shown');
      tr.find('td:first-child').html('<i class="material-icons">visibility</i>');
    }
  });
</script>
<style>
  .child-row-content {
    text-align: justify;
    text-justify: inter-word;
    word-wrap: break-word; /* Ensure long words are broken */
    white-space: normal; /* Ensure text wraps to the next line */
    max-width: 100%; /* Ensure content does not exceed the table width */
    padding: 10px; /* Optional: add some padding for better readability */
    /* font size */
    font-size: small;
  }
</style>
</html>







  
  




  



                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.top", "navigation.tabs"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    

      <script src="../assets/javascripts/bundle.c8d2eff1.min.js"></script>
      
    
<script>
  // Execute intro.js when a button with id 'intro' is clicked
  function startIntro(){
      introJs().setOptions({
          tooltipClass: 'customTooltip'
      }).start();
  }
</script>
<script>
  

  // new DataTable('#table1', {
  //   order: [[5, 'desc']],
  //   "columnDefs": [
  //       {"className": "dt-center", "targets": "_all"},
  //       { width: '30%', targets: 0 }
  //     ],
  //   pageLength: 10,
  //   layout: {
  //       topStart: {
  //           buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
  //       }
  //   }
  // });

  // new DataTable('#table2', {
  //   order: [[3, 'desc']],
  //   "columnDefs": [
  //       {"className": "dt-center", "targets": "_all"},
  //       { width: '30%', targets: 0 }
  //     ],
  //   pageLength: 10,
  //   layout: {
  //       topStart: {
  //           buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
  //       }
  //   }
  // });
  new DataTable('#table3', {
    initComplete: function () {
        this.api()
            .columns()
            .every(function () {
                let column = this;
 
                // Create select element
                let select = document.createElement('select');
                select.add(new Option(''));
                column.footer().replaceChildren(select);
 
                // Apply listener for user change in value
                select.addEventListener('change', function () {
                    column
                        .search(select.value, {exact: true})
                        .draw();
                });

                // keep the width of the select element same as the column
                select.style.width = '100%';
 
                // Add list of options
                column
                    .data()
                    .unique()
                    .sort()
                    .each(function (d, j) {
                        select.add(new Option(d));
                    });
            });
    },
    // order: [[3, 'desc']],
    "columnDefs": [
        {"className": "dt-center", "targets": "_all"},
        { width: '30%', targets: 0 }
      ],
    pageLength: 10,
    layout: {
        topStart: {
            buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
        }
    }
  });
  new DataTable('#table4', {
    initComplete: function () {
        this.api()
            .columns()
            .every(function () {
                let column = this;
 
                // Create select element
                let select = document.createElement('select');
                select.add(new Option(''));
                column.footer().replaceChildren(select);
 
                // Apply listener for user change in value
                select.addEventListener('change', function () {
                    column
                        .search(select.value, {exact: true})
                        .draw();
                });

                // keep the width of the select element same as the column
                select.style.width = '100%';
 
                // Add list of options
                column
                    .data()
                    .unique()
                    .sort()
                    .each(function (d, j) {
                        select.add(new Option(d));
                    });
            });
    },
    // order: [[3, 'desc']],
    "columnDefs": [
        {"className": "dt-center", "targets": "_all"},
        { width: '30%', targets: 0 }
      ],
    pageLength: 10,
    layout: {
        topStart: {
            buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
        }
    }
  });
</script>


  </body>
</html>