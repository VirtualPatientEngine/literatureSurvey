---
hide:
 - navigation
---
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
</head>

<body>
  <p>
  <i class="footer">This page was last updated on 2024-04-21 21:30:31 UTC</i>
  </p>
  

  <p>
  <h3>Recommendations for the article <i>Learning 3D Particle-based Simulators from RGB-D Videos</i></h3>
  <table id="table1" class="display" style="width:100%">
  <thead>
    <tr>
        <th>Title</th>
        <th>Authors</th>
        <th>Publication Date</th>
        <th>Journal/Conference</th>
        <th>Citation count</th>
        <th>Highest h-index</th>
    </tr>
  </thead>
  <tbody>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/414ab203d8fc3ecfbf40d004960d3a4774830b48" target='_blank'>Visual Interaction Networks: Learning a Physics Simulator from Video</a></td>
          <td>
            
              Nicholas Watters,
            
              Daniel Zoran,
            
              T. Weber,
            
              P. Battaglia,
            
              Razvan Pascanu,
            
              A. Tacchetti,
            
          </td>
          <td>2017-06-05</td>
          <td>None</td>
          <td>248</td>
          <td>65</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/f3f1592ff282fbf58864c243510eb4a425f3fc70" target='_blank'>3D-IntPhys: Towards More Generalized 3D-grounded Visual Intuitive Physics under Challenging Scenes</a></td>
          <td>
            
              Haotian Xue,
            
              A. Torralba,
            
              J. Tenenbaum,
            
              Daniel L. K. Yamins,
            
              Yunzhu Li,
            
              H. Tung,
            
          </td>
          <td>2023-04-22</td>
          <td>2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</td>
          <td>2</td>
          <td>126</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/18c4b8d0c878e91542c3277201f4eb50fee3a4b3" target='_blank'>T3VIP: Transformation-based $3\mathrm{D}$ Video Prediction</a></td>
          <td>
            
              Iman Nematollahi,
            
              Erick Rosete-Beas,
            
              Seyed Mahdi B. Azad,
            
              Raghunandan Rajan,
            
              F. Hutter,
            
              Wolfram Burgard,
            
          </td>
          <td>2022-09-19</td>
          <td>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
          <td>2</td>
          <td>120</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/18c4b8d0c878e91542c3277201f4eb50fee3a4b3" target='_blank'>T3VIP: Transformation-based $3\mathrm{D}$ Video Prediction</a></td>
          <td>
            
              Iman Nematollahi,
            
              Erick Rosete-Beas,
            
              Seyed Mahdi B. Azad,
            
              Raghunandan Rajan,
            
              F. Hutter,
            
              Wolfram Burgard,
            
          </td>
          <td>2022-09-19</td>
          <td>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
          <td>2</td>
          <td>120</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/f87c63cd336f859007a2c07744fb24f8ec466932" target='_blank'>Structured Object-Aware Physics Prediction for Video Modeling and Planning</a></td>
          <td>
            
              Jannik Kossen,
            
              Karl Stelzner,
            
              Marcel Hussing,
            
              C. Voelcker,
            
              K. Kersting,
            
          </td>
          <td>2019-10-06</td>
          <td>ArXiv</td>
          <td>64</td>
          <td>57</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/f3268665dd71fc2738f8bd86bb95dda36fc47bc9" target='_blank'>Hindsight for Foresight: Unsupervised Structured Dynamics Models from Physical Interaction</a></td>
          <td>
            
              Iman Nematollahi,
            
              Oier Mees,
            
              Lukás Hermann,
            
              Wolfram Burgard,
            
          </td>
          <td>2020-08-02</td>
          <td>2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
          <td>14</td>
          <td>120</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/eb597cceec6e0889d1423ae688e8854bfa6f822d" target='_blank'>Learning to See Physics via Visual De-animation</a></td>
          <td>
            
              Jiajun Wu,
            
              Erika Lu,
            
              Pushmeet Kohli,
            
              Bill Freeman,
            
              J. Tenenbaum,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>180</td>
          <td>122</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/2ac26ffe14d264fad2cf26632fab86e49a06b03e" target='_blank'>Physics-as-Inverse-Graphics: Joint Unsupervised Learning of Objects and Physics from Video</a></td>
          <td>
            
              Miguel Jaques,
            
              Michael Burke,
            
              Timothy M. Hospedales,
            
          </td>
          <td>2019-05-27</td>
          <td>ArXiv</td>
          <td>18</td>
          <td>69</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/890ca1eda87f0d0b3a32b4b177ace728ea7ca041" target='_blank'>Robotics Physically Plausible 4D Reconstruction from Monocular Videos</a></td>
          <td>
            
              Yue Zhang,
            
              Zeyu Sun,
            
              Naihao Deng,
            
              Shinka Mori,
            
              Zhijing Jin,
            
              G. Croisdale,
            
              Emily Huang,
            
              J. Chung,
            
              Xu Wang,
            
              Anhong Guo,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>5</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/623824d42c226e4024e97fc62a6030a2bf45b2c7" target='_blank'>Physics-as-Inverse-Graphics: Unsupervised Physical Parameter Estimation from Video</a></td>
          <td>
            
              Miguel Jaques,
            
              Michael Burke,
            
              Timothy M. Hospedales,
            
          </td>
          <td>2019-05-27</td>
          <td></td>
          <td>35</td>
          <td>69</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/3e19a257825066f9a6db913f8d546524c0dc3387" target='_blank'>Learning Plannable Representations with Causal InfoGAN</a></td>
          <td>
            
              Thanard Kurutach,
            
              Aviv Tamar,
            
              Ge Yang,
            
              Stuart J. Russell,
            
              P. Abbeel,
            
          </td>
          <td>2018-07-24</td>
          <td>ArXiv</td>
          <td>164</td>
          <td>143</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/65b6c8083d666b31d7d6f7d10c94f407fa26c906" target='_blank'>3D-OES: Viewpoint-Invariant Object-Factorized Environment Simulators</a></td>
          <td>
            
              H. Tung,
            
              Xian Zhou,
            
              Mihir Prabhudesai,
            
              Shamit Lal,
            
              Katerina Fragkiadaki,
            
          </td>
          <td>2020-11-12</td>
          <td>ArXiv</td>
          <td>26</td>
          <td>24</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/fc032661d3227f672db725aa2d3602912916ba72" target='_blank'>Learning Object Manipulation Skills from Video via Approximate Differentiable Physics</a></td>
          <td>
            
              V. Petrík,
            
              M. N. Qureshi,
            
              Josef Sivic,
            
              Makarand Tapaswi,
            
          </td>
          <td>2022-08-03</td>
          <td>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
          <td>2</td>
          <td>73</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/e2384d8b5930a22c60efaba829cd9959eccffd0d" target='_blank'>Unsupervised Intuitive Physics from Visual Observations</a></td>
          <td>
            
              Sébastien Ehrhardt,
            
              Áron Monszpart,
            
              N. Mitra,
            
              A. Vedaldi,
            
          </td>
          <td>2018-05-14</td>
          <td>None</td>
          <td>28</td>
          <td>95</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/f8b94b373c8e402a07d848c76eaee6e5842a862f" target='_blank'>3D Neural Scene Representations for Visuomotor Control</a></td>
          <td>
            
              Yunzhu Li,
            
              Shuang Li,
            
              V. Sitzmann,
            
              Pulkit Agrawal,
            
              A. Torralba,
            
          </td>
          <td>2021-07-08</td>
          <td>None</td>
          <td>101</td>
          <td>126</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/d857c7365c373395b494e1bc11bff528620ce74b" target='_blank'>Environment Predictive Coding for Embodied Agents</a></td>
          <td>
            
              Santhosh K. Ramakrishnan,
            
              Tushar Nagarajan,
            
              Ziad Al-Halah,
            
              K. Grauman,
            
          </td>
          <td>2021-02-03</td>
          <td>ArXiv</td>
          <td>14</td>
          <td>88</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/fe80c600e022b70e90b7b33e32e9801fff52c945" target='_blank'>MIT Open Access Articles DriveGAN: Towards a Controllable High-Quality Neural Simulation</a></td>
          <td>
            
              Seung Wook Kim,
            
              Jonah Philion,
            
              Antonio Torralba,
            
              Sanja Fidler,
            
              Nvidia,
            
              Driving Control DriveGAN,
            
              Neural Simulator,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>10</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/e044010a9ab895139480de9b15d14a9606188ccb" target='_blank'>Visual Dynamics Models for Robotic Planning and Control</a></td>
          <td>
            
              Alex X. Lee,
            
          </td>
          <td>None</td>
          <td></td>
          <td>1</td>
          <td>16</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/02f316857c1d20649b18e5fec3e92dda8ef1d0a0" target='_blank'>DriveGAN: Towards a Controllable High-Quality Neural Simulation</a></td>
          <td>
            
              S. Kim,
            
              Jonah Philion,
            
              A. Torralba,
            
              S. Fidler,
            
          </td>
          <td>2021-04-30</td>
          <td>2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
          <td>64</td>
          <td>126</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/d40531ed81859ce40f119c1bbc1d1cb50af498fd" target='_blank'>Learning Particle Dynamics for Manipulating Rigid Bodies, Deformable Objects, and Fluids</a></td>
          <td>
            
              Yunzhu Li,
            
              Jiajun Wu,
            
              Russ Tedrake,
            
              J. Tenenbaum,
            
              A. Torralba,
            
          </td>
          <td>2018-09-27</td>
          <td>ArXiv</td>
          <td>292</td>
          <td>126</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/7c594c0b9482624745dd95767f3eebde1ee7f043" target='_blank'>Representing Visual Scenes for Robot Control</a></td>
          <td>
            
              Dr Zeeshan Zia,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>0</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/4dd7db709220224fa5ade410876e273e7e306002" target='_blank'>E NVIRONMENT PREDICTIVE CODING FOR EMBODIED AGENTS</a></td>
          <td>
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>0</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/32a9a573aabf3404316b4c0254ff3d195afd456b" target='_blank'>Scene Physics Acquisition via Visual De-animation</a></td>
          <td>
            
              Jiajun Wu,
            
              Erika Lu,
            
              Pushmeet Kohli,
            
              Bill Freeman,
            
              J. Tenenbaum,
            
          </td>
          <td>None</td>
          <td></td>
          <td>0</td>
          <td>122</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/8cc468d19f60dd67e69d4fe0fccd604f5d2d633d" target='_blank'>Occlusion resistant learning of intuitive physics from videos</a></td>
          <td>
            
              Ronan Riochet,
            
              Josef Sivic,
            
              I. Laptev,
            
              Emmanuel Dupoux,
            
          </td>
          <td>2019-09-25</td>
          <td>ArXiv</td>
          <td>6</td>
          <td>73</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/203acdf81cbe92a8de3da2d2a3487716b3b3ea67" target='_blank'>Visual Grounding of Learned Physical Models</a></td>
          <td>
            
              Yunzhu Li,
            
              Toru Lin,
            
              Kexin Yi,
            
              Daniel Bear,
            
              Daniel L. K. Yamins,
            
              Jiajun Wu,
            
              J. Tenenbaum,
            
              A. Torralba,
            
          </td>
          <td>2020-04-28</td>
          <td>ArXiv</td>
          <td>58</td>
          <td>126</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/0d903acebb1d41e1cb45a0258ef7606de4ce8bdf" target='_blank'>Efficient RL via Disentangled Environment and Agent Representations</a></td>
          <td>
            
              Kevin Gmelin,
            
              Shikhar Bahl,
            
              Russell Mendonca,
            
              Deepak Pathak,
            
          </td>
          <td>2023-09-05</td>
          <td>ArXiv</td>
          <td>4</td>
          <td>20</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/cbc40f2b5822219c09b0d974f9703d5351fbe48d" target='_blank'>Dynamic Visual Reasoning by Learning Differentiable Physics Models from Video and Language</a></td>
          <td>
            
              Mingyu Ding,
            
              Zhenfang Chen,
            
              Tao Du,
            
              Ping Luo,
            
              J. Tenenbaum,
            
              Chuang Gan,
            
          </td>
          <td>2021-10-28</td>
          <td>None</td>
          <td>50</td>
          <td>122</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/74a6c2b6408fb1a14664b08c018fefa6aee22dc7" target='_blank'>Galileo: Perceiving Physical Object Properties by Integrating a Physics Engine with Deep Learning</a></td>
          <td>
            
              Jiajun Wu,
            
              Ilker Yildirim,
            
              Joseph J. Lim,
            
              Bill Freeman,
            
              J. Tenenbaum,
            
          </td>
          <td>2015-12-07</td>
          <td>None</td>
          <td>335</td>
          <td>122</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/2dddf7e912d01f93215e385aae6eac626136febd" target='_blank'>Going Beyond Images: 3D-Aware Representation Learning for Visuomotor Control</a></td>
          <td>
            
              Shuang Li,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>19</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/e917951e999e8fd9657684e33def83180c84a6d8" target='_blank'>ReCoRe: Regularized Contrastive Representation Learning of World Model</a></td>
          <td>
            
              Rudra P. K. Poudel,
            
              Harit Pandya,
            
              Stephan Liwicki,
            
              Roberto Cipolla,
            
          </td>
          <td>2023-12-14</td>
          <td>ArXiv</td>
          <td>2</td>
          <td>10</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/d920e8c8493efcc7bdcd96d06228b564e788806d" target='_blank'>Propagation Networks for Model-Based Control Under Partial Observation</a></td>
          <td>
            
              Yunzhu Li,
            
              Jiajun Wu,
            
              Jun-Yan Zhu,
            
              J. Tenenbaum,
            
              A. Torralba,
            
              Russ Tedrake,
            
          </td>
          <td>2018-09-28</td>
          <td>2019 International Conference on Robotics and Automation (ICRA)</td>
          <td>115</td>
          <td>126</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/11f83f00141a500e5ced0465ffa994b188a09590" target='_blank'>Counterfactual World Modeling for Physical Dynamics Understanding</a></td>
          <td>
            
              Rahul Venkatesh,
            
              Honglin Chen,
            
              Kevin T. Feigelis,
            
              Khaled Jedoui,
            
              Klemen Kotar,
            
              Felix Binder,
            
              Wanhee Lee,
            
              Sherry Liu,
            
              Kevin A. Smith,
            
              Judith E. Fan,
            
              Daniel L. K. Yamins,
            
          </td>
          <td>2023-12-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/4e8adade39705cf8683984705bf31f1884a8fff7" target='_blank'>Learning to Act from Actionless Videos through Dense Correspondences</a></td>
          <td>
            
              Po-Chen Ko,
            
              Jiayuan Mao,
            
              Yilun Du,
            
              Shao-Hua Sun,
            
              Josh Tenenbaum,
            
          </td>
          <td>2023-10-12</td>
          <td>ArXiv</td>
          <td>9</td>
          <td>33</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/da98d61a5ed63abe34d52bc9d500f702f9239e87" target='_blank'>RISP: Rendering-Invariant State Predictor with Differentiable Simulation and Rendering for Cross-Domain Parameter Estimation</a></td>
          <td>
            
              Pingchuan Ma,
            
              Tao Du,
            
              J. Tenenbaum,
            
              W. Matusik,
            
              Chuang Gan,
            
          </td>
          <td>2022-05-11</td>
          <td>ArXiv</td>
          <td>15</td>
          <td>122</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/70e896f999c6372cd92b32a97b7d821f20f19c95" target='_blank'>Learning to Identify Physical Parameters from Video Using Differentiable Physics</a></td>
          <td>
            
              Rama Krishna Kandukuri,
            
              Jan Achterhold,
            
              Michael Möller,
            
              J. Stückler,
            
          </td>
          <td>2020-09-17</td>
          <td>Pattern Recognition</td>
          <td>10</td>
          <td>38</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/fea3e63c97c7292dc6fbcb3ffe7131eb54053986" target='_blank'>Learning Latent Dynamics for Planning from Pixels</a></td>
          <td>
            
              Danijar Hafner,
            
              T. Lillicrap,
            
              Ian S. Fischer,
            
              Ruben Villegas,
            
              David R Ha,
            
              Honglak Lee,
            
              James Davidson,
            
          </td>
          <td>2018-11-12</td>
          <td>ArXiv</td>
          <td>1116</td>
          <td>86</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/c3d14e7a319ab764297a60112ce74af201762a73" target='_blank'>Learning Interactive Real-World Simulators</a></td>
          <td>
            
              Mengjiao Yang,
            
              Yilun Du,
            
              Kamyar Ghasemipour,
            
              Jonathan Tompson,
            
              D. Schuurmans,
            
              Pieter Abbeel,
            
          </td>
          <td>2023-10-09</td>
          <td>ArXiv</td>
          <td>19</td>
          <td>33</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/9c1e6eba865ccddef4df76c77e78ded4b5217e3f" target='_blank'>NeRF-ysics: A Differentiable Pipeline for Enriching NeRF-Represented Objects with Dynamical Properties</a></td>
          <td>
            
              Simon Le Cleac'h,
            
              Taylor A. Howell,
            
              M. Schwager,
            
              Zachary Manchester,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>49</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/33a44111726ab8f19b3c6a625db4c4f2c18ef2ee" target='_blank'>PIP: Physical Interaction Prediction via Mental Simulation with Span Selection</a></td>
          <td>
            
              Jiafei Duan,
            
              Samson Yu,
            
              Soujanya Poria,
            
              B. Wen,
            
              Cheston Tan,
            
          </td>
          <td>2021-09-10</td>
          <td>None</td>
          <td>1</td>
          <td>64</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/53e5551310a69697a2183464da5a499095904398" target='_blank'>PPR: Physically Plausible Reconstruction from Monocular Videos</a></td>
          <td>
            
              Gengshan Yang,
            
              Shuo Yang,
            
              John Z. Zhang,
            
              Zachary Manchester,
            
              Deva Ramanan,
            
          </td>
          <td>2023-10-01</td>
          <td>2023 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
          <td>6</td>
          <td>81</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/9a6b88c80decebcb322227432e3712a4af927cae" target='_blank'>Learning to predict 3D rotational dynamics from images of a rigid body with unknown mass distribution</a></td>
          <td>
            
              J. Mason,
            
              Christine Allen-Blanchette,
            
              Nicholas Zolman,
            
              Elizabeth Davison,
            
              N. Leonard,
            
          </td>
          <td>2023-08-24</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>5</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/0eca090aebd6b5867c523e04df2b6347ee824eab" target='_blank'>Learning Robotic Manipulation through Visual Planning and Acting</a></td>
          <td>
            
              Angelina Wang,
            
              Thanard Kurutach,
            
              Kara Liu,
            
              P. Abbeel,
            
              Aviv Tamar,
            
          </td>
          <td>2019-05-11</td>
          <td>ArXiv</td>
          <td>106</td>
          <td>143</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/a1786540a4e15f0757e1b84a02f98ed436a969e0" target='_blank'>A Compositional Object-Based Approach to Learning Physical Dynamics</a></td>
          <td>
            
              Michael Chang,
            
              T. Ullman,
            
              A. Torralba,
            
              J. Tenenbaum,
            
          </td>
          <td>2016-11-04</td>
          <td>ArXiv</td>
          <td>407</td>
          <td>126</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/c33e8da8d5a7bc6fed2f15c785c0ebec6093ff31" target='_blank'>Unsupervised Intuitive Physics from Past Experiences</a></td>
          <td>
            
              Sébastien Ehrhardt,
            
              Áron Monszpart,
            
              N. Mitra,
            
              A. Vedaldi,
            
          </td>
          <td>2019-05-26</td>
          <td>ArXiv</td>
          <td>2</td>
          <td>95</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/eba59ef649b1f8c203ff3ee5a2f630e840385e25" target='_blank'>Learning Interpretable Dynamics from Images of a Freely Rotating 3D Rigid Body</a></td>
          <td>
            
              J. Mason,
            
              Christine Allen-Blanchette,
            
              Nicholas Zolman,
            
              Elizabeth Davison,
            
              Naomi Ehrich Leonard,
            
          </td>
          <td>2022-09-23</td>
          <td>ArXiv</td>
          <td>4</td>
          <td>63</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/c201542be1a875302a14328a7c9b5207facde51f" target='_blank'>Learning to Imitate Object Interactions from Internet Videos</a></td>
          <td>
            
              Austin Patel,
            
              Andrew Wang,
            
              Ilija Radosavovic,
            
              J. Malik,
            
          </td>
          <td>2022-11-23</td>
          <td>ArXiv</td>
          <td>13</td>
          <td>46</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/32f3bc040bc7c175a982ab64a4aaa4e4843a039f" target='_blank'>Learning 3D Dynamic Scene Representations for Robot Manipulation</a></td>
          <td>
            
              Zhenjia Xu,
            
              Zhanpeng He,
            
              Jiajun Wu,
            
              Shuran Song,
            
          </td>
          <td>2020-11-03</td>
          <td>ArXiv</td>
          <td>39</td>
          <td>49</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/d1bedd988ec6cb0528d25bc3e108ac5b86b66e6a" target='_blank'>A Data-Efficient Framework for Training and Sim-to-Real Transfer of Navigation Policies</a></td>
          <td>
            
              Homanga Bharadhwaj,
            
              Zihan Wang,
            
              Yoshua Bengio,
            
              L. Paull,
            
          </td>
          <td>2018-10-11</td>
          <td>2019 International Conference on Robotics and Automation (ICRA)</td>
          <td>34</td>
          <td>202</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/c291a1a2c9fe192072f88e380f0ac5a51e8d431a" target='_blank'>Deep Forward and Inverse Perceptual Models for Tracking and Prediction</a></td>
          <td>
            
              Alexander Lambert,
            
              Amirreza Shaban,
            
              Amit Raj,
            
              Z. Liu,
            
              Byron Boots,
            
          </td>
          <td>2017-10-31</td>
          <td>2018 IEEE International Conference on Robotics and Automation (ICRA)</td>
          <td>17</td>
          <td>55</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/c827a85817257cae8476f3ac9e657d742aaddf81" target='_blank'>AutoNeRF: Training Implicit Scene Representations with Autonomous Agents</a></td>
          <td>
            
              Pierre Marza,
            
              L. Matignon,
            
              Olivier Simonin,
            
              Dhruv Batra,
            
              Christian Wolf,
            
              Devendra Singh Chaplot,
            
          </td>
          <td>2023-04-21</td>
          <td>ArXiv</td>
          <td>4</td>
          <td>71</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/d5ec28803ea982668093b622262633ec20289925" target='_blank'>NVFi: Neural Velocity Fields for 3D Physics Learning from Dynamic Videos</a></td>
          <td>
            
              Jinxi Li,
            
              Ziyang Song,
            
              Bo Yang,
            
          </td>
          <td>2023-12-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/226797c6e824cea1cfdc7b2e6522c57099d7492b" target='_blank'>Visual Navigation by Generating Next Expected Observations</a></td>
          <td>
            
              Qiaoyun Wu,
            
              Dinesh Manocha,
            
              Jun Wang,
            
              Kai Xu,
            
          </td>
          <td>2019-06-17</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>95</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/68bdc53d4849aaf4849f4fa4110043ca35f0f534" target='_blank'>ICLR 2022 ? 1 ? ? ? ? Predict visual features at ? ? ?</a></td>
          <td>
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>0</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/98273abd3ebf45923eeab0bd326c970a6f2b6ffe" target='_blank'>Discovering and Achieving Goals with World Models</a></td>
          <td>
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>2</td>
          <td>0</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/54a732a40047b65e69c41fd72b9f31c8683af624" target='_blank'>A Symmetric and Object-Centric World Model for Stochastic Environments</a></td>
          <td>
            
              Patrick Emami,
            
              Pan He,
            
              A. Rangarajan,
            
              S. Ranka,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>48</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/749fc01c222e526dab89e9cb4cb280447d7d65fe" target='_blank'>Simple and Effective Synthesis of Indoor 3D Scenes</a></td>
          <td>
            
              Jing Yu Koh,
            
              Harsh Agrawal,
            
              Dhruv Batra,
            
              Richard Tucker,
            
              Austin Waters,
            
              Honglak Lee,
            
              Yinfei Yang,
            
              Jason Baldridge,
            
              Peter Anderson,
            
          </td>
          <td>2022-04-06</td>
          <td>ArXiv</td>
          <td>18</td>
          <td>71</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/dbdb47913244562ff6cd2a70956997cbdeffd6cb" target='_blank'>DensePhysNet: Learning Dense Physical Object Representations via Multi-step Dynamic Interactions</a></td>
          <td>
            
              Zhenjia Xu,
            
              Jiajun Wu,
            
              Andy Zeng,
            
              J. Tenenbaum,
            
              Shuran Song,
            
          </td>
          <td>2019-06-10</td>
          <td>ArXiv</td>
          <td>84</td>
          <td>122</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/b0ac45f1e23225b012cbc56a845014a6974dd48e" target='_blank'>REASONING ABOUT PHYSICAL INTERACTIONS</a></td>
          <td>
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>0</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/c3d9eb1e31bfc69c5c4ede3056c2710dec4a8f5c" target='_blank'>Physical Representation Learning and Parameter Identification from Video Using Differentiable Physics</a></td>
          <td>
            
              Rama Krishna Kandukuri,
            
              Jan Achterhold,
            
              Michael Moeller,
            
              Joerg Stueckler,
            
          </td>
          <td>2021-10-17</td>
          <td>International Journal of Computer Vision</td>
          <td>5</td>
          <td>7</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/c3d9eb1e31bfc69c5c4ede3056c2710dec4a8f5c" target='_blank'>Physical Representation Learning and Parameter Identification from Video Using Differentiable Physics</a></td>
          <td>
            
              Rama Krishna Kandukuri,
            
              Jan Achterhold,
            
              Michael Moeller,
            
              Joerg Stueckler,
            
          </td>
          <td>2021-10-17</td>
          <td>International Journal of Computer Vision</td>
          <td>5</td>
          <td>7</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/091ccbcc52b77df62c1610831fbb3c196c65db76" target='_blank'>Neural Groundplans: Persistent Neural Scene Representations from a Single Image</a></td>
          <td>
            
              Prafull Sharma,
            
              A. Tewari,
            
              Yilun Du,
            
              Sergey Zakharov,
            
              Rares Ambrus,
            
              Adrien Gaidon,
            
              W. Freeman,
            
              F. Durand,
            
              J. Tenenbaum,
            
              V. Sitzmann,
            
          </td>
          <td>2022-07-22</td>
          <td>None</td>
          <td>13</td>
          <td>122</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/78204e62dd7567f4347930202a239f9421cda1c0" target='_blank'>Seeing 3D Objects in a Single Image via Self-Supervised Static-Dynamic Disentanglement</a></td>
          <td>
            
              Prafull Sharma,
            
              A. Tewari,
            
              Yilun Du,
            
              Sergey Zakharov,
            
              Rares Ambrus,
            
              Adrien Gaidon,
            
              W. Freeman,
            
              F. Durand,
            
              J. Tenenbaum,
            
              V. Sitzmann,
            
          </td>
          <td>None</td>
          <td>ArXiv</td>
          <td>15</td>
          <td>122</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/8ae094bdb975a39e4fcdac56b13144cf02dba52b" target='_blank'>Learning Compositional Dynamics Models for Model-based Control</a></td>
          <td>
            
              Li,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>1</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/d1f80ff7393691ea3ef03f781627f5719b504325" target='_blank'>Reasoning About Physical Interactions with Object-Centric Models</a></td>
          <td>
            
              Michael Janner,
            
              S. Levine,
            
              W. Freeman,
            
              J. Tenenbaum,
            
              Chelsea Finn,
            
              Jiajun Wu,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>26</td>
          <td>145</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/03b4fbbfe6660511bedb0735ea961fdff9019157" target='_blank'>Learning Robust Dynamics through Variational Sparse Gating</a></td>
          <td>
            
              A. Jain,
            
              Shivakanth Sujit,
            
              S. Joshi,
            
              Vincent Michalski,
            
              Danijar Hafner,
            
              Samira Ebrahimi Kahou,
            
          </td>
          <td>2022-10-21</td>
          <td>ArXiv</td>
          <td>4</td>
          <td>22</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/91cb47c26dffa7e3fcc339abdaab9fa229b37d95" target='_blank'>Reasoning About Physical Interactions with Object-Oriented Prediction and Planning</a></td>
          <td>
            
              Michael Janner,
            
              S. Levine,
            
              W. Freeman,
            
              J. Tenenbaum,
            
              Chelsea Finn,
            
              Jiajun Wu,
            
          </td>
          <td>2018-09-27</td>
          <td>ArXiv</td>
          <td>123</td>
          <td>145</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/c31f9302a48b8c40fe89650a154ad58e5103894b" target='_blank'>Task-Agnostic Dynamics Priors for Deep Reinforcement Learning</a></td>
          <td>
            
              Yilun Du,
            
              Karthik Narasimhan,
            
          </td>
          <td>2019-05-13</td>
          <td>ArXiv</td>
          <td>31</td>
          <td>33</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/09865ffe9d8f9a0438100de39bcf6131fa55ce11" target='_blank'>Which priors matter? Benchmarking models for learning latent dynamics</a></td>
          <td>
            
              Aleksandar Botev,
            
              Andrew Jaegle,
            
              Peter Wirnsberger,
            
              Daniel Hennes,
            
              I. Higgins,
            
          </td>
          <td>2021-11-09</td>
          <td>ArXiv</td>
          <td>24</td>
          <td>22</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/dba0e75a93b547aa25580aeeaab95d39a0450725" target='_blank'>Predicting the dynamics of 2d objects with a deep residual network</a></td>
          <td>
            
              F. Fleuret,
            
          </td>
          <td>2016-10-13</td>
          <td>ArXiv</td>
          <td>3</td>
          <td>66</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/a3c70071b0e1b100953daff24d6f3820dc0c0bc3" target='_blank'>Tracking and Planning with Spatial World Models</a></td>
          <td>
            
              Baris Kayalibay,
            
              Atanas Mirchev,
            
              Patrick van der Smagt,
            
              Justin Bayer,
            
          </td>
          <td>2022-01-25</td>
          <td>ArXiv</td>
          <td>2</td>
          <td>41</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/45dde4ce5dc531ded482d1fa6048445141a41905" target='_blank'>Unsupervised Learning of Lagrangian Dynamics from Images for Prediction and Control</a></td>
          <td>
            
              Yaofeng Desmond Zhong,
            
              Naomi Ehrich Leonard,
            
          </td>
          <td>2020-07-03</td>
          <td>ArXiv</td>
          <td>37</td>
          <td>63</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/400ba0f7479067046a4705331fbb31c59e3994f8" target='_blank'>Learning Object Manipulation Skills via Approximate State Estimation from Real Videos</a></td>
          <td>
            
              Vladim'ir Petr'ik,
            
              Makarand Tapaswi,
            
              I. Laptev,
            
              Josef Sivic,
            
          </td>
          <td>2020-11-13</td>
          <td>None</td>
          <td>20</td>
          <td>73</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/3b87ebf119b9085abd84e2c5c80719b3901660e4" target='_blank'>Dynamical Scene Representation and Control with Keypoint-Conditioned Neural Radiance Field</a></td>
          <td>
            
              Weiyao Wang,
            
              A. S. Morgan,
            
              A. Dollar,
            
              Gregory Hager,
            
          </td>
          <td>2022-08-20</td>
          <td>2022 IEEE 18th International Conference on Automation Science and Engineering (CASE)</td>
          <td>3</td>
          <td>76</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/9ad76852ae49dae41557e03568e30f84c22c20bd" target='_blank'>Deep Reinforcement Learning on a Budget: 3D Control and Reasoning Without a Supercomputer</a></td>
          <td>
            
              E. Beeching,
            
              Christian Wolf,
            
              J. Dibangoye,
            
              Olivier Simonin,
            
          </td>
          <td>2019-04-03</td>
          <td>2020 25th International Conference on Pattern Recognition (ICPR)</td>
          <td>22</td>
          <td>33</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/52b367ce0cd2c3f92ea26d295a6212ce23f2f041" target='_blank'>Unsupervised Learning of Object Structure and Dynamics from Videos</a></td>
          <td>
            
              Matthias Minderer,
            
              Chen Sun,
            
              Ruben Villegas,
            
              Forrester Cole,
            
              K. Murphy,
            
              Honglak Lee,
            
          </td>
          <td>2019-06-19</td>
          <td>ArXiv</td>
          <td>132</td>
          <td>86</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/640da643ecffb48b4b2136af0cef8355b8d3b7e1" target='_blank'>Learning Structured Representations of Spatial and Interactive Dynamics for Trajectory Prediction in Crowded Scenes</a></td>
          <td>
            
              Todor Davchev,
            
              Michael Burke,
            
              S. Ramamoorthy,
            
          </td>
          <td>2019-11-29</td>
          <td>IEEE Robotics and Automation Letters</td>
          <td>3</td>
          <td>23</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/76672cae3e1c9f536687e98ece25788f656f4021" target='_blank'>Neural Allocentric Intuitive Physics Prediction from Real Videos</a></td>
          <td>
            
              Zhihua Wang,
            
              Stefano Rosa,
            
              Yishu Miao,
            
              Zihang Lai,
            
              Linhai Xie,
            
              A. Markham,
            
              A. Trigoni,
            
          </td>
          <td>2018-09-07</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>47</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/4ea024b69849e80cb0e3de35ba1d5725fa41595c" target='_blank'>Neural Re-Simulation for Generating Bounces in Single Images</a></td>
          <td>
            
              Carlo Innamorati,
            
              Bryan C. Russell,
            
              D. Kaufman,
            
              N. Mitra,
            
          </td>
          <td>2019-08-17</td>
          <td>2019 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
          <td>8</td>
          <td>68</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/d5177b9018fce4319a2b62101e809df5ddf49bd1" target='_blank'>L EARNING A RTICULATED R IGID</a></td>
          <td>
            
              Eric Heiden,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>14</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/9f67271a1edea3bf80c64c2d54e2a0a57612a567" target='_blank'>Stochastic Adversarial Video Prediction</a></td>
          <td>
            
              Alex X. Lee,
            
              Richard Zhang,
            
              F. Ebert,
            
              P. Abbeel,
            
              Chelsea Finn,
            
              S. Levine,
            
          </td>
          <td>2018-04-04</td>
          <td>ArXiv</td>
          <td>414</td>
          <td>145</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/42ad6c6367e674a2341b7b63f5b1f5e45ed9f21b" target='_blank'>Adding Intuitive Physics to Neural-Symbolic Capsules Using Interaction Networks</a></td>
          <td>
            
              Michael D Kissner,
            
              H. Mayer,
            
          </td>
          <td>2019-05-23</td>
          <td>ArXiv</td>
          <td>2</td>
          <td>49</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/b39399b1b7c8d2950109b645552439a712913bf1" target='_blank'>Bounce and Learn: Modeling Scene Dynamics with Real-World Bounces</a></td>
          <td>
            
              Senthil Purushwalkam,
            
              A. Gupta,
            
              D. Kaufman,
            
              Bryan C. Russell,
            
          </td>
          <td>2019-04-01</td>
          <td>ArXiv</td>
          <td>19</td>
          <td>88</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/4cf9dfe7ba8a2c011e8cf7d0188504bb46aa493f" target='_blank'>Visual Reinforcement Learning With Self-Supervised 3D Representations</a></td>
          <td>
            
              Yanjie Ze,
            
              Nicklas Hansen,
            
              Yinbo Chen,
            
              Mohit Jain,
            
              Xiaolong Wang,
            
          </td>
          <td>2022-10-13</td>
          <td>IEEE Robotics and Automation Letters</td>
          <td>28</td>
          <td>34</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/aea777bdd260fcf83822c8a55fa80f396f425cc2" target='_blank'>Physion: Evaluating Physical Prediction from Vision in Humans and Machines</a></td>
          <td>
            
              Daniel Bear,
            
              E. Wang,
            
              Damian Mrowca,
            
              Felix Binder,
            
              Hsiau-Yu Fish Tung,
            
              R. Pramod,
            
              Cameron Holdaway,
            
              Sirui Tao,
            
              Kevin A. Smith,
            
              Li Fei-Fei,
            
              N. Kanwisher,
            
              J. Tenenbaum,
            
              Daniel Yamins,
            
              Judith E. Fan,
            
          </td>
          <td>2021-06-15</td>
          <td>ArXiv</td>
          <td>51</td>
          <td>129</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/1455461948fbe945f47b9a2fe3bd88fc4e1d155c" target='_blank'>Visual Affordance Prediction for Guiding Robot Exploration</a></td>
          <td>
            
              Homanga Bharadhwaj,
            
              Abhi Gupta,
            
              Shubham Tulsiani,
            
          </td>
          <td>2023-05-28</td>
          <td>2023 IEEE International Conference on Robotics and Automation (ICRA)</td>
          <td>6</td>
          <td>34</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/de3eb53f4e4e5eec707ccd7f1991566697a68e13" target='_blank'>Diff-LfD: Contact-aware Model-based Learning from Visual Demonstration for Robotic Manipulation via Differentiable Physics-based Simulation and Rendering</a></td>
          <td>
            
              Xinghao Zhu,
            
              JingHan Ke,
            
              Zhixuan Xu,
            
              Zhixin Sun,
            
              Bizhe Bai,
            
              Jun Lv,
            
              Qingtao Liu,
            
              Yuwei Zeng,
            
              Qi Ye,
            
              Cewu Lu,
            
              Masayoshi Tomizuka,
            
              Lin Shao,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>5</td>
          <td>10</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/4aafe4a526d3f4d302625eca4420ca830bdc6030" target='_blank'>Learning Robotic Manipulation from Demonstrations by Combining Deep Generative Model and Dynamic Control System</a></td>
          <td>
            
              Xiaojian Ma,
            
              Mingxuan Jing,
            
              F. Sun,
            
              Huaping Liu,
            
              Bin Fang,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>60</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/b8f0417844523d788630bb28a600dfeb74914e2d" target='_blank'>Hallucinative Topological Memory for Zero-Shot Visual Planning</a></td>
          <td>
            
              Kara Liu,
            
              Thanard Kurutach,
            
              Christine Tung,
            
              P. Abbeel,
            
              Aviv Tamar,
            
          </td>
          <td>2020-02-27</td>
          <td>None</td>
          <td>40</td>
          <td>143</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/4e70dead7d8d1f8e6c5e628c9ed31a268c92207a" target='_blank'>Real-World Robotic Perception and Control Using Synthetic Data</a></td>
          <td>
            
              Joshua Tobin,
            
          </td>
          <td>None</td>
          <td></td>
          <td>6</td>
          <td>7</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/a78bc54068384d9ea6f07db89a1ce902ef56c2c6" target='_blank'>VideoFlow: A Flow-Based Generative Model for Video</a></td>
          <td>
            
              Manoj Kumar,
            
              M. Babaeizadeh,
            
              D. Erhan,
            
              Chelsea Finn,
            
              S. Levine,
            
              Laurent Dinh,
            
              Durk Kingma,
            
          </td>
          <td>2019-03-04</td>
          <td>ArXiv</td>
          <td>119</td>
          <td>145</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/4b2b6c362fb3c572e9f2e8a8ec2d8f9e7349982f" target='_blank'>Automatic Generation of 3D Scene Animation Based on Dynamic Knowledge Graphs and Contextual Encoding</a></td>
          <td>
            
              Wenfeng Song,
            
              Xinyu Zhang,
            
              Yuting Guo,
            
              Shuai Li,
            
              A. Hao,
            
              Hong Qin,
            
          </td>
          <td>2023-07-01</td>
          <td>International Journal of Computer Vision</td>
          <td>1</td>
          <td>25</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/39e70d44b32f6c3eeb75eb2f8725da1e345ae72a" target='_blank'>DMotion: Robotic Visuomotor Control with Unsupervised Forward Model Learned from Videos</a></td>
          <td>
            
              Haoqi Yuan,
            
              Ruihai Wu,
            
              Andrew Zhao,
            
              Hanwang Zhang,
            
              Zihan Ding,
            
              Hao Dong,
            
          </td>
          <td>2021-03-07</td>
          <td>2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
          <td>1</td>
          <td>57</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/806725595f04849b3b4cc9f6c28d4a84744e8d95" target='_blank'>iGibson 1.0: A Simulation Environment for Interactive Tasks in Large Realistic Scenes</a></td>
          <td>
            
              Bokui Shen,
            
              Fei Xia,
            
              Chengshu Li,
            
              Roberto Mart'in-Mart'in,
            
              Linxi (Jim) Fan,
            
              Guanzhi Wang,
            
              S. Buch,
            
              C. D'Arpino,
            
              S. Srivastava,
            
              Lyne P. Tchapmi,
            
              Micael E. Tchapmi,
            
              Kent Vainio,
            
              Li Fei-Fei,
            
              S. Savarese,
            
          </td>
          <td>2020-12-05</td>
          <td>2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
          <td>135</td>
          <td>129</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/af25d5d13aa2d896822654d3f05baf7efb0a6d05" target='_blank'>FLD: Fourier Latent Dynamics for Structured Motion Representation and Learning</a></td>
          <td>
            
              Chenhao Li,
            
              Elijah Stanger-Jones,
            
              Steve Heim,
            
              Sangbae Kim,
            
          </td>
          <td>2024-02-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/7af7f2f539cd3479faae4c66bbef49b0f66202fa" target='_blank'>Target-driven visual navigation in indoor scenes using deep reinforcement learning</a></td>
          <td>
            
              Yuke Zhu,
            
              Roozbeh Mottaghi,
            
              Eric Kolve,
            
              Joseph J. Lim,
            
              A. Gupta,
            
              Li Fei-Fei,
            
              Ali Farhadi,
            
          </td>
          <td>2016-09-16</td>
          <td>2017 IEEE International Conference on Robotics and Automation (ICRA)</td>
          <td>1338</td>
          <td>129</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/7e6ea80c80fb0db5aa4fc5bbc3d987ecfc91c8dc" target='_blank'>Physical Dynamical Systems for Prediction and Control : A Survey</a></td>
          <td>
            
              J. LaChance,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>6</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/5c768e0faef22f9f0ce4132585058a9e8e169407" target='_blank'>InsActor: Instruction-driven Physics-based Characters</a></td>
          <td>
            
              Jiawei Ren,
            
              Mingyuan Zhang,
            
              Cunjun Yu,
            
              Xiao Ma,
            
              Liang Pan,
            
              Ziwei Liu,
            
          </td>
          <td>2023-12-28</td>
          <td>ArXiv</td>
          <td>2</td>
          <td>11</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/f7bdbebf180e23a13821a200267dacdc1afacc1c" target='_blank'>GUESs: Generative modeling of Unknown Environments and Spatial Abstraction for Robots</a></td>
          <td>
            
              Francesco Riccio,
            
              R. Capobianco,
            
              Daniele Nardi,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>1</td>
          <td>10</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/4b2c7a42b06f35e5a3ea7bc2c89837afd927bf29" target='_blank'>Tube-NeRF: Efficient Imitation Learning of Visuomotor Policies from MPC using Tube-Guided Data Augmentation and NeRFs</a></td>
          <td>
            
              Andrea Tagliabue,
            
              Jonathan P. How,
            
          </td>
          <td>2023-11-23</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>13</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/39c02227c37f0856e368d3dd5899f0867195a92e" target='_blank'>Learning Visual Predictive Models of Physics for Playing Billiards</a></td>
          <td>
            
              Katerina Fragkiadaki,
            
              Pulkit Agrawal,
            
              S. Levine,
            
              Jitendra Malik,
            
          </td>
          <td>2015-11-23</td>
          <td>CoRR</td>
          <td>245</td>
          <td>145</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/22005795db3a0e85c9091a855427a39b5f8bb33a" target='_blank'>Neural Embedding for Physical Manipulations</a></td>
          <td>
            
              Lingzhi Zhang,
            
              Andong Cao,
            
              Rui Li,
            
              Jianbo Shi,
            
          </td>
          <td>2019-07-13</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>52</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/bf4623b356406133b7c9a0e8b28c67482da12df8" target='_blank'>Physics-Based Deep Learning for Fluid Flow</a></td>
          <td>
            
              N. Thuerey,
            
              You Xie,
            
              Mengyu Chu,
            
              S. Wiewel,
            
              L. Prantl,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>1</td>
          <td>36</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/785139d4fdc017fe43ee986ebd89d7bdb1211843" target='_blank'>SyMetric: Measuring the Quality of Learnt Hamiltonian Dynamics Inferred from Vision</a></td>
          <td>
            
              I. Higgins,
            
              Peter Wirnsberger,
            
              Andrew Jaegle,
            
              Aleksandar Botev,
            
          </td>
          <td>2021-11-10</td>
          <td>None</td>
          <td>7</td>
          <td>20</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/fa28994c0d67e56f2cbfe7a51c59083efdca0ebb" target='_blank'>Visual Physics: Discovering Physical Laws from Videos</a></td>
          <td>
            
              Pradyumna Chari,
            
              Chinmay Talegaonkar,
            
              Yunhao Ba,
            
              A. Kadambi,
            
          </td>
          <td>2019-11-27</td>
          <td>ArXiv</td>
          <td>7</td>
          <td>20</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/d96ba4fc5c1046024db4172b569b8eb8eba3f16b" target='_blank'>Taking Visual Motion Prediction To New Heightfields</a></td>
          <td>
            
              Sébastien Ehrhardt,
            
              Áron Monszpart,
            
              N. Mitra,
            
              Andrea Vedaldi,
            
          </td>
          <td>2017-12-22</td>
          <td>ArXiv</td>
          <td>22</td>
          <td>68</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/d12fc4b80064c7b674eb55c7f7675c0820785d45" target='_blank'>Multi-Object Manipulation via Object-Centric Neural Scattering Functions</a></td>
          <td>
            
              Stephen Tian,
            
              Yancheng Cai,
            
              Hong-Xing Yu,
            
              Sergey Zakharov,
            
              Katherine Liu,
            
              Adrien Gaidon,
            
              Yunzhu Li,
            
              Jiajun Wu,
            
          </td>
          <td>2023-06-01</td>
          <td>2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
          <td>5</td>
          <td>49</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/150c9629c6850a2c8ba2909eb887deac76c2a86d" target='_blank'>Inferring Articulated Rigid Body Dynamics from RGBD Video</a></td>
          <td>
            
              Eric Heiden,
            
              Ziang Liu,
            
              Vibhav Vineet,
            
              Erwin Coumans,
            
              G. Sukhatme,
            
          </td>
          <td>2022-03-20</td>
          <td>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
          <td>5</td>
          <td>90</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/cb5e13ad829a67f5fc25c113a7d39bebb940f3f8" target='_blank'>SlotFormer: Unsupervised Visual Dynamics Simulation with Object-Centric Models</a></td>
          <td>
            
              Ziyi Wu,
            
              Nikita Dvornik,
            
              Klaus Greff,
            
              Thomas Kipf,
            
              Animesh Garg,
            
          </td>
          <td>2022-10-12</td>
          <td>ArXiv</td>
          <td>45</td>
          <td>45</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/f91c670b4125fd9a18bb34d7bd9eaa38542bb9bb" target='_blank'>Learning predict-and-simulate policies from unorganized human motion data</a></td>
          <td>
            
              Soohwan Park,
            
              Hoseok Ryu,
            
              Seyoung Lee,
            
              Sunmin Lee,
            
              Jehee Lee,
            
          </td>
          <td>2019-11-08</td>
          <td>ACM Transactions on Graphics (TOG)</td>
          <td>122</td>
          <td>35</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/17b851cfc672b65ccf16a7bdbe85d5db9527483b" target='_blank'>COPHY: Counterfactual Learning of Physical Dynamics</a></td>
          <td>
            
              Fabien Baradel,
            
              N. Neverova,
            
              J. Mille,
            
              Greg Mori,
            
              Christian Wolf,
            
          </td>
          <td>2019-09-26</td>
          <td>ArXiv</td>
          <td>77</td>
          <td>56</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/d10eb51285ced2e959d5cb37fd475004133ff345" target='_blank'>KeyCLD: Learning Constrained Lagrangian Dynamics in Keypoint Coordinates from Images</a></td>
          <td>
            
              Rembert Daems,
            
              Jeroen Taets,
            
              Francis wyffels,
            
              Guillaume Crevecoeur,
            
          </td>
          <td>2022-06-22</td>
          <td>None</td>
          <td>0</td>
          <td>1</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/51d6e73002e5cb2a4e810a94556f7949a373c3de" target='_blank'>On the difficulty of learning and predicting the long-term dynamics of bouncing objects</a></td>
          <td>
            
              Alberto Cenzato,
            
              Alberto Testolin,
            
              M. Zorzi,
            
          </td>
          <td>2019-07-31</td>
          <td>ArXiv</td>
          <td>4</td>
          <td>50</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/737a6e529fe5a532575c5e7afed74679a0affa80" target='_blank'>DISENTANGLED STATE SPACE MODELS: UNSUPER-</a></td>
          <td>
            
              Neous Environments,
            
              Ðorðe Miladinovic,
            
              J. Buhmann,
            
              Waleed M. Gondal,
            
              Stefan Bauer,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>74</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/cd1c95ee95fd7026bad1e115f26e4119678fdd83" target='_blank'>MUVO: A Multimodal Generative World Model for Autonomous Driving with Geometric Representations</a></td>
          <td>
            
              Daniel Bogdoll,
            
              Yitian Yang,
            
              J. Zollner,
            
          </td>
          <td>2023-11-20</td>
          <td>ArXiv</td>
          <td>4</td>
          <td>8</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/e89df83ab7c5ba97492315d9906892f68ce3b710" target='_blank'>Learning Transformable and Plannable se(3) Features for Scene Imitation of a Mobile Service Robot</a></td>
          <td>
            
              J. H. Park,
            
              Jigang Kim,
            
              Youngseok Jang,
            
              Inkyu Jang,
            
              H. Kim,
            
          </td>
          <td>2020-01-22</td>
          <td>IEEE Robotics and Automation Letters</td>
          <td>1</td>
          <td>24</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/fdfd09d6b95e3c5e1719cddd66bc332d2745b2ec" target='_blank'>Causal Navigation by Continuous-time Neural Networks</a></td>
          <td>
            
              Charles J. Vorbach,
            
              Ramin M. Hasani,
            
              Alexander Amini,
            
              Mathias Lechner,
            
              Daniela Rus,
            
          </td>
          <td>2021-06-15</td>
          <td>None</td>
          <td>34</td>
          <td>23</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/2e0381fa8439d24466aa2d4b9d1a5abd07f4ab34" target='_blank'>Keep It Simple: Data-Efficient Learning for Controlling Complex Systems With Simple Models</a></td>
          <td>
            
              Thomas Power,
            
              D. Berenson,
            
          </td>
          <td>2021-02-04</td>
          <td>IEEE Robotics and Automation Letters</td>
          <td>13</td>
          <td>34</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/87dddd05960e4089b7730668e497a70dd232e836" target='_blank'>Object-centric Forward Modeling for Model Predictive Control</a></td>
          <td>
            
              Yufei Ye,
            
              Dhiraj Gandhi,
            
              A. Gupta,
            
              Shubham Tulsiani,
            
          </td>
          <td>2019-10-08</td>
          <td>ArXiv</td>
          <td>34</td>
          <td>88</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/ecb16fdb258b2c0027267bc9689888fb474ef6d1" target='_blank'>CARFF: Conditional Auto-encoded Radiance Field for 3D Scene Forecasting</a></td>
          <td>
            
              Jiezhi Yang,
            
              Khushi Desai,
            
              Charles Packer,
            
              Harshil Bhatia,
            
              Nicholas Rhinehart,
            
              R. McAllister,
            
              Joseph Gonzalez,
            
          </td>
          <td>2024-01-31</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>18</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/d1c3885017f44429211cb7737463ffac5692074c" target='_blank'>Physically Plausible 3D Human-Scene Reconstruction From Monocular RGB Image Using an Adversarial Learning Approach</a></td>
          <td>
            
              S. Biswas,
            
              Kejie Li,
            
              Biplab Banerjee,
            
              S. Chaudhuri,
            
              Hamid Rezatofighi,
            
          </td>
          <td>2023-07-27</td>
          <td>IEEE Robotics and Automation Letters</td>
          <td>2</td>
          <td>45</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/6ee94863568af6d79abc93ab8fe08ab94b44a525" target='_blank'>Graph-Based Model Predictive Visual Imitation Learning</a></td>
          <td>
            
              Jan Peters,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>76</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/cf18287e79b1fd73cd333fc914bb24c00a537f4c" target='_blank'>Self-Supervised Visual Planning with Temporal Skip Connections</a></td>
          <td>
            
              F. Ebert,
            
              Chelsea Finn,
            
              Alex X. Lee,
            
              S. Levine,
            
          </td>
          <td>2017-10-15</td>
          <td>ArXiv</td>
          <td>280</td>
          <td>145</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/fc4742f32fd906a2627201d6170c33ed73965908" target='_blank'>Neural Marionette: Unsupervised Learning of Motion Skeleton and Latent Dynamics from Volumetric Video</a></td>
          <td>
            
              Jinseok Bae,
            
              Ho-Jin Jang,
            
              Cheol-Hui Min,
            
              H. Choi,
            
              Y. Kim,
            
          </td>
          <td>2022-02-17</td>
          <td>ArXiv</td>
          <td>3</td>
          <td>13</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/9c7002dddd499d3ed1c8e394bbf6db4a7a5b2d5f" target='_blank'>A Differentiable Recipe for Learning Visual Dexterous Planar Manipulation</a></td>
          <td>
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>0</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/e2d030f11a8027e9d970d66f738932d0f974e11f" target='_blank'>On the Efficacy of 3D Point Cloud Reinforcement Learning</a></td>
          <td>
            
              Z. Ling,
            
              Yuan Yao,
            
              Xuanlin Li,
            
              H. Su,
            
          </td>
          <td>2023-06-11</td>
          <td>ArXiv</td>
          <td>3</td>
          <td>48</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/8d3fddfe59a21b8245b375d33fe91e215237ddb1" target='_blank'>Affordance Learning from Play for Sample-Efficient Policy Learning</a></td>
          <td>
            
              Jessica Borja-Diaz,
            
              Oier Mees,
            
              Gabriel Kalweit,
            
              Lukás Hermann,
            
              J. Boedecker,
            
              Wolfram Burgard,
            
          </td>
          <td>2022-03-01</td>
          <td>2022 International Conference on Robotics and Automation (ICRA)</td>
          <td>21</td>
          <td>120</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/4325d6a0ed5f87efd60d84aca6fad2cc4f9c3467" target='_blank'>Slot Order Matters for Compositional Scene Understanding</a></td>
          <td>
            
              Patrick Emami,
            
              Pan He,
            
              Sanjay Ranka,
            
              A. Rangarajan,
            
          </td>
          <td>None</td>
          <td>ArXiv</td>
          <td>2</td>
          <td>11</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/69ef09f2ec8528a371b1dceacd364c2545027861" target='_blank'>Latent Space Planning for Multiobject Manipulation With Environment-Aware Relational Classifiers</a></td>
          <td>
            
              Yixuan Huang,
            
              Nichols Crawford Taylor,
            
              Adam Conkey,
            
              Weiyu Liu,
            
              Tucker Hermans,
            
          </td>
          <td>2023-05-18</td>
          <td>IEEE Transactions on Robotics</td>
          <td>1</td>
          <td>27</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/ec5c6c0b56e7593c726a963adb9c1f03a40e65f8" target='_blank'>Interpreting Dynamic Scenes by a Physics Engine and Bottom-Up Visual Cues</a></td>
          <td>
            
              Ilker Yildirim,
            
              Jiajun Wu,
            
              Yilun Du,
            
              J. Tenenbaum,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>1</td>
          <td>122</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/9825e4c620e97b5def1a1ae71f89182b36d77e61" target='_blank'>Video Autoencoder: self-supervised disentanglement of static 3D structure and motion</a></td>
          <td>
            
              Zihang Lai,
            
              Sifei Liu,
            
              Alexei A. Efros,
            
              Xiaolong Wang,
            
          </td>
          <td>2021-10-01</td>
          <td>2021 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
          <td>23</td>
          <td>100</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/7c1b75ab7bed79163d3d830a6a83a4023b496ebb" target='_blank'>Self-supervised Visual Reinforcement Learning with Object-centric Representations</a></td>
          <td>
            
              Andrii Zadaianchuk,
            
              Maximilian Seitzer,
            
              G. Martius,
            
          </td>
          <td>2020-11-29</td>
          <td>ArXiv</td>
          <td>21</td>
          <td>24</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/5b51b2e23deb02dae7538a0bb51d5e692f011553" target='_blank'>Understanding Object Dynamics for Interactive Image-to-Video Synthesis</a></td>
          <td>
            
              A. Blattmann,
            
              Timo Milbich,
            
              Michael Dorkenwald,
            
              B. Ommer,
            
          </td>
          <td>2021-06-01</td>
          <td>2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
          <td>23</td>
          <td>37</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/d53fbc2bd3adba8fd9d0df1aa7d852e0e20d53ac" target='_blank'>LagNetViP: A Lagrangian Neural Network for Video Prediction</a></td>
          <td>
            
              Christine Allen-Blanchette,
            
              Sushant Veer,
            
              Anirudha Majumdar,
            
              Naomi Ehrich Leonard,
            
          </td>
          <td>2020-10-24</td>
          <td>ArXiv</td>
          <td>22</td>
          <td>63</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/65350c1bc1f295bb76ac43cbecd1a5d20ccd0140" target='_blank'>GATSBI: Generative Agent-centric Spatio-temporal Object Interaction</a></td>
          <td>
            
              Cheol-Hui Min,
            
              Jinseok Bae,
            
              Junho Lee,
            
              Y. Kim,
            
          </td>
          <td>2021-04-09</td>
          <td>2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
          <td>5</td>
          <td>13</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/4aae4d3300179d180966ea9c116159469f69eb2d" target='_blank'>Newtonian Image Understanding: Unfolding the Dynamics of Objects in Static Images</a></td>
          <td>
            
              Roozbeh Mottaghi,
            
              Hessam Bagherinezhad,
            
              Mohammad Rastegari,
            
              Ali Farhadi,
            
          </td>
          <td>2015-11-12</td>
          <td>2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
          <td>139</td>
          <td>72</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/2f8b2f365ed7f6a2256db657449f8e199407744c" target='_blank'>Graph-based Task-specific Prediction Models for Interactions between Deformable and Rigid Objects</a></td>
          <td>
            
              Zehang Weng,
            
              Fabian Paus,
            
              Anastasiia Varava,
            
              Hang Yin,
            
              T. Asfour,
            
              D. Kragic,
            
          </td>
          <td>2021-03-04</td>
          <td>2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
          <td>16</td>
          <td>65</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/63317bb2cd56f9d90c282f3ac6add973e29d71ee" target='_blank'>Predicting Physical Object Properties from Video</a></td>
          <td>
            
              M. Link,
            
              Max Schwarz,
            
              Sven Behnke,
            
          </td>
          <td>2022-06-02</td>
          <td>2022 International Joint Conference on Neural Networks (IJCNN)</td>
          <td>1</td>
          <td>53</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/6eddfde78d5f6b10206f00675102fe3ddef8ff89" target='_blank'>Structured World Models from Human Videos</a></td>
          <td>
            
              Russell Mendonca,
            
              Shikhar Bahl,
            
              Deepak Pathak,
            
          </td>
          <td>2023-07-10</td>
          <td>ArXiv</td>
          <td>24</td>
          <td>28</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/d9e8ac993cd75c1ab9364ba30a86444f2537a9c4" target='_blank'>SimPoE: Simulated Character Control for 3D Human Pose Estimation</a></td>
          <td>
            
              Ye Yuan,
            
              S. Wei,
            
              T. Simon,
            
              Kris Kitani,
            
              Jason M. Saragih,
            
          </td>
          <td>2021-04-01</td>
          <td>2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
          <td>95</td>
          <td>41</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/336244cd35bdfe3a68643c1c429bccedae0e245e" target='_blank'>Differentiable simulation for system identification and visuomotor control ∇ Sim : D IFFERENTIABLE SIMULATION FOR SYSTEM IDENTIFICATION AND VISUOMOTOR CONTROL</a></td>
          <td>
            
              Krishna Murthy Jatavallabhula,
            
              M. Macklin,
            
              Florian Golemo,
            
              Vikram S. Voleti,
            
              Linda Petrini,
            
              Martin Weiss,
            
              Breandan Considine,
            
              Jérôme Parent-Lévesque,
            
              Kevin Xie,
            
              Kenny Erleben,
            
              L. Paull,
            
              F. Shkurti,
            
              D. Nowrouzezahrai,
            
              S. Fidler,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>43</td>
          <td>78</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/782d4accd2d3c4648de7b76d255e508c95a89fae" target='_blank'>Understanding 3D Object Interaction from a Single Image</a></td>
          <td>
            
              Shengyi Qian,
            
              D. Fouhey,
            
          </td>
          <td>2023-05-16</td>
          <td>2023 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
          <td>5</td>
          <td>25</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/9406e95bcafaf5dbce5629467a5e4282d40b667d" target='_blank'>NeRF2Real: Sim2real Transfer of Vision-guided Bipedal Motion Skills using Neural Radiance Fields</a></td>
          <td>
            
              Arunkumar Byravan,
            
              Jan Humplik,
            
              Leonard Hasenclever,
            
              Arthur Brussee,
            
              F. Nori,
            
              Tuomas Haarnoja,
            
              Ben Moran,
            
              Steven Bohez,
            
              Fereshteh Sadeghi,
            
              Bojan Vujatovic,
            
              N. Heess,
            
          </td>
          <td>2022-10-10</td>
          <td>2023 IEEE International Conference on Robotics and Automation (ICRA)</td>
          <td>24</td>
          <td>61</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/b9408b0c3445ad17f33e7a64073c1d2e6674e69a" target='_blank'>Pathdreamer: A World Model for Indoor Navigation</a></td>
          <td>
            
              Jing Yu Koh,
            
              Honglak Lee,
            
              Yinfei Yang,
            
              Jason Baldridge,
            
              Peter Anderson,
            
          </td>
          <td>2021-05-18</td>
          <td>2021 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
          <td>54</td>
          <td>44</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/1c44b632bcd6494f4cfc41c70ed53d93f72473cc" target='_blank'>Generative Temporal Models with Spatial Memory for Partially Observed Environments</a></td>
          <td>
            
              Marco Fraccaro,
            
              Danilo Jimenez Rezende,
            
              Yori Zwols,
            
              A. Pritzel,
            
              S. Eslami,
            
              Fabio Viola,
            
          </td>
          <td>2018-04-25</td>
          <td>ArXiv</td>
          <td>28</td>
          <td>42</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/a52871790b4e8bde7c4ed4d0f182d5fb58c798fe" target='_blank'>Learning Multi-Object Dynamics with Compositional NeRFs</a></td>
          <td>
            
              Danny Driess,
            
              Zhiao Huang,
            
              Yunzhu Li,
            
              Russ Tedrake,
            
              Marc Toussaint,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>65</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/43879cf527f4918955fd55128baa6745174d8555" target='_blank'>Graph networks as learnable physics engines for inference and control</a></td>
          <td>
            
              Alvaro Sanchez-Gonzalez,
            
              N. Heess,
            
              J. T. Springenberg,
            
              J. Merel,
            
              Martin A. Riedmiller,
            
              R. Hadsell,
            
              P. Battaglia,
            
          </td>
          <td>2018-06-04</td>
          <td>None</td>
          <td>535</td>
          <td>61</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/92c89db048fb825d2c81b086d7bd82ed230f685b" target='_blank'>gradSim: Differentiable simulation for system identification and visuomotor control</a></td>
          <td>
            
              Krishna Murthy Jatavallabhula,
            
              M. Macklin,
            
              Florian Golemo,
            
              Vikram S. Voleti,
            
              Linda,
            
              Petrini,
            
              Martin Weiss,
            
              Breandan Considine,
            
              Jérôme Parent-Lévesque,
            
              Kevin Xie,
            
              Kenny,
            
              Erleben,
            
              L. Paull,
            
              F. Shkurti,
            
              D. Nowrouzezahrai,
            
              S. Fidler,
            
          </td>
          <td>2021-04-06</td>
          <td>ArXiv</td>
          <td>56</td>
          <td>78</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/7234ace03d09b3c290cd6d5eff8eacbaa846e97e" target='_blank'>CoGS: Controllable Gaussian Splatting</a></td>
          <td>
            
              Heng Yu,
            
              Joel Julin,
            
              Z. '. Milacski,
            
              Koichiro Niinuma,
            
              László A. Jeni,
            
          </td>
          <td>2023-12-09</td>
          <td>ArXiv</td>
          <td>3</td>
          <td>24</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/4d70c9bc5b788611eec4ad1d6d32ad3154615dc7" target='_blank'>Latent Space Roadmap for Visual Action Planning of Deformable and Rigid Object Manipulation</a></td>
          <td>
            
              M. Lippi,
            
              Petra Poklukar,
            
              Michael C. Welle,
            
              Anastasiia Varava,
            
              Hang Yin,
            
              A. Marino,
            
              D. Kragic,
            
          </td>
          <td>2020-03-19</td>
          <td>2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
          <td>51</td>
          <td>65</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/5d925a022c6e20654ffcf1177e46ac5454593ea9" target='_blank'>D&D: Learning Human Dynamics from Dynamic Camera</a></td>
          <td>
            
              Jiefeng Li,
            
              Siyuan Bian,
            
              Chaoshun Xu,
            
              Gang Liu,
            
              Gang Yu,
            
              Cewu Lu,
            
          </td>
          <td>2022-09-19</td>
          <td>None</td>
          <td>24</td>
          <td>49</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/6926e678c9965710a7c6a09a292d66ae5e6a605a" target='_blank'>Unsupervised separation of dynamics from pixels</a></td>
          <td>
            
              S. Chiappa,
            
              U. Paquet,
            
          </td>
          <td>2019-07-20</td>
          <td>METRON</td>
          <td>4</td>
          <td>19</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/8a1c2424c6a7ea8ee8190a9fcc51e8c25a19f451" target='_blank'>Learning meaningful controls for fluids</a></td>
          <td>
            
              Mengyu Chu,
            
              Nils Thuerey,
            
              H. Seidel,
            
              C. Theobalt,
            
              Rhaleb Zayer,
            
          </td>
          <td>2021-07-17</td>
          <td>ACM Transactions on Graphics (TOG)</td>
          <td>17</td>
          <td>108</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/7ece667ecfc30ddc16d82482a38f54c356c8180c" target='_blank'>Refining 6D Object Pose Predictions using Abstract Render-and-Compare</a></td>
          <td>
            
              Arul Selvam Periyasamy,
            
              Max Schwarz,
            
              Sven Behnke,
            
          </td>
          <td>2019-10-01</td>
          <td>2019 IEEE-RAS 19th International Conference on Humanoid Robots (Humanoids)</td>
          <td>16</td>
          <td>53</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/72a49660561810cd9362ab5a3e7eb6e5882ea797" target='_blank'>Visual Imitation Learning for Robot Manipulation</a></td>
          <td>
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>1</td>
          <td>0</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/0933f3dd33cf907e07aa938ce9465fb0d4250394" target='_blank'>End-to-End Differentiable Physics for Learning and Control</a></td>
          <td>
            
              Filipe de Avila Belbute-Peres,
            
              Kevin A. Smith,
            
              Kelsey R. Allen,
            
              J. Tenenbaum,
            
              Zico Kolter,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>341</td>
          <td>122</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/d877dfdac29ef0557224fa5138b3b2085b22302c" target='_blank'>Visual Representation Learning with 3D View-Contrastive Inverse Graphics Networks</a></td>
          <td>
            
              Adam W. Harley,
            
              Fangyu Li,
            
              S. K. Lakshmikanth,
            
              Xian Zhou,
            
              H. Tung,
            
              Katerina Fragkiadaki,
            
          </td>
          <td>2019-06-10</td>
          <td>arXiv: Computer Vision and Pattern Recognition</td>
          <td>1</td>
          <td>28</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/6a5db0b50bacad4484b172fda74679c6bb6ca734" target='_blank'>Learning Latent Object-Centric Representations for Visual-Based Robot Manipulation</a></td>
          <td>
            
              Yunan Wang,
            
              Jiayu Wang,
            
              Yixiao Li,
            
              Chuxiong Hu,
            
              Y. Zhu,
            
          </td>
          <td>2022-07-09</td>
          <td>2022 International Conference on Advanced Robotics and Mechatronics (ICARM)</td>
          <td>2</td>
          <td>43</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/d65637b3121cc6a7abeaa7f0029193bd37ba71cf" target='_blank'>3D Probabilistic Representations for Vision and Action</a></td>
          <td>
            
              J. Piater,
            
              R. Detry,
            
          </td>
          <td>None</td>
          <td></td>
          <td>0</td>
          <td>34</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/6c1bb8b017c469208bd7e3a80639bdb5f1726e2c" target='_blank'>Latent Variable Sequential Set Transformers for Joint Multi-Agent Motion Prediction</a></td>
          <td>
            
              Roger Girgis,
            
              Florian Golemo,
            
              Felipe Codevilla,
            
              Martin Weiss,
            
              Jim Aldon D’Souza,
            
              Samira Ebrahimi Kahou,
            
              Felix Heide,
            
              C. Pal,
            
          </td>
          <td>2021-02-19</td>
          <td>None</td>
          <td>67</td>
          <td>50</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/c99798fce885b41ab1de66bbacf04b7de7274f85" target='_blank'>Predicting Object Dynamics in Scenes</a></td>
          <td>
            
              D. Fouhey,
            
              C. L. Zitnick,
            
          </td>
          <td>2014-06-23</td>
          <td>2014 IEEE Conference on Computer Vision and Pattern Recognition</td>
          <td>79</td>
          <td>61</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/fc1b9e75e955657840388db9ea7e217380f32afe" target='_blank'>Physics-based Human Motion Estimation and Synthesis from Videos</a></td>
          <td>
            
              Kevin Xie,
            
              Tingwu Wang,
            
              ,
            
              Yunrong Guo,
            
              S. Fidler,
            
              F. Shkurti,
            
          </td>
          <td>2021-09-21</td>
          <td>2021 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
          <td>54</td>
          <td>78</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/606f121892ee53da42fe118090712bb83ac50781" target='_blank'>Predicting the Future with Simple World Models</a></td>
          <td>
            
              Tankred Saanum,
            
              Peter Dayan,
            
              Eric Schulz,
            
          </td>
          <td>2024-01-31</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/2e9ff22cc1109cd251c6b8e2ff1c809df16ff9d8" target='_blank'>WorldGen: A Large Scale Generative Simulator</a></td>
          <td>
            
              Chahat Deep Singh,
            
              R. Kumari,
            
              Cornelia Fermuller,
            
              N. Sanket,
            
              Y. Aloimonos,
            
          </td>
          <td>2022-10-03</td>
          <td>2023 IEEE International Conference on Robotics and Automation (ICRA)</td>
          <td>1</td>
          <td>50</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/4d5877fd228612263762f04e955514fc9ad4f85a" target='_blank'>Optical Non-Line-of-Sight Physics-Based 3D Human Pose Estimation</a></td>
          <td>
            
              Mariko Isogawa,
            
              Ye Yuan,
            
              Matthew O'Toole,
            
              Kris M. Kitani,
            
          </td>
          <td>2020-03-31</td>
          <td>2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
          <td>46</td>
          <td>38</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/700f3ffd39b7fd9fb8addb0974ff39c19cc0aae6" target='_blank'>Combining discriminative features to infer complex trajectories</a></td>
          <td>
            
              David A. Ross,
            
              Simon Osindero,
            
              R. Zemel,
            
          </td>
          <td>2006-06-25</td>
          <td>Proceedings of the 23rd international conference on Machine learning</td>
          <td>18</td>
          <td>72</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/76d59de2a710e608f3f95579a6de831c002b249f" target='_blank'>Exploiting Priors from 3D Diffusion Models for RGB-Based One-Shot View Planning</a></td>
          <td>
            
              Sicong Pan,
            
              Liren Jin,
            
              Xuying Huang,
            
              C. Stachniss,
            
              Marija Popovi'c,
            
              Maren Bennewitz,
            
          </td>
          <td>2024-03-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>67</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/401dfc5efbd182eaef6945249aea8a0a1e3cced5" target='_blank'>Shaping Belief States with Generative Environment Models for RL</a></td>
          <td>
            
              Karol Gregor,
            
              Danilo Jimenez Rezende,
            
              F. Besse,
            
              Yan Wu,
            
              Hamza Merzic,
            
              Aäron van den Oord,
            
          </td>
          <td>2019-06-21</td>
          <td>ArXiv</td>
          <td>108</td>
          <td>42</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/df831eeae0385a5cad74e534d79e3bab594b1843" target='_blank'>General Flow as Foundation Affordance for Scalable Robot Learning</a></td>
          <td>
            
              Chengbo Yuan,
            
              Chuan Wen,
            
              Tong Zhang,
            
              Yang Gao,
            
          </td>
          <td>2024-01-21</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>6</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/96947cf4ee92243cefd014cbf899756dfc0f4b13" target='_blank'>Collision Replay: What Does Bumping Into Things Tell You About Scene Geometry?</a></td>
          <td>
            
              Alexander R. E. Raistrick,
            
              Nilesh Kulkarni,
            
              D. Fouhey,
            
          </td>
          <td>2021-05-03</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>25</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/056b7cf2db7672d39200bc399f87f06e02163d51" target='_blank'>Experience-Embedded Visual Foresight</a></td>
          <td>
            
              Yen-Chen Lin,
            
              Maria Bauzá,
            
              Phillip Isola,
            
          </td>
          <td>2019-11-12</td>
          <td>ArXiv</td>
          <td>32</td>
          <td>48</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/8b055cf00b2b525da5b292a20485a38fbdf4f4a1" target='_blank'>Predicting the Physical Dynamics of Unseen 3D Objects</a></td>
          <td>
            
              Davis Rempe,
            
              Srinath Sridhar,
            
              He Wang,
            
              L. Guibas,
            
          </td>
          <td>2020-01-16</td>
          <td>2020 IEEE Winter Conference on Applications of Computer Vision (WACV)</td>
          <td>7</td>
          <td>63</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/03e4d4911ce914d6a4e12b025a75e5719890bf39" target='_blank'>NeuPhysics: Editable Neural Geometry and Physics from Monocular Videos</a></td>
          <td>
            
              Yi-Ling Qiao,
            
              Alexander Gao,
            
              Ming-Chyuan Lin,
            
          </td>
          <td>2022-10-22</td>
          <td>ArXiv</td>
          <td>22</td>
          <td>11</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/a8eb2a70bc26fa395dcb648c78c709c5a4a8699f" target='_blank'>Is Anyone There? Learning a Planner Contingent on Perceptual Uncertainty</a></td>
          <td>
            
              Charles Packer,
            
              Nicholas Rhinehart,
            
              R. McAllister,
            
              Matthew A. Wright,
            
              Xin Wang,
            
              Jeff He,
            
              S. Levine,
            
              Joseph E. Gonzalez,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>9</td>
          <td>145</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/197037c0d6612d1510f98eb2a1719da05bede103" target='_blank'>Where2Act: From Pixels to Actions for Articulated 3D Objects</a></td>
          <td>
            
              Kaichun Mo,
            
              L. Guibas,
            
              Mustafa Mukadam,
            
              A. Gupta,
            
              Shubham Tulsiani,
            
          </td>
          <td>2021-01-07</td>
          <td>2021 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
          <td>105</td>
          <td>88</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/c31160da259cf38503ab9a27920bb994ec039d8b" target='_blank'>FlowBot3D: Learning 3D Articulation Flow to Manipulate Articulated Objects</a></td>
          <td>
            
              Ben Eisner,
            
              Harry Zhang,
            
              David Held,
            
          </td>
          <td>2022-05-09</td>
          <td>ArXiv</td>
          <td>45</td>
          <td>57</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/9b7429eb5cfbbefeba56680d54e65eac54fe6140" target='_blank'>Towards Non-Parametric Models for Confidence Aware Image Prediction from Low Data using Gaussian Processes</a></td>
          <td>
            
              Nikhil Shinde,
            
              Florian Richter,
            
              Michael C. Yip,
            
          </td>
          <td>2023-07-20</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>29</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/936f99700667ddb07f3bf26aa0a7e701bef2472b" target='_blank'>SPACE: A Simulator for Physical Interactions and Causal Learning in 3D Environments</a></td>
          <td>
            
              Jiafei Duan,
            
              Samson Yu,
            
              Cheston Tan,
            
          </td>
          <td>2021-08-13</td>
          <td>2021 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)</td>
          <td>8</td>
          <td>17</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/05d2e4252ec361c7e2f2b28e0ad67f4f5b34f38e" target='_blank'>Embodied View-Contrastive 3D Feature Learning</a></td>
          <td>
            
              Adam W. Harley,
            
              Fangyu Li,
            
              S. K. Lakshmikanth,
            
              Xian Zhou,
            
              H. Tung,
            
              Katerina Fragkiadaki,
            
          </td>
          <td>2019-06-10</td>
          <td>ArXiv</td>
          <td>5</td>
          <td>28</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/73f569498b9a847d86d6489da4235ba1bbf346fb" target='_blank'>Predicting Diverse and Plausible State Foresight For Robotic Pushing Tasks</a></td>
          <td>
            
              Lingzhi Zhang,
            
              Shenghao Zhou,
            
              Jianbo Shi,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>5</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/4a0834b438518c5a0915040708bec576aaee7474" target='_blank'>Learning Geometric Representations of Objects via Interaction</a></td>
          <td>
            
              Alfredo Reichlin,
            
              G. Marchetti,
            
              Hang Yin,
            
              Anastasiia Varava,
            
              Danica Kragic,
            
          </td>
          <td>2023-09-11</td>
          <td>None</td>
          <td>0</td>
          <td>10</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/02dbbcc0317a63a87134d2aafca213b7565515b8" target='_blank'>Inferring Fluid Dynamics via Inverse Rendering</a></td>
          <td>
            
              Jinxian Liu,
            
              Ye Chen,
            
              Bingbing Ni,
            
              Jiyao Mao,
            
              Zhenbo Yu,
            
          </td>
          <td>2023-04-10</td>
          <td>ArXiv</td>
          <td>2</td>
          <td>53</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/4ca19525f996c9e60cca4f7e04ea76a4a1160a11" target='_blank'>PLATO: Predicting Latent Affordances Through Object-Centric Play</a></td>
          <td>
            
              Suneel Belkhale,
            
              Dorsa Sadigh,
            
          </td>
          <td>2022-03-10</td>
          <td>None</td>
          <td>11</td>
          <td>41</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/4ec70c8bd6bd0bcca74ac88b56ee8dafc2357b55" target='_blank'>Physion++: Evaluating Physical Scene Understanding that Requires Online Inference of Different Physical Properties</a></td>
          <td>
            
              H. Tung,
            
              Mingyu Ding,
            
              Zhenfang Chen,
            
              Daniel Bear,
            
              Chuang Gan,
            
              J. Tenenbaum,
            
              Daniel L. K. Yamins,
            
              Judy Fan,
            
              Kevin A. Smith,
            
          </td>
          <td>2023-06-27</td>
          <td>ArXiv</td>
          <td>4</td>
          <td>122</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/7647da1038999a03551a3443eb92cf6d58c3fb39" target='_blank'>Learning Physical Dynamics for Object-centric Visual Prediction</a></td>
          <td>
            
              Hui Xu,
            
              Tao Chen,
            
              Feng Xu,
            
          </td>
          <td>2024-03-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/f608f39542b9e8ec432dba0d01bfd77a08b216d0" target='_blank'>Action-conditioned Deep Visual Prediction with RoAM, a new Indoor Human Motion Dataset for Autonomous Robots</a></td>
          <td>
            
              Meenakshi Sarkar,
            
              V. Honkote,
            
              D. Das,
            
              D. Ghose,
            
          </td>
          <td>2023-06-28</td>
          <td>2023 32nd IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)</td>
          <td>1</td>
          <td>28</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/351af30d48e1c545250efa883edd24bca903d493" target='_blank'>One-Shot Neural Fields for 3D Object Understanding</a></td>
          <td>
            
              Valts Blukis,
            
              Taeyeop Lee,
            
              Jonathan Tremblay,
            
              Bowen Wen,
            
              In-So Kweon,
            
              Kuk-Jin Yoon,
            
              D. Fox,
            
              Stan Birchfield,
            
          </td>
          <td>2022-10-21</td>
          <td>None</td>
          <td>2</td>
          <td>120</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/ee81f3cb0b6eb97e1709b1ccf13809dd121fa176" target='_blank'>Reconstructing Objects in-the-wild for Realistic Sensor Simulation</a></td>
          <td>
            
              Ze Yang,
            
              S. Manivasagam,
            
              Yun Chen,
            
              Jingkang Wang,
            
              Rui Hu,
            
              R. Urtasun,
            
          </td>
          <td>2023-05-29</td>
          <td>2023 IEEE International Conference on Robotics and Automation (ICRA)</td>
          <td>9</td>
          <td>105</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/1bcd18df118837ef4e1c53407bdf1a0568c4c0be" target='_blank'>Automatic Understanding of the Visual World</a></td>
          <td>
            
              C. Schmid,
            
          </td>
          <td>2019-07-18</td>
          <td>Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</td>
          <td>0</td>
          <td>140</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/511d2fb9a57ba5022b7ee9e1ea56adb4b9b23cbe" target='_blank'>Reconstruct, Rasterize and Backprop: Dense shape and pose estimation from a single image</a></td>
          <td>
            
              Aniket Pokale,
            
              Aditya Aggarwal,
            
              K. Krishna,
            
          </td>
          <td>2020-04-25</td>
          <td>2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</td>
          <td>1</td>
          <td>27</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/6ac0b99bd04a2b857da22ebb2dd58b0950f8739a" target='_blank'>Visual Reaction: Learning to Play Catch With Your Drone</a></td>
          <td>
            
              Kuo-Hao Zeng,
            
              Roozbeh Mottaghi,
            
              Luca Weihs,
            
              Ali Farhadi,
            
          </td>
          <td>2019-12-04</td>
          <td>2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
          <td>13</td>
          <td>72</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/b547c3888a331417a1441a243a83fed8aaa25b3e" target='_blank'>Learning Generalizable Feature Fields for Mobile Manipulation</a></td>
          <td>
            
              Ri-Zhao Qiu,
            
              Yafei Hu,
            
              Ge Yang,
            
              Yuchen Song,
            
              Yang Fu,
            
              Jianglong Ye,
            
              Jiteng Mu,
            
              Ruihan Yang,
            
              Nikolay Atanasov,
            
              Sebastian Scherer,
            
              Xiaolong Wang,
            
          </td>
          <td>2024-03-12</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>7</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/fb8a1dd5d3bc0395b8ceb7ee73475a10e39b52fe" target='_blank'>Neural Scene Graphs for Dynamic Scenes</a></td>
          <td>
            
              Julian Ost,
            
              Fahim Mannan,
            
              N. Thuerey,
            
              Julian Knodt,
            
              Felix Heide,
            
          </td>
          <td>2020-11-20</td>
          <td>2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
          <td>199</td>
          <td>42</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/2cb380b95092272961410ce0418654e7bad13eb2" target='_blank'>Object-Oriented Dynamics Learning through Multi-Level Abstraction</a></td>
          <td>
            
              Guangxiang Zhu,
            
              Jianhao Wang,
            
              Zhizhou Ren,
            
              Chongjie Zhang,
            
          </td>
          <td>2019-04-16</td>
          <td>None</td>
          <td>4</td>
          <td>29</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/ea2e5eb93f194ebf8a5c350cb5e20c63a66ff6bd" target='_blank'>Learning to Estimate Scenes from Images</a></td>
          <td>
            
              W. Freeman,
            
              E. Pasztor,
            
          </td>
          <td>1998-12-01</td>
          <td>None</td>
          <td>79</td>
          <td>111</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/f51627214f6b8b30bec34e6ff35699dace159f18" target='_blank'>Learning image representations from observer motions and interactions</a></td>
          <td>
            
              Dinesh Jayaraman,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>29</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/cd590f6490d10ea631ebc2dce24e95aa5a267515" target='_blank'>Physics-Based Rigid Body Object Tracking and Friction Filtering From RGB-D Videos</a></td>
          <td>
            
              Rama Krishna Kandukuri,
            
              Michael Strecke,
            
              Joerg Stueckler,
            
          </td>
          <td>2023-09-27</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/7a009257d453ca2226aa9ec594196c7bcfe1b9d3" target='_blank'>Controllable Human-Object Interaction Synthesis</a></td>
          <td>
            
              Jiaman Li,
            
              Alexander Clegg,
            
              Roozbeh Mottaghi,
            
              Jiajun Wu,
            
              Xavier Puig,
            
              C. K. Liu,
            
          </td>
          <td>2023-12-06</td>
          <td>ArXiv</td>
          <td>8</td>
          <td>37</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/1dcdfc4319297592f31df2291b3d6fac3b30bb5f" target='_blank'>RayNet: Learning Volumetric 3D Reconstruction with Ray Potentials</a></td>
          <td>
            
              Despoina Paschalidou,
            
              Ali O. Ulusoy,
            
              Carolin Schmitt,
            
              L. Gool,
            
              Andreas Geiger,
            
          </td>
          <td>2018-06-01</td>
          <td>2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</td>
          <td>84</td>
          <td>163</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/2fe52e92b8693e0fe9e63d39acb9391a9b9693c5" target='_blank'>PreSim: A 3D Photo-Realistic Environment Simulator for Visual AI</a></td>
          <td>
            
              Honglin Yuan,
            
              R. Veltkamp,
            
          </td>
          <td>2021-04-01</td>
          <td>IEEE Robotics and Automation Letters</td>
          <td>9</td>
          <td>40</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/68f50216374c50382e17890aa25871230517af13" target='_blank'>Neural state machine for character-scene interactions</a></td>
          <td>
            
              S. Starke,
            
              He Zhang,
            
              T. Komura,
            
              Jun Saito,
            
          </td>
          <td>2019-11-08</td>
          <td>ACM Transactions on Graphics (TOG)</td>
          <td>224</td>
          <td>41</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/e32a0a459142efd847b0bb27e68d13fcca0d9552" target='_blank'>Generative modeling for continuous non-linearly embedded visual inference</a></td>
          <td>
            
              C. Sminchisescu,
            
              A. Jepson,
            
          </td>
          <td>2004-07-04</td>
          <td>Proceedings of the twenty-first international conference on Machine learning</td>
          <td>171</td>
          <td>60</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/14d13f7da19caf8d542af18ee9d5efb262d092db" target='_blank'>Imitation Learning with THOR</a></td>
          <td>
            
              Albert Liu,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>1</td>
          <td>1</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/b223323e147d53a2315c442c3ca37e5158042051" target='_blank'>FlowControl: Optical Flow Based Visual Servoing</a></td>
          <td>
            
              Max Argus,
            
              Lukás Hermann,
            
              Jon Long,
            
              T. Brox,
            
          </td>
          <td>2020-07-01</td>
          <td>2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
          <td>19</td>
          <td>94</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/247a9af5911e0a84162f133e5a674d317ccab333" target='_blank'>iPOKE: Poking a Still Image for Controlled Stochastic Video Synthesis</a></td>
          <td>
            
              A. Blattmann,
            
              Timo Milbich,
            
              Michael Dorkenwald,
            
              B. Ommer,
            
          </td>
          <td>2021-07-06</td>
          <td>2021 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
          <td>25</td>
          <td>37</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/89cffaf2d0a16143f14fb907059e0d9b85ebc8fc" target='_blank'>Sim2Real$^2$: Actively Building Explicit Physics Model for Precise Articulated Object Manipulation</a></td>
          <td>
            
              Liqian Ma,
            
              Jiaojiao Meng,
            
              Shuntao Liu,
            
              Weihang Chen,
            
              Jing Xu,
            
              Rui Chen,
            
          </td>
          <td>2023-02-21</td>
          <td>None</td>
          <td>3</td>
          <td>11</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/6dea0d083a2830a7477073802232419329d08220" target='_blank'>SAVi++: Towards End-to-End Object-Centric Learning from Real-World Videos</a></td>
          <td>
            
              Gamaleldin F. Elsayed,
            
              Aravindh Mahendran,
            
              Sjoerd van Steenkiste,
            
              Klaus Greff,
            
              M. Mozer,
            
              Thomas Kipf,
            
          </td>
          <td>2022-06-15</td>
          <td>ArXiv</td>
          <td>80</td>
          <td>25</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/8d437fd63a689b583987210313ce6e20851473a9" target='_blank'>Kinematics-Guided Reinforcement Learning for Object-Aware 3D Ego-Pose Estimation</a></td>
          <td>
            
              Zhengyi Luo,
            
              Ryo Hachiuma,
            
              Ye Yuan,
            
              Shun Iwase,
            
              Kris M. Kitani,
            
          </td>
          <td>2020-11-10</td>
          <td>ArXiv</td>
          <td>7</td>
          <td>38</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/d62508d4b20be6af31f879d8d0abdddfa1df4042" target='_blank'>Robo360: A 3D Omnispective Multi-Material Robotic Manipulation Dataset</a></td>
          <td>
            
              Litian Liang,
            
              Liuyu Bian,
            
              Caiwei Xiao,
            
              Jialin Zhang,
            
              Linghao Chen,
            
              Isabella Liu,
            
              Fanbo Xiang,
            
              Zhiao Huang,
            
              Hao Su,
            
          </td>
          <td>2023-12-09</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>14</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/2a2a853ad53746433f9d11b4e19995195e86f5ee" target='_blank'>Physics-Inspired Neural Graph ODE for Long-term Dynamical Simulation</a></td>
          <td>
            
              Yang Liu,
            
              Jiashun Cheng,
            
              Haihong Zhao,
            
              Tingyang Xu,
            
              Peilin Zhao,
            
              F. Tsung,
            
              Jia Li,
            
              Yu Rong,
            
          </td>
          <td>None</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>47</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/883ac0fcebca7f8df1a8a253c4d27ed83494efae" target='_blank'>VAT-Mart: Learning Visual Action Trajectory Proposals for Manipulating 3D ARTiculated Objects</a></td>
          <td>
            
              Ruihai Wu,
            
              Yan Zhao,
            
              Kaichun Mo,
            
              Zizheng Guo,
            
              Yian Wang,
            
              Tianhao Wu,
            
              Qingnan Fan,
            
              Xuelin Chen,
            
              L. Guibas,
            
              Hao Dong,
            
          </td>
          <td>2021-06-28</td>
          <td>ArXiv</td>
          <td>50</td>
          <td>63</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/0d3fac8a5cb8036a779e8f13e588fc8199fd4bc9" target='_blank'>Neural Physicist: Learning Physical Dynamics from Image Sequences</a></td>
          <td>
            
              Baocheng Zhu,
            
              Shijun Wang,
            
              James Zhang,
            
          </td>
          <td>2020-06-09</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>10</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/f8998314ca38dcdc80afcf42f8234c54b46f4e7e" target='_blank'>Learning Multi-Object Dynamics with Compositional Neural Radiance Fields</a></td>
          <td>
            
              Danny Driess,
            
              Zhiao Huang,
            
              Yunzhu Li,
            
              Russ Tedrake,
            
              Marc Toussaint,
            
          </td>
          <td>2022-02-24</td>
          <td>ArXiv</td>
          <td>59</td>
          <td>65</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/b1a492c88f4f6c926b713f0880e6f95bd4d99dad" target='_blank'>Learning Manipulation under Physics Constraints with Visual Perception</a></td>
          <td>
            
              Wenbin Li,
            
              A. Leonardis,
            
              J. Bohg,
            
              Mario Fritz,
            
          </td>
          <td>2019-04-19</td>
          <td>ArXiv</td>
          <td>7</td>
          <td>64</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/addc813587a6e48b636789a2713d502984c647db" target='_blank'>Towards an Interpretable Latent Space in Structured Models for Video Prediction</a></td>
          <td>
            
              Rushil Gupta,
            
              Vishal Sharma,
            
              ,
            
              Yitao Liang,
            
              Guy Van den Broeck,
            
              Parag Singla,
            
          </td>
          <td>2021-07-16</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>37</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/e67e8500a00f2dd22537101fa76f2a60f7f1416f" target='_blank'>Learning Visual Dynamics Models of Rigid Objects using Relational Inductive Biases</a></td>
          <td>
            
              Fábio Ferreira,
            
              Lin Shao,
            
              T. Asfour,
            
              J. Bohg,
            
          </td>
          <td>2019-09-09</td>
          <td>ArXiv</td>
          <td>3</td>
          <td>53</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/b1fd132aafdacb1d778ff7f76624a97b22d5b8d3" target='_blank'>Learning Vision-Based Physics Intuition Models for Non-Disruptive Object Extraction</a></td>
          <td>
            
              Sarthak Ahuja,
            
              H. Admoni,
            
              Aaron Steinfeld,
            
          </td>
          <td>2020-10-24</td>
          <td>2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
          <td>0</td>
          <td>33</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/58efd506ba9f1ac80b2d44b3d04ad45da836fe5b" target='_blank'>Finite element inspired networks: Learning physically-plausible deformable object dynamics from partial observations</a></td>
          <td>
            
              Shamil Mamedov,
            
              A. R. Geist,
            
              J. Swevers,
            
              Sebastian Trimpe,
            
          </td>
          <td>None</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>51</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/ac975a749f5945d6eb0a42ece45e989073d65fff" target='_blank'>Structured World Belief for Reinforcement Learning in POMDP</a></td>
          <td>
            
              Gautam Singh,
            
              S. Peri,
            
              Junghyun Kim,
            
              Hyunseok Kim,
            
              Sungjin Ahn,
            
          </td>
          <td>2021-07-19</td>
          <td>None</td>
          <td>20</td>
          <td>14</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/e26997215e9b43a8867c0edbab8292615fbe6a34" target='_blank'>Visual Memory for Robust Path Following</a></td>
          <td>
            
              Ashish Kumar,
            
              Saurabh Gupta,
            
              D. Fouhey,
            
              S. Levine,
            
              Jitendra Malik,
            
          </td>
          <td>2018-12-03</td>
          <td>None</td>
          <td>41</td>
          <td>145</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/bbc9a5870c5ac5bd81a6677e0b35f4ea5e2312e1" target='_blank'>Learning to Recognize Reachable States from Visual Domains</a></td>
          <td>
            
              Ella S. Morgan,
            
              Christian Muise,
            
          </td>
          <td>2023-06-05</td>
          <td>Proceedings of the Canadian Conference on Artificial Intelligence</td>
          <td>0</td>
          <td>20</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/9e5ccf397837adf005533333d4f154ead78123ce" target='_blank'>Visual Assessment for Non-Disruptive Object Extraction</a></td>
          <td>
            
              Sarthak Ahuja,
            
              Oliver Kroemer,
            
              Senthil Purushwalkam,
            
              S. Prakash,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>33</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/5d9e55cd3919ccb62e7428a6e6909a9bb39885ff" target='_blank'>A Biologically-Inspired Dual Stream World Model</a></td>
          <td>
            
              Arthur Juliani,
            
              Margaret E. Sereno,
            
          </td>
          <td>2022-09-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>16</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/c03ca17b633f26c003b4f9c73a0c7fcbf8f6fff4" target='_blank'>Differentiable Blocks World: Qualitative 3D Decomposition by Rendering Primitives</a></td>
          <td>
            
              Tom Monnier,
            
              J. Austin,
            
              Angjoo Kanazawa,
            
              Alexei A. Efros,
            
              Mathieu Aubry,
            
          </td>
          <td>2023-07-11</td>
          <td>ArXiv</td>
          <td>6</td>
          <td>100</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/b9859bcf207a1f72353911d0ecc7ace160552360" target='_blank'>Transferable Environment Model With Disentangled Dynamics</a></td>
          <td>
            
              Qianyu Yan,
            
              Shangqi Guo,
            
              Dagui Chen,
            
              Zhile Yang,
            
              Feng Chen,
            
          </td>
          <td>None</td>
          <td>IEEE Access</td>
          <td>1</td>
          <td>6</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/a30fb7c390ab26114b0df4bec9a70bfadc8cbdb2" target='_blank'>Learning Modular Representations for Long-Term Multi-Agent Motion Predictions</a></td>
          <td>
            
              Todor Davchev,
            
              Michael Burke,
            
              S. Ramamoorthy,
            
          </td>
          <td>2019-11-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>23</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/fba7f7b8d606d1ef276a4f6256cdb5acfe37a337" target='_blank'>Visual Robot Task Planning</a></td>
          <td>
            
              Chris Paxton,
            
              Yotam Barnoy,
            
              Kapil D. Katyal,
            
              R. Arora,
            
              Gregory Hager,
            
          </td>
          <td>2018-03-30</td>
          <td>2019 International Conference on Robotics and Automation (ICRA)</td>
          <td>49</td>
          <td>76</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/f1ba488b092620a655ae48dfcf8fbd8d7e9afbe6" target='_blank'>DiMSam: Diffusion Models as Samplers for Task and Motion Planning under Partial Observability</a></td>
          <td>
            
              Xiaolin Fang,
            
              Caelan Reed Garrett,
            
              Clemens Eppner,
            
              Tomas Lozano-Perez,
            
              L. Kaelbling,
            
              D. Fox,
            
          </td>
          <td>2023-06-22</td>
          <td>ArXiv</td>
          <td>3</td>
          <td>120</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/4053a225b189852df0ef5d24bc5c400987778ac4" target='_blank'>Learning Long-term Visual Dynamics with Region Proposal Interaction Networks</a></td>
          <td>
            
              Haozhi Qi,
            
              Xiaolong Wang,
            
              Deepak Pathak,
            
              Yi Ma,
            
              J. Malik,
            
          </td>
          <td>2020-08-05</td>
          <td>ArXiv</td>
          <td>45</td>
          <td>46</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/19dd12ccc9c6997c9cecdaf12f937812066827aa" target='_blank'>Knowledge Transfer for Scene-Specific Motion Prediction</a></td>
          <td>
            
              Lamberto Ballan,
            
              F. Castaldo,
            
              Alexandre Alahi,
            
              F. Palmieri,
            
              S. Savarese,
            
          </td>
          <td>2016-03-22</td>
          <td>None</td>
          <td>105</td>
          <td>97</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/ade553725150104522d48032ee8a721546441ad7" target='_blank'>Go with the Flow: Perception-refined Physics Simulation</a></td>
          <td>
            
              Tom F. H. Runia,
            
              Kirill Gavrilyuk,
            
              Cees G. M. Snoek,
            
              A. Smeulders,
            
          </td>
          <td>2019-10-17</td>
          <td>ArXiv</td>
          <td>3</td>
          <td>64</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/c5306f6d7b76c5809baeeede7ee34d278573d3fb" target='_blank'>Supplementary Material: Physical Simulation Layer for Accurate 3D Modeling</a></td>
          <td>
            
              Mariem Mezghanni,
            
              M. Ovsjanikov,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>42</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/39e3b67edd0319ecfc3da8370a5ab20618b1cb0c" target='_blank'>MIRA: Mental Imagery for Robotic Affordances</a></td>
          <td>
            
              Yilun Du,
            
          </td>
          <td>2022-12-12</td>
          <td>None</td>
          <td>20</td>
          <td>33</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/00f08c464b63df753f7b1ae953f78c09ddf77e55" target='_blank'>Learning Robotic Manipulation of Granular Media</a></td>
          <td>
            
              Connor Schenck,
            
              Jonathan Tompson,
            
              S. Levine,
            
              D. Fox,
            
          </td>
          <td>2017-09-08</td>
          <td>None</td>
          <td>41</td>
          <td>145</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/4e67313238fc38da1ef6005611bd1b6b246af0b6" target='_blank'>Differentiable Dynamics for Articulated 3d Human Motion Reconstruction</a></td>
          <td>
            
              Erik Gartner,
            
              Mykhaylo Andriluka,
            
              Erwin Coumans,
            
              C. Sminchisescu,
            
          </td>
          <td>2022-05-24</td>
          <td>2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
          <td>24</td>
          <td>60</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/f400e4d0d8ff6ecfd4eca0549418ee65b54e740c" target='_blank'>Combining reinforcement learning with supervised deep learning for neural active scene understanding</a></td>
          <td>
            
              Dano Roost,
            
              Ralph Meier,
            
              G. T. Carughi,
            
              Thilo Stadelmann,
            
          </td>
          <td>2020-08-31</td>
          <td></td>
          <td>1</td>
          <td>18</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/3ad50d986a13c042f3346603bd2ddaf6bab400c8" target='_blank'>Position States Learning t t-1 t-2 t-3 pull push Velocity States Obs</a></td>
          <td>
            
              Rico Jonschkowski,
            
              Roland Hafner,
            
              Jonathan Scholz,
            
              Martin A. Riedmiller,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>52</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/ae5f9e6930b9357fd78459b1e285e1103569b6a7" target='_blank'>Object-centric Video Prediction without Annotation</a></td>
          <td>
            
              Karl Schmeckpeper,
            
              G. Georgakis,
            
              Kostas Daniilidis,
            
          </td>
          <td>2021-05-06</td>
          <td>2021 IEEE International Conference on Robotics and Automation (ICRA)</td>
          <td>6</td>
          <td>11</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/97dae983ea941b44fc6c7c6a4658ecaace5ea9f6" target='_blank'>High-Degrees-of-Freedom Dynamic Neural Fields for Robot Self-Modeling and Motion Planning</a></td>
          <td>
            
              Lennart Schulze,
            
              Hod Lipson,
            
          </td>
          <td>2023-10-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/52b67c48d3cece2930a6edd35ebed53d3ad00b7f" target='_blank'>Benchmarking Counterfactual Reasoning Abilities about Implicit Physical Properties</a></td>
          <td>
            
              Aykut Erdem,
            
              T. Goksun,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>1</td>
          <td>26</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/52b67c48d3cece2930a6edd35ebed53d3ad00b7f" target='_blank'>Benchmarking Counterfactual Reasoning Abilities about Implicit Physical Properties</a></td>
          <td>
            
              Aykut Erdem,
            
              T. Goksun,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>1</td>
          <td>26</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/0fda02b32b9f509a025d843f09d6824de9680335" target='_blank'>Factored World Models for Zero-Shot Generalization in Robotic Manipulation</a></td>
          <td>
            
              Ondrej Biza,
            
              Thomas Kipf,
            
              David Klee,
            
              Robert W. Platt,
            
              Jan-Willem van de Meent,
            
              Lawson L. S. Wong,
            
          </td>
          <td>2022-02-10</td>
          <td>ArXiv</td>
          <td>8</td>
          <td>25</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/625ea597c60f40668932a0639552cc0d3f0ec248" target='_blank'>Object-Oriented Dynamics Learning through Multi-Level Abstraction</a></td>
          <td>
            
              Guangxiang Zhu,
            
              Jianhao Wang,
            
              Zhizhou Ren,
            
              Chongjie Zhang,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>29</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/b0b51bf9267baf50c5b415bf9e206779228759db" target='_blank'>Filtered-CoPhy: Unsupervised Learning of Counterfactual Physics in Pixel Space</a></td>
          <td>
            
              Steeven Janny,
            
              Fabien Baradel,
            
              N. Neverova,
            
              M. Nadri,
            
              Greg Mori,
            
              Christian Wolf,
            
          </td>
          <td>2022-02-01</td>
          <td>ArXiv</td>
          <td>8</td>
          <td>56</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/ddc479b2767189b7dde78944cf0bdc190f6402d7" target='_blank'>Unsupervised Learning of Visual Structure using Predictive Generative Networks</a></td>
          <td>
            
              William Lotter,
            
              Gabriel Kreiman,
            
              David D. Cox,
            
          </td>
          <td>2015-11-19</td>
          <td>ArXiv</td>
          <td>126</td>
          <td>40</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/db16d53d3d370cbef93712516579ce7c30db7d36" target='_blank'>Counterfactual reasoning about intent for interactive navigation in dynamic environments</a></td>
          <td>
            
              Alejandro Bordallo,
            
              Fabio Previtali,
            
              Nantas Nardelli,
            
              S. Ramamoorthy,
            
          </td>
          <td>2015-12-17</td>
          <td>2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
          <td>25</td>
          <td>23</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/ad367b44f3434b9ba6b46b41ab083210f6827a9f" target='_blank'>Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning</a></td>
          <td>
            
              William Lotter,
            
              Gabriel Kreiman,
            
              David D. Cox,
            
          </td>
          <td>2016-05-25</td>
          <td>ArXiv</td>
          <td>838</td>
          <td>40</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/0bc3c06d64f2710baaff43b9cc2c34fe889fbc6e" target='_blank'>V ARIATIONAL M ODEL -B ASED I MITATION L EARNING IN H IGH -D IMENSIONAL O BSERVATION S PACES</a></td>
          <td>
            
              Rafael Rafailov,
            
              Tianhe Yu,
            
              A. Rajeswaran,
            
              Chelsea Finn,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>79</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/807b295ccb96fbcac4b1598bb25ee3c3b2bf0743" target='_blank'>DeformNet: Latent Space Modeling and Dynamics Prediction for Deformable Object Manipulation</a></td>
          <td>
            
              Chenchang Li,
            
              Zihao Ai,
            
              Tong Wu,
            
              Xiaosa Li,
            
              Wenbo Ding,
            
              Huazhe Xu,
            
          </td>
          <td>2024-02-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/c93873e8164174b1d7f514e25bd46ac20a85b351" target='_blank'>Multi-Abstractive Neural Controller: An Efficient Hierarchical Control Architecture for Interactive Driving</a></td>
          <td>
            
              Xiao Li,
            
              Igor Gilitschenski,
            
              G. Rosman,
            
              S. Karaman,
            
              D. Rus,
            
          </td>
          <td>2023-05-24</td>
          <td>IEEE Robotics and Automation Letters</td>
          <td>0</td>
          <td>119</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/ad367b44f3434b9ba6b46b41ab083210f6827a9f" target='_blank'>Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning</a></td>
          <td>
            
              William Lotter,
            
              Gabriel Kreiman,
            
              David D. Cox,
            
          </td>
          <td>2016-05-25</td>
          <td>ArXiv</td>
          <td>838</td>
          <td>40</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/571bae040916210633d3323c67a3bc1b76796ef0" target='_blank'>PIP: Physical Interaction Prediction via Mental Imagery with Span Selection</a></td>
          <td>
            
              Jiafei Duan,
            
              Samson Yu,
            
              Soujanya Poria,
            
              B. Wen,
            
              Cheston Tan,
            
          </td>
          <td>None</td>
          <td>ArXiv</td>
          <td>6</td>
          <td>64</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/73f959402b39929dbad93610436ca078262c0fbf" target='_blank'>Variational Causal Dynamics: Discovering Modular World Models from Interventions</a></td>
          <td>
            
              Anson Lei,
            
              B. Scholkopf,
            
              I. Posner,
            
          </td>
          <td>2022-06-22</td>
          <td>ArXiv</td>
          <td>3</td>
          <td>155</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/312f705fb76fa810464b12486c625c6fe6f5f1ac" target='_blank'>Learning Naive Physics by Visual Observation: Using Qualitative Spatial Representations and Probabilistic Reasoning</a></td>
          <td>
            
              P. A. Boxer,
            
          </td>
          <td>2001-09-01</td>
          <td>Int. J. Comput. Intell. Appl.</td>
          <td>2</td>
          <td>2</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/ccc3e5b4c9b391597282377fc6bf9401a7575fbe" target='_blank'>GenH2R: Learning Generalizable Human-to-Robot Handover via Scalable Simulation, Demonstration, and Imitation</a></td>
          <td>
            
              Zifan Wang,
            
              Junyu Chen,
            
              Ziqing Chen,
            
              Pengwei Xie,
            
              Rui Chen,
            
              Li Yi,
            
          </td>
          <td>2024-01-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/b4cd675a017b91e7e9f567e37cf8265449585472" target='_blank'>Towards Learning Naive Physics by Visual Observation: Qualitative Spatial Representations</a></td>
          <td>
            
              P. A. Boxer,
            
          </td>
          <td>2001-12-10</td>
          <td>None</td>
          <td>7</td>
          <td>2</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/eac753cc81b260b14a813df399f9b457a1ac28b3" target='_blank'>Physics-informed Reinforcement Learning for Perception and Reasoning about Fluids</a></td>
          <td>
            
              B. Moya,
            
              A. Badías,
            
              D. González,
            
              F. Chinesta,
            
              E. Cueto,
            
          </td>
          <td>None</td>
          <td>ArXiv</td>
          <td>3</td>
          <td>50</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/f8174da83188b4227af2afd5f7ad84a0f31e70c3" target='_blank'>Visual Prediction of Priors for Articulated Object Interaction</a></td>
          <td>
            
              Caris Moses,
            
              Michael Noseworthy,
            
              L. Kaelbling,
            
              Tomas Lozano-Perez,
            
              N. Roy,
            
          </td>
          <td>2020-05-01</td>
          <td>2020 IEEE International Conference on Robotics and Automation (ICRA)</td>
          <td>4</td>
          <td>72</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/f3be1302d03ddbdfbefa52e3c38019b5459f8dac" target='_blank'>Object Files and Schemata: Factorizing Declarative and Procedural Knowledge in Dynamical Systems</a></td>
          <td>
            
              Anirudh Goyal,
            
              Alex Lamb,
            
              Phanideep Gampa,
            
              Philippe Beaudoin,
            
              S. Levine,
            
              C. Blundell,
            
              Yoshua Bengio,
            
              M. Mozer,
            
          </td>
          <td>2020-06-29</td>
          <td>ArXiv</td>
          <td>62</td>
          <td>202</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/a68163dca89433f1ebd3f81ac58a482dd90174b3" target='_blank'>Motion Prediction Under Multimodality with Conditional Stochastic Networks</a></td>
          <td>
            
              Katerina Fragkiadaki,
            
              Jonathan Huang,
            
              Alexander A. Alemi,
            
              Sudheendra Vijayanarasimhan,
            
              Susanna Ricco,
            
              R. Sukthankar,
            
          </td>
          <td>2017-05-05</td>
          <td>ArXiv</td>
          <td>23</td>
          <td>61</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/6d2718d173b771edddbfae13ba8ec24c480363d3" target='_blank'>RoboTube: Learning Household Manipulation from Human Videos with Simulated Twin Environments</a></td>
          <td>
            
              Haoyu Xiong,
            
              Haoyuan Fu,
            
              Jieyi Zhang,
            
              Chen Bao,
            
              Qiang Zhang,
            
              Yongxi Huang,
            
              Wenqiang Xu,
            
              Animesh Garg,
            
              Cewu Lu,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>4</td>
          <td>49</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/a89fc944b2438c639e7b757ab1cf7a9d1566697a" target='_blank'>Physically Plausible Full-Body Hand-Object Interaction Synthesis</a></td>
          <td>
            
              Jona Braun,
            
              Sammy Christen,
            
              Muhammed Kocabas,
            
              Emre Aksan,
            
              Otmar Hilliges,
            
          </td>
          <td>2023-09-14</td>
          <td>ArXiv</td>
          <td>13</td>
          <td>26</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/af0ebef841b3b34b00fec375d841683c3a1f2a98" target='_blank'>Learning Shape, Motion and Elastic Models in Force Space</a></td>
          <td>
            
              Antonio Agudo,
            
              F. Moreno-Noguer,
            
          </td>
          <td>2015-12-07</td>
          <td>2015 IEEE International Conference on Computer Vision (ICCV)</td>
          <td>29</td>
          <td>43</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/1366799c0328fa9231f0b74a43e247441d537605" target='_blank'>Learning predictive models of a depth camera & manipulator from raw execution traces</a></td>
          <td>
            
              Byron Boots,
            
              Arunkumar Byravan,
            
              D. Fox,
            
          </td>
          <td>2014-09-29</td>
          <td>2014 IEEE International Conference on Robotics and Automation (ICRA)</td>
          <td>43</td>
          <td>120</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/7040e2a78bdb6ed01c237e52f0ace6c4f8608ba2" target='_blank'>Unsupervised Learning of Sensorimotor Affordances by Stochastic Future Prediction</a></td>
          <td>
            
              Oleh Rybkin,
            
              Karl Pertsch,
            
              Andrew Jaegle,
            
              K. Derpanis,
            
              Kostas Daniilidis,
            
          </td>
          <td>2018-06-25</td>
          <td>ArXiv</td>
          <td>6</td>
          <td>72</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/1b0399c455956a530475f517c09c0f1c26eb92c2" target='_blank'>Vid2Param: Online system identification from video for robotics applications</a></td>
          <td>
            
              Martin Asenov,
            
              Michael Burke,
            
              Daniel Angelov,
            
              Todor Davchev,
            
              Kartic Subr,
            
              S. Ramamoorthy,
            
          </td>
          <td>2019-07-15</td>
          <td>ArXiv</td>
          <td>5</td>
          <td>23</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/b98726c7c2006970366b84388f3fa18e8679eef8" target='_blank'>Probabilistic Programming Bots in Intuitive Physics Game Play</a></td>
          <td>
            
              Fahad Alhasoun,
            
              Sarah Alnegheimish,
            
              J. Tenenbaum,
            
          </td>
          <td>2021-04-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>122</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/a67326e9b3e9d1a85cc08bf5a5e198f44656eef1" target='_blank'>Enhancing Image-Based Rendering Through Intelligent Machine Learning: Realism, Immersion, and Future Directions</a></td>
          <td>
            
              Bheema Shanker Neyigapula,
            
          </td>
          <td>2023-07-05</td>
          <td>International Journal of Artificial Intelligence and Machine Learning</td>
          <td>0</td>
          <td>0</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/12750cfd6aa03e4ef24eabfd340550dd3be45355" target='_blank'>KeyTr: Keypoint Transporter for 3D Reconstruction of Deformable Objects in Videos</a></td>
          <td>
            
              David Novotný,
            
              Ignacio Rocco,
            
              Samarth Sinha,
            
              Alexandre Carlier,
            
              Gael Kerchenbaum,
            
              Roman Shapovalov,
            
              Nikita Smetanin,
            
              N. Neverova,
            
              Benjamin Graham,
            
              A. Vedaldi,
            
          </td>
          <td>2022-06-01</td>
          <td>2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
          <td>6</td>
          <td>95</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/72896b81330c687821263975a4e23ab9661f8c7c" target='_blank'>Mutual Information Maximization for Robust Plannable Representations</a></td>
          <td>
            
              Yiming Ding,
            
              I. Clavera,
            
              P. Abbeel,
            
          </td>
          <td>2019-09-25</td>
          <td>ArXiv</td>
          <td>14</td>
          <td>143</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/13a1d20381ef248068a881ebab27d1fe60cf3228" target='_blank'>Shadow puppetry</a></td>
          <td>
            
              M. Brand,
            
          </td>
          <td>1999-09-20</td>
          <td>Proceedings of the Seventh IEEE International Conference on Computer Vision</td>
          <td>254</td>
          <td>35</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/edb6a9d85721e2158f60aac89894da144e1fe941" target='_blank'>Learning to Represent Mechanics via Long-term Extrapolation and Interpolation</a></td>
          <td>
            
              Sébastien Ehrhardt,
            
              Áron Monszpart,
            
              A. Vedaldi,
            
              N. Mitra,
            
          </td>
          <td>2017-06-06</td>
          <td>ArXiv</td>
          <td>7</td>
          <td>95</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/55d68f4268a4bbe4558acacb05210864a65b38c7" target='_blank'>Edinburgh Research Explorer Learning Direct Optimization for scene understanding</a></td>
          <td>
            
              Lukasz Romaszko,
            
              Christopher K. I. Williams,
            
              J. Winn,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>7</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/898efd8b3d5bf76d4fbd0dcec342358214d6c812" target='_blank'>Physics informed neural fields for smoke reconstruction with sparse data</a></td>
          <td>
            
              Mengyu Chu,
            
              Lingjie Liu,
            
              Q. Zheng,
            
              Erik Franz,
            
              H. Seidel,
            
              C. Theobalt,
            
              Rhaleb Zayer,
            
          </td>
          <td>2022-06-14</td>
          <td>ACM Transactions on Graphics (TOG)</td>
          <td>24</td>
          <td>108</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/a32a93b1b03b266e32cc6b900d862c8cf813b9fa" target='_blank'>Active View Planning for Radiance Fields</a></td>
          <td>
            
              Kevin Lin,
            
              Brent Yi,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>6</td>
          <td>27</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/4f9ffac70c1129ef2aa1a5def83ec13f211a28d4" target='_blank'>Monocular depth perception and robotic grasping of novel objects</a></td>
          <td>
            
              A. Ng,
            
              Ashutosh Saxena,
            
          </td>
          <td>None</td>
          <td></td>
          <td>22</td>
          <td>126</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/07cf239db20908b18227648df28cefda640806c5" target='_blank'>Learning Object-Oriented Dynamics for Planning from Text</a></td>
          <td>
            
              Guiliang Liu,
            
              Ashutosh Adhikari,
            
              A. Farahmand,
            
              P. Poupart,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>7</td>
          <td>45</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/3d5fc85076191a74f946907a47bd6be9634163ec" target='_blank'>Trajectory Optimization for Physics-Based Reconstruction of 3d Human Pose from Monocular Video</a></td>
          <td>
            
              Erik Gärtner,
            
              Mykhaylo Andriluka,
            
              Hongyi Xu,
            
              C. Sminchisescu,
            
          </td>
          <td>2022-05-24</td>
          <td>2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
          <td>23</td>
          <td>60</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/026aea53a0364cec7769c79c7508876e32f8ac6e" target='_blank'>GraMMaR: Ground-aware Motion Model for 3D Human Motion Reconstruction</a></td>
          <td>
            
              Sihan Ma,
            
              Qiong Cao,
            
              Hongwei Yi,
            
              Jing Zhang,
            
              Dacheng Tao,
            
          </td>
          <td>2023-06-29</td>
          <td>Proceedings of the 31st ACM International Conference on Multimedia</td>
          <td>2</td>
          <td>23</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/7a753f09a817c17bc7d1e02440e60046226baf9b" target='_blank'>Image based view synthesis of articulated agents</a></td>
          <td>
            
              Martin Jagersand,
            
          </td>
          <td>1997-06-17</td>
          <td>Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition</td>
          <td>13</td>
          <td>9</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/7c399773001dc47de23038f4eb1f822bb6a11131" target='_blank'>Grounding Physical Concepts of Objects and Events Through Dynamic Visual Reasoning</a></td>
          <td>
            
              Zhenfang Chen,
            
              Jiayuan Mao,
            
              Jiajun Wu,
            
              Kwan-Yee Kenneth Wong,
            
              J. Tenenbaum,
            
              Chuang Gan,
            
          </td>
          <td>2021-03-30</td>
          <td>ArXiv</td>
          <td>77</td>
          <td>122</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/183dee7aba4ca4814502d0dfa48704d7c00e166c" target='_blank'>OmniPush : accurate , diverse , real-world dataset of pushing dynamics with RGBD images</a></td>
          <td>
            
              Maria Bauzá,
            
              Ferran Alet,
            
              Tomas Lozano-Perez,
            
              L. Kaelbling,
            
              Alberto Rodriguez,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>6</td>
          <td>68</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/57542739d3e2ccf29cd10bbce1fb9a3b291bfd57" target='_blank'>Cut-and-Approximate: 3D Shape Reconstruction from Planar Cross-sections with Deep Reinforcement Learning</a></td>
          <td>
            
              Azimkhon Ostonov,
            
          </td>
          <td>2022-10-22</td>
          <td>ArXiv</td>
          <td>3</td>
          <td>3</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/d295db274b50cdfffa5ca47fbffd8fb26ad7178e" target='_blank'>Modeling the visual world: reconstruction and neural episodic representation</a></td>
          <td>
            
              Nikolay Savinov,
            
          </td>
          <td>None</td>
          <td></td>
          <td>0</td>
          <td>15</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/aa237d7876a32c9bb5249c767febc4dfc35ea03d" target='_blank'>DronePose: Photorealistic UAV-Assistant Dataset Synthesis for 3D Pose Estimation via a Smooth Silhouette Loss</a></td>
          <td>
            
              G. Albanis,
            
              N. Zioulis,
            
              A. Dimou,
            
              D. Zarpalas,
            
              P. Daras,
            
          </td>
          <td>2020-08-20</td>
          <td>None</td>
          <td>7</td>
          <td>27</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/fef821f373189d2cf875ce1ba6b693b8bc05307a" target='_blank'>Out of Sight, Still in Mind: Reasoning and Planning about Unobserved Objects with Video Tracking Enabled Memory Models</a></td>
          <td>
            
              Yixuan Huang,
            
              Jialin Yuan,
            
              Chanho Kim,
            
              Pupul Pradhan,
            
              Bryan Chen,
            
              Fuxin Li,
            
              Tucker Hermans,
            
          </td>
          <td>2023-09-26</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>27</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/84e1a9ad6cf27ffe69b37c65f28e319c7b3accbd" target='_blank'>Dynamic Manipulation of Deformable Objects using Imitation Learning with Adaptation to Hardware Constraints</a></td>
          <td>
            
              Eric Hannus,
            
              Tran Nguyen Le,
            
              David Blanco Mulero,
            
              Ville Kyrki,
            
          </td>
          <td>2024-03-19</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/a86fe34e17cfc4847a39ab54a2f3adda534eb43d" target='_blank'>MaskViT: Masked Visual Pre-Training for Video Prediction</a></td>
          <td>
            
              Agrim Gupta,
            
              Stephen Tian,
            
              Yunzhi Zhang,
            
              Jiajun Wu,
            
              Roberto Mart'in-Mart'in,
            
              Li Fei-Fei,
            
          </td>
          <td>2022-06-23</td>
          <td>ArXiv</td>
          <td>84</td>
          <td>129</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/83bf96cab13ae8228b395f43a7d1633f5098a2b6" target='_blank'>Learning Latent Dynamics for Autonomous Shape Control of Deformable Object</a></td>
          <td>
            
              Huimin Lu,
            
              Yadong Teng,
            
              Yujie Li,
            
          </td>
          <td>2023-11-01</td>
          <td>IEEE Transactions on Intelligent Transportation Systems</td>
          <td>13</td>
          <td>9</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/ea358ab37d4d1a931371559e3e6a9829af7a6881" target='_blank'>Learning Direct Optimization for Scene Understanding</a></td>
          <td>
            
              Lukasz Romaszko,
            
              Christopher K. I. Williams,
            
              J. Winn,
            
          </td>
          <td>2018-12-18</td>
          <td>ArXiv</td>
          <td>7</td>
          <td>50</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/fe7070d209612678a87b86bc6342ec88e6bf4e90" target='_blank'>A thermodynamics-informed active learning approach to perception and reasoning about fluids</a></td>
          <td>
            
              B. Moya,
            
              A. Badías,
            
              D. González,
            
              F. Chinesta,
            
              E. Cueto,
            
          </td>
          <td>2022-03-11</td>
          <td>Computational Mechanics</td>
          <td>4</td>
          <td>50</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/df1d5aeea4beecbc925dc9c3e89f1891c38886d1" target='_blank'>Learning Social Affordance for Human-Robot Interaction</a></td>
          <td>
            
              Tianmin Shu,
            
              M. Ryoo,
            
              Song-Chun Zhu,
            
          </td>
          <td>2016-04-13</td>
          <td>ArXiv</td>
          <td>57</td>
          <td>84</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/67a462fd5c8f20846df0d1a8cfedac70d5678a50" target='_blank'>Combining self-supervised learning and imitation for vision-based rope manipulation</a></td>
          <td>
            
              Ashvin Nair,
            
              Dian Chen,
            
              Pulkit Agrawal,
            
              Phillip Isola,
            
              P. Abbeel,
            
              Jitendra Malik,
            
              S. Levine,
            
          </td>
          <td>2017-03-06</td>
          <td>2017 IEEE International Conference on Robotics and Automation (ICRA)</td>
          <td>270</td>
          <td>145</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/bc822c6e333ada7ccdac29f25cf0e0e9c0596143" target='_blank'>Multimodal Conditional Learning with Fast Thinking Policy-like Model and Slow Thinking Planner-like Model</a></td>
          <td>
            
              Jianwen Xie,
            
              Zilong Zheng,
            
              Xiaolin Fang,
            
              Song-Chun Zhu,
            
              Y. Wu,
            
          </td>
          <td>2019-02-07</td>
          <td>ArXiv</td>
          <td>4</td>
          <td>84</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/e61f725c27729cdfde1385adb95671e4ec22957f" target='_blank'>NARF22: Neural Articulated Radiance Fields for Configuration-Aware Rendering</a></td>
          <td>
            
              Stanley Lewis,
            
              Jana Pavlasek,
            
              O. C. Jenkins,
            
          </td>
          <td>2022-10-03</td>
          <td>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
          <td>2</td>
          <td>35</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/fc715a1aac98fd5f5609e8fae16905ec3b85a057" target='_blank'>Benchmarking Deformable Object Manipulation with Differentiable Physics</a></td>
          <td>
            
              Siwei Chen,
            
              Yiqing Xu,
            
              Cunjun Yu,
            
              Linfeng Li,
            
              Xiao Ma,
            
              Zhongwen Xu,
            
              David Hsu,
            
          </td>
          <td>2022-10-24</td>
          <td>ArXiv</td>
          <td>9</td>
          <td>50</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/e702a1620a9dc75c9c3d262c07641a0ef1bfbac3" target='_blank'>Contact and Human Dynamics from Monocular Video</a></td>
          <td>
            
              Davis Rempe,
            
              L. Guibas,
            
              Aaron Hertzmann,
            
              Bryan C. Russell,
            
              Ruben Villegas,
            
              Jimei Yang,
            
          </td>
          <td>2020-07-22</td>
          <td>None</td>
          <td>79</td>
          <td>64</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/6efd6d20b6f3613828ecd576030c1467ee820d68" target='_blank'>SNeRL: Semantic-aware Neural Radiance Fields for Reinforcement Learning</a></td>
          <td>
            
              D. Shim,
            
              Seungjae Lee,
            
              H. J. Kim,
            
          </td>
          <td>2023-01-27</td>
          <td>ArXiv</td>
          <td>10</td>
          <td>5</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/458fa7e578f54573ce313308b215b7d8e0abe33a" target='_blank'>Neural Implicit Representations for Physical Parameter Inference from a Single Video</a></td>
          <td>
            
              F. Hofherr,
            
              Lukas Koestler,
            
              Florian Bernard,
            
              D. Cremers,
            
          </td>
          <td>2022-04-29</td>
          <td>2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</td>
          <td>4</td>
          <td>102</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/edcf7fd9cb17dfd9f6e6d6e97620b31cd7613a8d" target='_blank'>Vision-Only Robot Navigation in a Neural Radiance World</a></td>
          <td>
            
              M. Adamkiewicz,
            
              Timothy Chen,
            
              Adam Caccavale,
            
              Rachel Gardner,
            
              Preston Culbertson,
            
              J. Bohg,
            
              M. Schwager,
            
          </td>
          <td>2021-10-01</td>
          <td>IEEE Robotics and Automation Letters</td>
          <td>135</td>
          <td>49</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/d47c7483a4cc45e2a63e710f566f9fef8bd0390c" target='_blank'>Tracking human motion and actions for interactive robots</a></td>
          <td>
            
              O. C. Jenkins,
            
              Germán González Serrano,
            
              M. Loper,
            
          </td>
          <td>2007-03-10</td>
          <td>2007 2nd ACM/IEEE International Conference on Human-Robot Interaction (HRI)</td>
          <td>36</td>
          <td>35</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/cee48dd6d6c68f05a7d105bec9f7ace2d71aace2" target='_blank'>DISeR: Designing Imaging Systems with Reinforcement Learning</a></td>
          <td>
            
              Tzofi Klinghoffer,
            
              Kushagra Tiwary,
            
              Nikhil Behari,
            
              B. Agrawalla,
            
              R. Raskar,
            
          </td>
          <td>2023-09-25</td>
          <td>2023 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
          <td>1</td>
          <td>7</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/1d3091fa4ceb3198a87b61a4b6dc7d77add820ec" target='_blank'>GEOMETRY-AWARE RECURRENT NETWORKS</a></td>
          <td>
            
              H. Tung,
            
              Ricson Cheng,
            
              Katerina Fragkiadaki,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>24</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/49e2e6f316cadeba3d2013fb60584fad2121f106" target='_blank'>Human dynamics from monocular video with dynamic camera movements</a></td>
          <td>
            
              R. Yu,
            
              Hwangpil Park,
            
              Jehee Lee,
            
          </td>
          <td>2021-12-01</td>
          <td>ACM Transactions on Graphics (TOG)</td>
          <td>25</td>
          <td>35</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/c360c3f6d57e6dede93b00aa3d9cc0d2791a86c8" target='_blank'>PHASE: PHysically-grounded Abstract Social Events for Machine Social Perception</a></td>
          <td>
            
              Aviv Netanyahu,
            
              Tianmin Shu,
            
              B. Katz,
            
              Andrei Barbu,
            
              J. Tenenbaum,
            
          </td>
          <td>2021-03-02</td>
          <td>ArXiv</td>
          <td>23</td>
          <td>122</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/4cc71edd2f09095ffa490d8ef835639f3146de4d" target='_blank'>Binding Vision to Physics Based Simulation: The Case Study of a Bouncing Ball</a></td>
          <td>
            
              Nikolaos Kyriazis,
            
              I. Oikonomidis,
            
              Antonis A. Argyros,
            
          </td>
          <td>None</td>
          <td></td>
          <td>6</td>
          <td>39</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/510b5f11bf1ea270f8cc33f6b16e15102bb2ee3d" target='_blank'>Learning Physics Constrained Dynamics Using Autoencoders</a></td>
          <td>
            
              Tsung-Yen Yang,
            
              Justinian P. Rosca,
            
              Karthik Narasimhan,
            
              Peter J. Ramadge,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>8</td>
          <td>29</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/46ec629b2c6c350b84fda012bab32303cd7d6466" target='_blank'>Causal Discovery for Modular World Models</a></td>
          <td>
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>4</td>
          <td>0</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/14d01d5fb15914f05da79046a041fb0370c607db" target='_blank'>3D-PhysNet: Learning the Intuitive Physics of Non-Rigid Object Deformations</a></td>
          <td>
            
              Zhihua Wang,
            
              Stefano Rosa,
            
              Bo Yang,
            
              Sen Wang,
            
              A. Trigoni,
            
              A. Markham,
            
          </td>
          <td>2018-04-25</td>
          <td>ArXiv</td>
          <td>25</td>
          <td>47</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/f4a0006ca411f102833b5b73248d23fc51086180" target='_blank'>Neural Predictive Belief Representations</a></td>
          <td>
            
              Z. Guo,
            
              M. G. Azar,
            
              Bilal Piot,
            
              B. '. Pires,
            
              Tobias Pohlen,
            
              R. Munos,
            
          </td>
          <td>2018-09-27</td>
          <td>ArXiv</td>
          <td>72</td>
          <td>80</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/9c0a3a77ea580a3a9e5a5ad7fc8d286e6eaa6e13" target='_blank'>Rapid Physical Predictions from Convolutional Neural Networks</a></td>
          <td>
            
              Filipe Peres,
            
              Kevin A. Smith,
            
              J. Tenenbaum,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>122</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/a820fe802e05391f8f94f6f87516fdaede0c407f" target='_blank'>DITTO: Demonstration Imitation by Trajectory Transformation</a></td>
          <td>
            
              Nick Heppert,
            
              Max Argus,
            
              Tim Welschehold,
            
              Thomas Brox,
            
              A. Valada,
            
          </td>
          <td>2024-03-22</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>9</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/e928f07457a5e51a320ad4e78436da01e9f62c28" target='_blank'>Symmetry and complexity in object-centric deep active inference models</a></td>
          <td>
            
              Stefano Ferraro,
            
              Toon Van de Maele,
            
              Tim Verbelen,
            
              B. Dhoedt,
            
          </td>
          <td>2023-04-14</td>
          <td>Interface Focus</td>
          <td>5</td>
          <td>44</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/1af67fb5c15470c9e8954cae66702293dd66bae8" target='_blank'>Learning Joint Top-Down and Bottom-up Processes for 3D Visual Inference</a></td>
          <td>
            
              C. Sminchisescu,
            
              Atul Kanaujia,
            
              Dimitris N. Metaxas,
            
          </td>
          <td>2006-06-17</td>
          <td>2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)</td>
          <td>119</td>
          <td>97</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/111422116fe0559f3ba2174c949f816ee6d084b8" target='_blank'>Rendering Humans from Object-Occluded Monocular Videos</a></td>
          <td>
            
              Tiange Xiang,
            
              Adam Sun,
            
              Jiajun Wu,
            
              E. Adeli,
            
              Li Fei-Fei,
            
          </td>
          <td>2023-08-08</td>
          <td>2023 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
          <td>2</td>
          <td>129</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/7265e6e13c3af731d92bbfb98827baa3dd690d45" target='_blank'>Attention, please: A Spatio-temporal Transformer for 3D Human Motion Prediction</a></td>
          <td>
            
              Emre Aksan,
            
              Peng Cao,
            
              Manuel Kaufmann,
            
              Otmar Hilliges,
            
          </td>
          <td>2020-04-18</td>
          <td>ArXiv</td>
          <td>28</td>
          <td>26</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/2fd0bee708cadd35e78adfe699b1e36276167c6a" target='_blank'>Generative models for action generation and action understanding</a></td>
          <td>
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>0</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/5f241981e3e7b1e4053284078e5c25592664794f" target='_blank'>Physical simulation for probabilistic motion tracking</a></td>
          <td>
            
              Marek Vondrak,
            
              L. Sigal,
            
              O. C. Jenkins,
            
          </td>
          <td>2008-06-23</td>
          <td>2008 IEEE Conference on Computer Vision and Pattern Recognition</td>
          <td>140</td>
          <td>53</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/160e7f5eb68104feee2c3fb696af8c43718e4ac5" target='_blank'>19th on Robots and Vision</a></td>
          <td>
            
              L. Agapito,
            
              M. Fallon,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>1</td>
          <td>38</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/d134e420a6007a95a7248221d3379adaf568ab0d" target='_blank'>Plan2Vec: Unsupervised Representation Learning by Latent Plans</a></td>
          <td>
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>0</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/3f0fbb00375e952a0526dce0e1cded9c2d0c0f4b" target='_blank'>Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D</a></td>
          <td>
            
              Hao-zhe Huang,
            
              Owen Howell,
            
              Xu Zhu,
            
              Dian Wang,
            
              R. Walters,
            
              Robert Platt,
            
          </td>
          <td>2024-01-22</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>15</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/fd711b836d649f837e72d75b29a989c08d2c0411" target='_blank'>Learning deep observation models for factor graph inference</a></td>
          <td>
            
              Paloma Sodhi,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>10</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/672ef260934caae5ac3ebb91ea151165e2de52ec" target='_blank'>CAMM: Building Category-Agnostic and Animatable 3D Models from Monocular Videos</a></td>
          <td>
            
              Tianshu Kuai,
            
              Akash Karthikeyan,
            
              Yash Kant,
            
              Ashkan Mirzaei,
            
              Igor Gilitschenski,
            
          </td>
          <td>2023-04-14</td>
          <td>2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</td>
          <td>2</td>
          <td>27</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/68b50cc7431a37fb063239f49800711528bb686e" target='_blank'>Sensory Anticipation of Optical Flow in Mobile Robotics</a></td>
          <td>
            
              A. Ribes,
            
              J. Cerquides,
            
              Y. Demiris,
            
              R. L. D. Mántaras,
            
          </td>
          <td>2012-10-03</td>
          <td>ArXiv</td>
          <td>2</td>
          <td>40</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/bab1c6eaf32c8c97efa33344a88039ca5f863eb5" target='_blank'>Human-Aware Object Placement for Visual Environment Reconstruction</a></td>
          <td>
            
              Hongwei Yi,
            
              C. Huang,
            
              Dimitrios Tzionas,
            
              Muhammed Kocabas,
            
              Mohamed Hassan,
            
              Siyu Tang,
            
              Justus Thies,
            
              Michael J. Black,
            
          </td>
          <td>2022-03-07</td>
          <td>2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
          <td>45</td>
          <td>122</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/a6ba31c87f4f346965300c2c0015f7e7cbedf434" target='_blank'>Compositional Law Parsing with Latent Random Functions</a></td>
          <td>
            
              Fan Shi,
            
              Bin Li,
            
              Xiangyang Xue,
            
          </td>
          <td>2022-09-15</td>
          <td>ArXiv</td>
          <td>4</td>
          <td>13</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/2e7d4e82b6efb2e756750cd66b70ec74d23fc4e4" target='_blank'>Efficient Human Motion Reconstruction from Monocular Videos with Physical Consistency Loss</a></td>
          <td>
            
              Lin Cong,
            
              Philipp Ruppel,
            
              Yizhou Wang,
            
              Xiang Pan,
            
              N. Hendrich,
            
              Jianwei Zhang,
            
          </td>
          <td>2023-12-10</td>
          <td>SIGGRAPH Asia 2023 Conference Papers</td>
          <td>1</td>
          <td>16</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/c0351c1319f308c9ef0c0992bcde23d3718be26c" target='_blank'>Learning Kinematic Machine Models from Videos</a></td>
          <td>
            
              Lucas Thies,
            
              M. Stamminger,
            
              F. Bauer,
            
          </td>
          <td>2020-12-01</td>
          <td>2020 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)</td>
          <td>0</td>
          <td>32</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/e881cc29a647bf5f0c9edcbd710ef56e3e2b2a7a" target='_blank'>CRIPP-VQA: Counterfactual Reasoning about Implicit Physical Properties via Video Question Answering</a></td>
          <td>
            
              Maitreya Patel,
            
              Tejas Gokhale,
            
              Chitta Baral,
            
              Yezhou Yang,
            
          </td>
          <td>2022-11-07</td>
          <td>ArXiv</td>
          <td>4</td>
          <td>19</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/7799534072f3b40bca444442def2b6671a1e32bd" target='_blank'>Causal Discovery in Physical Systems from Videos</a></td>
          <td>
            
              Yunzhu Li,
            
              A. Torralba,
            
              Anima Anandkumar,
            
              D. Fox,
            
              Animesh Garg,
            
          </td>
          <td>2020-07-01</td>
          <td>ArXiv</td>
          <td>91</td>
          <td>126</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/8319a62ed2168196d794e6166e40b6de7ddba346" target='_blank'>Embodied Scene-aware Human Pose Estimation</a></td>
          <td>
            
              Zhengyi Luo,
            
              Shun Iwase,
            
              Ye Yuan,
            
              Kris Kitani,
            
          </td>
          <td>2022-06-18</td>
          <td>ArXiv</td>
          <td>15</td>
          <td>41</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/2b5f51588f1c4cdca0865de20c1e2e1ff3570fd1" target='_blank'>Attend, Infer, Repeat: Fast Scene Understanding with Generative Models</a></td>
          <td>
            
              S. Eslami,
            
              N. Heess,
            
              T. Weber,
            
              Yuval Tassa,
            
              David Szepesvari,
            
              K. Kavukcuoglu,
            
              Geoffrey E. Hinton,
            
          </td>
          <td>2016-03-28</td>
          <td>ArXiv</td>
          <td>502</td>
          <td>157</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/1a2160f703867e41d14b2e3d6df0611f41c6363c" target='_blank'>Directional Semantic Grasping of Real-World Objects: From Simulation to Reality</a></td>
          <td>
            
              Shariq Iqbal,
            
              Jonathan Tremblay,
            
              Thang To,
            
              Jia Cheng,
            
              Erik Leitch,
            
              Andy Campbell,
            
              Kirby Leung,
            
              Duncan McKay,
            
              Stan Birchfield,
            
          </td>
          <td>2019-09-04</td>
          <td>ArXiv</td>
          <td>4</td>
          <td>46</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/26dc7a63c0660d6861de980f26a53c7fc2ee0d5f" target='_blank'>Look Ma, No Hands! Agent-Environment Factorization of Egocentric Videos</a></td>
          <td>
            
              Matthew Chang,
            
              Aditya Prakash,
            
              Saurabh Gupta,
            
          </td>
          <td>2023-05-25</td>
          <td>ArXiv</td>
          <td>4</td>
          <td>25</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/4a4dcb9a455e07b8795318d0a4795e574204c172" target='_blank'>Learning Internal Representations of 3D Transformations from 2D Projected Inputs</a></td>
          <td>
            
              Marissa Connor,
            
              B. Olshausen,
            
              C. Rozell,
            
          </td>
          <td>2023-03-31</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>50</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/e542a7803e6e59c6a60b937b829ac439fa9770c2" target='_blank'>Fast Motion Understanding with Spatiotemporal Neural Networks and Dynamic Vision Sensors</a></td>
          <td>
            
              Anthony Bisulco,
            
              F. Ojeda,
            
              Volkan Isler,
            
              Daniel D. Lee,
            
          </td>
          <td>2020-11-18</td>
          <td>2021 IEEE International Conference on Robotics and Automation (ICRA)</td>
          <td>4</td>
          <td>38</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/55a063830be615e2b676c34fe78ced5018485d53" target='_blank'>Modeling human intuitions about liquid flow with particle-based simulation</a></td>
          <td>
            
              Christopher Bates,
            
              Ilker Yildirim,
            
              J. Tenenbaum,
            
              P. Battaglia,
            
          </td>
          <td>2018-09-05</td>
          <td>PLoS Computational Biology</td>
          <td>44</td>
          <td>122</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/3b92bdfdf5d8d65fb5691fee954e4c7cb54909a0" target='_blank'>Symbolic Pregression: Discovering Physical Laws from Raw Distorted Video</a></td>
          <td>
            
              S. Udrescu,
            
              Max Tegmark,
            
          </td>
          <td>2020-05-19</td>
          <td>Physical review. E</td>
          <td>32</td>
          <td>80</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/a7680e975d395891522d3c10e3bf892f9b618048" target='_blank'>Vision-Based Multi-Task Manipulation for Inexpensive Robots Using End-to-End Learning from Demonstration</a></td>
          <td>
            
              Rouhollah Rahmatizadeh,
            
              P. Abolghasemi,
            
              Ladislau Bölöni,
            
              S. Levine,
            
          </td>
          <td>2017-07-10</td>
          <td>2018 IEEE International Conference on Robotics and Automation (ICRA)</td>
          <td>226</td>
          <td>145</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/0163d12ff0eb9d0b017da502f8b637fc242f7667" target='_blank'>MotioNet</a></td>
          <td>
            
              Mingyi Shi,
            
              Kfir Aberman,
            
              A. Aristidou,
            
              T. Komura,
            
              D. Lischinski,
            
              D. Cohen-Or,
            
              Baoquan Chen,
            
          </td>
          <td>2020-06-22</td>
          <td>ACM Transactions on Graphics (TOG)</td>
          <td>66</td>
          <td>104</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/0163d12ff0eb9d0b017da502f8b637fc242f7667" target='_blank'>MotioNet</a></td>
          <td>
            
              Mingyi Shi,
            
              Kfir Aberman,
            
              A. Aristidou,
            
              T. Komura,
            
              D. Lischinski,
            
              D. Cohen-Or,
            
              Baoquan Chen,
            
          </td>
          <td>2020-06-22</td>
          <td>ACM Transactions on Graphics (TOG)</td>
          <td>66</td>
          <td>104</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/8c71b2a8d622463f17ee1e38b71e1bc5296174fd" target='_blank'>Learning Intuitive Physics with Multimodal Generative Models</a></td>
          <td>
            
              S. Rezaei-Shoshtari,
            
              F. Hogan,
            
              M. Jenkin,
            
              D. Meger,
            
              Gregory Dudek,
            
          </td>
          <td>2021-01-12</td>
          <td>None</td>
          <td>8</td>
          <td>37</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/84effcd6231cd9d1e39767491403045c98abc3c1" target='_blank'>Bidirectional Model Learning for Visual Inference</a></td>
          <td>
            
              C. Sminchisescu,
            
              Atul Kanaujia,
            
              Dimitris N. Metaxas,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>60</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/b9dd7a59a101fcecc6fe0e7aed517e84a7df7d2e" target='_blank'>Learning Physical Intuition of Block Towers by Example</a></td>
          <td>
            
              Adam Lerer,
            
              Sam Gross,
            
              R. Fergus,
            
          </td>
          <td>2016-03-03</td>
          <td>ArXiv</td>
          <td>284</td>
          <td>73</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/c3eb68738dc491708c6443bad12a345bd6921ff8" target='_blank'>TeachMe: Three-phase learning framework for robotic motion imitation based on interactive teaching and reinforcement learning</a></td>
          <td>
            
              Taewoo Kim,
            
              Joo-Haeng Lee,
            
          </td>
          <td>2019-10-01</td>
          <td>2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)</td>
          <td>1</td>
          <td>10</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/5c306ce578a8da634a4a64fce282a48d0eacfda1" target='_blank'>Approximate Bayesian Image Interpretation using Generative Probabilistic Graphics Programs</a></td>
          <td>
            
              Vikash K. Mansinghka,
            
              Tejas D. Kulkarni,
            
              Yura N. Perov,
            
              J. Tenenbaum,
            
          </td>
          <td>2013-06-28</td>
          <td>ArXiv</td>
          <td>105</td>
          <td>122</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/157f77a508c1645a2609c9b265391e9d1bfa95e4" target='_blank'>Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics</a></td>
          <td>
            
              Ken Kansky,
            
              Tom Silver,
            
              David A. Mély,
            
              Mohamed Eldawy,
            
              M. Lázaro-Gredilla,
            
              Xinghua Lou,
            
              N. Dorfman,
            
              Szymon Sidor,
            
              Scott Phoenix,
            
              Dileep George,
            
          </td>
          <td>2017-06-14</td>
          <td>ArXiv</td>
          <td>218</td>
          <td>20</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/2b39bcfca5f7dac199632e384692ef669ef2157f" target='_blank'>A Spatio-temporal Transformer for 3D Human Motion Prediction</a></td>
          <td>
            
              Emre Aksan,
            
              Peng Cao,
            
              Manuel Kaufmann,
            
              Otmar Hilliges,
            
          </td>
          <td>2020-04-18</td>
          <td>2021 International Conference on 3D Vision (3DV)</td>
          <td>145</td>
          <td>26</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/d0eaba9317690ebb98e8d54a137de5bf8e8d39dc" target='_blank'>3D Human Pose Estimation via Intuitive Physics</a></td>
          <td>
            
              Shashank Tripathi,
            
              Lea Muller,
            
              C. Huang,
            
              Omid Taheri,
            
              Michael J. Black,
            
              Dimitrios Tzionas,
            
          </td>
          <td>2023-03-31</td>
          <td>2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
          <td>26</td>
          <td>122</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/188ab311ef518ac996c5277f4878e3dfa5d1f5d6" target='_blank'>Perceiving Physical Equation by Observing Visual Scenarios</a></td>
          <td>
            
              Siyu Huang,
            
              Zhi-Qi Cheng,
            
              Xi Li,
            
              Xiao Wu,
            
              Zhongfei Zhang,
            
              Alexander Hauptmann,
            
          </td>
          <td>2018-11-29</td>
          <td>ArXiv</td>
          <td>7</td>
          <td>80</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/e274c5a5af1fc9e363eac6f4d4b7bfb996b590d8" target='_blank'>A Visually-Grounded Library of Behaviors for Learning to Manipulate Diverse Objects across Diverse Conﬁgurations and Views</a></td>
          <td>
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>0</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/2d72e239fb7ce5c5e875e1a249c0bb24801c07b8" target='_blank'>Joint Estimation of Image Representations and their Lie Invariants</a></td>
          <td>
            
              Christine Allen-Blanchette,
            
              Kostas Daniilidis,
            
          </td>
          <td>2020-12-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>72</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/183ed9d2f5a89af06a34d8f3fe3bf049809c4c48" target='_blank'>Action Generative Networks Planning for Deformable Object with Raw Observations</a></td>
          <td>
            
              Ziqi Sheng,
            
              Kebing Jin,
            
              Zhihao Ma,
            
              Hankui Zhuo,
            
          </td>
          <td>2021-07-01</td>
          <td>Sensors (Basel, Switzerland)</td>
          <td>0</td>
          <td>17</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/ed62a56b81511d7fcf6d247014987163d9668982" target='_blank'>"What Happens If..." Learning to Predict the Effect of Forces in Images</a></td>
          <td>
            
              Roozbeh Mottaghi,
            
              Mohammad Rastegari,
            
              A. Gupta,
            
              Ali Farhadi,
            
          </td>
          <td>2016-03-17</td>
          <td>None</td>
          <td>116</td>
          <td>88</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/bd557bad9dba2bc4adcceb86403d54983815540a" target='_blank'>Auto-conditioned Recurrent Mixture Density Networks for Complex Trajectory Generation</a></td>
          <td>
            
              Hejia Zhang,
            
              Eric Heiden,
            
              Ryan C. Julian,
            
              Zhangpeng He,
            
              Joseph J. Lim,
            
              G. Sukhatme,
            
          </td>
          <td>2018-09-29</td>
          <td>ArXiv</td>
          <td>3</td>
          <td>90</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/97bb907a3f75f3f9df838f5f3896bd6243a2db40" target='_blank'>A Comparative Evaluation of Approximate Probabilistic Simulation and Deep Neural Networks as Accounts of Human Physical Scene Understanding</a></td>
          <td>
            
              Renqiao Zhang,
            
              Jiajun Wu,
            
              Chengkai Zhang,
            
              W. Freeman,
            
              J. Tenenbaum,
            
          </td>
          <td>2016-05-04</td>
          <td>ArXiv</td>
          <td>48</td>
          <td>122</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/13d6585962fd165f6e6bf5f9fda0f0d73d7128f5" target='_blank'>Creatures great and SMAL: Recovering the shape and motion of animals from video</a></td>
          <td>
            
              Benjamin Biggs,
            
              Thomas Roddick,
            
              A. Fitzgibbon,
            
              R. Cipolla,
            
          </td>
          <td>2018-11-14</td>
          <td>None</td>
          <td>83</td>
          <td>84</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/861897df39716877fb1e03a7d09a234faca076e9" target='_blank'>Learning Low-Level Vision</a></td>
          <td>
            
              W. T. Freeman,
            
              E. Pasztor,
            
              Owen T. Carmichael,
            
          </td>
          <td>1999-09-20</td>
          <td>International Journal of Computer Vision</td>
          <td>1774</td>
          <td>8</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/d5987b0ddbe11cff32e7c8591b2b829127849a31" target='_blank'>Learning Partially Contracting Dynamical Systems from Demonstrations</a></td>
          <td>
            
              H. Ravichandar,
            
              Iman Salehi,
            
              Ashwin P. Dani,
            
          </td>
          <td>2017-10-18</td>
          <td>None</td>
          <td>51</td>
          <td>18</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/5fbd89355f19598d068318c1b2af33ccf4441dc9" target='_blank'>Neural monocular 3D human motion capture with physical awareness</a></td>
          <td>
            
              Soshi Shimada,
            
              Vladislav Golyanik,
            
              Weipeng Xu,
            
              P. P'erez,
            
              C. Theobalt,
            
          </td>
          <td>2021-05-03</td>
          <td>ACM Transactions on Graphics (TOG)</td>
          <td>65</td>
          <td>96</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/769346d6a5fac8e9ae4b27c48b7f0ba8504e348f" target='_blank'>Anticipating Noxious States from Visual Cues using Deep Predictive Models</a></td>
          <td>
            
              Indranil Sur,
            
              H. B. Amor,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>27</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/f993962202d6cf2b12e7a75f6d642ec7eb86469b" target='_blank'>Learning from Demonstration using a Curvature Regularized Variational Auto-Encoder (CurvVAE)</a></td>
          <td>
            
              Travers Rhodes,
            
              T. Bhattacharjee,
            
              Daniel D. Lee,
            
          </td>
          <td>2022-10-23</td>
          <td>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
          <td>0</td>
          <td>21</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/8497b602d9b0372d84623411802b90418fc2806f" target='_blank'>Inferring human intent from video by sampling hierarchical plans</a></td>
          <td>
            
              Steven Holtzen,
            
              Yibiao Zhao,
            
              Tao Gao,
            
              J. Tenenbaum,
            
              Song-Chun Zhu,
            
          </td>
          <td>2016-10-01</td>
          <td>2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
          <td>32</td>
          <td>122</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/267ec67d3d1b8295d937ee05870b643065ebcaf5" target='_blank'>Disentangling Dynamics and Content for Control and Planning</a></td>
          <td>
            
              Ershad Banijamali,
            
              Ahmad Khajenezhad,
            
              A. Ghodsi,
            
              M. Ghavamzadeh,
            
          </td>
          <td>2017-11-24</td>
          <td>ArXiv</td>
          <td>2</td>
          <td>56</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/722bb232f1c9bfe016807b0633793ee9194fe39f" target='_blank'>A modular approach to learning manipulation strategies from human demonstration</a></td>
          <td>
            
              Bidan Huang,
            
              Miao Li,
            
              R. D. Souza,
            
              J. Bryson,
            
              A. Billard,
            
          </td>
          <td>2015-10-05</td>
          <td>Autonomous Robots</td>
          <td>27</td>
          <td>73</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/fc61a6ea3fee5ca03771902d2aa7c0efa084efb5" target='_blank'>Contextual RNN-GANs for Abstract Reasoning Diagram Generation</a></td>
          <td>
            
              Viveka Kulharia,
            
              Arna Ghosh,
            
              A. Mukerjee,
            
              Vinay P. Namboodiri,
            
              Mohit Bansal,
            
          </td>
          <td>2016-09-29</td>
          <td>None</td>
          <td>36</td>
          <td>67</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/e04f086c60214ab0d0f7ec827c0d3b0e0794d13e" target='_blank'>IntPhys: A Benchmark for Visual Intuitive Physics Reasoning</a></td>
          <td>
            
              Ronan Riochet,
            
              M. Castro,
            
              Mathieu Bernard,
            
              Adam Lerer,
            
              R. Fergus,
            
              Véronique Izard,
            
              Emmanuel Dupoux,
            
          </td>
          <td>2019-08-29</td>
          <td></td>
          <td>6</td>
          <td>73</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/bec1902f7198261ffde4cc875fb330dacfff8431" target='_blank'>Unsupervised Causal Generative Understanding of Images</a></td>
          <td>
            
              Titas Anciukevicius,
            
              P. Fox-Roberts,
            
              E. Rosten,
            
              Paul Henderson,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>4</td>
          <td>15</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/0705a08a0e84ceffb9d2075c7871bee4e9bdb1d7" target='_blank'>Incorporating physics into data-driven computer vision</a></td>
          <td>
            
              A. Kadambi,
            
              Celso de Melo,
            
              Cho-Jui Hsieh,
            
              Mani Srivastava,
            
              Stefano Soatto,
            
          </td>
          <td>2023-06-01</td>
          <td>Nature Machine Intelligence</td>
          <td>6</td>
          <td>82</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/4169028b6620b0aa985daaa7e74979e731c78550" target='_blank'>Approximate inference for planning in stochastic relational worlds</a></td>
          <td>
            
              Tobias Lang,
            
              Marc Toussaint,
            
          </td>
          <td>2009-06-14</td>
          <td>None</td>
          <td>21</td>
          <td>45</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/d3e0ba47c70ee6ee05865f9baeba9d8fdf2b4ee9" target='_blank'>Structure from Articulated Motion: Accurate and Stable Monocular 3D Reconstruction without Training Data</a></td>
          <td>
            
              Onorina Kovalenko,
            
              Vladislav Golyanik,
            
              J. Malik,
            
              Ahmed Elhayek,
            
              D. Stricker,
            
          </td>
          <td>2019-05-12</td>
          <td>Sensors (Basel, Switzerland)</td>
          <td>14</td>
          <td>43</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/e0c2db93e1aa2c9f089423390169cb60bc175ba3" target='_blank'>ComPhy: Compositional Physical Reasoning of Objects and Events from Videos</a></td>
          <td>
            
              Zhenfang Chen,
            
              Kexin Yi,
            
              Yunzhu Li,
            
              Mingyu Ding,
            
              A. Torralba,
            
              J. Tenenbaum,
            
              Chuang Gan,
            
          </td>
          <td>2022-05-02</td>
          <td>ArXiv</td>
          <td>34</td>
          <td>126</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/24346fd2106e0743033420c90d4944bcbc9f9c9d" target='_blank'>IntPhys: A Framework and Benchmark for Visual Intuitive Physics Reasoning</a></td>
          <td>
            
              Ronan Riochet,
            
              M. Castro,
            
              Mathieu Bernard,
            
              Adam Lerer,
            
              Rob Fergus,
            
              Véronique Izard,
            
              Emmanuel Dupoux,
            
          </td>
          <td>2018-03-20</td>
          <td>ArXiv</td>
          <td>2</td>
          <td>66</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/11afc89d8d41134913695e93f29d950a0fb7e4dc" target='_blank'>Reasoning about Objects under Full Occlusion by Shraman Ray Chaudhuri</a></td>
          <td>
            
              Ray Chaudhuri,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>0</td>
          <td>1</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/768bbf84700cb31cf9a264a96494d647015c9d78" target='_blank'>Distilling Governing Laws and Source Input for Dynamical Systems from Videos</a></td>
          <td>
            
              Lele Luan,
            
              Yang Liu,
            
              ,
            
          </td>
          <td>2022-05-03</td>
          <td>ArXiv</td>
          <td>3</td>
          <td>59</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/a6aad9ccdcb7674a3b7ab710f0a80d205834f847" target='_blank'>Learning Symbolic Physics with Graph Networks</a></td>
          <td>
            
              M. Cranmer,
            
              Rui Xu,
            
              P. Battaglia,
            
              S. Ho,
            
          </td>
          <td>2019-09-12</td>
          <td>ArXiv</td>
          <td>73</td>
          <td>68</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/384adb0d8c44801d276e7dfe625fa564ca755268" target='_blank'>Visually Debugging Restricted Boltzmann Machine Training with a 3D Example</a></td>
          <td>
            
              J. Yosinski,
            
              H. Lipson,
            
          </td>
          <td>None</td>
          <td></td>
          <td>22</td>
          <td>29</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/6551c77fd3a99b3ea00bdc54075357c8cc5a2150" target='_blank'>IFR-Explore: Learning Inter-object Functional Relationships in 3D Indoor Scenes</a></td>
          <td>
            
              Qi Li,
            
              Kaichun Mo,
            
              Yanchao Yang,
            
              Hang Zhao,
            
              L. Guibas,
            
          </td>
          <td>2021-12-10</td>
          <td>ArXiv</td>
          <td>4</td>
          <td>63</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/04d00e90eb614214b54d40ca77fb9b6d65d39d33" target='_blank'>PhysCap</a></td>
          <td>
            
              Soshi Shimada,
            
              Vladislav Golyanik,
            
              Weipeng Xu,
            
              C. Theobalt,
            
          </td>
          <td>2020-08-20</td>
          <td>ACM Transactions on Graphics (TOG)</td>
          <td>62</td>
          <td>96</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/b0c01ebb0f4c0c333c9693d1a3b123a153bde956" target='_blank'>VideoMocap: modeling physically realistic human motion from monocular video sequences</a></td>
          <td>
            
              Xiaolin K. Wei,
            
              Jinxiang Chai,
            
          </td>
          <td>2010-07-26</td>
          <td>ACM SIGGRAPH 2010 papers</td>
          <td>112</td>
          <td>37</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/0bb9845d252e67714a6fa62a6e6abdc1caf4ab08" target='_blank'>The "Inverse Hollywood Problem": From Video to Scripts and Storyboards via Causal Analysis</a></td>
          <td>
            
              M. Brand,
            
          </td>
          <td>1997-07-27</td>
          <td>None</td>
          <td>47</td>
          <td>35</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/fdb9569402673fd3542de7fae7d6949ab127f29c" target='_blank'>Toddler-inspired embodied vision for learning object representations</a></td>
          <td>
            
              A. Aubret,
            
              Céline Teulière,
            
              J. Triesch,
            
          </td>
          <td>2022-09-12</td>
          <td>2022 IEEE International Conference on Development and Learning (ICDL)</td>
          <td>2</td>
          <td>38</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/479aa780fb2568e6ddd9a86e7e651806e7474c2a" target='_blank'>Intrinsic Motivation Driven Intuitive Physics Learning using Deep Reinforcement Learning with Intrinsic Reward Normalization</a></td>
          <td>
            
              Jae-Woo Choi,
            
              Sung-eui Yoon,
            
          </td>
          <td>2019-07-06</td>
          <td>ArXiv</td>
          <td>2</td>
          <td>35</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/429d1826f8afe7572df849209428b920787a8473" target='_blank'>Object-centered Fourier Motion Estimation and Segment-Transformation Prediction</a></td>
          <td>
            
              M. Wolter,
            
              Angela Yao,
            
              Sven Behnke,
            
          </td>
          <td>None</td>
          <td>None</td>
          <td>2</td>
          <td>53</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/8e5c84e82c3f18b82840d8639b20d7cadafd9532" target='_blank'>Variational framework for partially-measured physical system control: examples of vision neuroscience and optical random media</a></td>
          <td>
            
              Babak Rahmani,
            
              D. Psaltis,
            
              C. Moser,
            
          </td>
          <td>2021-10-25</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>82</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/5fde129a851f9aafd889fda28606afc6cd7c00f1" target='_blank'>Autonomous learning of active multi-scale binocular vision</a></td>
          <td>
            
              L. Lonini,
            
              Yu Zhao,
            
              Pramod Chandrashekhariah,
            
              Bertram E. Shi,
            
              J. Triesch,
            
          </td>
          <td>2013-11-04</td>
          <td>2013 IEEE Third Joint International Conference on Development and Learning and Epigenetic Robotics (ICDL)</td>
          <td>26</td>
          <td>38</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/152736ca9eea3a673e2e5ef67b9bb548fb80a2a4" target='_blank'>Transporting Real World Rigid and Articulated Objects into Egocentric VR Experiences</a></td>
          <td>
            
              Catherine Taylor,
            
              Robin McNicholas,
            
              D. Cosker,
            
          </td>
          <td>2020-03-01</td>
          <td>2020 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)</td>
          <td>1</td>
          <td>23</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/baf30d47e034aed0570b63aec10f63ce77404e9b" target='_blank'>R2-Diff: Denoising by diffusion as a refinement of retrieved motion for image-based motion prediction</a></td>
          <td>
            
              Takeru Oba,
            
              N. Ukita,
            
          </td>
          <td>2023-06-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>22</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/dcd4ed645e123e175de618b6229b13e30609533a" target='_blank'>MPI-Video infrastructure for dynamic environments</a></td>
          <td>
            
              J. Boyd,
            
              Edward Hunter,
            
              P. Kelly,
            
              Li-Cheng Tai,
            
              C. B. Phillips,
            
              R. Jain,
            
          </td>
          <td>1998-06-28</td>
          <td>Proceedings. IEEE International Conference on Multimedia Computing and Systems (Cat. No.98TB100241)</td>
          <td>32</td>
          <td>47</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/d1906639c1b2258bc379971b604b06e705c23ee4" target='_blank'>Bidirectional Interaction between Visual and Motor Generative Models using Predictive Coding and Active Inference</a></td>
          <td>
            
              Louis Annabi,
            
              Alexandre Pitti,
            
              M. Quoy,
            
          </td>
          <td>2021-04-19</td>
          <td>Neural networks : the official journal of the International Neural Network Society</td>
          <td>9</td>
          <td>19</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/186089ae7d259677ce28e3c1eb05426ee1da9042" target='_blank'>Geometric Pose Affordance: 3D Human Pose with Scene Constraints</a></td>
          <td>
            
              Zhe Wang,
            
              Liyan Chen,
            
              Shaurya Rathore,
            
              Daeyun Shin,
            
              Charless C. Fowlkes,
            
          </td>
          <td>2019-05-19</td>
          <td>ArXiv</td>
          <td>47</td>
          <td>51</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/a7b148c0366d4beb7d878394fc6973060f0ade9c" target='_blank'>Interpretable Latent Spaces for Learning from Demonstration</a></td>
          <td>
            
              Yordan V. Hristov,
            
              A. Lascarides,
            
              S. Ramamoorthy,
            
          </td>
          <td>2018-07-17</td>
          <td>ArXiv</td>
          <td>21</td>
          <td>37</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/19eb007afbca03ac97fb78d00445d70303f326c4" target='_blank'>Controlling by Showing: i-Mimic: A Video-Based Method to Control Robotic Arms</a></td>
          <td>
            
              D. Chakraborty,
            
              Mukesh Sharma,
            
              Bhaskar Vijay,
            
          </td>
          <td>2021-01-27</td>
          <td>SN Computer Science</td>
          <td>0</td>
          <td>8</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/34b29308f1fdd0f408f92f6f86f09cdd8eae6554" target='_blank'>Neurocomputational Modeling of Human Physical Scene Understanding</a></td>
          <td>
            
              Ilker Yildirim,
            
              Kevin A. Smith,
            
              M. Belledonne,
            
              Jiajun Wu,
            
              J. Tenenbaum,
            
          </td>
          <td>None</td>
          <td></td>
          <td>13</td>
          <td>122</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/6a94075510e566c20727bfca8e0f4d26c087b8e8" target='_blank'>Efficient Generation of Motion Plans from Attribute-Based Natural Language Instructions Using Dynamic Constraint Mapping</a></td>
          <td>
            
              Jae Sung Park,
            
              Biao Jia,
            
              Mohit Bansal,
            
              Dinesh Manocha,
            
          </td>
          <td>2017-07-08</td>
          <td>2019 International Conference on Robotics and Automation (ICRA)</td>
          <td>9</td>
          <td>5</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/77abcc278c19009cb69e35bb2826d3fcbaa74733" target='_blank'>Geometric Pose Affordance: Monocular 3D Human Pose Estimation with Scene Constraints</a></td>
          <td>
            
              Zhe Wang,
            
              Liyan Chen,
            
              Shaurya Rathore,
            
              Daeyun Shin,
            
              Charless C. Fowlkes,
            
          </td>
          <td>2019-05-19</td>
          <td>None</td>
          <td>0</td>
          <td>51</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/26feb9f513d883434ab03e14a118f80f3bd74a06" target='_blank'>From Scratch to Sketch: Deep Decoupled Hierarchical Reinforcement Learning for Robotic Sketching Agent</a></td>
          <td>
            
              Ganghun Lee,
            
              Minji Kim,
            
              M. Lee,
            
              Byoung-Tak Zhang,
            
          </td>
          <td>2022-05-23</td>
          <td>2022 International Conference on Robotics and Automation (ICRA)</td>
          <td>6</td>
          <td>43</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/7c240ad2952c52e9601523a2c195e4c527cb14bf" target='_blank'>Learning to Manipulate Tools by Aligning Simulation to Video Demonstration</a></td>
          <td>
            
              Kateryna Zorina,
            
              Justin Carpentier,
            
              Josef Sivic,
            
              Vladim'ir Petr'ik,
            
          </td>
          <td>2021-11-04</td>
          <td>IEEE Robotics and Automation Letters</td>
          <td>5</td>
          <td>73</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/07822949406197bec0090085e55dc7761295c7a8" target='_blank'>WHAM: Reconstructing World-grounded Humans with Accurate 3D Motion</a></td>
          <td>
            
              Soyong Shin,
            
              Juyong Kim,
            
              Eni Halilaj,
            
              Michael J. Black,
            
          </td>
          <td>2023-12-12</td>
          <td>ArXiv</td>
          <td>4</td>
          <td>15</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/949688b991491e2acff7c4fee9fd8e6da0369ca9" target='_blank'>IntPhys 2019: A Benchmark for Visual Intuitive Physics Understanding</a></td>
          <td>
            
              Ronan Riochet,
            
              M. Castro,
            
              Mathieu Bernard,
            
              Adam Lerer,
            
              Rob Fergus,
            
              Véronique Izard,
            
              Emmanuel Dupoux,
            
          </td>
          <td>2021-05-26</td>
          <td>IEEE Transactions on Pattern Analysis and Machine Intelligence</td>
          <td>13</td>
          <td>66</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/de05a8a61edcf76a6384ddaa6f588fa234608150" target='_blank'>Gravity-Aware Monocular 3D Human-Object Reconstruction</a></td>
          <td>
            
              Rishabh Dabral,
            
              Soshi Shimada,
            
              Arjun Jain,
            
              C. Theobalt,
            
              Vladislav Golyanik,
            
          </td>
          <td>2021-08-19</td>
          <td>2021 IEEE/CVF International Conference on Computer Vision (ICCV)</td>
          <td>25</td>
          <td>96</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/4d7ea339013143530c6c61f9eb93259cb84e5b96" target='_blank'>Gaussian-Dirichlet Random Fields for Inference over High Dimensional Categorical Observations</a></td>
          <td>
            
              J. E. S. Soucie,
            
              H. Sosik,
            
              Yogesh A. Girdhar,
            
          </td>
          <td>2020-03-26</td>
          <td>2020 IEEE International Conference on Robotics and Automation (ICRA)</td>
          <td>3</td>
          <td>35</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/ff5a30d2f0dc3fd45a52f35bc228b9ee33b9892e" target='_blank'>A Brain-Inspired Approach for Collision-Free Movement Planning in the Small Operational Space</a></td>
          <td>
            
              Dengpeng Xing,
            
              Jiale Li,
            
              Tielin Zhang,
            
              Bo Xu,
            
          </td>
          <td>2021-09-14</td>
          <td>IEEE Transactions on Neural Networks and Learning Systems</td>
          <td>3</td>
          <td>15</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/3e92cf47967946ee66eca66c487473e16b79b4c1" target='_blank'>Background subtraction using the factored 3-way restricted Boltzmann machines</a></td>
          <td>
            
              Soonam Lee,
            
              Daekeun Kim,
            
          </td>
          <td>2018-02-05</td>
          <td>ArXiv</td>
          <td>7</td>
          <td>12</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/c9be43603c133fb61143481dc7af59653130c579" target='_blank'>Scenic: a language for scenario specification and scene generation</a></td>
          <td>
            
              Daniel J. Fremont,
            
              T. Dreossi,
            
              Shromona Ghosh,
            
              Xiangyu Yue,
            
              A. Sangiovanni-Vincentelli,
            
              S. Seshia,
            
          </td>
          <td>2018-09-25</td>
          <td>Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation</td>
          <td>188</td>
          <td>101</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/813a16796dd3229613b586bc729b04ce1245361a" target='_blank'>Grounding Predicates through Actions</a></td>
          <td>
            
              Toki Migimatsu,
            
              J. Bohg,
            
          </td>
          <td>2021-09-29</td>
          <td>2022 International Conference on Robotics and Automation (ICRA)</td>
          <td>17</td>
          <td>41</td>
        </tr>
    
        <tr>
          <td><a href="https://www.semanticscholar.org/paper/fd13384efeae1506586d6490618966c017330b17" target='_blank'>Smoothing of human movements recorded by a single RGB-D camera for robot demonstrations</a></td>
          <td>
            
              M. Dagioglou,
            
              Athanasios C. Tsitos,
            
              Aristeidis Smarnakis,
            
              V. Karkaletsis,
            
          </td>
          <td>2021-06-29</td>
          <td>Proceedings of the 14th PErvasive Technologies Related to Assistive Environments Conference</td>
          <td>4</td>
          <td>32</td>
        </tr>
    
  </tbody>
  <tfoot>
    <tr>
        <th>Title</th>
        <th>Authors</th>
        <th>Publication Date</th>
        <th>Journal/Conference</th>
        <th>Citation count</th>
        <th>Highest h-index</th>
    </tr>
  </tfoot>
  </table>
  </p>

</body>

<script>
var dataTableOptions = {
        initComplete: function () {
        this.api()
            .columns()
            .every(function () {
                let column = this;
 
                // Create select element
                let select = document.createElement('select');
                select.add(new Option(''));
                column.footer().replaceChildren(select);
 
                // Apply listener for user change in value
                select.addEventListener('change', function () {
                    column
                        .search(select.value, {exact: true})
                        .draw();
                });

                // keep the width of the select element same as the column
                select.style.width = '100%';
 
                // Add list of options
                column
                    .data()
                    .unique()
                    .sort()
                    .each(function (d, j) {
                        select.add(new Option(d));
                    });
            });
    },
    scrollX: true,
    scrollCollapse: true,
    paging: true,
    fixedColumns: true,
    // columnDefs: [
    //     {"className": "dt-center", "targets": "_all"},
    //     // set width for both columns 0 and 1 as 25%
    //     { width: '40%', targets: 4 }

    //   ],
    pageLength: 10,
    layout: {
        topStart: {
            buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
        }
    }
  }
  new DataTable('#table1', dataTableOptions);
</script>
</html>