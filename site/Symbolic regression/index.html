<!DOCTYPE html>

<html lang="en">


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../Time-series%20forecasting/">
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.12">
    
    
<title>Literature Survey (VPE)</title>

    
      <link rel="stylesheet" href="../assets/stylesheets/main.7e359304.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
  <!-- Add scripts that need to run before here -->
  <!-- Add jquery script -->
  <script src="https://code.jquery.com/jquery-3.7.1.js"></script>
  <!-- Add data table libraries -->
  <script src="https://cdn.datatables.net/2.0.1/js/dataTables.js"></script>
  <link rel="stylesheet" href="https://cdn.datatables.net/2.0.1/css/dataTables.dataTables.css">
  <!-- Load plotly.js into the DOM -->
	<script src='https://cdn.plot.ly/plotly-2.29.1.min.js'></script>
  <link rel="stylesheet" href="https://cdn.datatables.net/buttons/3.0.1/css/buttons.dataTables.css">
  <!-- fixedColumns -->
  <script src="https://cdn.datatables.net/fixedcolumns/5.0.0/js/dataTables.fixedColumns.js"></script>
  <script src="https://cdn.datatables.net/fixedcolumns/5.0.0/js/fixedColumns.dataTables.js"></script>
  <link rel="stylesheet" href="https://cdn.datatables.net/fixedcolumns/5.0.0/css/fixedColumns.dataTables.css">
  <!-- Already specified in mkdocs.yml -->
  <!-- <link rel="stylesheet" href="../docs/custom.css"> -->
  <script src="https://cdn.datatables.net/buttons/3.0.1/js/dataTables.buttons.js"></script>
  <script src="https://cdn.datatables.net/buttons/3.0.1/js/buttons.dataTables.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.1/jszip.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdfmake/0.2.7/pdfmake.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdfmake/0.2.7/vfs_fonts.js"></script>
  <script src="https://cdn.datatables.net/buttons/3.0.1/js/buttons.html5.min.js"></script>
  <script src="https://cdn.datatables.net/buttons/3.0.1/js/buttons.print.min.js"></script>
  <!-- Google fonts -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
  <!-- Intro.js -->
  <script src="https://cdn.jsdelivr.net/npm/intro.js@7.2.0/intro.min.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/intro.js@7.2.0/minified/introjs.min.css">


  <!-- 
      
     -->
  <!-- Add scripts that need to run afterwards here -->

    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../custom.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="black">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Literature Survey (VPE)" class="md-header__button md-logo" aria-label="Literature Survey (VPE)" data-md-component="logo">
      
  <img src="../assets/VPE.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Literature Survey (VPE)
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Symbolic regression
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="black"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="white" data-md-color-accent="black"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/VirtualPatientEngine/literatureSurvey" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    VPE/LiteratureSurvey
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href=".." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../Time-series%20forecasting/" class="md-tabs__link">
        
  
    
  
  Time-series forecasting

      </a>
    </li>
  

      
        
  
  
    
  
  
    <li class="md-tabs__item md-tabs__item--active">
      <a href="./" class="md-tabs__link">
        
  
    
  
  Symbolic regression

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
                
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" hidden>
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Literature Survey (VPE)" class="md-nav__button md-logo" aria-label="Literature Survey (VPE)" data-md-component="logo">
      
  <img src="../assets/VPE.png" alt="logo">

    </a>
    Literature Survey (VPE)
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/VirtualPatientEngine/literatureSurvey" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    VPE/LiteratureSurvey
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Time-series%20forecasting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Time-series forecasting
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Symbolic regression
  </span>
  

      </a>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
                
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>Symbolic regression</h1>

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
</head>

<body>
  <p>
  <i class="footer">This page was last updated on 2025-11-03 06:14:49 UTC</i>
  </p>

  <div class="note info" onclick="startIntro()">
    <p>
      <button type="button" class="buttons">
        <div style="display: flex; align-items: center;">
        Click here for a quick intro of the page! <i class="material-icons">help</i>
        </div>
      </button>
    </p>
  </div>

  <!--
  <div data-intro='Table of contents'>
    <p>
    <h3>Table of Contents</h3>
      <a href="#plot1">1. Citations over time on Symbolic regression</a><br>
      <a href="#manually_curated_articles">2. Manually curated articles on Symbolic regression</a><br>
      <a href="#recommended_articles">3. Recommended articles on Symbolic regression</a><br>
    <p>
  </div>

  <div data-intro='Plot displaying number of citations over time 
                  on the given topic based on recommended articles'>
    <p>
    <h3 id="plot1">1. Citations over time on Symbolic regression</h3>
      <div id='myDiv1'>
      </div>
    </p>
  </div>
  -->

  <div data-intro='Manually curated articles on the given topic'>
    <p>
    <h3 id="manually_curated_articles">Manually curated articles on <i>Symbolic regression</i></h3>
    <table id="table1" class="display" style="width:100%">
    <thead>
      <tr>
          <th data-intro='Click to view the abstract (if available)'>Abstract</th>
          <th>Title</th>
          <th>Authors</th>
          <th>Publication Date</th>
          <th>Journal/ Conference</th>
          <th>Citation count</th>
          <th data-intro='Highest h-index among the authors'>Highest h-index</th>
          <th data-intro='Recommended articles extracted by considering
                          only the given article'>
              View recommendations
              </th>
      </tr>
    </thead>
    <tbody>

        <tr id="Significance Understanding dynamic constraints and balances in nature has facilitated rapid development of knowledge and enabled technology, including aircraft, combustion engines, satellites, and electrical power. This work develops a novel framework to discover governing equations underlying a dynamical system simply from data measurements, leveraging advances in sparsity techniques and machine learning. The resulting models are parsimonious, balancing model complexity with descriptive ability while avoiding overfitting. There are many critical data-driven problems, such as understanding cognition from neural recordings, inferring climate patterns, determining stability of financial markets, predicting and suppressing the spread of disease, and controlling turbulence for greener transportation and energy. With abundant data and elusive laws, data-driven discovery of dynamics will continue to play an important role in these efforts. Extracting governing equations from data is a central challenge in many diverse areas of science and engineering. Data are abundant whereas models often remain elusive, as in climate science, neuroscience, ecology, finance, and epidemiology, to name only a few examples. In this work, we combine sparsity-promoting techniques and machine learning with nonlinear dynamical systems to discover governing equations from noisy measurement data. The only assumption about the structure of the model is that there are only a few important terms that govern the dynamics, so that the equations are sparse in the space of possible functions; this assumption holds for many physical systems in an appropriate basis. In particular, we use sparse regression to determine the fewest terms in the dynamic governing equations required to accurately represent the data. This results in parsimonious models that balance accuracy with model complexity to avoid overfitting. We demonstrate the algorithm on a wide range of problems, from simple canonical systems, including linear and nonlinear oscillators and the chaotic Lorenz system, to the fluid vortex shedding behind an obstacle. The fluid example illustrates the ability of this method to discover the underlying dynamics of a system that took experts in the community nearly 30 years to resolve. We also show that this method generalizes to parameterized systems and systems that are time-varying or have external forcing.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5d150cec2775f9bc863760448f14104cc8f42368" target='_blank'>
                Discovering governing equations from data by sparse identification of nonlinear dynamical systems
                </a>
              </td>
          <td>
            S. Brunton, J. Proctor, J. Kutz
          </td>
          <td>2015-09-11</td>
          <td>Proceedings of the National Academy of Sciences, Proceedings of the National Academy of Sciences of the United States of America</td>
          <td>4250</td>
          <td>74</td>

            <td><a href='../recommendations/5d150cec2775f9bc863760448f14104cc8f42368' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Machine learning offers an intriguing alternative to first-principle analysis for discovering new physics from experimental data. However, to date, purely data-driven methods have only proven successful in uncovering physical laws describing simple, low-dimensional systems with low levels of noise. Here we demonstrate that combining a data-driven methodology with some general physical principles enables discovery of a quantitatively accurate model of a non-equilibrium spatially extended system from high-dimensional data that is both noisy and incomplete. We illustrate this using an experimental weakly turbulent fluid flow where only the velocity field is accessible. We also show that this hybrid approach allows reconstruction of the inaccessible variables – the pressure and forcing field driving the flow. Reinbold et al. propose a physics-informed data-driven approach that successfully discovers a dynamical model using high-dimensional, noisy and incomplete experimental data describing a weakly turbulent fluid flow. This approach is relevant to other non-equilibrium spatially-extended systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/60d0d998fa038182b3b69a57adb9b2f82d40589c" target='_blank'>
                Robust learning from noisy, incomplete, high-dimensional experimental data via physically constrained symbolic regression
                </a>
              </td>
          <td>
            Patrick A. K. Reinbold, Logan Kageorge, M. Schatz, R. Grigoriev
          </td>
          <td>2021-02-24</td>
          <td>Nature Communications</td>
          <td>122</td>
          <td>25</td>

            <td><a href='../recommendations/60d0d998fa038182b3b69a57adb9b2f82d40589c' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Significance Governing equations are essential to the study of physical systems, providing models that can generalize to predict previously unseen behaviors. There are many systems of interest across disciplines where large quantities of data have been collected, but the underlying governing equations remain unknown. This work introduces an approach to discover governing models from data. The proposed method addresses a key limitation of prior approaches by simultaneously discovering coordinates that admit a parsimonious dynamical model. Developing parsimonious and interpretable governing models has the potential to transform our understanding of complex systems, including in neuroscience, biology, and climate science. The discovery of governing equations from scientific data has the potential to transform data-rich fields that lack well-characterized quantitative descriptions. Advances in sparse regression are currently enabling the tractable identification of both the structure and parameters of a nonlinear dynamical system from data. The resulting models have the fewest terms necessary to describe the dynamics, balancing model complexity with descriptive ability, and thus promoting interpretability and generalizability. This provides an algorithmic approach to Occam’s razor for model discovery. However, this approach fundamentally relies on an effective coordinate system in which the dynamics have a simple representation. In this work, we design a custom deep autoencoder network to discover a coordinate transformation into a reduced space where the dynamics may be sparsely represented. Thus, we simultaneously learn the governing equations and the associated coordinate system. We demonstrate this approach on several example high-dimensional systems with low-dimensional behavior. The resulting modeling framework combines the strengths of deep neural networks for flexible representation and sparse identification of nonlinear dynamics (SINDy) for parsimonious models. This method places the discovery of coordinates and models on an equal footing.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3c9961153493370500020c81527b3548c96f81e0" target='_blank'>
                Data-driven discovery of coordinates and governing equations
                </a>
              </td>
          <td>
            Kathleen P. Champion, Bethany Lusch, J. Kutz, S. Brunton
          </td>
          <td>2019-03-29</td>
          <td>Proceedings of the National Academy of Sciences of the United States of America</td>
          <td>825</td>
          <td>74</td>

            <td><a href='../recommendations/3c9961153493370500020c81527b3548c96f81e0' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Understanding the interplay of order and disorder in chaos is a central challenge in modern quantitative science. Approximate linear representations of nonlinear dynamics have long been sought, driving considerable interest in Koopman theory. We present a universal, data-driven decomposition of chaos as an intermittently forced linear system. This work combines delay embedding and Koopman theory to decompose chaotic dynamics into a linear model in the leading delay coordinates with forcing by low-energy delay coordinates; this is called the Hankel alternative view of Koopman (HAVOK) analysis. This analysis is applied to the Lorenz system and real-world examples including Earth’s magnetic field reversal and measles outbreaks. In each case, forcing statistics are non-Gaussian, with long tails corresponding to rare intermittent forcing that precedes switching and bursting phenomena. The forcing activity demarcates coherent phase space regions where the dynamics are approximately linear from those that are strongly nonlinear.The huge amount of data generated in fields like neuroscience or finance calls for effective strategies that mine data to reveal underlying dynamics. Here Brunton et al.develop a data-driven technique to analyze chaotic systems and predict their dynamics in terms of a forced linear model.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3df50e9b73cc2937dfd651f4c3344bc99b7ed3f2" target='_blank'>
                Chaos as an intermittently forced linear system
                </a>
              </td>
          <td>
            S. Brunton, Bingni W. Brunton, J. Proctor, E. Kaiser, J. Kutz
          </td>
          <td>2016-08-18</td>
          <td>Nature Communications</td>
          <td>563</td>
          <td>74</td>

            <td><a href='../recommendations/3df50e9b73cc2937dfd651f4c3344bc99b7ed3f2' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Data-driven discovery of dynamics via machine learning is pushing the frontiers of modelling and control efforts, providing a tremendous opportunity to extend the reach of model predictive control (MPC). However, many leading methods in machine learning, such as neural networks (NN), require large volumes of training data, may not be interpretable, do not easily include known constraints and symmetries, and may not generalize beyond the attractor where models are trained. These factors limit their use for the online identification of a model in the low-data limit, for example following an abrupt change to the system dynamics. In this work, we extend the recent sparse identification of nonlinear dynamics (SINDY) modelling procedure to include the effects of actuation and demonstrate the ability of these models to enhance the performance of MPC, based on limited, noisy data. SINDY models are parsimonious, identifying the fewest terms in the model needed to explain the data, making them interpretable and generalizable. We show that the resulting SINDY-MPC framework has higher performance, requires significantly less data, and is more computationally efficient and robust to noise than NN models, making it viable for online training and execution in response to rapid system changes. SINDY-MPC also shows improved performance over linear data-driven models, although linear models may provide a stopgap until enough data is available for SINDY. SINDY-MPC is demonstrated on a variety of dynamical systems with different challenges, including the chaotic Lorenz system, a simple model for flight control of an F8 aircraft, and an HIV model incorporating drug treatment.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b2eb064f432557c59ce99834d7dc7817e4687271" target='_blank'>
                Sparse identification of nonlinear dynamics for model predictive control in the low-data limit
                </a>
              </td>
          <td>
            E. Kaiser, J. Kutz, S. Brunton
          </td>
          <td>2017-11-15</td>
          <td>Proceedings of the Royal Society A, Proceedings. Mathematical, Physical, and Engineering Sciences</td>
          <td>567</td>
          <td>74</td>

            <td><a href='../recommendations/b2eb064f432557c59ce99834d7dc7817e4687271' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Inferring the structure and dynamics of network models is critical to understanding the functionality and control of complex systems, such as metabolic and regulatory biological networks. The increasing quality and quantity of experimental data enable statistical approaches based on information theory for model selection and goodness-of-fit metrics. We propose an alternative data-driven method to infer networked nonlinear dynamical systems by using sparsity-promoting optimization to select a subset of nonlinear interactions representing dynamics on a network. In contrast to standard model selection methods-based upon information content for a finite number of heuristic models (order 10 or less), our model selection procedure discovers a parsimonious model from a combinatorially large set of models, without an exhaustive search. Our particular innovation is appropriate for many biological networks, where the governing dynamical systems have rational function nonlinearities with cross terms, thus requiring an implicit formulation and the equations to be identified in the null-space of a library of mixed nonlinearities, including the state and derivative terms. This method, implicit-SINDy, succeeds in inferring three canonical biological models: 1) Michaelis-Menten enzyme kinetics; 2) the regulatory network for competence in bacteria; and 3) the metabolic network for yeast glycolysis.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/06a0ba437d41a7c82c08a9636a4438c1b5031378" target='_blank'>
                Inferring Biological Networks by Sparse Identification of Nonlinear Dynamics
                </a>
              </td>
          <td>
            N. Mangan, S. Brunton, J. Proctor, J. Kutz
          </td>
          <td>2016-05-26</td>
          <td>IEEE Transactions on Molecular, Biological and Multi-Scale Communications, IEEE Transactions on Molecular Biological and Multi-Scale Communications</td>
          <td>376</td>
          <td>74</td>

            <td><a href='../recommendations/06a0ba437d41a7c82c08a9636a4438c1b5031378' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Accurately modelling the nonlinear dynamics of a system from measurement data is a challenging yet vital topic. The sparse identification of nonlinear dynamics (SINDy) algorithm is one approach to discover dynamical systems models from data. Although extensions have been developed to identify implicit dynamics, or dynamics described by rational functions, these extensions are extremely sensitive to noise. In this work, we develop SINDy-PI (parallel, implicit), a robust variant of the SINDy algorithm to identify implicit dynamics and rational nonlinearities. The SINDy-PI framework includes multiple optimization algorithms and a principled approach to model selection. We demonstrate the ability of this algorithm to learn implicit ordinary and partial differential equations and conservation laws from limited and noisy data. In particular, we show that the proposed approach is several orders of magnitude more noise robust than previous approaches, and may be used to identify a class of ODE and PDE dynamics that were previously unattainable with SINDy, including for the double pendulum dynamics and simplified model for the Belousov–Zhabotinsky (BZ) reaction.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/4971f9abd024e40fbbdff2e9492745b68a6bca01" target='_blank'>
                SINDy-PI: a robust algorithm for parallel implicit sparse identification of nonlinear dynamics
                </a>
              </td>
          <td>
            Kadierdan Kaheman, J. Kutz, S. Brunton
          </td>
          <td>2020-04-05</td>
          <td>Proceedings of the Royal Society A, Proceedings. Mathematical, Physical, and Engineering Sciences</td>
          <td>298</td>
          <td>74</td>

            <td><a href='../recommendations/4971f9abd024e40fbbdff2e9492745b68a6bca01' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="A key task in the field of modeling and analyzing nonlinear dynamical systems is the recovery of unknown governing equations from measurement data only. There is a wide range of application areas for this important instance of system identification, ranging from industrial engineering and acoustic signal processing to stock market models. In order to find appropriate representations of underlying dynamical systems, various data-driven methods have been proposed by different communities. However, if the given data sets are high-dimensional, then these methods typically suffer from the curse of dimensionality. To significantly reduce the computational costs and storage consumption, we propose the method multidimensional approximation of nonlinear dynamical systems (MANDy) which combines data-driven methods with tensor network decompositions. The efficiency of the introduced approach will be illustrated with the aid of several high-dimensional nonlinear dynamical systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2b2aa13d4959073f61ad70555bc8c7da7d116196" target='_blank'>
                Multidimensional Approximation of Nonlinear Dynamical Systems
                </a>
              </td>
          <td>
            Patrick Gelß, Stefan Klus, J. Eisert, Christof Schutte
          </td>
          <td>2018-09-07</td>
          <td>Journal of Computational and Nonlinear Dynamics</td>
          <td>74</td>
          <td>24</td>

            <td><a href='../recommendations/2b2aa13d4959073f61ad70555bc8c7da7d116196' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="First principles modeling of physical systems has led to significant technological advances across all branches of science. For nonlinear systems, however, small modeling errors can lead to significant deviations from the true, measured behavior. Even in mechanical systems, where the equations are assumed to be well-known, there are often model discrepancies corresponding to nonlinear friction, wind resistance, etc. Discovering models for these discrepancies remains an open challenge for many complex systems. In this work, we use the sparse identification of nonlinear dynamics (SINDy) algorithm to discover a model for the discrepancy between a simplified model and measurement data. In particular, we assume that the model mismatch can be sparsely represented in a library of candidate model terms. We demonstrate the efficacy of our approach on several examples including experimental data from a double pendulum on a cart. We further design and implement a feed-forward controller in simulations, showing improvement with a discrepancy model.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/73dd9c49f205280991826b2ea4b50344203916b4" target='_blank'>
                Learning Discrepancy Models From Experimental Data
                </a>
              </td>
          <td>
            Kadierdan Kaheman, E. Kaiser, B. Strom, J. Kutz, S. Brunton
          </td>
          <td>2019-09-18</td>
          <td>arXiv.org, ArXiv</td>
          <td>47</td>
          <td>74</td>

            <td><a href='../recommendations/73dd9c49f205280991826b2ea4b50344203916b4' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Machine learning (ML) and artificial intelligence (AI) algorithms are now being used to automate the discovery of physics principles and governing equations from measurement data alone. However, positing a universal physical law from data is challenging without simultaneously proposing an accompanying discrepancy model to account for the inevitable mismatch between theory and measurements. By revisiting the classic problem of modeling falling objects of different size and mass, we highlight a number of nuanced issues that must be addressed by modern data-driven methods for automated physics discovery. Specifically, we show that measurement noise and complex secondary physical mechanisms, like unsteady fluid drag forces, can obscure the underlying law of gravitation, leading to an erroneous model. We use the sparse identification of non-linear dynamics (SINDy) method to identify governing equations for real-world measurement data and simulated trajectories. Incorporating into SINDy the assumption that each falling object is governed by a similar physical law is shown to improve the robustness of the learned models, but discrepancies between the predictions and observations persist due to subtleties in drag dynamics. This work highlights the fact that the naive application of ML/AI will generally be insufficient to infer universal physical laws without further modification.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/35e2571c17246577e0bc1b9de57a314c3b60e220" target='_blank'>
                Discovery of Physics From Data: Universal Laws and Discrepancies
                </a>
              </td>
          <td>
            Brian M. de Silva, D. Higdon, S. Brunton, J. Kutz
          </td>
          <td>2019-06-19</td>
          <td>Frontiers in Artificial Intelligence</td>
          <td>92</td>
          <td>74</td>

            <td><a href='../recommendations/35e2571c17246577e0bc1b9de57a314c3b60e220' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Researchers propose sparse regression for identifying governing partial differential equations for spatiotemporal systems. We propose a sparse regression method capable of discovering the governing partial differential equation(s) of a given system by time series measurements in the spatial domain. The regression framework relies on sparsity-promoting techniques to select the nonlinear and partial derivative terms of the governing equations that most accurately represent the data, bypassing a combinatorially large search through all possible candidate models. The method balances model complexity and regression accuracy by selecting a parsimonious model via Pareto analysis. Time series measurements can be made in an Eulerian framework, where the sensors are fixed spatially, or in a Lagrangian framework, where the sensors move with the dynamics. The method is computationally efficient, robust, and demonstrated to work on a variety of canonical problems spanning a number of scientific domains including Navier-Stokes, the quantum harmonic oscillator, and the diffusion equation. Moreover, the method is capable of disambiguating between potentially nonunique dynamical terms by using multiple time series taken with different initial data. Thus, for a traveling wave, the method can distinguish between a linear wave equation and the Korteweg–de Vries equation, for instance. The method provides a promising new technique for discovering governing equations and physical laws in parameterized spatiotemporal systems, where first-principles derivations are intractable.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0acd117521ef5aafb09fed02ab415523b330b058" target='_blank'>
                Data-driven discovery of partial differential equations
                </a>
              </td>
          <td>
            S. Rudy, S. Brunton, J. Proctor, J. Kutz
          </td>
          <td>2016-09-21</td>
          <td>Science Advances</td>
          <td>1468</td>
          <td>74</td>

            <td><a href='../recommendations/0acd117521ef5aafb09fed02ab415523b330b058' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Sparse model identification enables the discovery of nonlinear dynamical systems purely from data; however, this approach is sensitive to noise, especially in the low-data limit. In this work, we leverage the statistical approach of bootstrap aggregating (bagging) to robustify the sparse identification of the nonlinear dynamics (SINDy) algorithm. First, an ensemble of SINDy models is identified from subsets of limited and noisy data. The aggregate model statistics are then used to produce inclusion probabilities of the candidate functions, which enables uncertainty quantification and probabilistic forecasts. We apply this ensemble-SINDy (E-SINDy) algorithm to several synthetic and real-world datasets and demonstrate substantial improvements to the accuracy and robustness of model discovery from extremely noisy and limited data. For example, E-SINDy uncovers partial differential equations models from data with more than twice as much measurement noise as has been previously reported. Similarly, E-SINDy learns the Lotka Volterra dynamics from remarkably limited data of yearly lynx and hare pelts collected from 1900 to 1920. E-SINDy is computationally efficient, with similar scaling as standard SINDy. Finally, we show that ensemble statistics from E-SINDy can be exploited for active learning and improved model predictive control.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/883547fdbd88552328a6615ec620f96e39c57018" target='_blank'>
                Ensemble-SINDy: Robust sparse model discovery in the low-data, high-noise limit, with active learning and control
                </a>
              </td>
          <td>
            Urban Fasel, J. Kutz, Bingni W. Brunton, S. Brunton
          </td>
          <td>2021-11-22</td>
          <td>Proceedings of the Royal Society A, Proceedings. Mathematical, Physical, and Engineering Sciences</td>
          <td>272</td>
          <td>74</td>

            <td><a href='../recommendations/883547fdbd88552328a6615ec620f96e39c57018' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Discovering governing equations of complex dynamical systems directly from data is a central problem in scientific machine learning. In recent years, the sparse identification of nonlinear dynamics (SINDy) framework, powered by heuristic sparse regression methods, has become a dominant tool for learning parsimonious models. We propose an exact formulation of the SINDy problem using mixed-integer optimization (MIO-SINDy) to solve the sparsity constrained regression problem to provable optimality in seconds. On a large number of canonical ordinary and partial differential equations, we illustrate the dramatic improvement in our approach in accurate model discovery while being more sample efficient, robust to noise, and flexible in accommodating physical constraints.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e6f0a85009481dcfd93aaa43ed3f980e5033b0d8" target='_blank'>
                Learning sparse nonlinear dynamics via mixed-integer optimization
                </a>
              </td>
          <td>
            D. Bertsimas, Wes Gurnee
          </td>
          <td>2022-06-01</td>
          <td>Nonlinear Dynamics</td>
          <td>54</td>
          <td>97</td>

            <td><a href='../recommendations/e6f0a85009481dcfd93aaa43ed3f980e5033b0d8' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

        <tr id="Regularized regression problems are ubiquitous in statistical modeling, signal processing, and machine learning. Sparse regression, in particular, has been instrumental in scientific model discovery, including compressed sensing applications, variable selection, and high-dimensional analysis. We propose a broad framework for sparse relaxed regularized regression, called SR3. The key idea is to solve a relaxation of the regularized problem, which has three advantages over the state-of-the-art: 1) solutions of the relaxed problem are superior with respect to errors, false positives, and conditioning; 2) relaxation allows extremely fast algorithms for both convex and nonconvex formulations; and 3) the methods apply to composite regularizers, essential for total variation (TV) as well as sparsity-promoting formulations using tight frames. We demonstrate the advantages of SR3 (computational efficiency, higher accuracy, faster convergence rates, and greater flexibility) across a range of regularized regression problems with synthetic and real data, including applications in compressed sensing, LASSO, matrix completion, TV regularization, and group sparsity. Following standards of reproducible research, we also provide a companion MATLAB package that implements these examples.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c0fc3882a9976f6a9cdc3a724bce184b786503da" target='_blank'>
                A Unified Framework for Sparse Relaxed Regularized Regression: SR3
                </a>
              </td>
          <td>
            P. Zheng, T. Askham, S. Brunton, J. Kutz, A. Aravkin
          </td>
          <td>2018-07-14</td>
          <td>IEEE Access</td>
          <td>151</td>
          <td>74</td>

            <td><a href='../recommendations/c0fc3882a9976f6a9cdc3a724bce184b786503da' target='_blank'>
              <i class="material-icons">open_in_new</i></a>
            </td>

        </tr>

    </tbody>
    <tfoot>
      <tr>
          <th>Abstract</th>
          <th>Title</th>
          <th>Authors</th>
          <th>Publication Date</th>
          <th>Journal/ Conference</th>
          <th>Citation count</th>
          <th>Highest h-index</th>
          <th>View recommendations</th>
      </tr>
    </tfoot>
    </table>
    </p>
  </div>

  <div data-intro='Recommended articles extracted by contrasting
                  articles that are relevant against not relevant for Symbolic regression'>
    <p>
    <h3 id="recommended_articles">Recommended articles on <i>Symbolic regression</i></h3>
    <table id="table2" class="display" style="width:100%">
    <thead>
      <tr>
          <th>Abstract</th>
          <th>Title</th>
          <th>Authors</th>
          <th>Publication Date</th>
          <th>Journal/Conference</th>
          <th>Citation count</th>
          <th>Highest h-index</th>
      </tr>
    </thead>
    <tbody>

        <tr id="Learning the governing equations of dynamical systems from data has drawn significant attention across diverse fields, including physics, engineering, robotics and control, economics, climate science, and healthcare. Sparse regression techniques, exemplified by the Automatic Regression for Governing Equations (ARGOS) framework, have demonstrated effectiveness in extracting parsimonious models from time series data. However, real-world dynamical systems are driven by input control, external forces, or human interventions, which standard ARGOS does not accommodate. To address this, we introduce ARGOS with control (ARGOSc), an extension of ARGOS that incorporates external control inputs into the system identification process. ARGOSc extends the sparse regression framework to infer governing equations while accounting for the effects of exogenous inputs, enabling robust identification of forcing dynamics in low- to medium-noise datasets. We demonstrate ARGOSc efficacy on benchmark systems, including the Van der Pol oscillator, Lotka-Volterra, and the Lorenz system with forcing and feedback control, showing enhanced accuracy in discovering governing laws. Under the noisy conditions, ARGOSc outperforms the widely used sparse identification of nonlinear dynamics with control (SINDYc), in accurately identifying the underlying forced dynamics. In some cases, SINDYc fails to capture the true system dynamics, whereas ARGOSc consistently succeeds.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/27c530a2ec30608944027718b7026b81f5244a5a" target='_blank'>
              Automatic Regression for Governing Equations with Control (ARGOSc)
              </a>
            </td>
          <td>
            Amir Bahador Javadi, Amin Kargarian Marvasti, M. Naraghi-Pour
          </td>
          <td>2025-09-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>20</td>
        </tr>

        <tr id="Data-driven modeling of nonlinear dynamical systems is often hampered by measurement noise. We propose a denoising framework, called Runge-Kutta and Total Variation Based Implicit Neural Representation (RKTV-INR), that represents the state trajectory with an implicit neural representation (INR) fitted directly to noisy observations. Runge-Kutta integration and total variation are imposed as constraints to ensure that the reconstructed state is a trajectory of a dynamical system that remains close to the original data. The trained INR yields a clean, continuous trajectory and provides accurate first-order derivatives via automatic differentiation. These denoised states and derivatives are then supplied to Sparse Identification of Nonlinear Dynamics (SINDy) to recover the governing equations. Experiments demonstrate effective noise suppression, precise derivative estimation, and reliable system identification.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/efd9cbd9f04df79727795694d72822dfe2548220" target='_blank'>
              Data Denoising and Derivative Estimation for Data-Driven Modeling of Nonlinear Dynamical Systems
              </a>
            </td>
          <td>
            Jiaqi Yao, Lewis Mitchell, John Maclean, Hemanth Saratchandran
          </td>
          <td>2025-09-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>6</td>
        </tr>

        <tr id="Dynamical systems theory describes how interacting quantities change over time and space, from molecular oscillators to large-scale biological patterns. Such systems often involve nonlinear feedbacks, delays, and interactions across scales. Classical modeling derives explicit governing equations, often systems of differential equations, by combining mechanistic assumptions, experimental observations, and known physical laws. The growing complexity of biological processes has, however, motivated complementary data-driven methods that aim to infer model structure directly from measurements, often without specifying equations a priori. In this review, we survey approaches for model discovery in biological dynamical systems, focusing on three methodological families: regression-based methods, network-based architectures, and decomposition techniques. We compare their ability to address three core goals: forecasting future states, identifying interactions, and characterizing system states. Representative methods are applied to a common benchmark, the Oregonator model, a minimal nonlinear oscillator that captures shared design principles of chemical and biological systems. By highlighting strengths, limitations, and interpretability, we aim to guide researchers in selecting tools for analyzing complex, nonlinear, and high-dimensional dynamics in the life sciences.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/d935cca568c50f4f591621428c4ba98ec97822d4" target='_blank'>
              Data-driven discovery of dynamical models in biology
              </a>
            </td>
          <td>
            Bartosz Prokop, L. Gelens
          </td>
          <td>2025-09-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>33</td>
        </tr>

        <tr id="Model discovery aims to uncover governing differential equations of dynamical systems directly from experimental data. Benchmarking such methods is essential for tracking progress and understanding trade-offs in the field. While prior efforts have focused mostly on identifying single equations, typically framed as symbolic regression, there remains a lack of comprehensive benchmarks for discovering dynamical models. To address this, we introduce MDBench, an open-source benchmarking framework for evaluating model discovery methods on dynamical systems. MDBench assesses 12 algorithms on 14 partial differential equations (PDEs) and 63 ordinary differential equations (ODEs) under varying levels of noise. Evaluation metrics include derivative prediction accuracy, model complexity, and equation fidelity. We also introduce seven challenging PDE systems from fluid dynamics and thermodynamics, revealing key limitations in current methods. Our findings illustrate that linear methods and genetic programming methods achieve the lowest prediction error for PDEs and ODEs, respectively. Moreover, linear models are in general more robust against noise. MDBench accelerates the advancement of model discovery methods by offering a rigorous, extensible benchmarking framework and a rich, diverse collection of dynamical system datasets, enabling systematic evaluation, comparison, and improvement of equation accuracy and robustness.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1799d7cfae5d089c26a71830d51354e6399ecc1a" target='_blank'>
              MDBench: Benchmarking Data-Driven Methods for Model Discovery
              </a>
            </td>
          <td>
            Amirmohammad Ziaei Bideh, Aleksandra Georgievska, Jonathan Gryak
          </td>
          <td>2025-09-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Nonlinear system identification often involves a fundamental trade-off between interpretability and flexibility, often requiring the incorporation of physical constraints. We propose a unified data-driven framework that combines the mathematical structure of the governing differential equations with the flexibility of neural networks (NNs). At the core of our approach is the concept of characteristic curves (CCs), which represent individual nonlinear functions (e.g., friction and restoring components) of the system. Each CC is modeled by a dedicated NN, enabling a modular and interpretable representation of the system equation. To demonstrate the versatility of the CC-based formalism, we introduce three identification strategies: (1) SINDy-CC, which extends the sparse regression approach of SINDy by incorporating the mathematical structure of the governing equations as constraints; (2) Poly-CC, which represents each CC using high-degree polynomials; and (3) NN-CC, which uses NNs without requiring prior assumptions about basis functions. Our results show that all three approaches are well-suited for systems with simple polynomial nonlinearities, such as the van der Pol oscillator. In contrast, NN-CC demonstrates superior performance in modeling systems with complex nonlinearities and discontinuities, such as those observed in stick-slip systems. The key contribution of this work is to demonstrate that the CC-based framework, particularly the NN-CC approach, can capture complex nonlinearities while maintaining interpretability through the explicit representation of the CCs. This balance makes it well-suited for modeling systems with discontinuities and complex nonlinearities that are challenging to assess using traditional polynomial or sparse regression methods, providing a powerful tool for nonlinear system identification.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1fc4825eadb646fd1f5ff3efa405a2d7e582146a" target='_blank'>
              Interpretable neural network system identification method for two families of second-order systems based on characteristic curves
              </a>
            </td>
          <td>
            Federico J. Gonzalez, Luis P. Lara
          </td>
          <td>2025-09-12</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Modeling and predicting the dynamics of complex multiscale systems remains a significant challenge due to their inherent nonlinearities and sensitivity to initial conditions, as well as limitations of traditional machine learning methods that fail to capture high frequency behaviours. To overcome these difficulties, we propose three approaches for multiscale learning. The first leverages the Partition of Unity (PU) method, integrated with neural networks, to decompose the dynamics into local components and directly predict both macro- and micro-scale behaviors. The second applies the Singular Value Decomposition (SVD) to extract dominant modes that explicitly separate macro- and micro-scale dynamics. Since full access to the data matrix is rarely available in practice, we further employ a Sparse High-Order SVD to reconstruct multiscale dynamics from limited measurements. Together, these approaches ensure that both coarse and fine dynamics are accurately captured, making the framework effective for real-world applications involving complex, multi-scale phenomena and adaptable to higher-dimensional systems with incomplete observations, by providing an approximation and interpretation in all time scales present in the phenomena under study.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/17c8e96af904da744f902997f49075e3da209b08" target='_blank'>
              Application of Reduced-Order Models for Temporal Multiscale Representations in the Prediction of Dynamical Systems
              </a>
            </td>
          <td>
            Elias Al Ghazal, J. Mounayer, Beatriz Moya, Sebastian Rodriguez, C. Ghnatios, F. Chinesta
          </td>
          <td>2025-10-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>15</td>
        </tr>

        <tr id="In this paper, we revisit the investigation of solitary-wave interactions in the nonlinear Schr\"odinger model, both in the presence and absence of a parabolic trapping potential. While approximate dynamics, based on variational or similar methods, governed by a system of ordinary differential equations (ODEs) for both bright and dark-soliton interactions have been well established in the literature based on physical expert considerations, this study focuses on a data-driven approach, the so-called Sparse Identification of Nonlinear Dynamics (SINDy). Accordingly, our purpose is to use PDE time-series of select waveform diag- nostics in order to numerically reconstruct such approximate dynamics, without prior knowledge thereof. The purpose is not only to verify the robustness of the dynamical approximated ODEs, but also to shed light on the application of such a data-driven methodology in the study of soliton interactions and to formu- late a complementary approach, more reliant on the wealth of PDE data and less so on expert theoretical constructs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/dd733a6b454adb047aabf87993102beb4b67e409" target='_blank'>
              Data-driven Soliton Manifold Approximations for Dark and Bright Waves: Some Prototypical 1d Case Examples
              </a>
            </td>
          <td>
            Su Yang, Shaoxuan Chen, Wei Zhu, Panayotis Kevrekidis
          </td>
          <td>2025-10-15</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Ecological systems exhibit complex multi-scale dynamics that challenge traditional modeling. New methods must capture temporal oscillations and emergent spatiotemporal patterns while adhering to conservation principles. We present the Unified Spatiotemporal Physics-Informed Learning (USPIL) framework, a deep learning architecture integrating physics-informed neural networks (PINNs) and conservation laws to model predator-prey dynamics across dimensional scales. The framework provides a unified solution for both ordinary (ODE) and partial (PDE) differential equation systems, describing temporal cycles and reaction-diffusion patterns within a single neural network architecture. Our methodology uses automatic differentiation to enforce physics constraints and adaptive loss weighting to balance data fidelity with physical consistency. Applied to the Lotka-Volterra system, USPIL achieves 98.9% correlation for 1D temporal dynamics (loss: 0.0219, MAE: 0.0184) and captures complex spiral waves in 2D systems (loss: 4.7656, pattern correlation: 0.94). Validation confirms conservation law adherence within 0.5% and shows a 10-50x computational speedup for inference compared to numerical solvers. USPIL also enables mechanistic understanding through interpretable physics constraints, facilitating parameter discovery and sensitivity analysis not possible with purely data-driven methods. Its ability to transition between dimensional formulations opens new avenues for multi-scale ecological modeling. These capabilities make USPIL a transformative tool for ecological forecasting, conservation planning, and understanding ecosystem resilience, establishing physics-informed deep learning as a powerful and scientifically rigorous paradigm.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/3c6e23fc1dbb85276d12d77399c3c66aca7d86a7" target='_blank'>
              Unified Spatiotemporal Physics-Informed Learning (USPIL): A Framework for Modeling Complex Predator-Prey Dynamics
              </a>
            </td>
          <td>
            Julian Evan Chrisnanto, Salsabila Rahma Alia, Y. H. Chrisnanto, Ferry Faizal
          </td>
          <td>2025-09-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="A numerical framework is proposed for identifying partial differential equations (PDEs) governing dynamical systems directly from their observation data using Chebyshev polynomial approximation. In contrast to data-driven approaches such as dynamic mode decomposition (DMD), which approximate the Koopman operator without a clear connection to differential operators, the proposed method constructs finite-dimensional Koopman matrices by projecting the dynamics onto a Chebyshev basis, thereby capturing both differential and nonlinear terms. This establishes a numerical link between the Koopman and differential operators. Numerical experiments on benchmark dynamical systems confirm the accuracy and efficiency of the approach, underscoring its potential for interpretable operator learning. The framework also lays a foundation for future integration with symbolic regression, enabling the construction of explicit mathematical models directly from data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/cc4ede009e8167706e94d9a70ab82601c4f25e22" target='_blank'>
              Numerical Spectrum Linking: Identification of Governing PDE via Koopman-Chebyshev Approximation
              </a>
            </td>
          <td>
            Phonepaserth Sisaykeo, S. Muramatsu
          </td>
          <td>2025-10-27</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>14</td>
        </tr>

        <tr id="Over the past decade, scientific machine learning has transformed the development of mathematical and computational frameworks for analyzing, modeling, and predicting complex systems. From inverse problems to numerical PDEs, dynamical systems, and model reduction, these advances have pushed the boundaries of what can be simulated. Yet they have often progressed in parallel, with representation learning and algorithmic solution methods evolving largely as separate pipelines. With \emph{Latent Twins}, we propose a unifying mathematical framework that creates a hidden surrogate in latent space for the underlying equations. Whereas digital twins mirror physical systems in the digital world, Latent Twins mirror mathematical systems in a learned latent space governed by operators. Through this lens, classical modeling, inversion, model reduction, and operator approximation all emerge as special cases of a single principle. We establish the fundamental approximation properties of Latent Twins for both ODEs and PDEs and demonstrate the framework across three representative settings: (i) canonical ODEs, capturing diverse dynamical regimes; (ii) a PDE benchmark using the shallow-water equations, contrasting Latent Twin simulations with DeepONet and forecasts with a 4D-Var baseline; and (iii) a challenging real-data geopotential reanalysis dataset, reconstructing and forecasting from sparse, noisy observations. Latent Twins provide a compact, interpretable surrogate for solution operators that evaluate across arbitrary time gaps in a single-shot, while remaining compatible with scientific pipelines such as assimilation, control, and uncertainty quantification. Looking forward, this framework offers scalable, theory-grounded surrogates that bridge data-driven representation learning and classical scientific modeling across disciplines.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/c542b97d365abe263d0a4a8dcb69beb465722176" target='_blank'>
              Latent Twins
              </a>
            </td>
          <td>
            Matthias Chung, Deepanshu Verma, Max Collins, Amit N. Subrahmanya, V. Sastry, Vishwas Rao
          </td>
          <td>2025-09-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="We propose a machine learning framework based on the next-generation Equation-Free algorithm for learning the spatio-temporal dynamics of mass-constrained complex systems with hidden states, whose dynamics can in principle be described by PDEs, but lack explicit models. In these cases, some variables, closures, and potentials governing the dynamics are generally not directly observable and therefore must be inferred from data. Here, we construct manifold-ROMs -- using delayed coordinates, thus exploiting the Takens'/Whitney's embedding theorems. In the first stage, we employ both linear (POD) and nonlinear manifold learning (Diffusion Maps, DMs) to extract low-dimensional latent representations of the complex spatio-temporal evolution. In the second step, we learn predictive manifold-informed ROMs to approximate the solution operator on the latent space. In the final step, the latent dynamics are lifted back to the original high-dimensional space by solving a pre-image problem. We prove that both POD and the particular $k$-nearest neighbors lifting operators preserve the mass, a crucial property in the context of many problems, including computational fluid dynamics (CFD) and crowd dynamics. Actually, the proposed framework reconstructs the solution operator of the unavailable mass-constrained PDE, bypassing the need to discover an explicit form of the PDE per se. We demonstrate our approach via the Hughes model, approximating the dynamics of individuals minimizing travel time while avoiding obstacles and high-density regions. We show that DMs-informed ROMs outperform the best POD-informed ROMs thus resulting in stable and accurate approximations of the solution operator both in the latent space and, via reconstruction, in the high-dimensional space, and can therefore be integrated reliably over long time horizons.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/43cf0a1cd7e1b99dfc5dfb61026fd9570f060b26" target='_blank'>
              PDE-Free Mass-Constrained Learning of Complex Systems with Hidden States: The crowd dynamics case
              </a>
            </td>
          <td>
            Gianmaria Viola, Alessandro Della Pia, Lucia Russo, Ioannis G. Kevrekidis, Constantinos I. Siettos
          </td>
          <td>2025-10-20</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="In this study, we propose a novel epidemiological framework, the SEIHQR model, which integrates Scientific Machine Learning (SciML) with interpretable compartment-based modeling. We apply two pillars of Scientific Machine Learning (SciML) - neural ordinary differential equations (neural ODEs) and universal differential equations (UDEs) - to model this system of ordinary differential equations. Although traditional epidemiological modeling relies on agent-based or compartmental methods, our approach uses SciML to retain the interpretability of compartmental models while incorporating the expressive power of neural networks, similar to the complexity achievable with agent-based models. Our findings demonstrate that for this framework, neural ODEs yield poor performance and lack interpretability. In contrast, UDEs exhibit superior performance and, through symbolic recovery techniques, achieve full interpretability. This work opens avenues for the broader application of SciML frameworks in epidemiology, particularly for forecasting and monitoring disease spread.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8b05274336c4a222e7eb0db4b69a7aed59f92b74" target='_blank'>
              A Novel Scientific Machine Learning Method for Epidemiological Modelling
              </a>
            </td>
          <td>
            Tirtha Tilak Pani, R. Dandekar, Prathamesh Dinesh Joshi, R. Dandekar, S. Panat
          </td>
          <td>2025-09-15</td>
          <td>2025 IEEE International Conference on eScience (eScience)</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="Inverse problems involving nonlinear partial differential equations (PDEs) pose significant challenges due to their ill-posed nature and reliance on sparse or noisy observations. Traditional approaches often require complete knowledge of initial and boundary conditions, which may not be available in practical scenarios. Physics-informed neural networks (PINNs) have recently emerged as a powerful approach for addressing such problems by embedding physical laws into the structure of deep neural networks. In this work, we employ PINNs to solve the inverse problem for the Gardner-Kawahara equation, a high-order nonlinear dispersive PDE that modeling wave propagation in fluids and plasmas. The proposed PINNs framework accurately reconstructs unknown parameters and solution fields from limited data, even in the presence of noise. Numerical experiments conducted under varying parameter settings and noise levels demonstrate strong agreement with exact solutions, thereby highlighting the method’s accuracy, robustness, and computational efficiency. These results confirm the potential of PINNs for inverse modeling of complex nonlinear systems, even in the absence of complete initial or boundary information, and demonstrate that they outperform traditional methods in handling sparse and noisy data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/7d33c556ed76a811d663c20d0242b664256b94da" target='_blank'>
              Solving inverse Gardner–Kawahara problems with physics-informed neural networks: a data-driven approach
              </a>
            </td>
          <td>
            Mazaher Kabiri, Sanam Sabooni
          </td>
          <td>2025-09-16</td>
          <td>Physica Scripta</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Self-induced stochastic resonance (SISR) is the emergence of coherent oscillations in slow-fast excitable systems driven solely by noise, without external periodic forcing or proximity to a bifurcation. This work presents a physics-informed machine learning framework for modeling and predicting SISR in the stochastic FitzHugh-Nagumo neuron. We embed the governing stochastic differential equations and SISR-asymptotic timescale-matching constraints directly into a Physics-Informed Neural Network (PINN) based on a Noise-Augmented State Predictor architecture. The composite loss integrates data fidelity, dynamical residuals, and barrier-based physical constraints derived from Kramers'escape theory. The trained PINN accurately predicts the dependence of spike-train coherence on noise intensity, excitability, and timescale separation, matching results from direct stochastic simulations with substantial improvements in accuracy and generalization compared with purely data-driven methods, while requiring significantly less computation. The framework provides a data-efficient and interpretable surrogate model for simulating and analyzing noise-induced coherence in multiscale stochastic systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e9337c69661ae6de33ad808bd69fcfdef47a38d4" target='_blank'>
              Self-induced stochastic resonance: A physics-informed machine learning approach
              </a>
            </td>
          <td>
            Divyesh Savaliya, Marius E. Yamakou
          </td>
          <td>2025-10-26</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>10</td>
        </tr>

        <tr id="We present a differentiable framework that leverages the Discrete Empirical Interpolation Method (DEIM) for interpretable deep learning and dynamical system analysis. Although DEIM efficiently approximates nonlinear terms in projection-based reduced-order models (POD-ROM), its fixed interpolation points limit the adaptability to complex and time-varying dynamics. To address this limitation, we first develop a differentiable adaptive DEIM formulation for the one-dimensional viscous Burgers equation, which allows neural networks to dynamically select interpolation points in a computationally efficient and physically consistent manner. We then apply DEIM as an interpretable analysis tool for examining the learned dynamics of a pre-trained Neural Ordinary Differential Equation (NODE) on a two-dimensional vortex-merging problem. The DEIM trajectories reveal physically meaningful features in the learned dynamics of NODE and expose its limitations when extrapolating to unseen flow configurations. These findings demonstrate that DEIM can serve not only as a model reduction tool but also as a diagnostic framework for understanding and improving the generalization behavior of neural differential equation models.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e82fec368f7bfc6b5644d30daeb8c0ce5b2895e6" target='_blank'>
              Towards Interpretable Deep Learning and Analysis of Dynamical Systems via the Discrete Empirical Interpolation Method
              </a>
            </td>
          <td>
            Hojin Kim, R. Maulik
          </td>
          <td>2025-10-22</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>26</td>
        </tr>

        <tr id="We present Hybrid-Cooperative Learning (HYCO), a hybrid modeling framework that iteratively integrates physics-based and data-driven models through a mutual regularization mechanism. Unlike traditional approaches that impose physical constraints directly on synthetic models, HYCO treats the physical and synthetic components as co-trained agents: the physical and synthetic models are nudged toward agreement, while the synthetic model is enhanced to better fit the available data. This cooperative learning scheme is naturally parallelizable and improves robustness to noise as well as to sparse or heterogeneous data. Extensive numerical experiments on both static and time-dependent problems demonstrate that HYCO outperforms classical physics-based and data-driven methods, recovering accurate solutions and model parameters even under ill-posed conditions. The method also admits a natural game-theoretic interpretation, enabling alternating optimization and paving the way for future theoretical developments.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0ba2cfc42ca5afa00993e03432494e60dbcc26ea" target='_blank'>
              HYCO: Hybrid-Cooperative Learning for Data-Driven PDE Modeling
              </a>
            </td>
          <td>
            Lorenzo Liverani, Matthys J. Steynberg, Enrique Zuazua
          </td>
          <td>2025-09-17</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>2</td>
        </tr>

        <tr id="Data-driven discovery of emergent dynamics is gaining popularity, particularly in the context of reaction-diffusion systems. These systems are widely studied across various fields, including neuroscience, ecology, epidemiology, and several other subject areas that deal with emergent dynamics. A current challenge in the discovery process relates to system identification when there is no prior knowledge of the underlying physics. We attempt to address this challenge by learning Soft Artificial Life (Soft ALife) models, such as Agent-based and Cellular Automata (CA) models, from observed data for reaction-diffusion systems. In this paper, we present findings on the applicability of a conceptual framework, the Data-driven Rulesets for Soft Artificial Life (DRSALife) model, to learn Soft ALife rulesets that accurately represent emergent dynamics in a reaction-diffusion system from observed data. This model has demonstrated promising results for Elementary CA Rule 30, Game of Life, and Vicsek Flocking problems in recent work. To our knowledge, this is one of the few studies that explore machine-based Soft ALife ruleset learning and system identification for reaction-diffusion dynamics without any prior knowledge of the underlying physics. Moreover, we provide comprehensive findings from experiments investigating the potential effects of using noisy and sparse observed datasets on learning emergent dynamics. Additionally, we successfully identify the structure and parameters of the underlying partial differential equations (PDEs) representing these dynamics. Experimental results demonstrate that the learned models are able to predict the emergent dynamics with good accuracy (74%) and exhibit quite robust performance when subjected to Gaussian noise and temporal sparsity.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f8ed8d3aaae27f9d1c3d337c4f4327081a3e962b" target='_blank'>
              Data-Driven Discovery of Emergent Dynamics in Reaction-Diffusion Systems from Sparse and Noisy Observations
              </a>
            </td>
          <td>
            Saumitra Dwivedi, Ricardo da Silva Torres, Ibrahim A. Hameed, Gunnar Tufte, Anniken Susanne T. Karlsen
          </td>
          <td>2025-09-11</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/e369fd3ca7525d101af39b95e00a1c511d20451a" target='_blank'>
              Computation of simple invariant solutions in fluid turbulence with the aid of deep learning
              </a>
            </td>
          <td>
            Jacob Page
          </td>
          <td>2025-09-18</td>
          <td>Nonlinear Dynamics</td>
          <td>1</td>
          <td>0</td>
        </tr>

        <tr id="We present a simple and scalable implementation of next-generation reservoir computing for modeling dynamical systems from time series data. Our approach uses a pseudorandom nonlinear projection of time-delay embedded input, allowing an arbitrary dimension of the feature space, thus providing a flexible alternative to the polynomial-based projections used in previous next-generation reservoir computing variants. We apply the method to benchmark tasks -- including attractor reconstruction and bifurcation diagram estimation -- using only partial and noisy observations. We also include an exploratory example of estimating asymptotic oscillation phases. The models remain stable over long rollouts and generalize beyond training data. This framework enables the precise control of system state and is well suited for surrogate modeling and digital twin applications.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bd8d79610a31cb2cf7c3d03728b16d711bdd4ef5" target='_blank'>
              Next-Generation Reservoir Computing for Dynamical Inference
              </a>
            </td>
          <td>
            Rok Cestnik, E. A. Martens
          </td>
          <td>2025-09-14</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>7</td>
        </tr>

        <tr id="Causal relationships play a fundamental role in understanding the world around us. The ability to identify and understand cause-effect relationships is critical to making informed decisions, predicting outcomes, and developing effective strategies. However, deciphering causal relationships from observational data is a difficult task, as correlations alone may not provide definitive evidence of causality. In recent years, the field of machine learning (ML) has emerged as a powerful tool, offering new opportunities for uncovering hidden causal mechanisms and better understanding complex systems. In this work, we address the issue of detecting the intrinsic causal links of a large class of complex systems in the framework of the response theory in physics. We develop some theoretical ideas put forward by [1], and technically we use state-of-the-art ML techniques to build up models from data. We consider both linear stochastic and non-linear systems. Finally, we compute the asymptotic efficiency of the linear response based causal predictor in a case of large scale Markov process network of linear interactions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2b58d943f5e5053c35024bd20898424baa3e8f7f" target='_blank'>
              Building causation links in stochastic nonlinear systems from data
              </a>
            </td>
          <td>
            Sergio Chibbaro, Cyril Furtlehner, Th'eo Marchetta, A. Pantea, Davide Rossetti
          </td>
          <td>2025-09-09</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="The control of high-dimensional distributed parameter systems (DPS) remains a challenge when explicit coarse-grained equations are unavailable. Classical equation-free (EF) approaches rely on fine-scale simulators treated as black-box timesteppers. However, repeated simulations for steady-state computation, linearization, and control design are often computationally prohibitive, or the microscopic timestepper may not even be available, leaving us with data as the only resource. We propose a data-driven alternative that uses local neural operators, trained on spatiotemporal microscopic/mesoscopic data, to obtain efficient short-time solution operators. These surrogates are employed within Krylov subspace methods to compute coarse steady and unsteady-states, while also providing Jacobian information in a matrix-free manner. Krylov-Arnoldi iterations then approximate the dominant eigenspectrum, yielding reduced models that capture the open-loop slow dynamics without explicit Jacobian assembly. Both discrete-time Linear Quadratic Regulator (dLQR) and pole-placement (PP) controllers are based on this reduced system and lifted back to the full nonlinear dynamics, thereby closing the feedback loop.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8d4f2359cd49ac553a83cca4f818ad0608d88df8" target='_blank'>
              Equation-Free Coarse Control of Distributed Parameter Systems via Local Neural Operators
              </a>
            </td>
          <td>
            Gianluca Fabiani, Constantinos I. Siettos, Ioannis G. Kevrekidis
          </td>
          <td>2025-09-28</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>9</td>
        </tr>

        <tr id="Artificial Recurrent Neural Networks (RNNs) are widely used in neuroscience to model the collective activity of neurons during behavioral tasks. The high dimensionality of their parameter and activity spaces, however, often make it challenging to infer and interpret the fundamental features of their dynamics. In this study, we employ recent nonlinear dynamical system techniques to uncover the core dynamics of several RNNs used in contemporary neuroscience. Specifically, using a data-driven approach, we identify Spectral Submanifolds (SSMs), i.e., low-dimensional attracting invariant manifolds tangent to the eigenspaces of fixed points. The internal dynamics of SSMs serve as nonlinear models that reduce the dimensionality of the full RNNs by orders of magnitude. Through low-dimensional, SSM-reduced models, we give mathematically precise definitions of line and ring attractors, which are intuitive concepts commonly used to explain decision-making and working memory. The new level of understanding of RNNs obtained from SSM reduction enables the interpretation of mathematically well-defined and robust structures in neuronal dynamics, leading to novel predictions about the neural computations underlying behavior.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/dde11bc2ecd22df495bba2132bf0d61e083a3018" target='_blank'>
              Data-Driven Reduced Modeling of Recurrent Neural Networks
              </a>
            </td>
          <td>
            Alice Marraffa, Renate Krause, Valerio Mante, George Haller
          </td>
          <td>2025-10-14</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="By extending Takens'embedding theorem (1981), Deyle and Sugihara (2011) provided a theoretical justification for using parallel measurement time series to reconstruct a system's attractor. Building on Takens'framework, Brunton et al. (2017) introduced the Hankel alternative view of Koopman (HAVOK) algorithm, a data-driven approach capable of linearizing chaotic systems through delay embeddings. In this work, a modified version of the original algorithm is presented (mHAVOK), a practical realization of Deyle and Sugihara's generalized embedding theory. mHAVOK extends the original algorithm from one to multiple input time series and introduces a systematic approach to separating linear and nonlinear terms. An R2-informed quality score is introduced and shown to be a reliable guide for the selection of the reduced rank. The algorithm is tested on the familiar Lorenz system, as well as the more sophisticated Sprott system, which features different behaviors depending on the initial conditions. The quality of the reconstructions is assessed with the Chamfer distance, validating how mHAVOK allows for a more accurate reconstruction of the system dynamics. The new methodology generalizes HAVOK by allowing the analysis of multivariate time series, fundamental in real life data-driven applications.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/0a2bcc2b339e7baf49f58cf67c028a1d83b8417b" target='_blank'>
              A multichannel generalization of the HAVOK method for the analysis of nonlinear dynamical systems
              </a>
            </td>
          <td>
            Carlos Colchero, Jorge Perez, Alvaro Herrera, Oliver Probst
          </td>
          <td>2025-09-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Simulating turbulent fluid flows is computationally very demanding, as it requires resolving fine-scale structures and capturing complex nonlinear interactions across multiple scales. This is especially true for direct numerical simulation applied to real-world turbulent problems. Consequently, much research has focused on analyzing turbulent flows from a data-driven perspective. However, because these systems are complex and chaotic, traditional models often become unstable as they accumulate errors over time, leading to significant degradation even in short-term predictions. To address these limitations, we propose a purely stochastic approach that separately models the evolution of large-scale coherent structures and the closure of high-fidelity statistical data. Specifically, the dynamics of the filtered data, representing coherent motion, are learned using an autoregressive model that combines a Variational Autoencoder with a Transformer architecture. The VAE projection is probabilistic, ensuring consistency between the model's stochasticity and the statistical properties of the flow. The mean realization of stochastically sampled trajectories from our model shows relative errors of 6 percent and 10 percent, respectively, compared to the test set. Furthermore, our framework allows the construction of meaningful confidence intervals, achieving a prediction interval coverage probability of 80 percent with minimal interval width. To recover high-fidelity velocity fields from the filtered latent space, we employ Gaussian Process regression. This strategy has been tested on a Kolmogorov flow exhibiting chaotic behavior similar to real-world turbulence.red latent space, we employ Gaussian Process regression. This strategy has been tested on a Kolmogorov flow exhibiting chaotic behavior similar to real-world turbulence.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/87dc5a77eb7202d0c553c6ca10f76f3203bb97ff" target='_blank'>
              Leveraging Scale Separation and Stochastic Closure for Data-Driven Prediction of Chaotic Dynamics
              </a>
            </td>
          <td>
            Ismaël Zighed, Nicolas Thome, Patrick Gallinari, T. Sayadi
          </td>
          <td>2025-10-28</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>13</td>
        </tr>

        <tr id="We study the robustness of system estimation to parametric perturbations in system dynamics and initial conditions. We define the problem of sensitivity-based parametric uncertainty quantification in dynamical system estimation. The main contribution of this paper is the development of a novel robustness metric for estimation of parametrized linear dynamical systems with and without control actions. For the computation of this metric, we delineate the uncertainty contributions arising from control actions, system dynamics, and initial conditions. Furthermore, to validate our theoretical findings, we establish connections between these new results and the existing literature on the robustness of model reduction. This work provides guidance for selecting estimation methods based on tolerable levels of parametric uncertainty and paves the way for new cost functions in data-driven estimation that reward sensitivity to a desired subset of parameters while penalizing others.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/dd9dd3cdb56f5782439ecd40f452be236fe3b046" target='_blank'>
              Parameter Robustness in Data-Driven Estimation of Dynamical Systems
              </a>
            </td>
          <td>
            Ayush Pandey
          </td>
          <td>2025-09-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Hamiltonian dynamics describe a wide range of physical systems. As such, data-driven simulations of Hamiltonian systems are important for many scientific and engineering problems. In this work, we propose kernel-based methods for identifying and forecasting Hamiltonian systems directly from data. We present two approaches: a two-step method that reconstructs trajectories before learning the Hamiltonian, and a one-step method that jointly infers both. Across several benchmark systems, including mass-spring dynamics, a nonlinear pendulum, and the Henon-Heiles system, we demonstrate that our framework achieves accurate, data-efficient predictions and outperforms two-step kernel-based baselines, particularly in scarce-data regimes, while preserving the conservation properties of Hamiltonian dynamics. Moreover, our methodology provides theoretical a priori error estimates, ensuring reliability of the learned models. We also provide a more general, problem-agnostic numerical framework that goes beyond Hamiltonian systems and can be used for data-driven learning of arbitrary dynamical systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f9c76a9c57ea8ba81f8f1e8b6d537d9c732da862" target='_blank'>
              Data-efficient Kernel Methods for Learning Hamiltonian Systems
              </a>
            </td>
          <td>
            Yasamin Jalalian, Mostafa Samir, Boumediene Hamzi, P. Tavallali, H. Owhadi
          </td>
          <td>2025-09-21</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>38</td>
        </tr>

        <tr id="Detecting regime shifts in chaotic time series is hard because observation-space signals are entangled with intrinsic variability. We propose Parameter--Space Changepoint Detection (Param--CPD), a two--stage framework that first amortizes Bayesian inference of governing parameters with a neural posterior estimator trained by simulation-based inference, and then applies a standard CPD algorithm to the resulting parameter trajectory. On Lorenz--63 with piecewise-constant parameters, Param--CPD improves F1, reduces localization error, and lowers false positives compared to observation--space baselines. We further verify identifiability and calibration of the inferred posteriors on stationary trajectories, explaining why parameter space offers a cleaner detection signal. Robustness analyses over tolerance, window length, and noise indicate consistent gains. Our results show that operating in a physically interpretable parameter space enables accurate and interpretable changepoint detection in nonlinear dynamical systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ed4c2a1818f3db6c44ec83d296971338b8dac901" target='_blank'>
              From Observations to Parameters: Detecting Changepoint in Nonlinear Dynamics with Simulation-based Inference
              </a>
            </td>
          <td>
            Xiangbo Deng, Cheng Chen, Peng Yang
          </td>
          <td>2025-10-20</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="Methods for solving scientific computing and inference problems, such as kernel- and neural network-based approaches for partial differential equations (PDEs), inverse problems, and supervised learning tasks, depend crucially on the choice of hyperparameters. Specifically, the efficacy of such methods, and in particular their accuracy, stability, and generalization properties, strongly depends on the choice of hyperparameters. While bilevel optimization offers a principled framework for hyperparameter tuning, its nested optimization structure can be computationally demanding, especially in PDE-constrained contexts. In this paper, we propose an efficient strategy for hyperparameter optimization within the bilevel framework by employing a Gauss-Newton linearization of the inner optimization step. Our approach provides closed-form updates, eliminating the need for repeated costly PDE solves. As a result, each iteration of the outer loop reduces to a single linearized PDE solve, followed by explicit gradient-based hyperparameter updates. We demonstrate the effectiveness of the proposed method through Gaussian process models applied to nonlinear PDEs and to PDE inverse problems. Extensive numerical experiments highlight substantial improvements in accuracy and robustness compared to conventional random hyperparameter initialization. In particular, experiments with additive kernels and neural network-parameterized deep kernels demonstrate the method's scalability and effectiveness for high-dimensional hyperparameter optimization.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/8f58ff304ffae376d725f4099f716945c9b691a6" target='_blank'>
              Bilevel optimization for learning hyperparameters: Application to solving PDEs and inverse problems with Gaussian processes
              </a>
            </td>
          <td>
            Nicholas H. Nelsen, H. Owhadi, Andrew M. Stuart, Xianjin Yang, Zongren Zou
          </td>
          <td>2025-10-07</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>38</td>
        </tr>

        <tr id="All inverse problems rely on data to recover unknown parameters, yet not all data are equally informative. This raises the central question of data selection. A distinctive challenge in PDE-based inverse problems is their inherently infinite-dimensional nature: both the parameter space and the design space are infinite, which greatly complicates the selection process. Somewhat unexpectedly, randomized numerical linear algebra (RNLA), originally developed in very different contexts, has provided powerful tools for addressing this challenge. These methods are inherently probabilistic, with guarantees typically stating that information is preserved with probability at least 1-p when using N randomly selected, weighted samples. Here, the notion of information can take different mathematical forms depending on the setting. In this review, we survey the problem of data selection in PDE-based inverse problems, emphasize its unique infinite-dimensional aspects, and highlight how RNLA strategies have been adapted and applied in this context.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/2a468332dbff2751092855a76556071bfb31b593" target='_blank'>
              Data selection: at the interface of PDE-based inverse problem and randomized linear algebra
              </a>
            </td>
          <td>
            Kathrin Hellmuth, Ruhui Jin, Qin Li, Stephen J. Wright
          </td>
          <td>2025-10-02</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="Partial differential equation (PDE)-constrained optimization arises in many scientific and engineering domains, such as energy systems, fluid dynamics and material design. In these problems, the decision variables (e.g., control inputs or design parameters) are tightly coupled with the PDE state variables, and the feasible set is implicitly defined by the governing PDE constraints. This coupling makes the problems computationally demanding, as it requires handling high dimensional discretization and dynamic constraints. To address these challenges, this paper introduces a learning-based framework that integrates a dynamic predictor with an optimization surrogate. The dynamic predictor, a novel time-discrete Neural Operator (Lu et al.), efficiently approximate system trajectories governed by PDE dynamics, while the optimization surrogate leverages proxy optimizer techniques (Kotary et al.) to approximate the associated optimal decisions. This dual-network design enables real-time approximation of optimal strategies while explicitly capturing the coupling between decisions and PDE dynamics. We validate the proposed approach on benchmark PDE-constrained optimization tasks inlacing Burgers'equation, heat equation and voltage regulation, and demonstrate that it achieves solution quality comparable to classical control-based algorithms, such as the Direct Method and Model Predictive Control (MPC), while providing up to four orders of magnitude improvement in computational speed.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/65428eba4cd892629345ed4999014b484c52b135" target='_blank'>
              Learning to Solve Optimization Problems Constrained with Partial Differential Equations
              </a>
            </td>
          <td>
            Yusuf Guven, Vincenzo Di Vito, Ferdinando Fioretto
          </td>
          <td>2025-09-29</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="We study the Evolutionary Deep Neural Network (EDNN) framework for accelerating numerical solvers of time-dependent partial differential equations (PDEs). We introduce a Low-Rank Evolutionary Deep Neural Network (LR-EDNN), which constrains parameter evolution to a low-rank subspace, thereby reducing the effective dimensionality of training while preserving solution accuracy. The low-rank tangent subspace is defined layer-wise by the singular value decomposition (SVD) of the current network weights, and the resulting update is obtained by solving a well-posed, tractable linear system within this subspace. This design augments the underlying numerical solver with a parameter efficient EDNN component without requiring full fine-tuning of all network weights. We evaluate LR-EDNN on representative PDE problems and compare it against corresponding baselines. Across cases, LR-EDNN achieves comparable accuracy with substantially fewer trainable parameters and reduced computational cost. These results indicate that low-rank constraints on parameter velocities, rather than full-space updates, provide a practical path toward scalable, efficient, and reproducible scientific machine learning for PDEs.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/09eccd74fbc13a68cda055129fb5ecf119649852" target='_blank'>
              Low-Rank Adaptation of Evolutionary Deep Neural Networks for Efficient Learning of Time-Dependent PDEs
              </a>
            </td>
          <td>
            Jiahao Zhang, Shiheng Zhang, Guang Lin
          </td>
          <td>2025-09-19</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>2</td>
        </tr>

        <tr id="We introduce a robust framework for learning various generalized Hamiltonian dynamics from noisy, sparse phase-space data and in an unsupervised manner based on variational Bayesian inference. Although conservative, dissipative, and port-Hamiltonian systems might share the same initial total energy of a closed system, it is challenging for a single Hamiltonian network model to capture the distinctive and varying motion dynamics and physics of a phase space, from sampled observational phase space trajectories. To address this complicated Hamiltonian manifold learning challenge, we extend sparse symplectic, random Fourier Gaussian processes learning with predictive successive numerical estimations of the Hamiltonian landscape, using a generalized form of state and conjugate momentum Hamiltonian dynamics, appropriate to different classes of conservative, dissipative and port-Hamiltonian physical systems. In addition to the kernelized evidence lower bound (ELBO) loss for data fidelity, we incorporate stability and conservation constraints as additional hyper-parameter balanced loss terms to regularize the model's multi-gradients, enforcing physics correctness for improved prediction accuracy with bounded uncertainty.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/ce56165d84af633e3af26c1b67766103a4438589" target='_blank'>
              Learning Generalized Hamiltonian Dynamics with Stability from Noisy Trajectory Data
              </a>
            </td>
          <td>
            Luke McLennan, Yi Wang, R. Farell, Minh Nguyen, Chandrajit Bajaj
          </td>
          <td>2025-09-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="Approximating solutions to partial differential equations (PDEs) is fundamental for the modeling of dynamical systems in science and engineering. Physics-informed neural networks (PINNs) are a recent machine learning-based approach, for which many properties and limitations remain unknown. PINNs are widely accepted as inferior to traditional methods for solving PDEs, such as the finite element method, both with regard to computation time and accuracy. However, PINNs are commonly claimed to show promise in solving inverse problems and handling noisy or incomplete data. We compare the performance of PINNs in solving inverse problems with that of a traditional approach using the finite element method combined with a numerical optimizer. The models are tested on a series of increasingly difficult fluid mechanics problems, with and without noise. We find that while PINNs may require less human effort and specialized knowledge, they are outperformed by the traditional approach. However, the difference appears to decrease with higher dimensions and more data. We identify common failures during training to be addressed if the performance of PINNs on noisy inverse problems is to become more competitive.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/24756474c0f33e6415bd9a16ffafe91f97f7332a" target='_blank'>
              Examining the robustness of Physics-Informed Neural Networks to noise for Inverse Problems
              </a>
            </td>
          <td>
            Aleksandra Jekic, Afroditi Natsaridou, Signe Riemer-Sørensen, Helge Langseth, Odd Erik Gundersen
          </td>
          <td>2025-09-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>17</td>
        </tr>

        <tr id="Inferring parameters of high-dimensional partial differential equations (PDEs) poses significant computational and inferential challenges, primarily due to the curse of dimensionality and the inherent limitations of traditional numerical methods. This paper introduces a novel two-stage Bayesian framework that synergistically integrates training, physics-based deep kernel learning (DKL) with Hamiltonian Monte Carlo (HMC) to robustly infer unknown PDE parameters and quantify their uncertainties from sparse, exact observations. The first stage leverages physics-based DKL to train a surrogate model, which jointly yields an optimized neural network feature extractor and robust initial estimates for the PDE parameters. In the second stage, with the neural network weights fixed, HMC is employed within a full Bayesian framework to efficiently sample the joint posterior distribution of the kernel hyperparameters and the PDE parameters. Numerical experiments on canonical and high-dimensional inverse PDE problems demonstrate that our framework accurately estimates parameters, provides reliable uncertainty estimates, and effectively addresses challenges of data sparsity and model complexity, offering a robust and scalable tool for diverse scientific and engineering applications.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/807e9848c8d60012a3c05e6542f8262289cf9cd5" target='_blank'>
              Physics-based deep kernel learning for parameter estimation in high dimensional PDEs
              </a>
            </td>
          <td>
            Weihao Yan, Christoph Brune, Mengwu Guo
          </td>
          <td>2025-09-17</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>1</td>
        </tr>

        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/f10ac03e7ca29fe9ff8df6722ead9a25d4006e9d" target='_blank'>
              A novel approach to quantify out-of-distribution uncertainty in Neural and Universal Differential Equations
              </a>
            </td>
          <td>
            Stefano Giampiccolo, Giovanni Iacca, Luca Marchetti
          </td>
          <td>2025-10-03</td>
          <td>bioRxiv</td>
          <td>0</td>
          <td>5</td>
        </tr>

        <tr id="Nonlinear oscillations are commonly observed in complex systems far from equilibrium, such as living organisms. These oscillations are essential for sustaining vital processes, like neuronal firing, circadian rhythms, and heartbeats. In such systems, thermodynamic dissipation is necessary to maintain oscillations against noise. However, due to their nonlinear dynamics, it has been challenging to determine how the characteristics of oscillations, such as frequency, amplitude, and coherent patterns across elements, influence dissipation. To resolve this issue, we employ Koopman mode decomposition, which recasts nonlinear dynamics as a linear evolution in a function space. This linearization allows the dynamics to be decomposed into temporal oscillatory modes coherent across elements, with the Koopman eigenvalues determining their frequencies. Using this method, we decompose thermodynamic dissipation caused by nonconservative forces into contributions from oscillatory modes in overdamped nonlinear Langevin dynamics. We show that the dissipation from each mode is proportional to its frequency squared and its intensity, providing an interpretable, mode-by-mode picture. In the noisy FitzHugh--Nagumo model, we demonstrate the effectiveness of this framework in quantifying the impact of oscillatory modes on dissipation during nonlinear phenomena like stochastic resonance and bifurcation. For instance, our analysis of stochastic resonance reveals that the greatest dissipation at the optimal noise intensity is supported by a broad spectrum of frequencies, whereas at non-optimal noise levels, dissipation is dominated by specific frequency modes. Our work offers a general approach to connecting oscillations to dissipation in noisy environments and improves our understanding of diverse oscillation phenomena from a nonequilibrium thermodynamic perspective.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5376cc6444c8b47cf61c00455ac72807eb0ee554" target='_blank'>
              Koopman Mode Decomposition of Thermodynamic Dissipation in Nonlinear Langevin Dynamics
              </a>
            </td>
          <td>
            Daiki Sekizawa, Sosuke Ito, Masafumi Oizumi
          </td>
          <td>2025-10-24</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>15</td>
        </tr>

        <tr id="Forecasting chaotic systems is a cornerstone challenge in many scientific fields, complicated by the exponential amplification of even infinitesimal prediction errors. Modern machine learning approaches often falter due to two opposing pitfalls: over-specializing on a single, well-known chaotic system (e.g., Lorenz-63), which limits generalizability, or indiscriminately mixing vast, unrelated time-series, which prevents the model from learning the nuances of any specific dynamical regime. We propose Curriculum Chaos Forecasting (CCF), a training paradigm that bridges this gap. CCF organizes training data based on fundamental principles of dynamical systems theory, creating a curriculum that progresses from simple, periodic behaviors to highly complex, chaotic dynamics. We quantify complexity using the largest Lyapunov exponent and attractor dimension, two well-established metrics of chaos. By first training a sequence model on predictable systems and gradually introducing more chaotic trajectories, CCF enables the model to build a robust and generalizable representation of dynamical behaviors. We curate a library of over 50 synthetic ODE/PDE systems to build this curriculum. Our experiments show that pre-training with CCF significantly enhances performance on unseen, real-world benchmarks. On datasets including Sunspot numbers, electricity demand, and human ECG signals, CCF extends the valid prediction horizon by up to 40% compared to random-order training and more than doubles it compared to training on real-world data alone. We demonstrate that this benefit is consistent across various neural architectures (GRU, Transformer) and provide extensive ablations to validate the importance of the curriculum's structure.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/87413033394131a9577d5a696a526d4c6e5912a1" target='_blank'>
              Learning to Predict Chaos: Curriculum-Driven Training for Robust Forecasting of Chaotic Dynamics
              </a>
            </td>
          <td>
            Harshil Vejendla
          </td>
          <td>2025-10-05</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Control problems frequently arise in scientific and industrial applications, where the objective is to steer a dynamical system from an initial state to a desired target state. Recent advances in deep learning and automatic differentiation have made applying these methods to control problems increasingly practical. In this paper, we examine the use of neural networks and modern machine-learning libraries to parameterize control inputs across discrete-time and continuous-time systems, as well as deterministic and stochastic dynamics. We highlight applications in multiple domains, including biology, engineering, physics, and medicine. For continuous-time dynamical systems, neural ordinary differential equations (neural ODEs) offer a useful approach to parameterizing control inputs. For discrete-time systems, we show how custom control-input parameterizations can be implemented and optimized using automatic-differentiation methods. Overall, the methods presented provide practical solutions for control tasks that are computationally demanding or analytically intractable, making them valuable for complex real-world applications.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9d310319f5443fe3dabe0f8f04ccd7120e876a8c" target='_blank'>
              Control of dynamical systems with neural networks
              </a>
            </td>
          <td>
            Lucas Bottcher
          </td>
          <td>2025-10-06</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>0</td>
        </tr>

        <tr id="Parameter calibration in complex dynamical systems often relies on costly optimization routines or ad hoc tuning to match statistical properties of observations. In this work, we develop a principled framework for statistical calibration grounded in the Generalized Fluctuation-Dissipation Theorem (GFDT). This approach provides exact linear response formulas that relate infinitesimal changes in internal model parameters to infinitesimal changes in statistics of arbitrary observables. In other words, the GFDT yields parameter Jacobians of system statistics without requiring adjoint models, ensemble perturbations, or repeated simulations. We demonstrate the framework's utility across a hierarchy of systems, including analytically tractable linear models, nonlinear double-well potentials, and multiscale stochastic models relevant to climate dynamics. We show that these Jacobians can be embedded within classical optimization schemes - such as Newton-type updates or regularized least squares - to guide parameter updates. The method is further extended to handle perturbations in both drift and diffusion terms, enabling unified treatment of deterministic and stochastic calibration. Our results establish the GFDT as a rigorous and interpretable foundation for parameter tuning in non-equilibrium systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5171465e66c8a4c488461fabdd1ac321fbc96759" target='_blank'>
              Statistical Parameter Calibration with the Generalized Fluctuation Dissipation Theorem and Generative Modeling
              </a>
            </td>
          <td>
            L. T. Giorgini, Tobias Bischoff, Andre N. Souza
          </td>
          <td>2025-09-24</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>7</td>
        </tr>

        <tr id="Scientific data, from cellular snapshots in biology to celestial distributions in cosmology, often consists of static patterns from underlying dynamical systems. These snapshots, while lacking temporal ordering, implicitly encode the processes that preserve them. This work investigates how strongly such a distribution constrains its underlying dynamics and how to recover them. We introduce the Equilibrium flow method, a framework that learns continuous dynamics that preserve a given pattern distribution. Our method successfully identifies plausible dynamics for 2-D systems and recovers the signature chaotic behavior of the Lorenz attractor. For high-dimensional Turing patterns from the Gray-Scott model, we develop an efficient, training-free variant that achieves high fidelity to the ground truth, validated both quantitatively and qualitatively. Our analysis reveals the solution space is constrained not only by the data but also by the learning model's inductive biases. This capability extends beyond recovering known systems, enabling a new paradigm of inverse design for Artificial Life. By specifying a target pattern distribution, we can discover the local interaction rules that preserve it, leading to the spontaneous emergence of complex behaviors, such as life-like flocking, attraction, and repulsion patterns, from simple, user-defined snapshots.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/afc392c6e59ae7fe4953e133f52fa87433768866" target='_blank'>
              Equilibrium flow: From Snapshots to Dynamics
              </a>
            </td>
          <td>
            Yanbo Zhang, Michael Levin
          </td>
          <td>2025-09-22</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>3</td>
        </tr>

        <tr id="The purpose of this article is to provide a perspective - admittedly, a rather subjective one - of recent developments at the interface of machine learning/data-driven methods and nonlinear wave studies. We review some recent pillars of the rapidly evolving landscape of scientific machine learning, including deep learning, data-driven equation discovery, and operator learning, among others. We then showcase these methods in applications ranging from learning lattice dynamical models and reduced order modeling of effective dynamics to discovery of conservation laws and potential identification of integrability of ODE and PDE models. Our intention is to make clear that these machine learning methods are complementary to the preexisting powerful tools of the nonlinear waves community, and should be integrated into this toolkit to augment and enable mathematical discoveries and computational capabilities in the age of data.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/72a159fe93817b08360816b17c8e249258c39e4a" target='_blank'>
              Machine Learning of Nonlinear Waves: Data-Driven Methods for Computer-Assisted Discovery of Equations, Symmetries, Conservation Laws, and Integrability
              </a>
            </td>
          <td>
            J. Adriazola, Panayotis Kevrekidis, V. Koukouloyannis, Wei Zhu
          </td>
          <td>2025-10-16</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>12</td>
        </tr>

        <tr id="Certain classes of CUR algorithms, also referred to as cross or pseudoskeleton algorithms, are widely used for low-rank matrix approximation when direct access to all matrix entries is costly. Their key advantage lies in constructing a rank-r approximation by sampling only r columns and r rows of the target matrix. This property makes them particularly attractive for reduced-order modeling of nonlinear matrix differential equations, where nonlinear operations on low-rank matrices can otherwise produce high-rank or even full-rank intermediates that must subsequently be truncated to rank $r$. CUR cross algorithms bypass the intermediate step and directly form the rank-$r$ matrix. However, standard cross algorithms may suffer from loss of accuracy in some settings, limiting their robustness and broad applicability. In this work, we propose a cross oversampling algorithm that augments the intersection with additional sampled columns and rows. We provide an error analysis demonstrating that the proposed oversampling improves robustness. We also present an algorithm that adaptively selects the number of oversampling entries based on efficiently computable indicators. We demonstrate the performance of the proposed CUR algorithm for time integration of several nonlinear stochastic PDEs on low-rank matrix manifolds.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/600a74c2e9835d9c98f8f43e37aed6347695f40c" target='_blank'>
              An Adaptive CUR Algorithm and its Application to Reduced-Order Modeling of Random PDEs
              </a>
            </td>
          <td>
            G. Palkar, H. Babaee
          </td>
          <td>2025-09-25</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>4</td>
        </tr>

        <tr id="Residual-based adaptive strategies are widely used in scientific machine learning but remain largely heuristic. We introduce a unifying variational framework that formalizes these methods by integrating convex transformations of the residual. Different transformations correspond to distinct objective functionals: exponential weights target the minimization of uniform error, while linear weights recover the minimization of quadratic error. Within this perspective, adaptive weighting is equivalent to selecting sampling distributions that optimize the primal objective, thereby linking discretization choices directly to error metrics. This principled approach yields three benefits: (1) it enables systematic design of adaptive schemes across norms, (2) reduces discretization error through variance reduction of the loss estimator, and (3) enhances learning dynamics by improving the gradient signal-to-noise ratio. Extending the framework to operator learning, we demonstrate substantial performance gains across optimizers and architectures. Our results provide a theoretical justification of residual-based adaptivity and establish a foundation for principled discretization and training strategies.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/1d46fb7a429ed69725b26aeb562574a64ff7c624" target='_blank'>
              A Variational Framework for Residual-Based Adaptivity in Neural PDE Solvers and Operator Learning
              </a>
            </td>
          <td>
            Juan Diego Toscano, Daniel T. Chen, Vivek Oommen, Jérôme Darbon, G. Karniadakis
          </td>
          <td>2025-09-17</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>9</td>
        </tr>

        <tr id="Learning stochastic models of dynamical systems underlying observed data is of interest in many scientific fields. Here we propose a novel method for this task, based on the framework of variational autoencoders for dynamical systems. The method estimates from the data both the system state trajectories and noise time series. This approach allows to perform multi-step system evolution and supports a teacher forcing strategy, alleviating limitations of autoencoder-based approaches for stochastic systems. We demonstrate the performance of the proposed approach on six test problems, covering simulated and experimental data. We further show the effects of the teacher forcing interval on the nature of the internal dynamics, and compare it to the deterministic models with equivalent architecture.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a383190e3d6a967121c6fa2cd862e7db196198a9" target='_blank'>
              Dynamical system reconstruction from partial observations using stochastic dynamics
              </a>
            </td>
          <td>
            Viktor Sip, Martin Breyton, S. Petkoski, V. Jirsa
          </td>
          <td>2025-10-01</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>21</td>
        </tr>

        <tr id="This paper presents a kernel-based framework for physics-informed nonlinear system identification. The key contribution is a structured methodology that extends kernel-based techniques to seamlessly embed partially known physics-based models, improving parameter estimation and overall model accuracy. The proposed method enhances traditional modeling approaches by embedding a parametric model, which provides physical interpretability, with a kernel-based function, which accounts for unmodeled dynamics. The two models'components are identified from the data simultaneously, thereby minimizing a suitable cost that balances the relative importance of the physical and the black-box parts of the model. Additionally, nonlinear state smoothing is employed to address scenarios involving state-space models with not fully measurable states. Numerical simulations on an experimental benchmark system demonstrate the effectiveness of the proposed approach, achieving up to 51% reduction in simulation root mean square error compared to physics-only models and 31% performance improvement over state-of-the-art identification techniques.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/aeec404b0f9f87c5702ac79084417c8494ffbff0" target='_blank'>
              A kernel-based approach to physics-informed nonlinear system identification
              </a>
            </td>
          <td>
            Cesare Donati, Martina Mammarella, G. Calafiore, F. Dabbene, C. Lagoa, C. Novara
          </td>
          <td>2025-09-09</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>40</td>
        </tr>

        <tr id="Physics-Informed Neural Networks (PINNs) have emerged as a powerful neural framework for solving partial differential equations (PDEs). However, standard MLP-based PINNs often fail to converge when dealing with complex initial-value problems, leading to solutions that violate causality and suffer from a spectral bias towards low-frequency components. To address these issues, we introduce NeuSA (Neuro-Spectral Architectures), a novel class of PINNs inspired by classical spectral methods, designed to solve linear and nonlinear PDEs with variable coefficients. NeuSA learns a projection of the underlying PDE onto a spectral basis, leading to a finite-dimensional representation of the dynamics which is then integrated with an adapted Neural ODE (NODE). This allows us to overcome spectral bias, by leveraging the high-frequency components enabled by the spectral representation; to enforce causality, by inheriting the causal structure of NODEs, and to start training near the target solution, by means of an initialization scheme based on classical methods. We validate NeuSA on canonical benchmarks for linear and nonlinear wave equations, demonstrating strong performance as compared to other architectures, with faster convergence, improved temporal consistency and superior predictive accuracy. Code and pretrained models will be released.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/068ca3dacfd12380ffa5790a9a9da48c3bdf3984" target='_blank'>
              Neuro-Spectral Architectures for Causal Physics-Informed Networks
              </a>
            </td>
          <td>
            Arthur Bizzi, Leonardo M. Moreira, M'arcio Marques, Leonardo Mendonça, Christian J'unior de Oliveira, Vitor Balestro, Lucas dos Santos Fernandez, Daniel Yukimura, Pavel Petrov, João M. Pereira, Tiago Novello, Lucas Nissenbaum
          </td>
          <td>2025-09-05</td>
          <td>ArXiv</td>
          <td>1</td>
          <td>8</td>
        </tr>

    </tbody>
    <tfoot>
      <tr>
          <th>Abstract</th>
          <th>Title</th>
          <th>Authors</th>
          <th>Publication Date</th>
          <th>Journal/Conference</th>
          <th>Citation count</th>
          <th>Highest h-index</th>
      </tr>
    </tfoot>
    </table>
    </p>
  </div>

</body>

<script>

  function create_author_list(author_list) {
    let td_author_element = document.getElementById();
    for (let i = 0; i < author_list.length; i++) {
          // tdElements[i].innerHTML = greet(tdElements[i].innerHTML);
          alert (author_list[i]);
      }
  }

  var trace1 = {
    x: ['2025'],
    y: [5],
    name: 'Num of citations',
    yaxis: 'y1',
    type: 'scatter'
  };

  var data = [trace1];

  var layout = {
    yaxis: {
      title: 'Num of citations',
      }
  };
  Plotly.newPlot('myDiv1', data, layout);
</script>
<script>
var dataTableOptions = {
        initComplete: function () {
        this.api()
            .columns()
            .every(function () {
                let column = this;

                // Create select element
                let select = document.createElement('select');
                select.add(new Option(''));
                column.footer().replaceChildren(select);

                // Apply listener for user change in value
                select.addEventListener('change', function () {
                    column
                        .search(select.value, {exact: true})
                        .draw();
                });

                // keep the width of the select element same as the column
                select.style.width = '100%';

                // Add list of options
                column
                    .data()
                    .unique()
                    .sort()
                    .each(function (d, j) {
                        select.add(new Option(d));
                    });
            });
    },
    scrollX: true,
    scrollCollapse: true,
    paging: true,
    fixedColumns: true,
    columnDefs: [
        {"className": "dt-center", "targets": "_all"},
        // set width for both columns 0 and 1 as 25%
        { width: '7%', targets: 0 },
        { width: '30%', targets: 1 },
        { width: '25%', targets: 2 },
        { width: '15%', targets: 4 }

      ],
    pageLength: 10,
    layout: {
        topStart: {
            buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
        }
    }
  }
  new DataTable('#table1', dataTableOptions);
  new DataTable('#table2', dataTableOptions);

  var table1 = $('#table1').DataTable();
  $('#table1 tbody').on('click', 'td:first-child', function () {
    var tr = $(this).closest('tr');
    var row = table1.row( tr );

    var rowId = tr.attr('id');
    // alert(rowId);

    if (row.child.isShown()) {
      // This row is already open - close it.
      row.child.hide();
      tr.removeClass('shown');
      tr.find('td:first-child').html('<i class="material-icons">visibility_off</i>');
    } else {
      // Open row.
      // row.child('foo').show();
      tr.find('td:first-child').html('<i class="material-icons">visibility</i>');
      var content = '<div class="child-row-content"><strong>Abstract:</strong> ' + rowId + '</div>';
      row.child(content).show();
      tr.addClass('shown');
    }
  });
  var table2 = $('#table2').DataTable();
  $('#table2 tbody').on('click', 'td:first-child', function () {
    var tr = $(this).closest('tr');
    var row = table2.row( tr );

    var rowId = tr.attr('id');
    // alert(rowId);

    if (row.child.isShown()) {
      // This row is already open - close it.
      row.child.hide();
      tr.removeClass('shown');
      tr.find('td:first-child').html('<i class="material-icons">visibility_off</i>');
    } else {
      // Open row.
      // row.child('foo').show();
      var content = '<div class="child-row-content"><strong>Abstract:</strong> ' + rowId + '</div>';
      row.child(content).show();
      tr.addClass('shown');
      tr.find('td:first-child').html('<i class="material-icons">visibility</i>');
    }
  });
</script>
<style>
  .child-row-content {
    text-align: justify;
    text-justify: inter-word;
    word-wrap: break-word; /* Ensure long words are broken */
    white-space: normal; /* Ensure text wraps to the next line */
    max-width: 100%; /* Ensure content does not exceed the table width */
    padding: 10px; /* Optional: add some padding for better readability */
    /* font size */
    font-size: small;
  }
</style>
</html>







  
  




  



                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.top", "navigation.tabs"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    

      <script src="../assets/javascripts/bundle.c8d2eff1.min.js"></script>
      
    
<script>
  // Execute intro.js when a button with id 'intro' is clicked
  function startIntro(){
      introJs().setOptions({
          tooltipClass: 'customTooltip'
      }).start();
  }
</script>
<script>
  

  // new DataTable('#table1', {
  //   order: [[5, 'desc']],
  //   "columnDefs": [
  //       {"className": "dt-center", "targets": "_all"},
  //       { width: '30%', targets: 0 }
  //     ],
  //   pageLength: 10,
  //   layout: {
  //       topStart: {
  //           buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
  //       }
  //   }
  // });

  // new DataTable('#table2', {
  //   order: [[3, 'desc']],
  //   "columnDefs": [
  //       {"className": "dt-center", "targets": "_all"},
  //       { width: '30%', targets: 0 }
  //     ],
  //   pageLength: 10,
  //   layout: {
  //       topStart: {
  //           buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
  //       }
  //   }
  // });
  new DataTable('#table3', {
    initComplete: function () {
        this.api()
            .columns()
            .every(function () {
                let column = this;
 
                // Create select element
                let select = document.createElement('select');
                select.add(new Option(''));
                column.footer().replaceChildren(select);
 
                // Apply listener for user change in value
                select.addEventListener('change', function () {
                    column
                        .search(select.value, {exact: true})
                        .draw();
                });

                // keep the width of the select element same as the column
                select.style.width = '100%';
 
                // Add list of options
                column
                    .data()
                    .unique()
                    .sort()
                    .each(function (d, j) {
                        select.add(new Option(d));
                    });
            });
    },
    // order: [[3, 'desc']],
    "columnDefs": [
        {"className": "dt-center", "targets": "_all"},
        { width: '30%', targets: 0 }
      ],
    pageLength: 10,
    layout: {
        topStart: {
            buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
        }
    }
  });
  new DataTable('#table4', {
    initComplete: function () {
        this.api()
            .columns()
            .every(function () {
                let column = this;
 
                // Create select element
                let select = document.createElement('select');
                select.add(new Option(''));
                column.footer().replaceChildren(select);
 
                // Apply listener for user change in value
                select.addEventListener('change', function () {
                    column
                        .search(select.value, {exact: true})
                        .draw();
                });

                // keep the width of the select element same as the column
                select.style.width = '100%';
 
                // Add list of options
                column
                    .data()
                    .unique()
                    .sort()
                    .each(function (d, j) {
                        select.add(new Option(d));
                    });
            });
    },
    // order: [[3, 'desc']],
    "columnDefs": [
        {"className": "dt-center", "targets": "_all"},
        { width: '30%', targets: 0 }
      ],
    pageLength: 10,
    layout: {
        topStart: {
            buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
        }
    }
  });
</script>


  </body>
</html>