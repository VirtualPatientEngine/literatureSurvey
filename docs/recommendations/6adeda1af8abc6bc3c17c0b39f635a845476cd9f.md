---
hide:
 - navigation
---
<!DOCTYPE html>
#
<html lang="en">
<head>
  <meta charset="utf-8">
</head>

<body>
  <p>
  <i class="footer">This page was last updated on 2024-07-15 06:06:41 UTC</i>
  </p>
  
  <div class="note info" onclick="startIntro()">
    <p>
      <button type="button" class="buttons">
        <div style="display: flex; align-items: center;">
        Click here for a quick intro of the page! <i class="material-icons">help</i>
        </div>
      </button>
    </p>
  </div>

  <p>
  <h3 data-intro='Recommendations for the article'>
    Recommendations for the article <i>Deep learning for universal linear embeddings of nonlinear dynamics</i>
  </h3>
  <table id="table1" class="display wrap" style="width:100%">
  <thead>
    <tr>
        <th data-intro='Click to view the abstract (if available)'>Abstract</th>
        <th>Title</th>
        <th>Authors</th>
        <th>Publication Date</th>
        <th>Journal/ Conference</th>
        <th>Citation count</th>
        <th data-intro='Highest h-index among the authors'>Highest h-index</th>
    </tr>
  </thead>
  <tbody>
    
        <tr id="Over the last few years, several works have proposed deep learning architectures to learn dynamical systems from observation data with no or little knowledge of the underlying physics. A line of work relies on learning representations where the dynamics of the underlying phenomenon can be described by a linear operator, based on the Koopman operator theory. However, despite being able to provide reliable long-term predictions for some dynamical systems in ideal situations, the methods proposed so far have limitations, such as requiring to discretize intrinsically continuous dynamical systems, leading to data loss, especially when handling incomplete or sparsely sampled data. Here, we propose a new deep Koopman framework that represents dynamics in an intrinsically continuous way, leading to better performance on limited training data, as exemplified on several datasets arising from dynamical systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/5605d94c26994720fa032f1e9ff32423d9dcf51d" target='_blank'>Leveraging Neural Koopman Operators to Learn Continuous Representations of Dynamical Systems from Scarce Data</a></td>
          <td>
            Anthony Frion, Lucas Drumetz, M. Mura, G. Tochon, Abdeldjalil Aissa El Bey
          </td>
          <td>2023-03-13</td>
          <td>ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</td>
          <td>4</td>
          <td>34</td>
        </tr>
    
        <tr id="The field of dynamical systems is being transformed by the mathematical tools and algorithms emerging from modern computing and data science. First-principles derivations and asymptotic reductions are giving way to data-driven approaches that formulate models in operator theoretic or probabilistic frameworks. Koopman spectral theory has emerged as a dominant perspective over the past decade, in which nonlinear dynamics are represented in terms of an infinite-dimensional linear operator acting on the space of all possible measurement functions of the system. This linear representation of nonlinear dynamics has tremendous potential to enable the prediction, estimation, and control of nonlinear systems with standard textbook methods developed for linear systems. However, obtaining finite-dimensional coordinate systems and embeddings in which the dynamics appear approximately linear remains a central open challenge. The success of Koopman analysis is due primarily to three key factors: 1) there exists rigorous theory connecting it to classical geometric approaches for dynamical systems, 2) the approach is formulated in terms of measurements, making it ideal for leveraging big-data and machine learning techniques, and 3) simple, yet powerful numerical algorithms, such as the dynamic mode decomposition (DMD), have been developed and extended to reduce Koopman theory to practice in real-world applications. In this review, we provide an overview of modern Koopman operator theory, describing recent theoretical and algorithmic developments and highlighting these methods with a diverse range of applications. We also discuss key advances and challenges in the rapidly growing field of machine learning that are likely to drive future developments and significantly transform the theoretical landscape of dynamical systems.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/68b6ca45a588d538b36335b23f6969c960cf2e6e" target='_blank'>Modern Koopman Theory for Dynamical Systems</a></td>
          <td>
            S. Brunton, M. Budišić, E. Kaiser, J. Kutz
          </td>
          <td>2021-02-24</td>
          <td>SIAM Rev.</td>
          <td>269</td>
          <td>63</td>
        </tr>
    
        <tr id="Discovering a suitable coordinate transformation for nonlinear systems enables the construction of simpler models, facilitating prediction, control, and optimization for complex nonlinear systems. To that end, Koopman operator theory offers a framework for global linearization for nonlinear systems, thereby allowing the usage of linear tools for design studies. In this work, we focus on the identification of global linearized embeddings for canonical nonlinear Hamiltonian systems through a symplectic transformation. While this task is often challenging, we leverage the power of deep learning to discover the desired embeddings. Furthermore, to overcome the shortcomings of Koopman operators for systems with continuous spectra, we apply the lifting principle and learn global cubicized embeddings. Additionally, a key emphasis is paid to enforce the bounded stability for the dynamics of the discovered embeddings. We demonstrate the capabilities of deep learning in acquiring compact symplectic coordinate transformation and the corresponding simple dynamical models, fostering data-driven learning of nonlinear canonical Hamiltonian systems, even those with continuous spectra.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/89d480a9bf884e736c0779a23e8e67f81c484b8e" target='_blank'>Deep Learning for Structure-Preserving Universal Stable Koopman-Inspired Embeddings for Nonlinear Canonical Hamiltonian Dynamics</a></td>
          <td>
            P. Goyal, Süleyman Yıldız, P. Benner
          </td>
          <td>2023-08-26</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>53</td>
        </tr>
    
        <tr id="Reduced order modelling relies on representing complex dynamical systems using simplified modes, which can be achieved through the Koopman operator(KO) analysis. However, computing Koopman eigenpairs for high-dimensional observable data can be inefficient. This paper proposes using deep autoencoders(AE), a type of deep learning technique, to perform nonlinear geometric transformations on raw data before computing Koopman eigenvectors. The encoded data produced by the deep AE is diffeomorphic to a manifold of the dynamical system and has a significantly lower dimension than the raw data. To handle high-dimensional time series data, Takens' time delay embedding is presented as a preprocessing technique. The paper concludes by presenting examples of these techniques in action.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/bb005a9027b08e1d2b513a9c23001bbc4c28c352" target='_blank'>Autoencoding for the 'Good Dictionary' of eigen pairs of the Koopman Operator</a></td>
          <td>
            Neranjaka Jayarathne, E. Bollt
          </td>
          <td>2023-06-08</td>
          <td>ArXiv</td>
          <td>0</td>
          <td>37</td>
        </tr>
    
        <tr id="None">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/000794cdc9985ec8e3008d8f4e61c56e1dc96820" target='_blank'>Deep learning for Koopman Operator Optimal Control.</a></td>
          <td>
            Mostafa Al‐Gabalawy
          </td>
          <td>2021-01-06</td>
          <td>ISA transactions</td>
          <td>13</td>
          <td>11</td>
        </tr>
    
        <tr id="The engineering design process often relies on mathematical modeling that can describe the underlying dynamic behavior. In this work, we present a data-driven methodology for modeling the dynamics of nonlinear systems. To simplify this task, we aim to identify a coordinate transformation that allows us to represent the dynamics of nonlinear systems using a common, simple model structure. The advantage of a common simple model is that customized design tools developed for it can be applied to study a large variety of nonlinear systems. The simplest common model -- one can think of -- is linear, but linear systems often fall short in accurately capturing the complex dynamics of nonlinear systems. In this work, we propose using quadratic systems as the common structure, inspired by the lifting principle. According to this principle, smooth nonlinear systems can be expressed as quadratic systems in suitable coordinates without approximation errors. However, finding these coordinates solely from data is challenging. Here, we leverage deep learning to identify such lifted coordinates using only data, enabling a quadratic dynamical system to describe the system's dynamics. Additionally, we discuss the asymptotic stability of these quadratic dynamical systems. We illustrate the approach using data collected from various numerical examples, demonstrating its superior performance with the existing well-known techniques.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/b7dc380fa94c29c88c415c89f8170c0d653e7ca5" target='_blank'>Generalized Quadratic-Embeddings for Nonlinear Dynamics using Deep Learning</a></td>
          <td>
            P. Goyal, P. Benner
          </td>
          <td>2022-11-01</td>
          <td>ArXiv</td>
          <td>6</td>
          <td>53</td>
        </tr>
    
        <tr id="This letter presents a Koopman lifting linearization method that is applicable to nonlinear dynamical systems having both stable and unstable regions. It is known that Dynamic Mode Decomposition (DMD) and its extended methods are often unable to model unstable systems accurately and reliably. Here we solve the problem through merging three methodologies: decomposition of a lifted linear system into stable and unstable modes, deep learning of a dictionary of observable functions in the separated subspaces, and a new formula for obtaining the Koopman operator, called Direct Encoding. Two sets of effective observable functions are obtained through neural net training where the training data are separated into stable and unstable trajectories. The resultant learned observables are used for lifting the state space, and a linear state transition matrix is constructed using Direct Encoding where inner products of the learned observables are computed. The proposed method shows a dramatic improvement over existing DMD and data-driven methods. Furthermore, a method is developed for determining the boundaries between stable and unstable regions.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/eba28c4d66f0e67ded357875e2d04a95a5adeb39" target='_blank'>Learned Lifted Linearization Applied to Unstable Dynamic Systems Enabled by Koopman Direct Encoding</a></td>
          <td>
            Jerry Ng, H. Asada
          </td>
          <td>2022-10-24</td>
          <td>IEEE Control Systems Letters</td>
          <td>1</td>
          <td>12</td>
        </tr>
    
        <tr id="The Koopman operator has recently garnered much attention for its value in dynamical systems analysis and data-driven model discovery. However, its application has been hindered by the computational complexity of extended dynamic mode decomposition; this requires a combinatorially large basis set to adequately describe many nonlinear systems of interest, e.g. cyber-physical infrastructure systems, biological networks, social systems, and fluid dynamics. Often the dictionaries generated for these problems are manually curated, requiring domain-specific knowledge and painstaking tuning. In this paper we introduce a computational framework for learning Koopman operators of nonlinear dynamical systems using deep learning. We show that this novel method automatically selects efficient deep dictionaries, requiring much lower dimensional dictionaries while outperforming state-of-the-art methods. We benchmark this method on partially observed nonlinear systems, including the glycolytic oscillator and show it is able to predict on test data quantitatively 100 steps into the future, using only a single timepoint as an initial condition, and quantitative oscillatory behavior 400 steps into the future.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/a02e0608b79a4b3670324839160073a8f49d77f9" target='_blank'>Learning Deep Neural Network Representations for Koopman Operators of Nonlinear Dynamical Systems</a></td>
          <td>
            Enoch Yeung, Soumya Kundu, Nathan Oken Hodas
          </td>
          <td>2017-08-22</td>
          <td>2019 American Control Conference (ACC)</td>
          <td>326</td>
          <td>17</td>
        </tr>
    
        <tr id="We present DLKoopman -- a software package for Koopman theory that uses deep learning to learn an encoding of a nonlinear dynamical system into a linear space, while simultaneously learning the linear dynamics. While several previous efforts have either restricted the ability to learn encodings, or been bespoke efforts designed for specific systems, DLKoopman is a generalized tool that can be applied to data-driven learning and optimization of any dynamical system. It can either be trained on data from individual states (snapshots) of a system and used to predict its unknown states, or trained on data from trajectories of a system and used to predict unknown trajectories for new initial states. DLKoopman is available on the Python Package Index (PyPI) as 'dlkoopman', and includes extensive documentation and tutorials. Additional contributions of the package include a novel metric called Average Normalized Absolute Error for evaluating performance, and a ready-to-use hyperparameter search module for improving performance.">
          <td id="tag"><i class="material-icons">visibility_off</i></td>
          <td><a href="https://www.semanticscholar.org/paper/9e4566a8c46f18398a26546ebc874d6f571c55a4" target='_blank'>DLKoopman: A deep learning software package for Koopman theory</a></td>
          <td>
            Sourya Dey, Eric K. Davis
          </td>
          <td>2022-11-15</td>
          <td>ArXiv, DBLP</td>
          <td>2</td>
          <td>6</td>
        </tr>
    
  </tbody>
  <tfoot>
    <tr>
        <th>Abstract</th>
        <th>Title</th>
        <th>Authors</th>
        <th>Publication Date</th>
        <th>Journal/Conference</th>
        <th>Citation count</th>
        <th>Highest h-index</th>
    </tr>
  </tfoot>
  </table>
  </p>

</body>

<script>
var dataTableOptions = {
        initComplete: function () {
        this.api()
            .columns()
            .every(function () {
                let column = this;
 
                // Create select element
                let select = document.createElement('select');
                select.add(new Option(''));
                column.footer().replaceChildren(select);
 
                // Apply listener for user change in value
                select.addEventListener('change', function () {
                    column
                        .search(select.value, {exact: true})
                        .draw();
                });

                // keep the width of the select element same as the column
                select.style.width = '100%';
 
                // Add list of options
                column
                    .data()
                    .unique()
                    .sort()
                    .each(function (d, j) {
                        select.add(new Option(d));
                    });
            });
    },
    scrollX: false,
    scrollCollapse: true,
    paging: true,
    fixedColumns: true,
    columnDefs: [
        {"className": "dt-center", "targets": "_all"},
        // set width for both columns 0 and 1 as 25%
        { width: '5%', targets: 0 },
        { width: '25%', targets: 1 },
        { width: '20%', targets: 2 },
        { width: '10%', targets: 3 },
        { width: '20%', targets: 4 }

      ],
    pageLength: 10,
    layout: {
        topStart: {
            buttons: ['copy', 'csv', 'excel', 'pdf', 'print']
        }
    }
  }
  new DataTable('#table1', dataTableOptions);
  
  var table = $('#table1').DataTable();
  $('#table1 tbody').on('click', 'td:first-child', function () {
    var tr = $(this).closest('tr');
    var row = table.row( tr );

    var rowId = tr.attr('id');
    // alert(rowId);

    if (row.child.isShown()) {
      // This row is already open - close it.
      row.child.hide();
      tr.removeClass('shown');
      tr.find('td:first-child').html('<i class="material-icons">visibility_off</i>');
    } else {
      // Open row.
      // row.child('foo').show();
      var content = '<div class="child-row-content"><strong>Abstract:</strong> ' + rowId + '</div>';
      row.child(content).show();
      tr.addClass('shown');
      tr.find('td:first-child').html('<i class="material-icons">visibility</i>');
    }
  });
</script>
<style>
  .child-row-content {
    text-align: justify;
    text-justify: inter-word;
    word-wrap: break-word; /* Ensure long words are broken */
    white-space: normal; /* Ensure text wraps to the next line */
    max-width: 100%; /* Ensure content does not exceed the table width */
    padding: 10px; /* Optional: add some padding for better readability */
    /* font size */
    font-size: small;
  }
</style>
</html>